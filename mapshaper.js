(function () {

  var utils = /*#__PURE__*/Object.freeze({
    __proto__: null,
    get default () { return utils; },
    get getUniqueName () { return getUniqueName; },
    get isFunction () { return isFunction; },
    get isPromise () { return isPromise; },
    get isObject () { return isObject; },
    get clamp () { return clamp; },
    get isArray () { return isArray; },
    get isNumber () { return isNumber; },
    get isValidNumber () { return isValidNumber; },
    get isFiniteNumber () { return isFiniteNumber; },
    get isNonNegNumber () { return isNonNegNumber; },
    get isInteger () { return isInteger; },
    get isEven () { return isEven; },
    get isOdd () { return isOdd$1; },
    get isString () { return isString; },
    get isDate () { return isDate; },
    get isBoolean () { return isBoolean; },
    get formatDateISO () { return formatDateISO; },
    get toArray () { return toArray; },
    get isArrayLike () { return isArrayLike; },
    get addslashes () { return addslashes; },
    get regexEscape () { return regexEscape; },
    get htmlEscape () { return htmlEscape; },
    get defaults () { return defaults; },
    get extend () { return extend$1; },
    get inherit () { return inherit; },
    get promisify () { return promisify; },
    get reduceAsync () { return reduceAsync; },
    get merge () { return merge; },
    get difference () { return difference; },
    get intersection () { return intersection; },
    get indexOf () { return indexOf; },
    get contains () { return contains; },
    get some () { return some; },
    get every () { return every; },
    get find () { return find; },
    get range () { return range; },
    get repeat () { return repeat; },
    get sum () { return sum$1; },
    get getArrayBounds () { return getArrayBounds; },
    get uniq () { return uniq; },
    get pluck () { return pluck; },
    get countValues () { return countValues; },
    get indexOn () { return indexOn; },
    get groupBy () { return groupBy; },
    get arrayToIndex () { return arrayToIndex; },
    get forEach () { return forEach; },
    get forEachProperty () { return forEachProperty; },
    get initializeArray () { return initializeArray; },
    get replaceArray () { return replaceArray; },
    get repeatString () { return repeatString; },
    get splitLines () { return splitLines; },
    get pluralSuffix () { return pluralSuffix; },
    get endsWith () { return endsWith; },
    get lpad () { return lpad; },
    get rpad () { return rpad; },
    get trim () { return trim; },
    get ltrim () { return ltrim; },
    get rtrim () { return rtrim; },
    get addThousandsSep () { return addThousandsSep; },
    get numToStr () { return numToStr; },
    get formatNumber () { return formatNumber$1; },
    get formatIntlNumber () { return formatIntlNumber; },
    get formatNumberForDisplay () { return formatNumberForDisplay; },
    get shuffle () { return shuffle; },
    get sortOn () { return sortOn; },
    get genericSort () { return genericSort; },
    get getSortedIds () { return getSortedIds; },
    get sortArrayIndex () { return sortArrayIndex; },
    get reorderArray () { return reorderArray; },
    get getKeyComparator () { return getKeyComparator; },
    get getGenericComparator () { return getGenericComparator; },
    get quicksort () { return quicksort$1; },
    get quicksortPartition () { return quicksortPartition; },
    get findRankByValue () { return findRankByValue; },
    get findValueByPct () { return findValueByPct; },
    get findValueByRank () { return findValueByRank; },
    get findMedian () { return findMedian; },
    get findQuantile () { return findQuantile; },
    get mean () { return mean; },
    get format () { return format; },
    get formatter () { return formatter; },
    get wildcardToRegExp () { return wildcardToRegExp; },
    get createBuffer () { return createBuffer; },
    get toBuffer () { return toBuffer; },
    get expandoBuffer () { return expandoBuffer; },
    get copyElements () { return copyElements; },
    get extendBuffer () { return extendBuffer; },
    get mergeNames () { return mergeNames; },
    get findStringPrefix () { return findStringPrefix; },
    get parsePercent () { return parsePercent; },
    get formatVersionedName () { return formatVersionedName; },
    get uniqifyNames () { return uniqifyNames; },
    get parseString () { return parseString; },
    get parseNumber () { return parseNumber; },
    get parseIntlNumber () { return parseIntlNumber; },
    get cleanNumericString () { return cleanNumericString; },
    get trimQuotes () { return trimQuotes; }
  });

  // This module provides a way for multiple jobs to run together asynchronously
  // while keeping job-level context variables (like "defs") separate.

  var stash = {};

  function stashVar(key, val) {
    if (key in stash) {
      error('Tried to replace a stashed variable:', key);
    }
    stash[key] = val;
  }

  function getStashedVar(key) {
    if (key in stash === false) {
      return undefined; // to support running commands in tests
      // error('Tried to read a nonexistent variable from the stash:', key);
    }
    return stash[key];
  }

  function clearStash() {
    stash = {};
  }

  var Stash = /*#__PURE__*/Object.freeze({
    __proto__: null,
    stashVar: stashVar,
    getStashedVar: getStashedVar,
    clearStash: clearStash
  });

  // Fall back to browserify's Buffer polyfill
  var B$3 = typeof Buffer != 'undefined' ? Buffer : require('buffer').Buffer;

  var uniqCount = 0;
  function getUniqueName(prefix) {
    return (prefix || "__id_") + (++uniqCount);
  }

  function isFunction(obj) {
    return typeof obj == 'function';
  }

  function isPromise(arg) {
    return arg ? isFunction(arg.then) : false;
  }

  function isObject(obj) {
    return obj === Object(obj); // via underscore
  }

  function clamp(val, min, max) {
    return val < min ? min : (val > max ? max : val);
  }

  function isArray(obj) {
    return Array.isArray(obj);
  }

  // Is obj a valid number or NaN? (test if obj is type number)
  function isNumber(obj) {
    return obj != null && obj.constructor == Number;
  }

  function isValidNumber(val) {
    return isNumber(val) && !isNaN(val);
  }

  // Similar to isFinite() but does not coerce strings or other types
  function isFiniteNumber(val) {
    return isValidNumber(val) && val !== Infinity && val !== -Infinity;
  }

  // This uses type conversion
  // export function isFiniteNumber(val) {
  //   return val > -Infinity && val < Infinity;
  // }

  function isNonNegNumber(val) {
    return isNumber(val) && val >= 0;
  }

  function isInteger(obj) {
    return isNumber(obj) && ((obj | 0) === obj);
  }

  function isEven(obj) {
    return (obj % 2) === 0;
  }

  function isOdd$1(obj) {
    return (obj % 2) === 1;
  }

  function isString(obj) {
    return obj != null && obj.toString === String.prototype.toString;
    // TODO: replace w/ something better.
  }

  function isDate(obj) {
    return !!obj && obj.getTime === Date.prototype.getTime;
  }

  function isBoolean(obj) {
    return obj === true || obj === false;
  }

  function formatDateISO(d) {
    if (!isDate(d)) return '';
    return d.toISOString().replace(':00.000Z', 'Z');
  }

  // Convert an array-like object to an Array, or make a copy if @obj is an Array
  function toArray(obj) {
    var arr;
    if (!isArrayLike(obj)) error("toArray() requires an array-like object");
    try {
      arr = Array.prototype.slice.call(obj, 0); // breaks in ie8
    } catch(e) {
      // support ie8
      arr = [];
      for (var i=0, n=obj.length; i<n; i++) {
        arr[i] = obj[i];
      }
    }
    return arr;
  }

  // Array like: has length property, is numerically indexed and mutable.
  // TODO: try to detect objects with length property but no indexed data elements
  function isArrayLike(obj) {
    if (!obj) return false;
    if (isArray(obj)) return true;
    if (isString(obj)) return false;
    if (obj.length === 0 || obj.length > 0) return true;
    return false;
  }

  // See https://raw.github.com/kvz/phpjs/master/functions/strings/addslashes.js
  function addslashes(str) {
    return (str + '').replace(/[\\"']/g, '\\$&').replace(/\u0000/g, '\\0');
  }

  // Escape a literal string to use in a regexp.
  // Ref.: http://simonwillison.net/2006/Jan/20/escape/
  function regexEscape(str) {
    return str.replace(/[-[\]{}()*+?.,\\^$|#\s]/g, '\\$&');
  }


  // See https://github.com/janl/mustache.js/blob/master/mustache.js
  var entityMap = {
    '&': '&amp;',
    '<': '&lt;',
    '>': '&gt;',
    '"': '&quot;',
    "'": '&#39;',
    '/': '&#x2F;'
  };
  function htmlEscape(s) {
    return String(s).replace(/[&<>"'/]/g, function(s) {
      return entityMap[s];
    });
  }


  function defaults(dest) {
    for (var i=1, n=arguments.length; i<n; i++) {
      var src = arguments[i] || {};
      for (var key in src) {
        if (key in dest === false && src.hasOwnProperty(key)) {
          dest[key] = src[key];
        }
      }
    }
    return dest;
  }

  function extend$1(o) {
    var dest = o || {},
        n = arguments.length,
        key, i, src;
    for (i=1; i<n; i++) {
      src = arguments[i] || {};
      for (key in src) {
        if (src.hasOwnProperty(key)) {
          dest[key] = src[key];
        }
      }
    }
    return dest;
  }

  // Pseudoclassical inheritance
  //
  // Inherit from a Parent function:
  //    inherit(Child, Parent);
  // Call parent's constructor (inside child constructor):
  //    this.__super__([args...]);
  function inherit(targ, src) {
    var f = function() {
      if (this.__super__ == f) {
        // add __super__ of parent to front of lookup chain
        // so parent class constructor can call its parent using this.__super__
        this.__super__ = src.prototype.__super__;
        // call parent constructor function. this.__super__ now points to parent-of-parent
        src.apply(this, arguments);
        // remove temp __super__, expose targ.prototype.__super__ again
        delete this.__super__;
      }
    };

    f.prototype = src.prototype || src; // added || src to allow inheriting from objects as well as functions
    // Extend targ prototype instead of wiping it out --
    //   in case inherit() is called after targ.prototype = {stuff}; statement
    targ.prototype = extend$1(new f(), targ.prototype); //
    targ.prototype.constructor = targ;
    targ.prototype.__super__ = f;
  }

  function promisify(asyncFn) {
    return function() {
      var args = toArray(arguments);
      return new Promise((resolve, reject) => {
        var cb = function(err, data) {
          if (err) reject(err);
          else resolve(data);
        };
        args.push(cb);
        asyncFn.apply(this, args);
      });
    };
  }

  // Call @iter on each member of an array (similar to Array#reduce(iter))
  //    iter: function(memo, item, callback)
  // Call @done when all members have been processed or if an error occurs
  //    done: function(err, memo)
  // @memo: Initial value
  //
  function reduceAsync(arr, memo, iter, done) {
    var call = typeof setImmediate == 'undefined' ? setTimeout : setImmediate;
    var i=0;
    next(null, memo);

    function next(err, memo) {
      // Detach next operation from call stack to prevent overflow
      // Don't use setTimeout(, 0) if setImmediate is available
      // (setTimeout() can introduce a long delay if previous operation was slow,
      //    as of Node 0.10.32 -- a bug?)
      if (err) {
        return done(err, null);
      }
      call(function() {
        if (i < arr.length === false) {
          done(null, memo);
        } else {
          iter(memo, arr[i++], next);
        }
      }, 0);
    }
  }


  // Append elements of @src array to @dest array
  function merge(dest, src) {
    if (!isArray(dest) || !isArray(src)) {
      error("Usage: merge(destArray, srcArray);");
    }
    for (var i=0, n=src.length; i<n; i++) {
      dest.push(src[i]);
    }
    return dest;
  }

  // Returns elements in arr and not in other
  // (similar to underscore diff)
  function difference(arr, other) {
    var index = arrayToIndex(other);
    return arr.filter(function(el) {
      return !Object.prototype.hasOwnProperty.call(index, el);
    });
  }

  // Return the intersection of two arrays
  function intersection(a, b) {
    return a.filter(function(el) {
      return b.includes(el);
    });
  }

  function indexOf(arr, item) {
    var nan = item !== item;
    for (var i = 0, len = arr.length || 0; i < len; i++) {
      if (arr[i] === item) return i;
      if (nan && arr[i] !== arr[i]) return i;
    }
    return -1;
  }

  // Test a string or array-like object for existence of substring or element
  function contains(container, item) {
    if (isString(container)) {
      return container.indexOf(item) != -1;
    }
    else if (isArrayLike(container)) {
      return indexOf(container, item) != -1;
    }
    error("Expected Array or String argument");
  }

  function some(arr, test) {
    return arr.reduce(function(val, item) {
      return val || test(item); // TODO: short-circuit?
    }, false);
  }

  function every(arr, test) {
    return arr.reduce(function(val, item) {
      return val && test(item);
    }, true);
  }

  function find(arr, test, ctx) {
    var matches = arr.filter(test, ctx);
    return matches.length === 0 ? null : matches[0];
  }

  function range(len, start, inc) {
    var arr = [],
        v = start === void 0 ? 0 : start,
        i = inc === void 0 ? 1 : inc;
    while(len--) {
      arr.push(v);
      v += i;
    }
    return arr;
  }

  function repeat(times, func) {
    var values = [],
        val;
    for (var i=0; i<times; i++) {
      val = func(i);
      if (val !== void 0) {
        values[i] = val;
      }
    }
    return values.length > 0 ? values : void 0;
  }

  // Calc sum, skip falsy and NaN values
  // Assumes: no other non-numeric objects in array
  //
  function sum$1(arr, info) {
    if (!isArrayLike(arr)) error ("sum() expects an array, received:", arr);
    var tot = 0,
        nan = 0,
        val;
    for (var i=0, n=arr.length; i<n; i++) {
      val = arr[i];
      if (val) {
        tot += val;
      } else if (isNaN(val)) {
        nan++;
      }
    }
    if (info) {
      info.nan = nan;
    }
    return tot;
  }

  // Calculate min and max values of an array, ignoring NaN values
  function getArrayBounds(arr) {
    var min = Infinity,
      max = -Infinity,
      nan = 0, val;
    for (var i=0, len=arr.length; i<len; i++) {
      val = arr[i];
      if (val !== val) nan++;
      if (val < min) min = val;
      if (val > max) max = val;
    }
    return {
      min: min,
      max: max,
      nan: nan
    };
  }

  // export function uniq(src) {
  //   var index = {};
  //   return src.reduce(function(memo, el) {
  //     if (el in index === false) {
  //       index[el] = true;
  //       memo.push(el);
  //     }
  //     return memo;
  //   }, []);
  // }

  function uniq(src) {
    var index = new Set();
    var arr = [];
    var item;
    for (var i=0, n=src.length; i<n; i++) {
      item = src[i];
      if (!index.has(item)) {
        arr.push(item);
        index.add(item);
      }
    }
    return arr;
  }

  function pluck(arr, key) {
    return arr.map(function(obj) {
      return obj[key];
    });
  }

  function countValues(arr) {
    return arr.reduce(function(memo, val) {
      memo[val] = (val in memo) ? memo[val] + 1 : 1;
      return memo;
    }, {});
  }

  function indexOn(arr, k) {
    return arr.reduce(function(index, o) {
      index[o[k]] = o;
      return index;
    }, {});
  }

  function groupBy(arr, k) {
    return arr.reduce(function(index, o) {
      var keyval = o[k];
      if (keyval in index) {
        index[keyval].push(o);
      } else {
        index[keyval] = [o];
      }
      return index;
    }, {});
  }

  function arrayToIndex(arr, val) {
    var init = arguments.length > 1;
    return arr.reduce(function(index, key) {
      index[key] = init ? val : true;
      return index;
    }, {});
  }

  // Support for iterating over array-like objects, like typed arrays
  function forEach(arr, func, ctx) {
    if (!isArrayLike(arr)) {
      throw new Error("#forEach() takes an array-like argument. " + arr);
    }
    for (var i=0, n=arr.length; i < n; i++) {
      func.call(ctx, arr[i], i);
    }
  }

  function forEachProperty(o, func, ctx) {
    Object.keys(o).forEach(function(key) {
      func.call(ctx, o[key], key);
    });
  }

  function initializeArray(arr, init) {
    for (var i=0, len=arr.length; i<len; i++) {
      arr[i] = init;
    }
    return arr;
  }

  function replaceArray(arr, arr2) {
    arr.splice(0, arr.length);
    for (var i=0, n=arr2.length; i<n; i++) {
      arr.push(arr2[i]);
    }
  }

  function repeatString(src, n) {
    var str = "";
    for (var i=0; i<n; i++)
      str += src;
    return str;
  }

  function splitLines(str) {
    return str.split(/\r?\n/);
  }

  function pluralSuffix(count) {
    return count != 1 ? 's' : '';
  }

  function endsWith(str, ending) {
      return str.indexOf(ending, str.length - ending.length) !== -1;
  }

  function lpad(str, size, pad) {
    pad = pad || ' ';
    str = String(str);
    return repeatString(pad, size - str.length) + str;
  }

  function rpad(str, size, pad) {
    pad = pad || ' ';
    str = String(str);
    return str + repeatString(pad, size - str.length);
  }

  function trim(str) {
    return ltrim(rtrim(str));
  }

  var ltrimRxp = /^\s+/;
  function ltrim(str) {
    return str.replace(ltrimRxp, '');
  }

  var rtrimRxp = /\s+$/;
  function rtrim(str) {
    return str.replace(rtrimRxp, '');
  }

  function addThousandsSep(str) {
    var fmt = '',
        start = str[0] == '-' ? 1 : 0,
        dec = str.indexOf('.'),
        end = str.length,
        ins = (dec == -1 ? end : dec) - 3;
    while (ins > start) {
      fmt = ',' + str.substring(ins, end) + fmt;
      end = ins;
      ins -= 3;
    }
    return str.substring(0, end) + fmt;
  }

  function numToStr(num, decimals) {
    return decimals >= 0 ? num.toFixed(decimals) : String(num);
  }

  function formatNumber$1(val) {
    return val + '';
  }

  function formatIntlNumber(val) {
    var str = formatNumber$1(val);
    return '"' + str.replace('.', ',') + '"'; // need to quote if comma-delimited
  }

  function formatNumberForDisplay(num, decimals, nullStr, showPos) {
    var fmt;
    if (isNaN(num)) {
      fmt = nullStr || '-';
    } else {
      fmt = numToStr(num, decimals);
      fmt = addThousandsSep(fmt);
      if (showPos && parseFloat(fmt) > 0) {
        fmt = "+" + fmt;
      }
    }
    return fmt;
  }

  function shuffle(arr) {
    var tmp, i, j;
    for (i = arr.length - 1; i > 0; i--) {
      j = Math.floor(Math.random() * (i + 1));
      tmp = arr[i];
      arr[i] = arr[j];
      arr[j] = tmp;
    }
  }

  // Sort an array of objects based on one or more properties.
  // Usage: sortOn(array, key1, asc?[, key2, asc? ...])
  //
  function sortOn(arr) {
    var comparators = [];
    for (var i=1; i<arguments.length; i+=2) {
      comparators.push(getKeyComparator(arguments[i], arguments[i+1]));
    }
    arr.sort(function(a, b) {
      var cmp = 0,
          i = 0,
          n = comparators.length;
      while (i < n && cmp === 0) {
        cmp = comparators[i](a, b);
        i++;
      }
      return cmp;
    });
    return arr;
  }

  // Sort array of values that can be compared with < > operators (strings, numbers)
  // null, undefined and NaN are sorted to the end of the array
  // default order is ascending
  //
  function genericSort(arr, ascending) {
    var compare = getGenericComparator(ascending);
    Array.prototype.sort.call(arr, compare);
    return arr;
  }

  function getSortedIds(arr, asc) {
    var ids = range(arr.length);
    sortArrayIndex(ids, arr, asc);
    return ids;
  }

  function sortArrayIndex(ids, arr, asc) {
    var compare = getGenericComparator(asc);
    ids.sort(function(i, j) {
      // added i, j comparison to guarantee that sort is stable
      var cmp = compare(arr[i], arr[j]);
      return cmp > 0 || cmp === 0 && i > j ? 1 : -1;
    });
  }

  function reorderArray(arr, idxs) {
    var len = idxs.length;
    var arr2 = [];
    for (var i=0; i<len; i++) {
      var idx = idxs[i];
      if (idx < 0 || idx >= len) error("Out-of-bounds array idx");
      arr2[i] = arr[idx];
    }
    replaceArray(arr, arr2);
  }

  function getKeyComparator(key, asc) {
    var compare = getGenericComparator(asc);
    return function(a, b) {
      return compare(a[key], b[key]);
    };
  }

  function getGenericComparator(asc) {
    asc = asc !== false && asc != 'descending'; // ascending is the default
    return function(a, b) {
      var retn = 0;
      if (b == null) {
        retn = a == null ? 0 : -1;
      } else if (a == null) {
        retn = 1;
      } else if (a < b) {
        retn = asc ? -1 : 1;
      } else if (a > b) {
        retn = asc ? 1 : -1;
      } else if (a !== a) {
        retn = 1;
      } else if (b !== b) {
        retn = -1;
      }
      return retn;
    };
  }


  // Generic in-place sort (null, NaN, undefined not handled)
  function quicksort$1(arr, asc) {
    quicksortPartition(arr, 0, arr.length-1);
    if (asc === false) Array.prototype.reverse.call(arr); // Works with typed arrays
    return arr;
  }

  // Moved out of quicksort() (saw >100% speedup in Chrome with deep recursion)
  function quicksortPartition (a, lo, hi) {
    var i = lo,
        j = hi,
        pivot, tmp;
    while (i < hi) {
      pivot = a[lo + hi >> 1]; // avoid n^2 performance on sorted arrays
      while (i <= j) {
        while (a[i] < pivot) i++;
        while (a[j] > pivot) j--;
        if (i <= j) {
          tmp = a[i];
          a[i] = a[j];
          a[j] = tmp;
          i++;
          j--;
        }
      }
      if (lo < j) quicksortPartition(a, lo, j);
      lo = i;
      j = hi;
    }
  }


  function findRankByValue(arr, value) {
    if (isNaN(value)) return arr.length;
    var rank = 1;
    for (var i=0, n=arr.length; i<n; i++) {
      if (value > arr[i]) rank++;
    }
    return rank;
  }

  function findValueByPct(arr, pct) {
    var rank = Math.ceil((1-pct) * (arr.length));
    return findValueByRank(arr, rank);
  }

  // See http://ndevilla.free.fr/median/median/src/wirth.c
  // Elements of @arr are reordered
  //
  function findValueByRank(arr, rank) {
    if (!arr.length || rank < 1 || rank > arr.length) error("[findValueByRank()] invalid input");

    rank = clamp(rank | 0, 1, arr.length);
    var k = rank - 1, // conv. rank to array index
        n = arr.length,
        l = 0,
        m = n - 1,
        i, j, val, tmp;

    while (l < m) {
      val = arr[k];
      i = l;
      j = m;
      do {
        while (arr[i] < val) {i++;}
        while (val < arr[j]) {j--;}
        if (i <= j) {
          tmp = arr[i];
          arr[i] = arr[j];
          arr[j] = tmp;
          i++;
          j--;
        }
      } while (i <= j);
      if (j < k) l = i;
      if (k < i) m = j;
    }
    return arr[k];
  }

  function findMedian(arr) {
    return findQuantile(arr, 0.5);
  }

  function findQuantile(arr, k) {
    var n = arr.length,
        i1 = Math.floor((n - 1) * k),
        i2 = Math.ceil((n - 1) * k);
    if (i1 < 0 || i2 >= n) return NaN;
    var v1 = findValueByRank(arr, i1 + 1);
    if (i1 == i2) return v1;
    var v2 = findValueByRank(arr, i2 + 1);
    // use linear interpolation
    var w1 = i2 / (n - 1) - k;
    var w2 = k - i1 / (n - 1);
    var v = (v1 * w1 + v2 * w2) * (n - 1);
    return v;
  }

  function mean(arr) {
    var count = 0,
        avg = NaN,
        val;
    for (var i=0, n=arr.length; i<n; i++) {
      val = arr[i];
      if (isNaN(val)) continue;
      avg = ++count == 1 ? val : val / count + (count - 1) / count * avg;
    }
    return avg;
  }


  /*
  A simplified version of printf formatting
  Format codes: %[flags][width][.precision]type

  supported flags:
    +   add '+' before positive numbers
    0   left-pad with '0'
    '   Add thousands separator
  width: 1 to many
  precision: .(1 to many)
  type:
    s     string
    di    integers
    f     decimal numbers
    xX    hexidecimal (unsigned)
    %     literal '%'

  Examples:
    code    val    formatted
    %+d     1      '+1'
    %4i     32     '  32'
    %04i    32     '0032'
    %x      255    'ff'
    %.2f    0.125  '0.13'
    %'f     1000   '1,000'
  */

  // Usage: format(formatString, [values])
  // Tip: When reusing the same format many times, use formatter() for 5x - 10x better performance
  //
  function format(fmt) {
    var fn = formatter(fmt);
    var str = fn.apply(null, Array.prototype.slice.call(arguments, 1));
    return str;
  }

  function formatValue(val, matches) {
    var flags = matches[1];
    var padding = matches[2];
    var decimals = matches[3] ? parseInt(matches[3].substr(1)) : void 0;
    var type = matches[4];
    var isString = type == 's',
        isHex = type == 'x' || type == 'X',
        // isInt = type == 'd' || type == 'i',
        // isFloat = type == 'f',
        isNumber = !isString;

    var sign = "",
        padDigits = 0,
        isZero = false,
        isNeg = false;

    var str, padChar, padStr;
    if (isString) {
      str = String(val);
    }
    else if (isHex) {
      str = val.toString(16);
      if (type == 'X')
        str = str.toUpperCase();
    }
    else if (isNumber) {
      // str = formatNumberForDisplay(val, isInt ? 0 : decimals);
      str = numToStr(val, decimals);
      if (str[0] == '-') {
        isNeg = true;
        str = str.substr(1);
      }
      isZero = parseFloat(str) == 0;
      if (flags.indexOf("'") != -1 || flags.indexOf(',') != -1) {
        str = addThousandsSep(str);
      }
      if (!isZero) { // BUG: sign is added when num rounds to 0
        if (isNeg) {
          sign = "\u2212"; // U+2212
        } else if (flags.indexOf('+') != -1) {
          sign = '+';
        }
      }
    }

    if (padding) {
      var strLen = str.length + sign.length;
      var minWidth = parseInt(padding, 10);
      if (strLen < minWidth) {
        padDigits = minWidth - strLen;
        padChar = flags.indexOf('0') == -1 ? ' ' : '0';
        padStr = repeatString(padChar, padDigits);
      }
    }

    if (padDigits == 0) {
      str = sign + str;
    } else if (padChar == '0') {
      str = sign + padStr + str;
    } else {
      str = padStr + sign + str;
    }
    return str;
  }

  // Get a function for interpolating formatted values into a string.
  function formatter(fmt) {
    var codeRxp = /%([',+0]*)([1-9]?)((?:\.[1-9])?)([sdifxX%])/g;
    var literals = [],
        formatCodes = [],
        startIdx = 0,
        prefix = "",
        matches = codeRxp.exec(fmt),
        literal;

    while (matches) {
      literal = fmt.substring(startIdx, codeRxp.lastIndex - matches[0].length);
      if (matches[0] == '%%') {
        prefix += literal + '%';
      } else {
        literals.push(prefix + literal);
        prefix = '';
        formatCodes.push(matches);
      }
      startIdx = codeRxp.lastIndex;
      matches = codeRxp.exec(fmt);
    }
    literals.push(prefix + fmt.substr(startIdx));

    return function() {
      var str = literals[0],
          n = arguments.length;
      if (n != formatCodes.length) {
        error("[format()] Data does not match format string; format:", fmt, "data:", arguments);
      }
      for (var i=0; i<n; i++) {
        str += formatValue(arguments[i], formatCodes[i]) + literals[i+1];
      }
      return str;
    };
  }

  function wildcardToRegExp(name) {
    var rxp = name.split('*').map(function(str) {
      return regexEscape(str);
    }).join('.*');
    return new RegExp('^' + rxp + '$');
  }

  function createBuffer(arg, arg2) {
    if (isInteger(arg)) {
      return B$3.allocUnsafe ? B$3.allocUnsafe(arg) : new B$3(arg);
    } else {
      // check allocUnsafe to make sure Buffer.from() will accept strings (it didn't before Node v5.10)
      return B$3.from && B$3.allocUnsafe ? B$3.from(arg, arg2) : new B$3(arg, arg2);
    }
  }

  function toBuffer(src) {
    if (src instanceof B$3) return src;
    if (src instanceof ArrayBuffer) return B$3.from(src);
    if (src instanceof Uint8Array) {
      return B$3.from(src.buffer, src.byteOffset, src.byteLength);
    }
    error('Unexpected argument type');
  }

  function expandoBuffer(constructor, rate) {
    var capacity = 0,
        k = rate >= 1 ? rate : 1.2,
        buf;
    return function(size) {
      if (size > capacity) {
        capacity = Math.ceil(size * k);
        buf = constructor ? new constructor(capacity) : createBuffer(capacity);
      }
      return buf;
    };
  }

  function copyElements(src, i, dest, j, n, rev) {
    var same = src == dest || src.buffer && src.buffer == dest.buffer;
    var inc = 1,
        offs = 0,
        k;
    if (rev) {
      if (same) error('copy error');
      inc = -1;
      offs = n - 1;
    }
    if (same && j > i) {
      for (k=n-1; k>=0; k--) {
        dest[j + k] = src[i + k];
      }
    } else {
      for (k=0; k<n; k++, offs += inc) {
        dest[k + j] = src[i + offs];
      }
    }
  }

  function extendBuffer(src, newLen, copyLen) {
    var len = Math.max(src.length, newLen);
    var n = copyLen || src.length;
    var dest = new src.constructor(len);
    copyElements(src, 0, dest, 0, n);
    return dest;
  }

  function mergeNames(name1, name2) {
    var merged;
    if (name1 && name2) {
      merged = findStringPrefix(name1, name2).replace(/[-_]$/, '');
    }
    return merged || '';
  }

  function findStringPrefix(a, b) {
    var i = 0;
    for (var n=a.length; i<n; i++) {
      if (a[i] !== b[i]) break;
    }
    return a.substr(0, i);
  }

  function parsePercent(o) {
    var str = String(o);
    var isPct = str.indexOf('%') > 0;
    var pct;
    if (isPct) {
      pct = Number(str.replace('%', '')) / 100;
    } else {
      pct = Number(str);
    }
    if (!(pct >= 0 && pct <= 1)) {
      stop(format("Invalid percentage: %s", str));
    }
    return pct;
  }

  function formatVersionedName(name, i) {
    var suffix = String(i);
    if (/[0-9]$/.test(name)) {
      suffix = '-' + suffix;
    }
    return name + suffix;
  }

  function uniqifyNames(names, formatter) {
    var counts = countValues(names),
        format = formatter || formatVersionedName,
        names2 = [];

    names.forEach(function(name) {
      var i = 0,
          candidate = name,
          versionedName;
      while (
          names2.indexOf(candidate) > -1 || // candidate name has already been used
          candidate == name && counts[candidate] > 1 || // duplicate unversioned names
          candidate != name && counts[candidate] > 0) { // versioned name is a preexisting name
        i++;
        versionedName = format(name, i);
        if (!versionedName || versionedName == candidate) {
          throw new Error("Naming error"); // catch buggy versioning function
        }
        candidate = versionedName;
      }
      names2.push(candidate);
    });
    return names2;
  }


  // Assume: @raw is string, undefined or null
  function parseString(raw) {
    return raw ? raw : "";
  }

  // Assume: @raw is string, undefined or null
  // Use null instead of NaN for unparsable values
  // (in part because if NaN is used, empty strings get converted to "NaN"
  // when re-exported).
  function parseNumber(raw) {
    return parseToNum(raw, cleanNumericString);
  }

  function parseIntlNumber(raw) {
    return parseToNum(raw, convertIntlNumString);
  }

  function parseToNum(raw, clean) {
    var str = String(raw).trim();
    var parsed = str ? Number(clean(str)) : NaN;
    return isNaN(parsed) ? null : parsed;
  }

  // Remove comma separators from strings
  function cleanNumericString(str) {
    return (str.indexOf(',') > 0) ? str.replace(/,([0-9]{3})/g, '$1') : str;
  }

  function convertIntlNumString(str) {
    str = str.replace(/[ .]([0-9]{3})/g, '$1');
    return str.replace(',', '.');
  }

  function trimQuotes(str) {
    var len = str.length, first, last;
    if (len >= 2) {
      first = str.charAt(0);
      last = str.charAt(len-1);
      if (first == '"' && last == '"' && !str.includes('","') ||
          first == "'" && last == "'" && !str.includes("','")) {
        str = str.substr(1, len-2);
        // remove string escapes
        str = str.replace(first == '"' ? /\\(?=")/g : /\\(?=')/g, '');
      }
    }
    return str;
  }

  var LOGGING = false;
  var STDOUT = false; // use stdout for status messages
  var _error, _stop, _message, _warn;

  var _interrupt = function() {
    throw new NonFatalError(formatLogArgs(arguments));
  };

  setLoggingForCLI();

  function getLoggingSetter() {
    var e = _error, s = _stop, m = _message, w = _warn;
    return function() {
      setLoggingFunctions(m, e, s, w);
    };
  }

  function setLoggingForCLI() {
    function stop() {
      throw new UserError(formatLogArgs(arguments));
    }

    function error() {
      var msg = utils.toArray(arguments).join(' ');
      throw new Error(msg);
    }

    function message() {
      logArgs(arguments);
    }

    // CLI warning is just a message (GUI behaves differently)
    var warn = message;

    setLoggingFunctions(message, error, stop, warn);
  }

  function enableLogging() {
    LOGGING = true;
  }

  function loggingEnabled() {
    return !!LOGGING;
  }

  // Handle an unexpected condition (internal error)
  function error() {
    _error.apply(null, utils.toArray(arguments));
  }

  // Handle an error caused by invalid input or misuse of API
  function stop() {
    // _stop.apply(null, utils.toArray(arguments));
    _stop.apply(null, messageArgs(arguments));
  }

  function interrupt() {
    _interrupt.apply(null, utils.toArray(arguments));
  }

  // Print a status message
  function message() {
    _message.apply(null, messageArgs(arguments));
  }

  function warn() {
    _warn.apply(null, messageArgs(arguments));
  }

  // A way for the GUI to replace the CLI logging functions
  function setLoggingFunctions(message, error, stop, warn) {
    _message = message;
    _error = error;
    _stop = stop;
    _warn = warn;
  }

  // get detailed error information from error stack (if available)
  // Example stack string (Node.js):
  /*
  /Users/someuser/somescript.js:226
      opacity: Math.round(weight * 5 / 5 // 0.2 0.4 0.6 etc
                                       ^

  SyntaxError: missing ) after argument list
      at internalCompileFunction (node:internal/vm:73:18)
      at wrapSafe (node:internal/modules/cjs/loader:1149:20)
      at Module._compile (node:internal/modules/cjs/loader:1190:27)
      ...
  */
  function getErrorDetail(e) {
    var parts = (typeof e.stack == 'string') ? e.stack.split(/\n\s*\n/) : [];
    if (parts.length > 1 || true) {
      return '\nError details:\n' + parts[0];
    }
    return '';
  }

  // print a message to stdout
  function print() {
    STDOUT = true; // tell logArgs() to print to stdout, not stderr
    // calling message() adds the "[command name]" prefix
    _message(utils.toArray(arguments));
    STDOUT = false;
  }

  function verbose() {
    // verbose can be set globally with the -verbose command or separately for each command
    if (getStashedVar('VERBOSE')) {
      message.apply(null, arguments);
    }
  }

  function debug() {
    if (getStashedVar('DEBUG')) {
      logArgs(arguments);
    }
  }

  function printError(err) {
    var msg;
    if (!LOGGING) return;
    if (utils.isString(err)) {
      err = new UserError(err);
    }
    if (err.name == 'NonFatalError') {
      console.error(messageArgs([err.message]).join(' '));
    } else if (err.name == 'UserError') {
      msg = err.message;
      if (!/Error/.test(msg)) {
        msg = "Error: " + msg;
      }
      console.error(messageArgs([msg]).join(' '));
      console.error("Run mapshaper -h to view help");
    } else {
      // not a user error (i.e. a bug in mapshaper)
      console.error(err);
      // throw err;
    }
  }

  function UserError(msg) {
    var err = new Error(msg);
    err.name = 'UserError';
    return err;
  }

  function NonFatalError(msg) {
    var err = new Error(msg);
    err.name = 'NonFatalError';
    return err;
  }

  function formatColumns(arr, alignments) {
    var widths = arr.reduce(function(memo, line) {
      return line.map(function(str, i) {
        return memo ? Math.max(memo[i], str.length) : str.length;
      });
    }, null);
    return arr.map(function(line) {
      line = line.map(function(str, i) {
        var rt = alignments && alignments[i] == 'right';
        var pad = (rt ? str.padStart : str.padEnd).bind(str);
        return pad(widths[i], ' ');
      });
      return '  ' + line.join(' ');
    }).join('\n');
  }

  // Format an array of (preferably short) strings in columns for console logging.
  function formatStringsAsGrid(arr, width) {
    // TODO: variable column width
    var longest = arr.reduce(function(len, str) {
          return Math.max(len, str.length);
        }, 0),
        colWidth = longest + 2,
        perLine = Math.floor((width || 80) / colWidth) || 1;
    return arr.reduce(function(memo, name, i) {
      var col = i % perLine;
      if (i > 0 && col === 0) memo += '\n';
      if (col < perLine - 1) { // right-pad all but rightmost column
        name = utils.rpad(name, colWidth - 2, ' ');
      }
      return memo +  '  ' + name;
    }, '');
  }

  // expose so GUI can use it
  function formatLogArgs(args) {
    return utils.toArray(args).join(' ');
  }

  function messageArgs(args) {
    var arr = utils.toArray(args);
    var cmd = getStashedVar('current_command');
    if (cmd && cmd != 'help') {
      arr.unshift('[' + cmd + ']');
    }
    return arr;
  }

  function logArgs(args) {
    if (!LOGGING || getStashedVar('QUIET') || !utils.isArrayLike(args)) return;
    var msg = formatLogArgs(args);
    if (STDOUT) console.log(msg);
    else console.error(msg);
  }

  function truncateString(str, maxLen) {
    maxLen = maxLen || 80;
    if (str.length > maxLen) {
      str = str.substring(0, maxLen - 3).trimEnd() + '...';
    }
    return str;
  }

  var Logging = /*#__PURE__*/Object.freeze({
    __proto__: null,
    getLoggingSetter: getLoggingSetter,
    setLoggingForCLI: setLoggingForCLI,
    enableLogging: enableLogging,
    loggingEnabled: loggingEnabled,
    error: error,
    stop: stop,
    interrupt: interrupt,
    message: message,
    warn: warn,
    setLoggingFunctions: setLoggingFunctions,
    getErrorDetail: getErrorDetail,
    print: print,
    verbose: verbose,
    debug: debug,
    printError: printError,
    UserError: UserError,
    NonFatalError: NonFatalError,
    formatColumns: formatColumns,
    formatStringsAsGrid: formatStringsAsGrid,
    formatLogArgs: formatLogArgs,
    logArgs: logArgs,
    truncateString: truncateString
  });

  function Transform() {
    this.mx = this.my = 1;
    this.bx = this.by = 0;
  }

  Transform.prototype.isNull = function() {
    return !this.mx || !this.my || isNaN(this.bx) || isNaN(this.by);
  };

  Transform.prototype.invert = function() {
    var inv = new Transform();
    inv.mx = 1 / this.mx;
    inv.my = 1 / this.my;
    //inv.bx = -this.bx * inv.mx;
    //inv.by = -this.by * inv.my;
    inv.bx = -this.bx / this.mx;
    inv.by = -this.by / this.my;
    return inv;
  };


  Transform.prototype.transform = function(x, y, xy) {
    xy = xy || [];
    xy[0] = x * this.mx + this.bx;
    xy[1] = y * this.my + this.by;
    return xy;
  };

  Transform.prototype.toString = function() {
    return JSON.stringify(Object.assign({}, this));
  };

  function Bounds() {
    if (arguments.length > 0) {
      this.setBounds.apply(this, arguments);
    }
  }

  Bounds.from = function() {
    var b = new Bounds();
    return b.setBounds.apply(b, arguments);
  };

  Bounds.prototype.toString = function() {
    return JSON.stringify({
      xmin: this.xmin,
      xmax: this.xmax,
      ymin: this.ymin,
      ymax: this.ymax
    });
  };

  Bounds.prototype.toArray = function() {
    return this.hasBounds() ? [this.xmin, this.ymin, this.xmax, this.ymax] : [];
  };

  Bounds.prototype.hasBounds = function() {
    return this.xmin <= this.xmax && this.ymin <= this.ymax;
  };

  Bounds.prototype.sameBounds =
  Bounds.prototype.equals = function(bb) {
    return bb && this.xmin === bb.xmin && this.xmax === bb.xmax &&
      this.ymin === bb.ymin && this.ymax === bb.ymax;
  };

  Bounds.prototype.width = function() {
    return (this.xmax - this.xmin) || 0;
  };

  Bounds.prototype.height = function() {
    return (this.ymax - this.ymin) || 0;
  };

  Bounds.prototype.area = function() {
    return this.width() * this.height() || 0;
  };

  Bounds.prototype.empty = function() {
    this.xmin = this.ymin = this.xmax = this.ymax = void 0;
    return this;
  };

  Bounds.prototype.setBounds = function(a, b, c, d) {
    if (arguments.length == 1) {
      // assume first arg is a Bounds or array
      if (utils.isArrayLike(a)) {
        b = a[1];
        c = a[2];
        d = a[3];
        a = a[0];
      } else {
        b = a.ymin;
        c = a.xmax;
        d = a.ymax;
        a = a.xmin;
      }
    }

    this.xmin = a;
    this.ymin = b;
    this.xmax = c;
    this.ymax = d;
    if (a > c || b > d) this.update();
    return this;
  };


  Bounds.prototype.centerX = function() {
    var x = (this.xmin + this.xmax) * 0.5;
    return x;
  };

  Bounds.prototype.centerY = function() {
    var y = (this.ymax + this.ymin) * 0.5;
    return y;
  };

  Bounds.prototype.containsPoint = function(x, y) {
    if (x >= this.xmin && x <= this.xmax &&
      y <= this.ymax && y >= this.ymin) {
      return true;
    }
    return false;
  };

  // intended to speed up slightly bubble symbol detection; could use intersects() instead
  // TODO: fix false positive where circle is just outside a corner of the box
  Bounds.prototype.containsBufferedPoint =
  Bounds.prototype.containsCircle = function(x, y, buf) {
    if ( x + buf > this.xmin && x - buf < this.xmax ) {
      if ( y - buf < this.ymax && y + buf > this.ymin ) {
        return true;
      }
    }
    return false;
  };

  Bounds.prototype.intersects = function(bb) {
    if (bb.xmin <= this.xmax && bb.xmax >= this.xmin &&
      bb.ymax >= this.ymin && bb.ymin <= this.ymax) {
      return true;
    }
    return false;
  };

  Bounds.prototype.contains = function(bb) {
    if (bb.xmin >= this.xmin && bb.ymax <= this.ymax &&
      bb.xmax <= this.xmax && bb.ymin >= this.ymin) {
      return true;
    }
    return false;
  };

  Bounds.prototype.shift = function(x, y) {
    this.setBounds(this.xmin + x,
      this.ymin + y, this.xmax + x, this.ymax + y);
  };

  Bounds.prototype.padBounds = function(a, b, c, d) {
    this.xmin -= a;
    this.ymin -= b;
    this.xmax += c;
    this.ymax += d;
  };

  // Rescale the bounding box by a fraction. TODO: implement focus.
  // @param {number} pct Fraction of original extents
  // @param {number} pctY Optional amount to scale Y
  //
  Bounds.prototype.scale = function(pct, pctY) { /*, focusX, focusY*/
    var halfWidth = (this.xmax - this.xmin) * 0.5;
    var halfHeight = (this.ymax - this.ymin) * 0.5;
    var kx = pct - 1;
    var ky = pctY === undefined ? kx : pctY - 1;
    this.xmin -= halfWidth * kx;
    this.ymin -= halfHeight * ky;
    this.xmax += halfWidth * kx;
    this.ymax += halfHeight * ky;
    return this;
  };

  // Return a bounding box with the same extent as this one.
  Bounds.prototype.cloneBounds = // alias so child classes can override clone()
  Bounds.prototype.clone = function() {
    return new Bounds(this.xmin, this.ymin, this.xmax, this.ymax);
  };

  Bounds.prototype.clearBounds = function() {
    this.setBounds(new Bounds());
  };

  Bounds.prototype.mergePoint = function(x, y) {
    if (this.xmin === void 0) {
      this.setBounds(x, y, x, y);
    } else {
      // this works even if x,y are NaN
      if (x < this.xmin)  this.xmin = x;
      else if (x > this.xmax)  this.xmax = x;

      if (y < this.ymin) this.ymin = y;
      else if (y > this.ymax) this.ymax = y;
    }
  };

  // expands either x or y dimension to match @aspect (width/height ratio)
  // @focusX, @focusY (optional): expansion focus, as a fraction of width and height
  Bounds.prototype.fillOut = function(aspect, focusX, focusY) {
    if (arguments.length < 3) {
      focusX = 0.5;
      focusY = 0.5;
    }
    var w = this.width(),
        h = this.height(),
        currAspect = w / h,
        pad;
    if (isNaN(aspect) || aspect <= 0) ; else if (currAspect < aspect) { // fill out x dimension
      pad = h * aspect - w;
      this.xmin -= (1 - focusX) * pad;
      this.xmax += focusX * pad;
    } else {
      pad = w / aspect - h;
      this.ymin -= (1 - focusY) * pad;
      this.ymax += focusY * pad;
    }
    return this;
  };

  Bounds.prototype.update = function() {
    var tmp;
    if (this.xmin > this.xmax) {
      tmp = this.xmin;
      this.xmin = this.xmax;
      this.xmax = tmp;
    }
    if (this.ymin > this.ymax) {
      tmp = this.ymin;
      this.ymin = this.ymax;
      this.ymax = tmp;
    }
  };

  Bounds.prototype.transform = function(t) {
    this.xmin = this.xmin * t.mx + t.bx;
    this.xmax = this.xmax * t.mx + t.bx;
    this.ymin = this.ymin * t.my + t.by;
    this.ymax = this.ymax * t.my + t.by;
    this.update();
    return this;
  };

  // Returns a Transform object for mapping this onto Bounds @b2
  // @flipY (optional) Flip y-axis coords, for converting to/from pixel coords
  //
  Bounds.prototype.getTransform = function(b2, flipY) {
    var t = new Transform();
    t.mx = b2.width() / this.width() || 1; // TODO: better handling of 0 w,h
    t.bx = b2.xmin - t.mx * this.xmin;
    if (flipY) {
      t.my = -b2.height() / this.height() || 1;
      t.by = b2.ymax - t.my * this.ymin;
    } else {
      t.my = b2.height() / this.height() || 1;
      t.by = b2.ymin - t.my * this.ymin;
    }
    return t;
  };

  Bounds.prototype.mergeCircle = function(x, y, r) {
    if (r < 0) r = -r;
    this.mergeBounds([x - r, y - r, x + r, y + r]);
  };

  Bounds.prototype.mergeBounds = function(bb) {
    var a, b, c, d;
    if (bb instanceof Bounds) {
      a = bb.xmin;
      b = bb.ymin;
      c = bb.xmax;
      d = bb.ymax;
    } else if (arguments.length == 4) {
      a = arguments[0];
      b = arguments[1];
      c = arguments[2];
      d = arguments[3];
    } else if (bb.length == 4) {
      // assume array: [xmin, ymin, xmax, ymax]
      a = bb[0];
      b = bb[1];
      c = bb[2];
      d = bb[3];
    } else {
      error("Bounds#mergeBounds() invalid argument:", bb);
    }

    if (this.xmin === void 0) {
      this.setBounds(a, b, c, d);
    } else {
      if (a < this.xmin) this.xmin = a;
      if (b < this.ymin) this.ymin = b;
      if (c > this.xmax) this.xmax = c;
      if (d > this.ymax) this.ymax = d;
    }
    return this;
  };

  function countPointsInLayer(lyr) {
    var count = 0;
    if (layerHasPoints(lyr)) {
      forEachPoint(lyr.shapes, function() {count++;});
    }
    return count;
  }

  function getPointBounds$1(shapes) {
    var bounds = new Bounds();
    forEachPoint(shapes, function(p) {
      bounds.mergePoint(p[0], p[1]);
    });
    return bounds;
  }

  function getPointFeatureBounds(shape, bounds) {
    var n = shape ? shape.length : 0;
    var p;
    if (!bounds) bounds = new Bounds();
    for (var i=0; i<n; i++) {
      p = shape[i];
      bounds.mergePoint(p[0], p[1]);
    }
    return bounds;
  }

  // NOTE: layers can have multipoint features and null features
  function getPointsInLayer(lyr) {
    var coords = [];
    forEachPoint(lyr.shapes, function(p) {
      coords.push(p);
    });
    return coords;
  }

  // Iterate over each [x,y] point in a layer
  // shapes: one layer's "shapes" array
  function forEachPoint(shapes, cb) {
    var i, n, j, m, shp;
    for (i=0, n=shapes.length; i<n; i++) {
      shp = shapes[i];
      for (j=0, m=shp ? shp.length : 0; j<m; j++) {
        cb(shp[j], i);
      }
    }
  }

  var PointUtils = /*#__PURE__*/Object.freeze({
    __proto__: null,
    countPointsInLayer: countPointsInLayer,
    getPointBounds: getPointBounds$1,
    getPointFeatureBounds: getPointFeatureBounds,
    getPointsInLayer: getPointsInLayer,
    forEachPoint: forEachPoint
  });

  function absArcId(arcId) {
    return arcId >= 0 ? arcId : ~arcId;
  }

  function calcArcBounds(xx, yy, start, len) {
    var i = start | 0,
        n = isNaN(len) ? xx.length - i : len + i,
        x, y, xmin, ymin, xmax, ymax;
    if (n > 0) {
      xmin = xmax = xx[i];
      ymin = ymax = yy[i];
    }
    for (i++; i<n; i++) {
      x = xx[i];
      y = yy[i];
      if (x < xmin) xmin = x;
      if (x > xmax) xmax = x;
      if (y < ymin) ymin = y;
      if (y > ymax) ymax = y;
    }
    return [xmin, ymin, xmax, ymax];
  }

  function getUnfilteredArcLength(arcId, arcs) {
    var data = arcs.getVertexData();
    return data.nn[arcId];
  }

  function getUnfilteredArcCoords(arcId, arcs) {
    var data = arcs.getVertexData();
    var coords = [];
    var start = data.ii[arcId];
    var n = data.nn[arcId];
    for (var i=0; i<n; i++) {
      coords.push([data.xx[start + i], data.yy[start + i]]);
    }
    return coords;
  }

  function findArcIdFromVertexId(i, ii) {
    // binary search
    // possible optimization: use interpolation to find a better partition value.
    var lower = 0, upper = ii.length - 1;
    var middle;
    while (lower < upper) {
      middle = Math.ceil((lower + upper) / 2);
      if (i < ii[middle]) {
        upper = middle - 1;
      } else {
        lower = middle;
      }
    }
    return lower; // assumes dataset is not empty
  }

  function deleteLastArc(arcs) {
    var data = arcs.getVertexData();
    var arcId = arcs.size() - 1;
    var arcLen = data.nn[arcId];
    var n = data.xx.length;
    var z = arcs.getRetainedInterval();
    var xx2 = new Float64Array(data.xx.buffer, 0, n-arcLen);
    var yy2 = new Float64Array(data.yy.buffer, 0, n-arcLen);
    var nn2 = new Int32Array(data.nn.buffer, 0, arcs.size() - 1);
    var zz2 = arcs.isFlat() ?
      null :
      new Float64Array(data.zz.buffer, 0, n-arcLen);
    arcs.updateVertexData(nn2, xx2, yy2, zz2);
    arcs.setRetainedInterval(z);
  }

  function deleteVertex(arcs, i) {
    var data = arcs.getVertexData();
    var nn = data.nn;
    var n = data.xx.length;
    // avoid re-allocating memory
    var xx2 = new Float64Array(data.xx.buffer, 0, n-1);
    var yy2 = new Float64Array(data.yy.buffer, 0, n-1);
    var zz2 = arcs.isFlat() ? null : new Float64Array(data.zz.buffer, 0, n-1);
    var z = arcs.getRetainedInterval();
    var count = 0;
    var found = false;
    for (var j=0; j<nn.length; j++) {
      count += nn[j];
      if (count >= i && !found) { // TODO: confirm this
        nn[j] = nn[j] - 1;
        found = true;
      }
    }
    utils.copyElements(data.xx, 0, xx2, 0, i);
    utils.copyElements(data.yy, 0, yy2, 0, i);
    utils.copyElements(data.xx, i+1, xx2, i, n-i-1);
    utils.copyElements(data.yy, i+1, yy2, i, n-i-1);
    if (zz2) {
      utils.copyElements(data.zz, 0, zz2, 0, i);
      utils.copyElements(data.zz, i+1, zz2, i, n-i-1);
    }
    arcs.updateVertexData(nn, xx2, yy2, zz2);
    arcs.setRetainedInterval(z);
  }

  function appendEmptyArc(arcs) {
    var data = arcs.getVertexData();
    var nn = utils.extendBuffer(data.nn, data.nn.length + 1, data.nn.length);
    arcs.updateVertexData(nn, data.xx, data.yy, data.zz);
  }

  // adds vertex to last arc
  // (used when adding lines in the GUI)
  // p: [x, y] point in display coordinates
  function appendVertex(arcs, p) {
    var i = arcs.getPointCount(); // one past the last idx
    insertVertex(arcs, i, p);
  }

  function insertVertex(arcs, i, p) {
    var data = arcs.getVertexData();
    var nn = data.nn;
    var n = data.xx.length;
    var count = 0;
    var xx2, yy2, zz2;
    // avoid re-allocating memory on each insertion
    if (data.xx.buffer.byteLength >= data.xx.length * 8 + 8) {
      xx2 = new Float64Array(data.xx.buffer, 0, n+1);
      yy2 = new Float64Array(data.yy.buffer, 0, n+1);
    } else {
      xx2 = new Float64Array(new ArrayBuffer((n + 50) * 8), 0, n+1);
      yy2 = new Float64Array(new ArrayBuffer((n + 50) * 8), 0, n+1);
    }
    if (!arcs.isFlat()) {
      zz2 = new Float64Array(new ArrayBuffer((n + 1) * 8), 0, n+1);
    }
    if (i < 0 || i > n) {
      error('Out-of-range vertex insertion index:', i);
    } else if (i == n) {
      // appending vertex to last arc
      nn[nn.length - 1]++;
    } else {
      for (var j=0; j<nn.length; j++) {
        count += nn[j];
        if (count >= i) { // TODO: confirm this
          nn[j] = nn[j] + 1;
          break;
        }
      }
    }

    utils.copyElements(data.xx, 0, xx2, 0, i);
    utils.copyElements(data.yy, 0, yy2, 0, i);
    utils.copyElements(data.xx, i, xx2, i+1, n-i);
    utils.copyElements(data.yy, i, yy2, i+1, n-i);
    xx2[i] = p[0];
    yy2[i] = p[1];
    if (zz2) {
      zz2[i] = Infinity;
      utils.copyElements(data.zz, 0, zz2, 0, i);
      utils.copyElements(data.zz, i, zz2, i+1, n-i);
    }
    arcs.updateVertexData(nn, xx2, yy2, zz2);
  }

  function countFilteredVertices(zz, zlimit) {
    var count = 0;
    for (var i=0, n = zz.length; i<n; i++) {
      if (zz[i] >= zlimit) count++;
    }
    return count;
  }

  function filterVertexData(o, zlimit) {
    if (!o.zz) error('Expected simplification data');
    var xx = o.xx,
        yy = o.yy,
        zz = o.zz,
        len2 = countFilteredVertices(zz, zlimit),
        arcCount = o.nn.length,
        xx2 = new Float64Array(len2),
        yy2 = new Float64Array(len2),
        zz2 = new Float64Array(len2),
        nn2 = new Int32Array(arcCount),
        i = 0, i2 = 0,
        n, n2;

    for (var arcId=0; arcId < arcCount; arcId++) {
      n2 = 0;
      n = o.nn[arcId];
      for (var end = i+n; i < end; i++) {
        if (zz[i] >= zlimit) {
          xx2[i2] = xx[i];
          yy2[i2] = yy[i];
          zz2[i2] = zz[i];
          i2++;
          n2++;
        }
      }
      if (n2 == 1) {
        error("Collapsed arc");
        // This should not happen (endpoints should be z == Infinity)
        // Could handle like this, instead of throwing an error:
        // n2 = 0;
        // xx2.pop();
        // yy2.pop();
        // zz2.pop();
      }
      nn2[arcId] = n2;
    }
    return {
      xx: xx2,
      yy: yy2,
      zz: zz2,
      nn: nn2
    };
  }

  var ArcUtils = /*#__PURE__*/Object.freeze({
    __proto__: null,
    absArcId: absArcId,
    calcArcBounds: calcArcBounds,
    getUnfilteredArcLength: getUnfilteredArcLength,
    getUnfilteredArcCoords: getUnfilteredArcCoords,
    findArcIdFromVertexId: findArcIdFromVertexId,
    deleteLastArc: deleteLastArc,
    deleteVertex: deleteVertex,
    appendEmptyArc: appendEmptyArc,
    appendVertex: appendVertex,
    insertVertex: insertVertex,
    countFilteredVertices: countFilteredVertices,
    filterVertexData: filterVertexData
  });

  var WGS84 = {
    // https://en.wikipedia.org/wiki/Earth_radius
    SEMIMAJOR_AXIS: 6378137,
    SEMIMINOR_AXIS: 6356752.3142,
    AUTHALIC_RADIUS: 6371007.2,
    VOLUMETRIC_RADIUS: 6371000.8
  };

  // TODO: remove this constant, use actual data from dataset CRS,
  // also consider using ellipsoidal formulas where greater accuracy might be important.
  var R$1 = WGS84.SEMIMAJOR_AXIS;
  var D2R = Math.PI / 180;
  var R2D = 180 / Math.PI;

  // Equirectangular projection
  function degreesToMeters(deg) {
    return deg * D2R * R$1;
  }

  function distance3D(ax, ay, az, bx, by, bz) {
    var dx = ax - bx,
      dy = ay - by,
      dz = az - bz;
    return Math.sqrt(dx * dx + dy * dy + dz * dz);
  }

  function distanceSq(ax, ay, bx, by) {
    var dx = ax - bx,
        dy = ay - by;
    return dx * dx + dy * dy;
  }

  function distance2D(ax, ay, bx, by) {
    var dx = ax - bx,
        dy = ay - by;
    return Math.sqrt(dx * dx + dy * dy);
  }

  function distanceSq3D(ax, ay, az, bx, by, bz) {
    var dx = ax - bx,
        dy = ay - by,
        dz = az - bz;
    return dx * dx + dy * dy + dz * dz;
  }

  // atan2() makes this function fairly slow, replaced by ~2x faster formula
  function innerAngle2(ax, ay, bx, by, cx, cy) {
    var a1 = Math.atan2(ay - by, ax - bx),
        a2 = Math.atan2(cy - by, cx - bx),
        a3 = Math.abs(a1 - a2);
    if (a3 > Math.PI) {
      a3 = 2 * Math.PI - a3;
    }
    return a3;
  }

  // Return angle abc in range [0, 2PI) or NaN if angle is invalid
  // (e.g. if length of ab or bc is 0)
  /*
  function signedAngle2(ax, ay, bx, by, cx, cy) {
    var a1 = Math.atan2(ay - by, ax - bx),
        a2 = Math.atan2(cy - by, cx - bx),
        a3 = a2 - a1;

    if (ax == bx && ay == by || bx == cx && by == cy) {
      a3 = NaN; // Use NaN for invalid angles
    } else if (a3 >= Math.PI * 2) {
      a3 = 2 * Math.PI - a3;
    } else if (a3 < 0) {
      a3 = a3 + 2 * Math.PI;
    }
    return a3;
  }
  */

  function standardAngle(a) {
    var twoPI = Math.PI * 2;
    while (a < 0) {
      a += twoPI;
    }
    while (a >= twoPI) {
      a -= twoPI;
    }
    return a;
  }

  function signedAngle(ax, ay, bx, by, cx, cy) {
    if (ax == bx && ay == by || bx == cx && by == cy) {
      return NaN; // Use NaN for invalid angles
    }
    var abx = ax - bx,
        aby = ay - by,
        cbx = cx - bx,
        cby = cy - by,
        dotp = abx * cbx + aby * cby,
        crossp = abx * cby - aby * cbx,
        a = Math.atan2(crossp, dotp);
    return standardAngle(a);
  }

  function bearing2D(x1, y1, x2, y2) {
    var val = Math.PI/2 - Math.atan2(y2 - y1, x2 - x1);
    return val > Math.PI ? val - 2 * Math.PI : val;
  }

  // Calc bearing in radians at lng1, lat1
  function bearing(lng1, lat1, lng2, lat2) {
    var D2R = Math.PI / 180;
    lng1 *= D2R;
    lng2 *= D2R;
    lat1 *= D2R;
    lat2 *= D2R;
    var y = Math.sin(lng2-lng1) * Math.cos(lat2),
        x = Math.cos(lat1)*Math.sin(lat2) - Math.sin(lat1)*Math.cos(lat2)*Math.cos(lng2-lng1);
    return Math.atan2(y, x);
  }

  // Calc angle of turn from ab to bc, in range [0, 2PI)
  // Receive lat-lng values in degrees
  function signedAngleSph(alng, alat, blng, blat, clng, clat) {
    if (alng == blng && alat == blat || blng == clng && blat == clat) {
      return NaN;
    }
    var b1 = bearing(blng, blat, alng, alat), // calc bearing at b
        b2 = bearing(blng, blat, clng, clat),
        a = Math.PI * 2 + b1 - b2;
    return standardAngle(a);
  }

  /*
  // Convert arrays of lng and lat coords (xsrc, ysrc) into
  // x, y, z coords (meters) on the most common spherical Earth model.
  //
  function convLngLatToSph(xsrc, ysrc, xbuf, ybuf, zbuf) {
    var deg2rad = Math.PI / 180,
        r = R;
    for (var i=0, len=xsrc.length; i<len; i++) {
      var lng = xsrc[i] * deg2rad,
          lat = ysrc[i] * deg2rad,
          cosLat = Math.cos(lat);
      xbuf[i] = Math.cos(lng) * cosLat * r;
      ybuf[i] = Math.sin(lng) * cosLat * r;
      zbuf[i] = Math.sin(lat) * r;
    }
  }
  */

  // Convert arrays of lng and lat coords (xsrc, ysrc) into
  // x, y, z coords (meters) on the most common spherical Earth model.
  //
  function convLngLatToSph(xsrc, ysrc, xbuf, ybuf, zbuf) {
    var p = [];
    for (var i=0, len=xsrc.length; i<len; i++) {
      lngLatToXYZ(xsrc[i], ysrc[i], p);
      xbuf[i] = p[0];
      ybuf[i] = p[1];
      zbuf[i] = p[2];
    }
  }

  function xyzToLngLat(x, y, z, p) {
    var d = distance3D(0, 0, 0, x, y, z); // normalize
    var lat = Math.asin(z / d) / D2R;
    var lng = Math.atan2(y / d, x / d) / D2R;
    p[0] = lng;
    p[1] = lat;
  }

  function lngLatToXYZ(lng, lat, p) {
    var cosLat;
    lng *= D2R;
    lat *= D2R;
    cosLat = Math.cos(lat);
    p[0] = Math.cos(lng) * cosLat * R$1;
    p[1] = Math.sin(lng) * cosLat * R$1;
    p[2] = Math.sin(lat) * R$1;
  }

  // Haversine formula (well conditioned at small distances)
  function sphericalDistance(lam1, phi1, lam2, phi2) {
    var dlam = lam2 - lam1,
        dphi = phi2 - phi1,
        a = Math.sin(dphi / 2) * Math.sin(dphi / 2) +
            Math.cos(phi1) * Math.cos(phi2) *
            Math.sin(dlam / 2) * Math.sin(dlam / 2),
        c = 2 * Math.atan2(Math.sqrt(a), Math.sqrt(1 - a));
    return c;
  }

  // Receive: coords in decimal degrees;
  // Return: distance in meters on spherical earth
  function greatCircleDistance(lng1, lat1, lng2, lat2) {
    var D2R = Math.PI / 180,
        dist = sphericalDistance(lng1 * D2R, lat1 * D2R, lng2 * D2R, lat2 * D2R);
    return dist * R$1;
  }

  // TODO: make this safe for small angles
  function innerAngle(ax, ay, bx, by, cx, cy) {
    var ab = distance2D(ax, ay, bx, by),
        bc = distance2D(bx, by, cx, cy),
        theta, dotp;
    if (ab === 0 || bc === 0) {
      theta = 0;
    } else {
      dotp = ((ax - bx) * (cx - bx) + (ay - by) * (cy - by)) / (ab * bc);
      if (dotp >= 1 - 1e-14) {
        theta = 0;
      } else if (dotp <= -1 + 1e-14) {
        theta = Math.PI;
      } else {
        theta = Math.acos(dotp); // consider using other formula at small dp
      }
    }
    return theta;
  }

  function innerAngle3D(ax, ay, az, bx, by, bz, cx, cy, cz) {
    var ab = distance3D(ax, ay, az, bx, by, bz),
        bc = distance3D(bx, by, bz, cx, cy, cz),
        theta, dotp;
    if (ab === 0 || bc === 0) {
      theta = 0;
    } else {
      dotp = ((ax - bx) * (cx - bx) + (ay - by) * (cy - by) + (az - bz) * (cz - bz)) / (ab * bc);
      if (dotp >= 1) {
        theta = 0;
      } else if (dotp <= -1) {
        theta = Math.PI;
      } else {
        theta = Math.acos(dotp); // consider using other formula at small dp
      }
    }
    return theta;
  }

  function triangleArea(ax, ay, bx, by, cx, cy) {
    var area = Math.abs(((ay - cy) * (bx - cx) + (by - cy) * (cx - ax)) / 2);
    return area;
  }

  function detSq(ax, ay, bx, by, cx, cy) {
    var det = ax * by - ax * cy + bx * cy - bx * ay + cx * ay - cx * by;
    return det * det;
  }

  function cosine(ax, ay, bx, by, cx, cy) {
    var den = distance2D(ax, ay, bx, by) * distance2D(bx, by, cx, cy),
        cos = 0;
    if (den > 0) {
      cos = ((ax - bx) * (cx - bx) + (ay - by) * (cy - by)) / den;
      if (cos > 1) cos = 1; // handle fp rounding error
      else if (cos < -1) cos = -1;
    }
    return cos;
  }

  function cosine3D(ax, ay, az, bx, by, bz, cx, cy, cz) {
    var den = distance3D(ax, ay, az, bx, by, bz) * distance3D(bx, by, bz, cx, cy, cz),
        cos = 0;
    if (den > 0) {
      cos = ((ax - bx) * (cx - bx) + (ay - by) * (cy - by) + (az - bz) * (cz - bz)) / den;
      if (cos > 1) cos = 1; // handle fp rounding error
      else if (cos < -1) cos = -1;
    }
    return cos;
  }

  function triangleArea3D(ax, ay, az, bx, by, bz, cx, cy, cz) {
    var area = 0.5 * Math.sqrt(detSq(ax, ay, bx, by, cx, cy) +
      detSq(ax, az, bx, bz, cx, cz) + detSq(ay, az, by, bz, cy, cz));
    return area;
  }

  // Given point B and segment AC, return the squared distance from B to the
  // nearest point on AC
  // Receive the squared length of segments AB, BC, AC
  // TODO: analyze rounding error. Returns 0 for these coordinates:
  //    P: [2, 3 - 1e-8]  AB: [[1, 3], [3, 3]]
  //
  function apexDistSq(ab2, bc2, ac2) {
    var dist2;
    if (ac2 === 0) {
      dist2 = ab2;
    } else if (ab2 >= bc2 + ac2) {
      dist2 = bc2;
    } else if (bc2 >= ab2 + ac2) {
      dist2 = ab2;
    } else {
      var dval = (ab2 + ac2 - bc2);
      dist2 = ab2 -  dval * dval / ac2  * 0.25;
    }
    if (dist2 < 0) {
      dist2 = 0;
    }
    return dist2;
  }

  function pointSegDistSq(ax, ay, bx, by, cx, cy) {
    var ab2 = distanceSq(ax, ay, bx, by),
        ac2 = distanceSq(ax, ay, cx, cy),
        bc2 = distanceSq(bx, by, cx, cy);
    return apexDistSq(ab2, ac2, bc2);
  }

  function pointSegDistSq3D(ax, ay, az, bx, by, bz, cx, cy, cz) {
    var ab2 = distanceSq3D(ax, ay, az, bx, by, bz),
        ac2 = distanceSq3D(ax, ay, az, cx, cy, cz),
        bc2 = distanceSq3D(bx, by, bz, cx, cy, cz);
    return apexDistSq(ab2, ac2, bc2);
  }

  // Apparently better conditioned for some inputs than pointSegDistSq()
  //
  function pointSegDistSq2(px, py, ax, ay, bx, by) {
    var ab2 = distanceSq(ax, ay, bx, by);
    var t = ((px - ax) * (bx - ax) + (py - ay) * (by - ay)) / ab2;
    if (ab2 === 0) return distanceSq(px, py, ax, ay);
    if (t < 0) t = 0;
    if (t > 1) t = 1;
    return distanceSq(px, py, ax + t * (bx - ax), ay + t * (by - ay));
  }


  // internal.reversePathCoords = function(arr, start, len) {
  //   var i = start,
  //       j = start + len - 1,
  //       tmp;
  //   while (i < j) {
  //     tmp = arr[i];
  //     arr[i] = arr[j];
  //     arr[j] = tmp;
  //     i++;
  //     j--;
  //   }
  // };

  // merge B into A
  // function mergeBounds(a, b) {
  //   if (b[0] < a[0]) a[0] = b[0];
  //   if (b[1] < a[1]) a[1] = b[1];
  //   if (b[2] > a[2]) a[2] = b[2];
  //   if (b[3] > a[3]) a[3] = b[3];
  // }

  function containsBounds(a, b) {
    return a[0] <= b[0] && a[2] >= b[2] && a[1] <= b[1] && a[3] >= b[3];
  }

  // function boundsArea(b) {
  //   return (b[2] - b[0]) * (b[3] - b[1]);
  // }

  var Geom = /*#__PURE__*/Object.freeze({
    __proto__: null,
    R: R$1,
    D2R: D2R,
    R2D: R2D,
    degreesToMeters: degreesToMeters,
    distance3D: distance3D,
    distanceSq: distanceSq,
    distance2D: distance2D,
    distanceSq3D: distanceSq3D,
    innerAngle2: innerAngle2,
    standardAngle: standardAngle,
    signedAngle: signedAngle,
    bearing2D: bearing2D,
    bearing: bearing,
    signedAngleSph: signedAngleSph,
    convLngLatToSph: convLngLatToSph,
    xyzToLngLat: xyzToLngLat,
    lngLatToXYZ: lngLatToXYZ,
    sphericalDistance: sphericalDistance,
    greatCircleDistance: greatCircleDistance,
    innerAngle: innerAngle,
    innerAngle3D: innerAngle3D,
    triangleArea: triangleArea,
    cosine: cosine,
    cosine3D: cosine3D,
    triangleArea3D: triangleArea3D,
    pointSegDistSq: pointSegDistSq,
    pointSegDistSq3D: pointSegDistSq3D,
    pointSegDistSq2: pointSegDistSq2,
    containsBounds: containsBounds
  });

  function pathIsClosed(ids, arcs) {
    var firstArc = ids[0];
    var lastArc = ids[ids.length - 1];
    var p1 = arcs.getVertex(firstArc, 0);
    var p2 = arcs.getVertex(lastArc, -1);
    var closed = p1.x === p2.x && p1.y === p2.y;
    return closed;
  }

  function getPointToPathDistance(px, py, ids, arcs) {
    return getPointToPathInfo(px, py, ids, arcs).distance;
  }

  function getPointToPathInfo(px, py, ids, arcs) {
    var iter = arcs.getShapeIter(ids);
    var pPathSq = Infinity;
    var arcId;
    var ax, ay, bx, by, axmin, aymin, bxmin, bymin, pabSq;
    if (iter.hasNext()) {
      ax = axmin = bxmin = iter.x;
      ay = aymin = bymin = iter.y;
    }
    while (iter.hasNext()) {
      bx = iter.x;
      by = iter.y;
      pabSq = pointSegDistSq2(px, py, ax, ay, bx, by);
      if (pabSq < pPathSq) {
        pPathSq = pabSq;
        arcId = iter._ids[iter._i]; // kludge
        axmin = ax;
        aymin = ay;
        bxmin = bx;
        bymin = by;
      }
      ax = bx;
      ay = by;
    }
    if (pPathSq == Infinity) return {distance: Infinity};
    return {
      segment: [[axmin, aymin], [bxmin, bymin]],
      distance: Math.sqrt(pPathSq),
      arcId: arcId
    };
  }


  // Return unsigned distance of a point to the nearest point on a polygon or polyline path
  //
  function getPointToShapeDistance(x, y, shp, arcs) {
    var info = getPointToShapeInfo(x, y, shp, arcs);
    return info ? info.distance : Infinity;
  }

  function getPointToShapeInfo(x, y, shp, arcs) {
    return (shp || []).reduce(function(memo, ids) {
      var pathInfo = getPointToPathInfo(x, y, ids, arcs);
      if (!memo || pathInfo.distance < memo.distance) return pathInfo;
      return memo;
    }, null) || {
      distance: Infinity,
      arcId: -1,
      segment: null
    };
  }

  // @ids array of arc ids
  // @arcs ArcCollection
  function getAvgPathXY(ids, arcs) {
    var iter = arcs.getShapeIter(ids);
    if (!iter.hasNext()) return null;
    var x0 = iter.x,
        y0 = iter.y,
        count = 0,
        sumX = 0,
        sumY = 0;
    while (iter.hasNext()) {
      count++;
      sumX += iter.x;
      sumY += iter.y;
    }
    if (count === 0 || iter.x !== x0 || iter.y !== y0) {
      sumX += x0;
      sumY += y0;
      count++;
    }
    return {
      x: sumX / count,
      y: sumY / count
    };
  }

  // Return path with the largest (area) bounding box
  // @shp array of array of arc ids
  // @arcs ArcCollection
  function getMaxPath(shp, arcs) {
    var maxArea = 0;
    return (shp || []).reduce(function(maxPath, path) {
      var bbArea = arcs.getSimpleShapeBounds(path).area();
      if (bbArea > maxArea) {
        maxArea = bbArea;
        maxPath = path;
      }
      return maxPath;
    }, null);
  }

  function countVerticesInPath(ids, arcs) {
    var iter = arcs.getShapeIter(ids),
        count = 0;
    while (iter.hasNext()) count++;
    return count;
  }

  function getPathBounds$1(points) {
    var bounds = new Bounds();
    for (var i=0, n=points.length; i<n; i++) {
      bounds.mergePoint(points[i][0], points[i][1]);
    }
    return bounds;
  }

  var calcPathLen;
  calcPathLen = (function() {
    var len, calcLen;
    function addSegLen(i, j, xx, yy) {
      len += calcLen(xx[i], yy[i], xx[j], yy[j]);
    }
    // @spherical (optional bool) calculate great circle length in meters
    return function(path, arcs, spherical) {
      if (spherical && arcs.isPlanar()) {
        error("Expected lat-long coordinates");
      }
      calcLen = spherical ? greatCircleDistance : distance2D;
      len = 0;
      for (var i=0, n=path.length; i<n; i++) {
        arcs.forEachArcSegment(path[i], addSegLen);
      }
      return len;
    };
  }());

  var PathGeom = /*#__PURE__*/Object.freeze({
    __proto__: null,
    pathIsClosed: pathIsClosed,
    getPointToPathDistance: getPointToPathDistance,
    getPointToPathInfo: getPointToPathInfo,
    getPointToShapeDistance: getPointToShapeDistance,
    getPointToShapeInfo: getPointToShapeInfo,
    getAvgPathXY: getAvgPathXY,
    getMaxPath: getMaxPath,
    countVerticesInPath: countVerticesInPath,
    getPathBounds: getPathBounds$1,
    get calcPathLen () { return calcPathLen; }
  });

  // Get the centroid of the largest ring of a polygon
  // TODO: Include holes in the calculation
  // TODO: Add option to find centroid of all rings, not just the largest
  function getShapeCentroid(shp, arcs) {
    var maxPath = getMaxPath(shp, arcs);
    return maxPath ? getPathCentroid(maxPath, arcs) : null;
  }

  function getPathCentroid(ids, arcs) {
    var iter = arcs.getShapeIter(ids),
        sum = 0,
        sumX = 0,
        sumY = 0,
        dx, dy, ax, ay, bx, by, tmp, area;
    if (!iter.hasNext()) return null;
    // reduce effect of fp errors by shifting shape origin to 0,0 (issue #304)
    ax = 0;
    ay = 0;
    dx = -iter.x;
    dy = -iter.y;
    while (iter.hasNext()) {
      bx = ax;
      by = ay;
      ax = iter.x + dx;
      ay = iter.y + dy;
      tmp = bx * ay - by * ax;
      sum += tmp;
      sumX += tmp * (bx + ax);
      sumY += tmp * (by + ay);
    }
    area = sum / 2;
    if (area === 0) {
      return getAvgPathXY(ids, arcs);
    } else return {
      x: sumX / (6 * area) - dx,
      y: sumY / (6 * area) - dy
    };
  }

  var PolygonCentroid = /*#__PURE__*/Object.freeze({
    __proto__: null,
    getShapeCentroid: getShapeCentroid,
    getPathCentroid: getPathCentroid
  });

  function testSegmentBoundsIntersection(a, b, bb) {
    if (bb.containsPoint(a[0], a[1])) {
      return true;
    }
    return !!(
      geom.segmentIntersection(a[0], a[1], b[0], b[1], bb.xmin, bb.ymin, bb.xmin, bb.ymax) ||
      geom.segmentIntersection(a[0], a[1], b[0], b[1], bb.xmin, bb.ymax, bb.xmax, bb.ymax) ||
      geom.segmentIntersection(a[0], a[1], b[0], b[1], bb.xmax, bb.ymax, bb.xmax, bb.ymin) ||
      geom.segmentIntersection(a[0], a[1], b[0], b[1], bb.xmax, bb.ymin, bb.xmin, bb.ymin));
  }

  // A compactness measure designed for testing electoral districts for gerrymandering.
  // Returns value in [0-1] range. 1 = perfect circle, 0 = collapsed polygon
  function calcPolsbyPopperCompactness(area, perimeter) {
    if (perimeter <= 0) return 0;
    return Math.abs(area) * Math.PI * 4 / (perimeter * perimeter);
  }

  // Larger values (less severe penalty) than Polsby Popper
  function calcSchwartzbergCompactness(area, perimeter) {
    if (perimeter <= 0) return 0;
    return 2 * Math.PI * Math.sqrt(Math.abs(area) / Math.PI) / perimeter;
  }

  // Returns: 1 if CW, -1 if CCW, 0 if collapsed
  function getPathWinding(ids, arcs) {
    var area = getPathArea(ids, arcs);
    return area > 0 && 1 || area < 0 && -1 || 0;
  }

  function getShapeArea(shp, arcs) {
    // return (arcs.isPlanar() ? geom.getPlanarShapeArea : geom.getSphericalShapeArea)(shp, arcs);
    return (shp || []).reduce(function(area, ids) {
      return area + getPathArea(ids, arcs);
    }, 0);
  }

  function getPlanarShapeArea(shp, arcs) {
    return (shp || []).reduce(function(area, ids) {
      return area + getPlanarPathArea(ids, arcs);
    }, 0);
  }

  function getSphericalShapeArea(shp, arcs, R) {
    if (arcs.isPlanar()) {
      error("[getSphericalShapeArea()] Function requires decimal degree coordinates");
    }
    return (shp || []).reduce(function(area, ids) {
      return area + getSphericalPathArea(ids, arcs, R);
    }, 0);
  }

  // export function getEllipsoidalShapeArea(shp, arcs, crs) {
  //   return (shp || []).reduce(function(area, ids) {
  //     return area + getEllipsoidalPathArea(ids, arcs, crs);
  //   }, 0);
  // }

  // test if a rectangle is completely enclosed in a planar polygon
  function testBoundsInPolygon(bounds, shp, arcs) {
    if (!shp || !testPointInPolygon(bounds.xmin, bounds.ymin, shp, arcs)) return false;
    var isIn = true;
    shp.forEach(function(ids) {
      forEachSegmentInPath(ids, arcs, function(a, b, xx, yy) {
        isIn = isIn && !testSegmentBoundsIntersection([xx[a], yy[a]], [xx[b], yy[b]], bounds);
      });
    });
    return isIn;
  }

  // Return true if point is inside or on boundary of a shape
  //
  function testPointInPolygon(x, y, shp, arcs) {
    var isIn = false,
        isOn = false;
    if (!shp) return false;
    shp.forEach(function(ids) {
      var inRing = testPointInRing(x, y, ids, arcs);
      if (inRing == 1) {
        isIn = !isIn;
      } else if (inRing == -1) {
        isOn = true;
      }
    });
    return isOn || isIn;
  }

  function getYIntercept(x, ax, ay, bx, by) {
    return ay + (x - ax) * (by - ay) / (bx - ax);
  }



  // Test if point (x, y) is inside, outside or on the boundary of a polygon ring
  // Return 0: outside; 1: inside; -1: on boundary
  //
  function testPointInRing(x, y, ids, arcs) {
    /*
    // arcs.getSimpleShapeBounds() doesn't apply simplification, can't use here
    //// wait, why not? simplifcation shoudn't expand bounds, so this test makes sense
    if (!arcs.getSimpleShapeBounds(ids).containsPoint(x, y)) {
      return false;
    }
    */
    var isIn = false,
        isOn = false;
    forEachSegmentInPath(ids, arcs, function(a, b, xx, yy) {
      var result = testRayIntersection(x, y, xx[a], yy[a], xx[b], yy[b]);
      if (result == 1) {
        isIn = !isIn;
      } else if (isNaN(result)) {
        isOn = true;
      }
    });
    return isOn ? -1 : (isIn ? 1 : 0);
  }

  // test if a vertical ray originating at (x, y) intersects a segment
  // returns 1 if intersection, 0 if no intersection, NaN if point touches segment
  // (Special rules apply to endpoint intersections, to support point-in-polygon testing.)
  function testRayIntersection(x, y, ax, ay, bx, by) {
    var val = getRayIntersection(x, y, ax, ay, bx, by);
    if (val != val) {
      return NaN;
    }
    return val == -Infinity ? 0 : 1;
  }

  function getRayIntersection(x, y, ax, ay, bx, by) {
    var hit = -Infinity, // default: no hit
        yInt;

    // case: p is entirely above, left or right of segment
    if (x < ax && x < bx || x > ax && x > bx || y > ay && y > by) ;
    // case: px aligned with a segment vertex
    else if (x === ax || x === bx) {
      // case: vertical segment or collapsed segment
      if (x === ax && x === bx) {
        // p is on segment
        if (y == ay || y == by || y > ay != y > by) {
          hit = NaN;
        }
        // else: no hit
      }
      // case: px equal to ax (only)
      else if (x === ax) {
        if (y === ay) {
          hit = NaN;
        } else if (bx < ax && y < ay) {
          // only score hit if px aligned to rightmost endpoint
          hit = ay;
        }
      }
      // case: px equal to bx (only)
      else {
        if (y === by) {
          hit = NaN;
        } else if (ax < bx && y < by) {
          // only score hit if px aligned to rightmost endpoint
          hit = by;
        }
      }
    // case: px is between endpoints
    } else {
      yInt = getYIntercept(x, ax, ay, bx, by);
      if (yInt > y) {
        hit = yInt;
      } else if (yInt == y) {
        hit = NaN;
      }
    }
    return hit;
  }

  function getPathArea(ids, arcs) {
    return (arcs.isPlanar() ? getPlanarPathArea : getSphericalPathArea)(ids, arcs);
  }

  function getSphericalPathArea(ids, arcs, R) {
    var iter = arcs.getShapeIter(ids);
    return getSphericalPathArea2(iter, R);
  }

  function getSphericalPathArea2(iter, R) {
    var sum = 0,
        started = false,
        deg2rad = Math.PI / 180,
        x, y, xp, yp;
    R = R || WGS84.SEMIMAJOR_AXIS;
    while (iter.hasNext()) {
      x = iter.x * deg2rad;
      y = Math.sin(iter.y * deg2rad);
      if (started) {
        sum += (x - xp) * (2 + y + yp);
      } else {
        started = true;
      }
      xp = x;
      yp = y;
    }
    return sum / 2 * R * R;
  }

  // Get path area from an array of [x, y] points
  // TODO: consider removing duplication with getPathArea(), e.g. by
  //   wrapping points in an iterator.
  //
  function getPlanarPathArea2(points) {
    var sum = 0,
        ax, ay, bx, by, dx, dy, p;
    for (var i=0, n=points.length; i<n; i++) {
      p = points[i];
      if (i === 0) {
        ax = 0;
        ay = 0;
        dx = -p[0];
        dy = -p[1];
      } else {
        ax = p[0] + dx;
        ay = p[1] + dy;
        sum += ax * by - bx * ay;
      }
      bx = ax;
      by = ay;
    }
    return sum / 2;
  }

  function getPlanarPathArea(ids, arcs) {
    var iter = arcs.getShapeIter(ids),
        sum = 0,
        ax, ay, bx, by, dx, dy;
    if (iter.hasNext()) {
      ax = 0;
      ay = 0;
      dx = -iter.x;
      dy = -iter.y;
      while (iter.hasNext()) {
        bx = ax;
        by = ay;
        ax = iter.x + dx;
        ay = iter.y + dy;
        sum += ax * by - bx * ay;
      }
    }
    return sum / 2;
  }

  function getPathPerimeter(ids, arcs) {
    return (arcs.isPlanar() ? getPlanarPathPerimeter : getSphericalPathPerimeter)(ids, arcs);
  }

  function getShapePerimeter(shp, arcs) {
    return (shp || []).reduce(function(len, ids) {
      return len + getPathPerimeter(ids, arcs);
    }, 0);
  }

  function getSphericalShapePerimeter(shp, arcs) {
    if (arcs.isPlanar()) {
      error("[getSphericalShapePerimeter()] Function requires decimal degree coordinates");
    }
    return (shp || []).reduce(function(len, ids) {
      return len + getSphericalPathPerimeter(ids, arcs);
    }, 0);
  }

  function getPlanarPathPerimeter(ids, arcs) {
    return calcPathLen(ids, arcs, false);
  }

  function getSphericalPathPerimeter(ids, arcs) {
    return calcPathLen(ids, arcs, true);
  }

  var PolygonGeom = /*#__PURE__*/Object.freeze({
    __proto__: null,
    calcPolsbyPopperCompactness: calcPolsbyPopperCompactness,
    calcSchwartzbergCompactness: calcSchwartzbergCompactness,
    getPathWinding: getPathWinding,
    getShapeArea: getShapeArea,
    getPlanarShapeArea: getPlanarShapeArea,
    getSphericalShapeArea: getSphericalShapeArea,
    testBoundsInPolygon: testBoundsInPolygon,
    testPointInPolygon: testPointInPolygon,
    testPointInRing: testPointInRing,
    testRayIntersection: testRayIntersection,
    getRayIntersection: getRayIntersection,
    getPathArea: getPathArea,
    getSphericalPathArea: getSphericalPathArea,
    getSphericalPathArea2: getSphericalPathArea2,
    getPlanarPathArea2: getPlanarPathArea2,
    getPlanarPathArea: getPlanarPathArea,
    getPathPerimeter: getPathPerimeter,
    getShapePerimeter: getShapePerimeter,
    getSphericalShapePerimeter: getSphericalShapePerimeter,
    getPlanarPathPerimeter: getPlanarPathPerimeter,
    getSphericalPathPerimeter: getSphericalPathPerimeter
  });

  // Returns an interval for snapping together coordinates that be co-incident bug
  // have diverged because of floating point rounding errors. Intended to be small
  // enought not not to snap points that should be distinct.
  // This is not a robust method... e.g. some formulas for some inputs may produce
  // errors that are larger than this interval.
  // @coords: Array of relevant coordinates (e.g. bbox coordinates of vertex coordinates
  //   of two intersecting segments).
  //
  function getHighPrecisionSnapInterval(coords) {
    var maxCoord = Math.max.apply(null, coords.map(Math.abs));
    return maxCoord * 1e-14;
  }

  function snapCoords(arcs, threshold) {
      var avgDist = getAvgSegment(arcs),
          autoSnapDist = avgDist * 0.0025,
          snapDist = autoSnapDist;

    if (threshold > 0) {
      snapDist = threshold;
      message(utils.format("Applying snapping threshold of %s -- %.6f times avg. segment length", threshold, threshold / avgDist));
    }
    var snapCount = snapCoordsByInterval(arcs, snapDist);
    if (snapCount > 0) arcs.dedupCoords();
    message(utils.format("Snapped %s point%s", snapCount, utils.pluralSuffix(snapCount)));
  }

  function snapCoordsByInterval(arcs, snapDist) {
    if (snapDist > 0 === false) return 0;
    var ids = getCoordinateIds(arcs);
    return snapCoordsInternal(ids, arcs, snapDist);
  }

  function snapEndpointsByInterval(arcs, snapDist) {
    if (snapDist > 0 === false) return 0;
    var ids = getEndpointIds(arcs);
    return snapCoordsInternal(ids, arcs, snapDist);
  }

  // Snap together points within a small threshold
  //
  function snapCoordsInternal(ids, arcs, snapDist) {
    var snapCount = 0,
        n = ids.length,
        data = arcs.getVertexData();

    quicksortIds(data.xx, ids, 0, n-1);

    // Consider: speed up sorting -- try bucket sort as first pass.
    for (var i=0; i<n; i++) {
      snapCount += snapPoint(i, snapDist, ids, data.xx, data.yy);
    }
    return snapCount;

    function snapPoint(i, limit, ids, xx, yy) {
      var j = i,
          n = ids.length,
          x = xx[ids[i]],
          y = yy[ids[i]],
          snaps = 0,
          id2, dx, dy;

      while (++j < n) {
        id2 = ids[j];
        dx = xx[id2] - x;
        if (dx > limit) break;
        dy = yy[id2] - y;
        if (dx === 0 && dy === 0 || dx * dx + dy * dy > limit * limit) continue;
        xx[id2] = x;
        yy[id2] = y;
        snaps++;
      }
      return snaps;
    }
  }

  function getCoordinateIds(arcs) {
    var data = arcs.getVertexData(),
        n = data.xx.length,
        ids = new Uint32Array(n);
    for (var i=0; i<n; i++) {
      ids[i] = i;
    }
    return ids;
  }

  function getEndpointIds(arcs) {
    var i = 0;
    var ids = [];
    var data = arcs.getVertexData();
    data.nn.forEach(function(n) {
      if (n > 0 === false) return;
      ids.push(i, i+n-1);
      i += n;
    });
    return ids;
  }

  /*
  // Returns array of array ids, in ascending order.
  // @a array of numbers
  //
  utils.sortCoordinateIds = function(a) {
    return utils.bucketSortIds(a);
  };

  // This speeds up sorting of large datasets (~2x faster for 1e7 values)
  // worth the additional code?
  utils.bucketSortIds = function(a, n) {
    var len = a.length,
        ids = new Uint32Array(len),
        bounds = utils.getArrayBounds(a),
        buckets = Math.ceil(n > 0 ? n : len / 10),
        counts = new Uint32Array(buckets),
        offsets = new Uint32Array(buckets),
        i, j, offs, count;

    // get bucket sizes
    for (i=0; i<len; i++) {
      j = bucketId(a[i], bounds.min, bounds.max, buckets);
      counts[j]++;
    }

    // convert counts to offsets
    offs = 0;
    for (i=0; i<buckets; i++) {
      offsets[i] = offs;
      offs += counts[i];
    }

    // assign ids to buckets
    for (i=0; i<len; i++) {
      j = bucketId(a[i], bounds.min, bounds.max, buckets);
      offs = offsets[j]++;
      ids[offs] = i;
    }

    // sort each bucket with quicksort
    for (i = 0; i<buckets; i++) {
      count = counts[i];
      if (count > 1) {
        offs = offsets[i] - count;
        utils.quicksortIds(a, ids, offs, offs + count - 1);
      }
    }
    return ids;

    function bucketId(val, min, max, buckets) {
      var id = (buckets * (val - min) / (max - min)) | 0;
      return id < buckets ? id : buckets - 1;
    }
  };
  */

  function quicksortIds(a, ids, lo, hi) {
    if (hi - lo > 24) {
      var pivot = a[ids[lo + hi >> 1]],
          i = lo,
          j = hi,
          tmp;
      while (i <= j) {
        while (a[ids[i]] < pivot) i++;
        while (a[ids[j]] > pivot) j--;
        if (i <= j) {
          tmp = ids[i];
          ids[i] = ids[j];
          ids[j] = tmp;
          i++;
          j--;
        }
      }
      if (j > lo) quicksortIds(a, ids, lo, j);
      if (i < hi) quicksortIds(a, ids, i, hi);
    } else {
      insertionSortIds(a, ids, lo, hi);
    }
  }

  function insertionSortIds(arr, ids, start, end) {
    var id, i, j;
    for (j = start + 1; j <= end; j++) {
      id = ids[j];
      for (i = j - 1; i >= start && arr[id] < arr[ids[i]]; i--) {
        ids[i+1] = ids[i];
      }
      ids[i+1] = id;
    }
  }

  var Snapping = /*#__PURE__*/Object.freeze({
    __proto__: null,
    getHighPrecisionSnapInterval: getHighPrecisionSnapInterval,
    snapCoords: snapCoords,
    snapCoordsByInterval: snapCoordsByInterval,
    snapEndpointsByInterval: snapEndpointsByInterval,
    getCoordinateIds: getCoordinateIds,
    getEndpointIds: getEndpointIds
  });

  // Find the intersection between two 2D segments
  // Returns 0, 1 or 2 [x, y] locations as null, [x, y], or [x1, y1, x2, y2]
  // Special cases:
  // Endpoint-to-endpoint touches are not treated as intersections.
  // If the segments touch at a T-intersection, it is treated as an intersection.
  // If the segments are collinear and partially overlapping, each subsumed endpoint
  //    is counted as an intersection (there will be either one or two)
  //
  function segmentIntersection(ax, ay, bx, by, cx, cy, dx, dy, epsArg) {
    // Use a small tolerance interval, so collinear segments and T-intersections
    // are detected (floating point rounding often causes exact functions to fail)
    var eps = epsArg >= 0 ? epsArg :
        getHighPrecisionSnapInterval([ax, ay, bx, by, cx, cy, dx, dy]);
    var epsSq = eps * eps;
    var touches, cross;
    // Detect 0, 1 or 2 'touch' intersections, where a vertex of one segment
    // is very close to the other segment's linear portion.
    // One touch indicates either a T-intersection or two overlapping collinear
    // segments that share an endpoint. Two touches indicates overlapping
    // collinear segments that do not share an endpoint.
    touches = findPointSegTouches(epsSq, ax, ay, bx, by, cx, cy, dx, dy);
    // if (touches) return touches;
    // Ignore endpoint-only intersections
    if (!touches && testEndpointHit(epsSq, ax, ay, bx, by, cx, cy, dx, dy)) {
      return null;
    }
    // Detect cross intersection
    cross = findCrossIntersection(ax, ay, bx, by, cx, cy, dx, dy, eps);
    return touches || cross || null;
  }


  // Find the intersection point of two segments that cross each other,
  // or return null if the segments do not cross.
  // Assumes endpoint intersections have already been detected
  function findCrossIntersection(ax, ay, bx, by, cx, cy, dx, dy, eps) {
    if (!segmentHit(ax, ay, bx, by, cx, cy, dx, dy)) return null;
    var den = determinant2D(bx - ax, by - ay, dx - cx, dy - cy);
    var m = orient2D(cx, cy, dx, dy, ax, ay) / den;
    var p = [ax + m * (bx - ax), ay + m * (by - ay)];
    if (Math.abs(den) < 1e-18) {
      // assume that collinear and near-collinear segment intersections have been
      // accounted for already.
      // TODO: is this a valid assumption?
      return null;
    }

    // Snap p to a vertex if very close to one
    // This avoids tiny segments caused by T-intersection overshoots and prevents
    //   pathfinder errors related to f-p rounding.
    // (NOTE: this may no longer be needed, since T-intersections are now detected
    // first)
    if (eps > 0) {
      snapIntersectionPoint(p, ax, ay, bx, by, cx, cy, dx, dy, eps);
    }
    // Clamp point to x range and y range of both segments
    // (This may occur due to fp rounding, if one segment is vertical or horizontal)
    clampIntersectionPoint(p, ax, ay, bx, by, cx, cy, dx, dy);
    return p;
  }

  function testEndpointHit(epsSq, ax, ay, bx, by, cx, cy, dx, dy) {
    return distanceSq(ax, ay, cx, cy) <= epsSq || distanceSq(ax, ay, dx, dy) <= epsSq ||
      distanceSq(bx, by, cx, cy) <= epsSq || distanceSq(bx, by, dx, dy) <= epsSq;
  }

  function findPointSegTouches(epsSq, ax, ay, bx, by, cx, cy, dx, dy) {
    var touches = [];
    collectPointSegTouch(touches, epsSq, ax, ay, cx, cy, dx, dy);
    collectPointSegTouch(touches, epsSq, bx, by, cx, cy, dx, dy);
    collectPointSegTouch(touches, epsSq, cx, cy, ax, ay, bx, by);
    collectPointSegTouch(touches, epsSq, dx, dy, ax, ay, bx, by);
    if (touches.length === 0) return null;
    if (touches.length > 4) {
      // Geometrically, more than two touch intersections can not occur.
      // Is it possible that fp rounding or a bug might result in >2 touches?
      debug('Intersection detection error');
    }
    return touches;
  }

  function collectPointSegTouch(arr, epsSq, px, py, ax, ay, bx, by) {
    // The original point-seg distance function caused errors in test data.
    // (probably because of large rounding errors with some inputs).
    // var pab = pointSegDistSq(px, py, ax, ay, bx, by);
    var pab = pointSegDistSq2(px, py, ax, ay, bx, by);
    if (pab > epsSq) return; // point is too far from segment to touch
    var pa = distanceSq(ax, ay, px, py);
    var pb = distanceSq(bx, by, px, py);
    if (pa <= epsSq || pb <= epsSq) return; // ignore endpoint hits
    arr.push(px, py); // T intersection at P and AB
  }


  // Used by mapshaper-undershoots.js
  // TODO: make more robust, make sure result is compatible with segmentIntersection()
  // (rounding errors currently must be handled downstream)
  function findClosestPointOnSeg(px, py, ax, ay, bx, by, snapArg) {
    var dx = bx - ax,
        dy = by - ay,
        dotp = (px - ax) * dx + (py - ay) * dy,
        abSq = dx * dx + dy * dy,
        k = abSq === 0 ? -1 : dotp / abSq,
        eps = snapArg >= 0 ? snapArg : 0.1, // 1e-6, // snap to endpoint
        p;
    if (k <= eps) {
      p = [ax, ay];
    } else if (k >= 1 - eps) {
      p = [bx, by];
    } else {
      p = [ax + k * dx, ay + k * dy];
    }
    return p;
  }

  function snapIfCloser(p, minDist, x, y, x2, y2) {
    var dist = distance2D(x, y, x2, y2);
    if (dist < minDist) {
      minDist = dist;
      p[0] = x2;
      p[1] = y2;
    }
    return minDist;
  }

  function snapIntersectionPoint(p, ax, ay, bx, by, cx, cy, dx, dy, eps) {
    var x = p[0],
        y = p[1],
        snapDist = eps;
    snapDist = snapIfCloser(p, snapDist, x, y, ax, ay);
    snapDist = snapIfCloser(p, snapDist, x, y, bx, by);
    snapDist = snapIfCloser(p, snapDist, x, y, cx, cy);
    snapDist = snapIfCloser(p, snapDist, x, y, dx, dy);
  }

  function clampIntersectionPoint(p, ax, ay, bx, by, cx, cy, dx, dy) {
    // Handle intersection points that fall outside the x-y range of either
    // segment by snapping to nearest endpoint coordinate. Out-of-range
    // intersection points can be caused by floating point rounding errors
    // when a segment is vertical or horizontal. This has caused problems when
    // repeatedly applying bbox clipping along the same segment
    var x = p[0],
        y = p[1];
    // assumes that segment ranges intersect
    x = clampToCloseRange(x, ax, bx);
    x = clampToCloseRange(x, cx, dx);
    y = clampToCloseRange(y, ay, by);
    y = clampToCloseRange(y, cy, dy);
    p[0] = x;
    p[1] = y;
  }

  // a: coordinate of point
  // b: endpoint coordinate of segment
  // c: other endpoint of segment
  function outsideRange(a, b, c) {
    var out;
    if (b < c) {
      out = a < b || a > c;
    } else if (b > c) {
      out = a > b || a < c;
    } else {
      out = a != b;
    }
    return out;
  }

  function clampToCloseRange(a, b, c) {
    var lim;
    if (outsideRange(a, b, c)) {
      lim = Math.abs(a - b) < Math.abs(a - c) ? b : c;
      if (Math.abs(a - lim) > 1e-15) {
        debug("[clampToCloseRange()] large clamping interval", a, b, c);
      }
      a = lim;
    }
    return a;
  }

  // Determinant of matrix
  //  | a  b |
  //  | c  d |
  function determinant2D(a, b, c, d) {
    return a * d - b * c;
  }

  // returns a positive value if the points a, b, and c are arranged in
  // counterclockwise order, a negative value if the points are in clockwise
  // order, and zero if the points are collinear.
  // Source: Jonathan Shewchuk http://www.cs.berkeley.edu/~jrs/meshpapers/robnotes.pdf
  function orient2D(ax, ay, bx, by, cx, cy) {
    return determinant2D(ax - cx, ay - cy, bx - cx, by - cy);
  }

  // Source: Sedgewick, _Algorithms in C_
  // (Other functions were tried that were more sensitive to floating point errors
  //  than this function)
  function segmentHit(ax, ay, bx, by, cx, cy, dx, dy) {
    return orient2D(ax, ay, bx, by, cx, cy) *
        orient2D(ax, ay, bx, by, dx, dy) <= 0 &&
        orient2D(cx, cy, dx, dy, ax, ay) *
        orient2D(cx, cy, dx, dy, bx, by) <= 0;
  }

  // Useful for determining if a segment that intersects another segment is
  // entering or leaving an enclosed buffer area
  // returns -1 if angle of p1p2 -> p3p4 is counter-clockwise (left turn)
  // returns 1 if angle is clockwise
  // return 0 if segments are collinear
  function segmentTurn(p1, p2, p3, p4) {
    var ax = p1[0],
        ay = p1[1],
        bx = p2[0],
        by = p2[1],
        // shift p3p4 segment to start at p2
        dx = bx - p3[0],
        dy = by - p3[1],
        cx = p4[0] + dx,
        cy = p4[1] + dy,
        orientation = orient2D(ax, ay, bx, by, cx, cy);
      if (!orientation) return 0;
      return orientation < 0 ? 1 : -1;
  }

  var SegmentGeom = /*#__PURE__*/Object.freeze({
    __proto__: null,
    segmentIntersection: segmentIntersection,
    findClosestPointOnSeg: findClosestPointOnSeg,
    orient2D: orient2D,
    segmentHit: segmentHit,
    segmentTurn: segmentTurn
  });

  var geom = Object.assign({}, Geom, PolygonGeom, PathGeom, SegmentGeom, PolygonCentroid);

  // Utility functions for working with ArcCollection and arrays of arc ids.

  // Return average segment length (with simplification)
  function getAvgSegment(arcs) {
    var sum = 0;
    var count = arcs.forEachSegment(function(i, j, xx, yy) {
      var dx = xx[i] - xx[j],
          dy = yy[i] - yy[j];
      sum += Math.sqrt(dx * dx + dy * dy);
    });
    return sum / count || 0;
  }

  // Return average magnitudes of dx, dy (with simplification)
  function getAvgSegment2(arcs) {
    var dx = 0, dy = 0;
    var count = arcs.forEachSegment(function(i, j, xx, yy) {
      dx += Math.abs(xx[i] - xx[j]);
      dy += Math.abs(yy[i] - yy[j]);
    });
    return [dx / count || 0, dy / count || 0];
  }

  /*
  this.getAvgSegmentSph2 = function() {
    var sumx = 0, sumy = 0;
    var count = this.forEachSegment(function(i, j, xx, yy) {
      var lat1 = yy[i],
          lat2 = yy[j];
      sumy += geom.degreesToMeters(Math.abs(lat1 - lat2));
      sumx += geom.degreesToMeters(Math.abs(xx[i] - xx[j]) *
          Math.cos((lat1 + lat2) * 0.5 * geom.D2R);
    });
    return [sumx / count || 0, sumy / count || 0];
  };
  */

  function getDirectedArcPresenceTest(shapes, n) {
    var flags = new Uint8Array(n);
    forEachArcId(shapes, function(id) {
      var absId = absArcId(id);
      if (absId < n === false) error('index error');
      flags[absId] |= id < 0 ? 2 : 1;
    });
    return function(arcId) {
      var absId = absArcId(arcId);
      return arcId < 0 ? (flags[absId] & 2) == 2 : (flags[absId] & 1) == 1;
    };
  }

  function getArcPresenceTest(shapes, arcs) {
    var counts = new Uint8Array(arcs.size());
    countArcsInShapes(shapes, counts);
    return function(id) {
      if (id < 0) id = ~id;
      return counts[id] > 0;
    };
  }

  // @counts A typed array for accumulating count of each abs arc id
  //   (assume it won't overflow)
  function countArcsInShapes(shapes, counts) {
    traversePaths(shapes, null, function(obj) {
      var arcs = obj.arcs,
          id;
      for (var i=0; i<arcs.length; i++) {
        id = arcs[i];
        if (id < 0) id = ~id;
        counts[id]++;
      }
    });
  }

  function getPathBounds(shapes, arcs) {
    var bounds = new Bounds();
    forEachArcId(shapes, function(id) {
      arcs.mergeArcBounds(id, bounds);
    });
    return bounds;
  }

  // Returns subset of shapes in @shapes that contain one or more arcs in @arcIds
  function findShapesByArcId(shapes, arcIds, numArcs) {
    var index = numArcs ? new Uint8Array(numArcs) : [],
        found = [];
    arcIds.forEach(function(id) {
      index[absArcId(id)] = 1;
    });
    shapes.forEach(function(shp, shpId) {
      var isHit = false;
      forEachArcId(shp || [], function(id) {
        isHit = isHit || index[absArcId(id)] == 1;
      });
      if (isHit) {
        found.push(shpId);
      }
    });
    return found;
  }

  function reversePath(ids) {
    ids.reverse();
    for (var i=0, n=ids.length; i<n; i++) {
      ids[i] = ~ids[i];
    }
    return ids;
  }

  function clampIntervalByPct(z, pct) {
    if (pct <= 0) z = Infinity;
    else if (pct >= 1) z = 0;
    return z;
  }

  // Return id of the vertex between @start and @end with the highest
  // threshold that is less than @zlim, or -1 if none
  //
  function findNextRemovableVertex(zz, zlim, start, end) {
    var tmp, jz = 0, j = -1, z;
    if (start > end) {
      tmp = start;
      start = end;
      end = tmp;
    }
    for (var i=start+1; i<end; i++) {
      z = zz[i];
      if (z < zlim && z > jz) {
        j = i;
        jz = z;
      }
    }
    return j;
  }

  // Visit each arc id in a path, shape or array of shapes
  // Use non-undefined return values of callback @cb as replacements.
  function forEachArcId(arr, cb) {
    var item;
    for (var i=0; i<arr.length; i++) {
      item = arr[i];
      if (Array.isArray(item)) {
        forEachArcId(item, cb);
      } else if (utils.isInteger(item)) {
        var val = cb(item);
        if (val !== void 0) {
          arr[i] = val;
        }
      } else if (item) {
        error("Non-integer arc id in:", arr);
      }
    }
  }

  function forEachSegmentInShape(shape, arcs, cb) {
    for (var i=0, n=shape ? shape.length : 0; i<n; i++) {
      forEachSegmentInPath(shape[i], arcs, cb);
    }
  }

  function forEachSegmentInPath(ids, arcs, cb) {
    for (var i=0, n=ids.length; i<n; i++) {
      arcs.forEachArcSegment(ids[i], cb);
    }
  }

  function traversePaths(shapes, cbArc, cbPart, cbShape) {
    var segId = 0;
    shapes.forEach(function(parts, shapeId) {
      if (!parts || parts.length === 0) return; // null shape
      var arcIds, arcId;
      if (cbShape) {
        cbShape(shapeId);
      }
      for (var i=0, m=parts.length; i<m; i++) {
        arcIds = parts[i];
        if (cbPart) {
          cbPart({
            i: i,
            shapeId: shapeId,
            shape: parts,
            arcs: arcIds
          });
        }

        if (cbArc) {
          for (var j=0, n=arcIds.length; j<n; j++, segId++) {
            arcId = arcIds[j];
            cbArc({
              i: j,
              shapeId: shapeId,
              partId: i,
              arcId: arcId,
              segId: segId
            });
          }
        }
      }
    });
  }

  function arcHasLength(id, coords) {
    var iter = coords.getArcIter(id), x, y;
    if (iter.hasNext()) {
      x = iter.x;
      y = iter.y;
      while (iter.hasNext()) {
        if (iter.x != x || iter.y != y) return true;
      }
    }
    return false;
  }

  function filterEmptyArcs(shape, coords) {
    if (!shape) return null;
    var shape2 = [];
    shape.forEach(function(ids) {
      var path = [];
      for (var i=0; i<ids.length; i++) {
        if (arcHasLength(ids[i], coords)) {
          path.push(ids[i]);
        }
      }
      if (path.length > 0) shape2.push(path);
    });
    return shape2.length > 0 ? shape2 : null;
  }

  // Return an array of information about each part/ring in a polygon or polyline shape
  function getPathMetadata(shape, arcs, type) {
    var data = [],
        ids;
    for (var i=0, n=shape && shape.length; i<n; i++) {
      ids = shape[i];
      data.push({
        ids: ids,
        area: type == 'polygon' ? geom.getPlanarPathArea(ids, arcs) : 0,
        bounds: arcs.getSimpleShapeBounds(ids)
      });
    }
    return data;
  }

  function quantizeArcs(arcs, quanta) {
    // Snap coordinates to a grid of @quanta locations on both axes
    // This may snap nearby points to the same coordinates.
    // Consider a cleanup pass to remove dupes, make sure collapsed arcs are
    //   removed on export.
    //
    var bb1 = arcs.getBounds(),
        bb2 = new Bounds(0, 0, quanta-1, quanta-1),
        fw = bb1.getTransform(bb2),
        inv = fw.invert();

    arcs.transformPoints(function(x, y) {
      var p = fw.transform(x, y);
      return inv.transform(Math.round(p[0]), Math.round(p[1]));
    });
  }

  var PathUtils = /*#__PURE__*/Object.freeze({
    __proto__: null,
    getAvgSegment: getAvgSegment,
    getAvgSegment2: getAvgSegment2,
    getDirectedArcPresenceTest: getDirectedArcPresenceTest,
    getArcPresenceTest: getArcPresenceTest,
    countArcsInShapes: countArcsInShapes,
    getPathBounds: getPathBounds,
    findShapesByArcId: findShapesByArcId,
    reversePath: reversePath,
    clampIntervalByPct: clampIntervalByPct,
    findNextRemovableVertex: findNextRemovableVertex,
    forEachArcId: forEachArcId,
    forEachSegmentInShape: forEachSegmentInShape,
    forEachSegmentInPath: forEachSegmentInPath,
    traversePaths: traversePaths,
    filterEmptyArcs: filterEmptyArcs,
    getPathMetadata: getPathMetadata,
    quantizeArcs: quantizeArcs
  });

  // Utility functions for both paths and points

  // @shp An element of the layer.shapes array
  //   (may be null, or, depending on layer type, an array of points or an array of arrays of arc ids)
  function cloneShape(shp) {
    if (!shp) return null;
    return shp.map(function(part) {
      return part.concat();
    });
  }

  function cloneShapes(arr) {
    return utils.isArray(arr) ? arr.map(cloneShape) : null;
  }

  function forEachShapePart(paths, cb) {
    editShapeParts(paths, cb);
  }

  // Updates shapes array in-place.
  // editPart: callback function
  function editShapes(shapes, editPart) {
    for (var i=0, n=shapes.length; i<n; i++) {
      shapes[i] = editShapeParts(shapes[i], editPart);
    }
  }

  // @parts: geometry of a feature (array of paths, array of points or null)
  // @cb: function(part, i, parts)
  //    If @cb returns an array, it replaces the existing value
  //    If @cb returns null, the path is removed from the feature
  //
  function editShapeParts(parts, cb) {
    if (!parts) return null; // null geometry not edited
    if (!utils.isArray(parts)) error("Expected an array, received:", parts);
    var nulls = 0,
        n = parts.length,
        retn;

    for (var i=0; i<n; i++) {
      retn = cb(parts[i], i, parts);
      if (retn === null) {
        nulls++;
        parts[i] = null;
      } else if (utils.isArray(retn)) {
        parts[i] = retn;
      }
    }
    if (nulls == n) {
      return null;
    } else if (nulls > 0) {
      return parts.filter(function(part) {return !!part;});
    } else {
      return parts;
    }
  }

  // Get max number of parts in a single shape from an array of shapes.
  // Caveat: polygon holes are counted as separate parts.
  function findMaxPartCount(shapes) {
    var maxCount = 0, shp;
    for (var i=0, n=shapes.length; i<n; i++) {
      shp = shapes[i];
      if (shp && shp.length > maxCount) {
        maxCount = shp.length;
      }
    }
    return maxCount;
  }

  var ShapeUtils = /*#__PURE__*/Object.freeze({
    __proto__: null,
    cloneShape: cloneShape,
    cloneShapes: cloneShapes,
    forEachShapePart: forEachShapePart,
    editShapes: editShapes,
    editShapeParts: editShapeParts,
    findMaxPartCount: findMaxPartCount
  });

  // Several dependencies are loaded via require() ... this module returns a
  // stub function when require() does not exist as a global function,
  // to avoid runtime errors (this should only happen in some tests when single
  // modules are imported)
  var f;
  if (typeof require == 'function') {
    f = require;
  } else {
    f = function() {
      // console.error('Unable to load module', name);
    };
  }
  var require$1 = f;

  var iconv = require$1('iconv-lite');

  // import iconv from 'iconv-lite';
  // import * as iconv from 'iconv-lite';
  // import * as iconv from '../../node_modules/iconv-lite/lib/index.js';

  // List of encodings supported by iconv-lite:
  // https://github.com/ashtuchkin/iconv-lite/wiki/Supported-Encodings

  var toUtf8 = getNativeEncoder('utf8');
  var fromUtf8 = getNativeDecoder('utf8');

  // Return list of supported encodings
  function getEncodings() {
    iconv.encodingExists('ascii'); // make iconv load its encodings
    return Object.keys(iconv.encodings);
  }

  function validateEncoding(enc) {
    if (!encodingIsSupported(enc)) {
      stop("Unknown encoding:", enc, "\nRun the -encodings command see a list of supported encodings");
    }
    return enc;
  }

  function stringsAreAscii(arr) {
    return stringIsAscii(arr.join(''));
  }

  function stringIsAscii(str) {
    var c;
    for (var i=0, n=str.length; i<n; i++) {
      c = str.charCodeAt(i);
      if (c >= 128) return false;
    }
    return true;
  }

  function encodingIsUtf8(enc) {
    // treating utf-8 as default
    return !enc || /^utf-?8$/i.test(String(enc));
  }

  // Identify the most common encodings that are supersets of ascii at the
  // single-byte level (meaning that bytes in 0 - 0x7f range must be ascii)
  // (this allows identifying line breaks and other ascii patterns in buffers)
  function encodingIsAsciiCompat(enc) {
    enc = standardizeEncodingName(enc);
    // gb.* selects the Guo Biao encodings
    // big5 in not compatible -- second byte starts at 0x40
    return !enc || /^(win|latin|utf8|ascii|iso88|gb)/.test(enc);
  }

  // Ex. convert UTF-8 to utf8
  function standardizeEncodingName(enc) {
    return (enc || '').toLowerCase().replace(/[_-]/g, '');
  }

  // Similar to Buffer#toString(); tries to speed up utf8 conversion in
  // web browser (when using browserify Buffer shim)
  function bufferToString(buf, enc, start, end) {
    if (start >= 0) {
      buf = buf.slice(start, end);
    }
    return decodeString(buf, enc);
  }

  function getNativeEncoder(enc) {
    var encoder = null;
    enc = standardizeEncodingName(enc);
    if (enc != 'utf8') {
      // TODO: support more encodings if TextEncoder is available
      return null;
    }
    if (typeof TextEncoder != 'undefined') {
      encoder = new TextEncoder(enc);
    }
    return function(str) {
      // Convert Uint8Array from encoder to Buffer (fix for issue #216)
      return encoder ? B$3.from(encoder.encode(str).buffer) : utils.createBuffer(str, enc);
    };
  }

  function encodeString(str, enc) {
    // TODO: faster ascii encoding?
    var buf;
    if (encodingIsUtf8(enc)) {
      buf = toUtf8(str);
    } else {
      buf = iconv.encode(str, enc);
    }
    return buf;
  }

  function getNativeDecoder(enc) {
    var decoder = null;
    enc = standardizeEncodingName(enc);
    if (enc != 'utf8') {
      // TODO: support more encodings if TextDecoder is available
      return null;
    }
    if (typeof TextDecoder != 'undefined') {
      decoder = new TextDecoder(enc);
    }
    return function(buf) {
      return decoder ? decoder.decode(buf) : buf.toString(enc);
    };
  }

  // @buf a Node Buffer
  function decodeString(buf, enc) {
    var str;
    if (encodingIsUtf8(enc)) {
      str = fromUtf8(buf);
    } else {
      str = iconv.decode(buf, enc);
    }
    return str;
  }

  function encodingIsSupported(raw) {
    var enc = standardizeEncodingName(raw);
    return getEncodings().includes(enc);
  }

  function trimBOM(str) {
    // remove BOM if present
    if (str.charCodeAt(0) == 0xfeff) {
      str = str.substr(1);
    }
    return str;
  }

  function printEncodings() {
    var encodings = getEncodings().filter(function(name) {
      // filter out some aliases and non-applicable encodings
      return !/^(_|cs|internal|ibm|isoir|singlebyte|table|[0-9]|l[0-9]|windows)/.test(name);
    });
    encodings.sort();
    print("Supported encodings:\n" + formatStringsAsGrid(encodings));
  }

  var Encodings = /*#__PURE__*/Object.freeze({
    __proto__: null,
    getEncodings: getEncodings,
    validateEncoding: validateEncoding,
    stringsAreAscii: stringsAreAscii,
    stringIsAscii: stringIsAscii,
    encodingIsUtf8: encodingIsUtf8,
    encodingIsAsciiCompat: encodingIsAsciiCompat,
    standardizeEncodingName: standardizeEncodingName,
    bufferToString: bufferToString,
    encodeString: encodeString,
    decodeString: decodeString,
    encodingIsSupported: encodingIsSupported,
    trimBOM: trimBOM,
    printEncodings: printEncodings
  });

  // Not a general-purpose deep copy function
  function copyRecord(o) {
    var o2 = {}, key, val;
    if (!o) return null;
    for (key in o) {
      if (o.hasOwnProperty(key)) {
        val = o[key];
        if (val == o) {
          // avoid infinite recursion if val is a circular reference, by copying all properties except key
          val = utils.extend({}, val);
          delete val[key];
        }
        o2[key] = val && val.constructor === Object ? copyRecord(val) : val;
      }
    }
    return o2;
  }

  function getValueType(val) {
    var type = null;
    if (utils.isString(val)) {
      type = 'string';
    } else if (utils.isNumber(val)) {
      type = 'number';
    } else if (utils.isBoolean(val)) {
      type = 'boolean';
    } else if (utils.isDate(val)) {
      type = 'date';
    } else if (utils.isObject(val)) {
      type = 'object';
    }
    return type;
  }

  // Fill out a data table with undefined values
  // The undefined members will disappear when records are exported as JSON,
  // but will show up when fields are listed using Object.keys()
  function fixInconsistentFields(records) {
    var fields = findIncompleteFields(records);
    patchMissingFields(records, fields);
  }

  function findIncompleteFields(records) {
    var counts = {},
        i, j, keys;
    for (i=0; i<records.length; i++) {
      keys = Object.keys(records[i] || {});
      for (j=0; j<keys.length; j++) {
        counts[keys[j]] = (counts[keys[j]] | 0) + 1;
      }
    }
    return Object.keys(counts).filter(function(k) {return counts[k] < records.length;});
  }

  function patchMissingFields(records, fields) {
    var rec, i, j, f;
    for (i=0; i<records.length; i++) {
      rec = records[i] || (records[i] = {});
      for (j=0; j<fields.length; j++) {
        f = fields[j];
        if (f in rec === false) {
          rec[f] = undefined;
        }
      }
    }
  }

  function fieldListContainsAll(list, fields) {
    return list.indexOf('*') > -1 || utils.difference(fields, list).length === 0;
  }

  function getColumnType(key, records) {
    var type = null,
        rec;
    for (var i=0, n=records.length; i<n; i++) {
      rec = records[i];
      type = rec ? getValueType(rec[key]) : null;
      if (type) break;
    }
    return type;
  }

  function deleteFields(table, test) {
    table.getFields().forEach(function(name) {
      if (test(name)) {
        table.deleteField(name);
      }
    });
  }

  function isInvalidFieldName(f) {
    // Reject empty and all-whitespace strings. TODO: consider other criteria
    return /^\s*$/.test(f);
  }

  // Resolve name conflicts in field names by appending numbers
  // @fields Array of field names
  // @maxLen (optional) Maximum chars in name
  //
  function getUniqFieldNames(fields, maxLen, encoding) {
    var used = {};
    return fields.map(function(name) {
      var i = 0,
          validName;
      do {
        validName = encoding && encoding != 'ascii' ?
          adjustEncodedFieldName(name, maxLen, i, encoding) :
          adjustFieldName(name, maxLen, i);
        i++;
      } while ((validName in used) ||
        // don't replace an existing valid field name with a truncated name
        name != validName && utils.contains(fields, validName));
      used[validName] = true;
      return validName;
    });
  }

  function getFieldValues(records, field) {
    return records.map(function(rec) {
      return rec ? rec[field] : undefined;
    });
  }

  function getUniqFieldValues(records, field) {
    var index = {};
    var values = [];
    records.forEach(function(rec) {
      var val = rec[field];
      if (val in index === false) {
        index[val] = true;
        values.push(val);
      }
    });
    return values;
  }

  // Truncate and/or uniqify a name (if relevant params are present)
  function adjustFieldName(name, maxLen, i) {
    var name2, suff;
    maxLen = maxLen || 256;
    if (!i) {
      name2 = name.substr(0, maxLen);
    } else {
      suff = String(i);
      if (suff.length == 1) {
        suff = '_' + suff;
      }
      name2 = name.substr(0, maxLen - suff.length) + suff;
    }
    return name2;
  }

  // Truncate and/or uniqify a name (if relevant params are present)
  function adjustEncodedFieldName(name, maxLen, i, encoding) {
    var suff = i ? String(i) : '';
    var name2 = name + suff;
    var buf = encodeString(name2, encoding);
    if (buf.length > (maxLen || 256)) {
      name = name.substr(0, name.length - 1);
      return adjustEncodedFieldName(name, maxLen, i, encoding);
    }
    return name2;
  }

  function applyFieldOrder(arr, option) {
    if (option == 'ascending') {
      arr.sort(function(a, b) {
        return a.toLowerCase() < b.toLowerCase() ? -1 : 1;
      });
    }
    return arr;
  }

  function getFirstNonEmptyRecord(records) {
    for (var i=0, n=records ? records.length : 0; i<n; i++) {
      if (records[i]) return records[i];
    }
    return null;
  }

  function findFieldNames(records, order) {
    var first = getFirstNonEmptyRecord(records);
    var names = first ? Object.keys(first) : [];
    return applyFieldOrder(names, order);
  }


  function parseUnknownType(str) {
    var val = getInputParser('number')(str);
    if (val !== null) return val;
    val = getInputParser('object')(str);
    if (val !== null) return val;
    return str;
  }

  // used by GUI data editing
  function getInputParser(type) {
    return inputParsers[type || 'multiple'];
  }

  var inputParsers = {
    date: function(raw) {
      var d = new Date(raw);
      return isNaN(+d) ? null : d;
    },
    string: function(raw) {
      return raw;
    },
    number: function(raw) {
      var val = Number(raw);
      if (raw == 'NaN') {
        val = NaN;
      } else if (isNaN(val)) {
        val = null;
      }
      return val;
    },
    object: function(raw) {
      var val = null;
      try {
        val = JSON.parse(raw);
      } catch(e) {}
      return val;
    },
    boolean: function(raw) {
      var val = null;
      if (raw == 'true') {
        val = true;
      } else if (raw == 'false') {
        val = false;
      }
      return val;
    },
    multiple: function(raw) {
      var val = Number(raw);
      return isNaN(val) ? raw : val;
    }
  };

  var DataUtils = /*#__PURE__*/Object.freeze({
    __proto__: null,
    copyRecord: copyRecord,
    getValueType: getValueType,
    fixInconsistentFields: fixInconsistentFields,
    fieldListContainsAll: fieldListContainsAll,
    getColumnType: getColumnType,
    deleteFields: deleteFields,
    isInvalidFieldName: isInvalidFieldName,
    getUniqFieldNames: getUniqFieldNames,
    getFieldValues: getFieldValues,
    getUniqFieldValues: getUniqFieldValues,
    applyFieldOrder: applyFieldOrder,
    getFirstNonEmptyRecord: getFirstNonEmptyRecord,
    findFieldNames: findFieldNames,
    parseUnknownType: parseUnknownType,
    getInputParser: getInputParser
  });

  function DataTable(obj) {
    var records;
    if (utils.isArray(obj)) {
      records = obj;
    } else {
      records = [];
      // integer object: create empty records
      if (utils.isInteger(obj)) {
        for (var i=0; i<obj; i++) {
          records.push({});
        }
      } else if (obj) {
        error("Invalid DataTable constructor argument:", obj);
      }
    }

    this.getRecords = function() {
      return records;
    };

    // Same-name method in ShapefileTable doesn't require parsing the entire DBF file
    this.getReadOnlyRecordAt = function(i) {
      return copyRecord(records[i]); // deep-copies plain objects but not other constructed objects
    };
  }

  DataTable.prototype = {

    fieldExists: function(name) {
      return utils.contains(this.getFields(), name);
    },

    toString: function() {return JSON.stringify(this);},

    toJSON: function() {
      return this.getRecords();
    },

    addField: function(name, init) {
      var useFunction = utils.isFunction(init);
      if (!utils.isNumber(init) && !utils.isString(init) && !useFunction) {
        error("DataTable#addField() requires a string, number or function for initialization");
      }
      if (this.fieldExists(name)) error("DataTable#addField() tried to add a field that already exists:", name);
      // var dataFieldRxp = /^[a-zA-Z_][a-zA-Z_0-9]*$/;
      // if (!dataFieldRxp.test(name)) error("DataTable#addField() invalid field name:", name);

      this.getRecords().forEach(function(obj, i) {
        obj[name] = useFunction ? init(obj, i) : init;
      });
    },

    getRecordAt: function(i) {
      return this.getRecords()[i];
    },

    addIdField: function() {
      this.addField('FID', function(obj, i) {
        return i;
      });
    },

    deleteField: function(f) {
      this.getRecords().forEach(function(o) {
        delete o[f];
      });
    },

    getFields: function() {
      return findFieldNames(this.getRecords());
    },

    isEmpty: function() {
      return this.getFields().length === 0 || this.size() === 0;
    },

    update: function(f) {
      var records = this.getRecords();
      for (var i=0, n=records.length; i<n; i++) {
        records[i] = f(records[i], i);
      }
    },

    clone: function() {
      // TODO: this could be sped up using a record constructor function
      // (see getRecordConstructor() in DbfReader)
      var records2 = this.getRecords().map(copyRecord);
      return new DataTable(records2);
    },

    size: function() {
      return this.getRecords().length;
    }
  };

  // TODO: make this stricter (could give false positive on some degenerate paths)
  function pathIsRectangle(ids, arcs) {
    var bbox = arcs.getSimpleShapeBounds(ids).toArray();
    var iter = arcs.getShapeIter(ids);
    var count = 0;
    while (iter.hasNext()) {
      if (iter.x != bbox[0] && iter.x != bbox[2] ||
          iter.y != bbox[1] && iter.y != bbox[3]) {
        return false;
      }
      count++;
    }
    if (count < 5) return false;
    if (bbox[2] > bbox[0] === false || bbox[3] > bbox[1] === false) return false;
    return true;
  }

  function bboxToCoords(bbox) {
    return [[bbox[0], bbox[1]], [bbox[0], bbox[3]], [bbox[2], bbox[3]],
        [bbox[2], bbox[1]], [bbox[0], bbox[1]]];
  }

  var RectangleUtils = /*#__PURE__*/Object.freeze({
    __proto__: null,
    pathIsRectangle: pathIsRectangle,
    bboxToCoords: bboxToCoords
  });

  // Insert a column of values into a (new or existing) data field
  function insertFieldValues(lyr, fieldName, values) {
    var size = getFeatureCount(lyr) || values.length,
        table = lyr.data = (lyr.data || new DataTable(size)),
        records = table.getRecords(),
        rec, val;

    for (var i=0, n=records.length; i<n; i++) {
      rec = records[i];
      val = values[i];
      if (!rec) rec = records[i] = {};
      rec[fieldName] = val === undefined ? null : val;
    }
  }

  function getLayerDataTable(lyr) {
    var data = lyr.data;
    if (!data) {
      data = lyr.data = new DataTable(lyr.shapes ? lyr.shapes.length : 0);
    }
    return data;
  }

  function layerHasAttributeData(lyr) {
    return lyr.data && lyr.data.getFields().length > 0;
  }

  function layerHasNonNullData(lyr) {
    return lyr.data && getFirstNonEmptyRecord(lyr.data.getRecords()) ? true : false;
  }

  function layerHasGeometry(lyr) {
    return layerHasPaths(lyr) || layerHasPoints(lyr);
  }

  function layerIsGeometric(lyr) {
    return !!lyr.geometry_type; // only checks type, includes empty layers
  }

  function layerHasPaths(lyr) {
    return (lyr.geometry_type == 'polygon' || lyr.geometry_type == 'polyline') &&
      layerHasNonNullShapes(lyr);
  }

  function layerHasPoints(lyr) {
    return lyr.geometry_type == 'point' && layerHasNonNullShapes(lyr);
  }

  function layerIsRectangle(lyr, arcs) {
    return layerOnlyHasRectangles(lyr, arcs) && lyr.shapes.length == 1;
  }

  function layerOnlyHasRectangles(lyr, arcs) {
    if (!layerHasPaths(lyr)) return false;
    if (countMultiPartFeatures(lyr) > 0) return false;
    return lyr.shapes.every(function(shp) {
      if (!shp) return true;
      return pathIsRectangle(shp[0], arcs);
    });
  }

  function layerHasNonNullShapes(lyr) {
    return utils.some(lyr.shapes || [], function(shp) {
      return !!shp;
    });
  }

  function deleteFeatureById(lyr, i) {
    if (lyr.shapes) lyr.shapes.splice(i, 1);
    if (lyr.data) lyr.data.getRecords().splice(i, 1);
  }

  // TODO: move elsewhere (moved here from mapshaper-point-utils to avoid circular dependency)
  function transformPointsInLayer(lyr, f) {
    if (layerHasPoints(lyr)) {
      forEachPoint(lyr.shapes, function(p) {
        var p2 = f(p[0], p[1]);
        p[0] = p2[0];
        p[1] = p2[1];
      });
    }
  }

  function getFeatureCount(lyr) {
    var count = 0;
    if (lyr.data) {
      count = lyr.data.size();
    } else if (lyr.shapes) {
      count = lyr.shapes.length;
    }
    return count;
  }

  function layerIsEmpty(lyr) {
    return getFeatureCount(lyr) == 0;
  }

  function requireDataField(obj, field, msg) {
    var data = obj.fieldExists ? obj : obj.data; // accept layer or DataTable
    if (!field) stop('Missing a field parameter');
    if (!data || !data.fieldExists(field)) {
      stop(msg || 'Missing a field named:', field);
    }
  }

  function requireDataFields(table, fields) {
    if (!fields || !fields.length) return;
    if (!table) {
      stop("Missing attribute data");
    }
    var dataFields = table.getFields(),
        missingFields = utils.difference(fields, dataFields);
    if (missingFields.length > 0) {
      stop("Table is missing one or more fields:\n",
          missingFields, "\nExisting fields:", '\n' + formatStringsAsGrid(dataFields));
    }
  }

  function layerTypeMessage(lyr, defaultMsg, customMsg) {
    var msg;
    // check that custom msg is a string (could be an index if require function is called by forEach)
    if (customMsg && utils.isString(customMsg)) {
      msg = customMsg;
    } else {
      msg = defaultMsg + ', ';
      if (!lyr || !lyr.geometry_type) {
        msg += 'received a layer with no geometry';
      } else {
        msg += 'received a ' + lyr.geometry_type + ' layer';
      }
    }
    return msg;
  }

  function requirePointLayer(lyr, msg) {
    if (!lyr || lyr.geometry_type !== 'point')
      stop(layerTypeMessage(lyr, "Expected a point layer", msg));
  }

  function requireSinglePointLayer(lyr, msg) {
    requirePointLayer(lyr);
    if (countMultiPartFeatures(lyr) > 0) {
      stop(msg || 'This command requires single points; layer contains multi-point features.');
    }
  }

  function requirePolylineLayer(lyr, msg) {
    if (!lyr || lyr.geometry_type !== 'polyline')
      stop(layerTypeMessage(lyr, "Expected a polyline layer", msg));
  }

  function requirePolygonLayer(lyr, msg) {
    if (!lyr || lyr.geometry_type !== 'polygon')
      stop(layerTypeMessage(lyr, "Expected a polygon layer", msg));
  }

  function requirePathLayer(lyr, msg) {
    if (!lyr || !layerHasPaths(lyr))
      stop(layerTypeMessage(lyr, "Expected a polygon or polyline layer", msg));
  }

  // Used by info command and gui layer menu
  function getLayerSourceFile(lyr, dataset) {
    var inputs = dataset.info && dataset.info.input_files;
    return inputs && inputs[0] || '';
  }

  // Divide a collection of features with mixed types into layers of a single type
  // (Used for importing TopoJSON and GeoJSON features)
  function divideFeaturesByType(shapes, properties, types) {
    var typeSet = utils.uniq(types);
    var layers = typeSet.map(function(geoType) {
      var p = [],
          s = [],
          dataNulls = 0,
          rec;

      for (var i=0, n=shapes.length; i<n; i++) {
        if (types[i] != geoType) continue;
        if (geoType) s.push(shapes[i]);
        rec = properties[i];
        p.push(rec);
        if (!rec) dataNulls++;
      }
      return {
        geometry_type: geoType,
        shapes: s,
        data: dataNulls < p.length ? new DataTable(p) : null
      };
    });
    return layers;
  }

  // make a stub copy if the no_replace option is given, else pass thru src layer
  function getOutputLayer(src, opts) {
    return opts && opts.no_replace ? {geometry_type: src.geometry_type} : src;
  }

  //
  function setOutputLayerName(dest, src, defName, opts) {
    opts = opts || {};
    if (opts.name) {
      dest.name = opts.name;
    } else if (opts.no_replace) {
      dest.name = defName || undefined;
    } else {
      dest.name = src && src.name || defName || undefined;
    }
  }

  // Make a deep copy of a layer
  function copyLayer(lyr) {
    var copy = copyLayerShapes(lyr);
    if (copy.data) {
      copy.data = copy.data.clone();
    }
    return copy;
  }

  // Make a shallow copy of a path layer; replace layer.shapes with an array that is
  // filtered to exclude paths containing any of the arc ids contained in arcIds.
  // arcIds: an array of (non-negative) arc ids to exclude
  function filterPathLayerByArcIds(pathLyr, arcIds) {
    var index = arcIds.reduce(function(memo, id) {
      memo[id] = true;
      return memo;
    }, {});
    // deep copy shapes; this could be optimized to only copy shapes that are modified
    var shapes = cloneShapes(pathLyr.shapes);
    editShapes(shapes, onPath); // remove paths that are missing shapes
    return utils.defaults({shapes: shapes}, pathLyr);

    function onPath(path) {
      for (var i=0; i<path.length; i++) {
        if (absArcId(path[i]) in index) {
          return null;
        }
      }
      return path;
    }
  }

  function copyLayerShapes(lyr) {
    var copy = utils.extend({}, lyr);
    if (lyr.shapes) {
      copy.shapes = cloneShapes(lyr.shapes);
    }
    return copy;
  }

  function countMultiPartFeatures(shapes) {
    var count = 0;
    for (var i=0, n=shapes.length; i<n; i++) {
      if (shapes[i] && shapes[i].length > 1) count++;
    }
    return count;
  }

  // moving this here from mapshaper-path-utils to avoid circular dependency
  function getArcPresenceTest2(layers, arcs) {
    var counts = countArcsInLayers(layers, arcs);
    return function(arcId) {
      return counts[absArcId(arcId)] > 0;
    };
  }

  // Count arcs in a collection of layers
  function countArcsInLayers(layers, arcs) {
    var counts = new Uint32Array(arcs.size());
    layers.filter(layerHasPaths).forEach(function(lyr) {
      countArcsInShapes(lyr.shapes, counts);
    });
    return counts;
  }

  // Returns a Bounds object
  function getLayerBounds(lyr, arcs) {
    var bounds = null;
    if (lyr.geometry_type == 'point') {
      bounds = getPointBounds$1(lyr.shapes);
    } else if (lyr.geometry_type == 'polygon' || lyr.geometry_type == 'polyline') {
      bounds = getPathBounds(lyr.shapes, arcs);
    } else ;
    return bounds;
  }

  function isolateLayer(layer, dataset) {
    return utils.defaults({
      layers: dataset.layers.filter(function(lyr) {return lyr == layer;})
    }, dataset);
  }

  function initDataTable(lyr) {
    lyr.data = new DataTable(getFeatureCount(lyr));
  }

  var LayerUtils = /*#__PURE__*/Object.freeze({
    __proto__: null,
    insertFieldValues: insertFieldValues,
    getLayerDataTable: getLayerDataTable,
    layerHasAttributeData: layerHasAttributeData,
    layerHasNonNullData: layerHasNonNullData,
    layerHasGeometry: layerHasGeometry,
    layerIsGeometric: layerIsGeometric,
    layerHasPaths: layerHasPaths,
    layerHasPoints: layerHasPoints,
    layerIsRectangle: layerIsRectangle,
    layerOnlyHasRectangles: layerOnlyHasRectangles,
    layerHasNonNullShapes: layerHasNonNullShapes,
    deleteFeatureById: deleteFeatureById,
    transformPointsInLayer: transformPointsInLayer,
    getFeatureCount: getFeatureCount,
    layerIsEmpty: layerIsEmpty,
    requireDataField: requireDataField,
    requireDataFields: requireDataFields,
    layerTypeMessage: layerTypeMessage,
    requirePointLayer: requirePointLayer,
    requireSinglePointLayer: requireSinglePointLayer,
    requirePolylineLayer: requirePolylineLayer,
    requirePolygonLayer: requirePolygonLayer,
    requirePathLayer: requirePathLayer,
    getLayerSourceFile: getLayerSourceFile,
    divideFeaturesByType: divideFeaturesByType,
    getOutputLayer: getOutputLayer,
    setOutputLayerName: setOutputLayerName,
    copyLayer: copyLayer,
    filterPathLayerByArcIds: filterPathLayerByArcIds,
    copyLayerShapes: copyLayerShapes,
    countMultiPartFeatures: countMultiPartFeatures,
    getArcPresenceTest2: getArcPresenceTest2,
    countArcsInLayers: countArcsInLayers,
    getLayerBounds: getLayerBounds,
    isolateLayer: isolateLayer,
    initDataTable: initDataTable
  });

  // A matrix class that supports affine transformations (scaling, translation, rotation).
  // Elements:
  //   a  c  tx
  //   b  d  ty
  //   0  0  1  (u v w are not used)
  //
  function Matrix2D() {
    this.a = 1;
    this.c = 0;
    this.tx = 0;
    this.b = 0;
    this.d = 1;
    this.ty = 0;
  }

  Matrix2D.prototype.transformXY = function(x, y, p) {
    p = p || {};
    p.x = x * this.a + y * this.c + this.tx;
    p.y = x * this.b + y * this.d + this.ty;
    return p;
  };

  Matrix2D.prototype.translate = function(dx, dy) {
    this.tx += dx;
    this.ty += dy;
  };

  // x, y: optional origin
  Matrix2D.prototype.rotate = function(q, x, y) {
    var cos = Math.cos(q);
    var sin = Math.sin(q);
    x = x || 0;
    y = y || 0;
    this.a = cos;
    this.c = -sin;
    this.b = sin;
    this.d = cos;
    this.tx += x - x * cos + y * sin;
    this.ty += y - x * sin - y * cos;
  };

  // cx, cy: optional origin
  Matrix2D.prototype.scale = function(sx, sy, cx, cy) {
    cx = cx || 0;
    cy = cy || 0;
    this.a *= sx;
    this.c *= sx;
    this.b *= sy;
    this.d *= sy;
    this.tx -= cx * (sx - 1);
    this.ty -= cy * (sy - 1);
  };

  var mproj$1 = require$1('mproj');

  // Constructor function for a compound projection consisting of a default
  //   projection and one or more rectangular frames that are projected separately
  //   and affine transformed.
  // @mainParams: parameters for main projection, including:
  //    proj: Proj string
  //    bbox: lat-lon bounding box
  // Returns a mproj CRS object for the main CRS with the CRS objects of the
  //    embedded projections attached.
  function MixedProjection(mainParams, options) {
    var mainFrame = initFrame(mainParams);
    var mainP = mainFrame.crs;
    var frames = [mainFrame];
    var mixedP = initMixedProjection(mproj$1);

    // This CRS masquerades as the main projection... the version with
    // custom insets is exposed to savvy users
    mainP.__mixed_crs = mixedP;

    // required opts:
    //    origin: [lng, lat] origin of frame (unprojected)
    //    placement: [x, y] location (in projected coordinates) to shift the origin
    //    proj: Proj.4 string for projecting data within the frame
    //    bbox: Lat-long bounding box of frame area
    //
    // optional:
    //    dx: x shift (meters)
    //    dy: y shift (meters)
    //    scale: scale factor (1 = no scaling)
    //    rotation: rotation in degrees (0 = no rotation)
    //
    mainP.addFrame = function(paramsArg) {
      var params = getFrameParams(paramsArg, options); // apply defaults and overrides
      var frame = initFrame(params);
      var m = new Matrix2D();
      //  originXY: the projected coordinates of the frame origin
      var originXY = params.origin ? projectFrameOrigin(params.origin, frame.crs) : [0, 0];
      var placementXY = params.placement || [0, 0];
      var dx = placementXY[0] - originXY[0] + (+params.dx || 0);
      var dy = placementXY[1] - originXY[1] + (+params.dy || 0);

      if (params.rotation) {
        m.rotate(params.rotation * Math.PI / 180.0, originXY[0], originXY[1]);
      }
      if (params.scale) {
        m.scale(params.scale, params.scale, originXY[0], originXY[1]);
      }
      m.translate(dx, dy);

      frame.matrix = m;
      frames.push(frame);
      return this;
    };

    function initFrame(params) {
      return {
        bounds: new Bounds(bboxToRadians(params.bbox)),
        crs:  mproj$1.pj_init(params.proj)
      };
    }

    function bboxToRadians(bbox) {
      var D2R = Math.PI / 180;
      return bbox.map(function(deg) {
        return deg * D2R;
      });
    }

    function projectFrameOrigin(origin, P) {
      var xy = mproj$1.pj_fwd_deg({lam: origin[0], phi: origin[1]}, P);
      return [xy.x, xy.y];
    }

    mixedP.fwd = function(lp, xy) {
      var frame, xy2;
      for (var i=0, n=frames.length; i<n; i++) {
        frame = frames[i];
        if (frame.bounds.containsPoint(lp.lam, lp.phi)) {
          xy2 = mproj$1.pj_fwd(lp, frame.crs);
          if (frame.matrix) {
            frame.matrix.transformXY(xy2.x, xy2.y, xy2);
          }
          break;
        }
      }
      xy.x = xy2 ? xy2.x : Infinity;
      xy.y = xy2 ? xy2.y : Infinity;
    };

    return mainP;
  }

  function initMixedProjection(mproj) {
    if (!mproj.internal.pj_list.mixed) {
      mproj.pj_add(function(P) {
        P.a = 1;
      }, 'mixed', 'Mapshaper Mixed Projection');
    }
    return mproj.pj_init('+proj=mixed');
  }

  function getFrameParams (params, options) {
    var opts = options[params.name];
    utils.defaults(params, {scale: 1, dx: 0, dy: 0, rotation: 0}); // add defaults
    if (!opts) return params;
    Object.keys(opts).forEach(function(key) {
      var val = opts[key];
      if (key in params) {
        params[key] = opts[key];
      } else {
        params.proj = replaceProjParam(params.proj, key, val);
      }
    });
    return params;
  }

  function replaceProjParam(proj, key, val) {
    var param = '+' + key + '=';
    return proj.split(' ').map(function(str) {
      if (str.indexOf(param) === 0) {
        str = str.substr(0, param.length) + val;
      }
      return str;
    }).join(' ');
  }

  // str: a custom projection string, e.g.: "albersusa +PR"
  function parseCustomProjection(str) {
    var parts = str.trim().split(/ +/);
    var params = [];
    var names = parts.filter(function(part) {
      if (/^\+/.test(part)) {
        params.push(part.substr(1)); // strip '+'
        return false;
      }
      return true;
    });
    var name = names[0];
    var opts = parseCustomParams(params);
    if (names.length != 1) return null; // parse error if other than one name found
    return getCustomProjection(name, opts);
  }

  // returns a custom projection object
  function getCustomProjection(name, opts) {
    if (name == 'albersusa') {
      return new AlbersUSA(opts);
    }
    return null;
  }

  function AlbersUSA(optsArg) {
    var opts = optsArg || {};
    var main = {
      proj: '+proj=aea +lon_0=-96 +lat_0=37.5 +lat_1=29.5 +lat_2=45.5',
      bbox: [-129,23,-62,52]
    };
    var AK = {
      name: 'AK',
      proj: '+proj=aea +lat_1=55 +lat_2=70 +lat_0=65 +lon_0=-148 +x_0=0 +y_0=0',
      bbox: [-172.26,50.89,-127.00,73.21],
      origin: [-152, 63],
      placement: [-1882782,-969242],
      scale: 0.37
    };
    var HI = {
      name: 'HI',
      proj: '+proj=aea +lat_1=19 +lat_2=24 +lat_0=20.9 +lon_0=-156.5 +x_0=0 +y_0=0',
      bbox: [-160.50,18.72,-154.57,22.58],
      origin: [-157, 21],
      placement: [-1050326,-1055362]
    };
    var PR = {
      name: 'PR',
      proj: '+proj=aea +lat_1=18 +lat_2=18.43 +lat_0=17.83 +lon_0=-66.43 +x_0=0 +y_0=0',
      bbox: [-68.092,17.824,-65.151,18.787],
      origin: [-66.431, 18.228],
      placement: [1993101,-1254517]
    };
    var VI = {
      name: 'VI',
      // same projection and origin as PR, so they maintain their true geographical relationship
      proj: '+proj=aea +lat_1=18 +lat_2=18.43 +lat_0=17.83 +lon_0=-66.43 +x_0=0 +y_0=0',
      bbox: [-65.104,17.665,-64.454,18.505],
      origin: [-66.431, 18.228],
      placement: [1993101,-1254517]
    };
    var mixed = new MixedProjection(main, opts)
      .addFrame(AK)
      .addFrame(HI);
    if (opts.PR) {
      mixed.addFrame(PR);
    }
    if (opts.VI) {
      mixed.addFrame(VI);
    }
    return mixed;
  }


  function parseCustomParams(arr) {
    var opts = {};
    arr.forEach(function(str) {
      parseCustomParam(str, opts);
    });
    return opts;
  }

  function parseCustomParam(str, opts) {
    var parts = str.split('=');
    var path = parts[0].split('.');
    var key = path.pop();
    var obj = path.reduce(function(memo, name) {
      if (name in memo === false) {
        memo[name] = {};
      } else if (!utils.isObject(memo[name])) {
        return {};// error condition, could display a warning
      }
      return memo[name];
    }, opts);
    if (parts.length > 1) {
      obj[key] = parseCustomParamValue(parts[1]);
    } else if (key in obj === false && !path.length) {
      // e.g. convert string 'PR' into {PR: {}} (empty object),
      // to show PR with default properties
      obj[key] = {};
    }
  }

  function parseCustomParamValue(str) {
    var val;
    if (str.indexOf(',') > 0) {
      val = str.split(',').map(parseFloat);
      // TODO: validate
      return val;
    }
    val = utils.parseNumber(str);
    if (val === null) {
      val = str;
    }
    return val;
  }

  var CustomProjections = /*#__PURE__*/Object.freeze({
    __proto__: null,
    parseCustomProjection: parseCustomProjection,
    AlbersUSA: AlbersUSA,
    parseCustomParams: parseCustomParams
  });

  function getWorldBounds(e) {
    e = utils.isFiniteNumber(e) ? e : 1e-10;
    return [-180 + e, -90 + e, 180 - e, 90 - e];
  }

  function probablyDecimalDegreeBounds(b) {
    var world = getWorldBounds(-1), // add a bit of excess
        bbox = (b instanceof Bounds) ? b.toArray() : b;
    return geom.containsBounds(world, bbox);
  }

  function clampToWorldBounds(b) {
    var bbox = (b instanceof Bounds) ? b.toArray() : b;
    return new Bounds().setBounds(Math.max(bbox[0], -180), Math.max(bbox[1], -90),
        Math.min(bbox[2], 180), Math.min(bbox[3], 90));
  }

  function getAntimeridian(lon0) {
    var anti = lon0 - 180;
    while (anti <= -180) anti += 360;
    return anti;
  }

  var LatLon = /*#__PURE__*/Object.freeze({
    __proto__: null,
    getWorldBounds: getWorldBounds,
    probablyDecimalDegreeBounds: probablyDecimalDegreeBounds,
    clampToWorldBounds: clampToWorldBounds,
    getAntimeridian: getAntimeridian
  });

  var mproj = require$1('mproj');

  var asyncLoader = null;

  var projectionAliases = {
    robinson: '+proj=robin +datum=WGS84',
    webmercator: '+proj=merc +a=6378137 +b=6378137',
    wgs84: '+proj=longlat +datum=WGS84',
    albersusa: AlbersUSA
  };

  async function initProjLibrary(opts) {
    if (asyncLoader) await asyncLoader(opts);
  }

  // used by web UI to support loading projection assets asyncronously
  function setProjectionLoader(loader) {
    asyncLoader = loader;
  }

  // Find Proj.4 definition file names in strings like "+init=epsg:3000"
  // (Used by GUI, defined here for testing)
  function findProjLibs(str) {
    var matches = str.match(/\b(esri|epsg|nad83|nad27)(?=:[0-9]+\b)/ig) || [];
    return utils.uniq(matches.map(function(str) {return str.toLowerCase();}));
  }

  // Returns a function for reprojecting [x, y] points; function throws an error
  // if the transformation fails
  // src, dest: proj4 objects
  function getProjTransform(src, dest) {
    var clampSrc = isLatLngCRS(src);
    dest = dest.__mixed_crs || dest;
    return function(x, y) {
      var xy;
      if (clampSrc) {
        // snap lng to bounds
        if (x < -180) x = -180;
        else if (x > 180) x = 180;
      }
      xy = [x, y];
      mproj.pj_transform_point(src, dest, xy);
      return xy;
    };
  }

  // Same as getProjTransform(), but return null if projection fails
  // (also faster)
  function getProjTransform2(src, dest) {
    var xx = [0],
        yy = [0],
        preK = src.is_latlong ? mproj.internal.DEG_TO_RAD : 1,
        postK = dest.is_latlong ? mproj.internal.RAD_TO_DEG : 1,
        clampSrc = isLatLngCRS(src);

    return function(x, y) {
      var fail;
      if (clampSrc) {
        // snap lng to bounds
        if (x < -180) x = -180;
        else if (x > 180) x = 180;
      }
      xx[0] = x * preK;
      yy[0] = y * preK;
      try {
        dest = dest.__mixed_crs || dest;
        mproj.pj_transform(src, dest, xx, yy);
        fail = xx[0] == Infinity; // mproj invalid coord value
      } catch(e) {
        fail = true;
      }
      return fail ? null : [xx[0] * postK, yy[0] * postK];
    };
  }

  function toLngLat(xy, P) {
    return projectPoint(xy, P, parseCrsString('wgs84'));
  }

  function projectPoint(xy, crsFrom, crsTo) {
    if (crsAreEqual(crsFrom, crsTo)) return xy.concat();
    var proj = getProjTransform2(crsFrom, crsTo);
    return proj(xy[0], xy[1]);
  }

  function getProjInfo(dataset) {
    var P, info;
    try {
      P = getDatasetCRS(dataset);
      if (P) {
        info = crsToProj4(P);
      }
    } catch(e) {}
    return info || "[unknown]";
  }

  function crsToProj4(P) {
    return mproj.internal.get_proj_defn(P);
  }

  function crsToPrj(P) {
    var wkt;
    try {
      wkt = mproj.internal.wkt_from_proj4(P);
    } catch(e) {
      // console.log(e)
    }
    return wkt;
  }

  function crsAreEqual(a, b) {
    var str = crsToProj4(a);
    return !!str && str == crsToProj4(b);
  }

  function isProjAlias(str) {
    return str in projectionAliases;
  }

  // str: projection string in a variety of forms accepted by the -proj command
  //   (e.g. alias, EPSG:XXXX, Proj.4 string, bare Proj.4 projection name)
  // Returns a properly formatted Proj.4 string or an instantiated mproj object
  function getProjDefn(str) {
    var defn;
    // prepend '+proj=' to bare proj names
    str = str.replace(/(^| )([\w]+)($| )/, function(a, b, c, d) {
      if (c in mproj.internal.pj_list) {
        return b + '+proj=' + c + d;
      }
      return a;
    });
    if (looksLikeProj4String(str)) {
      defn = str;
    } else if (isProjAlias(str)) {
      defn = projectionAliases[str];
      if (utils.isFunction(defn)) {
        defn = defn();
      }
    } else if (looksLikeInitString(str)) {
      defn = '+init=' + str.toLowerCase();
    } else if (str in (getStashedVar('defs') || {})) {
      // a proj4 alias could be dynamically created in a -calc expression
      defn = getStashedVar('defs')[str];
    } else {
      defn = parseCustomProjection(str);
    }
    if (!defn) {
      stop("Unknown projection definition:", str);
    }
    return defn;
  }

  function looksLikeInitString(str) {
    return /^(esri|epsg|nad83|nad27):[0-9]+$/i.test(String(str));
  }

  function looksLikeProj4String(str) {
    return /^(\+[^ ]+ *)+$/.test(str);
  }

  function getCrsInfo(str) {
    return {
      crs_string: str,
      crs: parseCrsString(str)
    };
  }

  function parseCrsString(str) {
    var defn = getProjDefn(str);  // defn is a string or a Proj object
    var P;
    if (!utils.isString(defn)) {
      P = defn;
    } else {
      try {
        P = mproj.pj_init(defn);
      } catch(e) {
        stop('Unable to use projection', defn, '(' + e.message + ')');
      }
    }
    return P || null;
  }

  function requireProjectedDataset(dataset) {
    if (isLatLngCRS(getDatasetCRS(dataset))) {
      stop("Command requires a target with projected coordinates (not lat-long)");
    }
  }

  // @info: info property of source dataset (instead of crs object, so wkt string
  //        can be preserved if present)
  function setDatasetCrsInfo(dataset, crsInfo) {
    crsInfo = crsInfo || {}; // also accepts null/unknown crs info
    dataset.info = dataset.info || {};
    // Assumes that proj4 object is never mutated.
    // TODO: assign a copy of crs (if present)
    dataset.info.crs = crsInfo.crs;
    dataset.info.prj = crsInfo.prj;
    dataset.info.crs_string = crsInfo.crs_string;
    return dataset;
  }

  function getDatasetCrsInfo(dataset) {
    var info = dataset.info || {},
        P = info.crs,
        str = info.crs_string;
    if (!P && info.prj) {
      P = parseCrsString(translatePrj(info.prj));
    }
    if (!P) {
      if (probablyDecimalDegreeBounds(getDatasetBounds(dataset))) {
        // use wgs84 for probable latlong datasets with unknown datums
        str = 'wgs84';
        P = parseCrsString(str);
      }
    }
    return {
      crs: P || null,
      crs_string: str,
      prj: info.prj
    };
  }

  function getDatasetCRS(dataset) {
    return getDatasetCrsInfo(dataset).crs;
  }

  function requireDatasetsHaveCompatibleCRS(arr, msg) {
    arr.reduce(function(memo, dataset) {
      var P = getDatasetCRS(dataset);
      if (memo && P) {
        if (isLatLngCRS(memo) != isLatLngCRS(P)) {
          stop(msg || "Unable to combine projected and unprojected datasets");
        }
      }
      return P || memo;
    }, null);
  }

  // Assumes conformal projections; consider returning average of vertical and
  // horizontal scale factors.
  // x, y: a point location in projected coordinates
  // Returns k, the ratio of coordinate distance to distance on the ground
  function getScaleFactorAtXY(x, y, crs) {
    var dist = 1 / crs.to_meter;
    var lp = mproj.pj_inv_deg({x: x, y: y}, crs);
    var lp2 = mproj.pj_inv_deg({x: x + dist, y: y}, crs);
    var k = 1 / geom.greatCircleDistance(lp.lam, lp.phi, lp2.lam, lp2.phi);
    return k;
  }

  function isProjectedCRS(P) {
    return !isLatLngCRS(P);
  }

  function isInvertibleCRS(P) {
    if (!P || !P.inv) return false;
    return true;
  }

  function isLatLngCRS(P) {
    return P && P.is_latlong || false;
  }

  function isWGS84(P) {
    if (!isLatLngCRS(P)) return false;
    var proj4 = crsToProj4(P);
    return proj4.toLowerCase().includes('84');
  }

  function isWebMercator(P) {
    if (!P) return false;
    var str = crsToProj4(P);
    // e.g. +proj=merc +lat_ts=0.0 +lon_0=0.0 +x_0=0.0 +y_0=0 +k=1.0 +units=m +wktext +a=6378137 +b=6378137 +nadgrids=@null
    // e.g. +proj=merc +a=6378137 +b=6378137
    // TODO: support  https://proj.org/operations/projections/webmerc.html
    return str.includes('+proj=merc') && str.includes('+a=6378137') && str.includes('+b=6378137');
  }

  function isLatLngDataset(dataset) {
    return isLatLngCRS(getDatasetCRS(dataset));
  }

  function printProjections() {
    var index = mproj.internal.pj_list;
    var msg = 'Proj4 projections\n';
    Object.keys(index).sort().forEach(function(id) {
      msg += '  ' + utils.rpad(id, 7, ' ') + '  ' + index[id].name + '\n';
    });
    msg += '\nAliases';
    Object.keys(projectionAliases).sort().forEach(function(n) {
      msg += '\n  ' + n;
    });
    print(msg);
  }

  function translatePrj(str) {
    var proj4;
    try {
      proj4 = mproj.internal.wkt_to_proj4(str);
    } catch(e) {
      stop('Unusable .prj file (' + e.message + ')');
    }
    return proj4;
  }

  // Convert contents of a .prj file to a projection object
  function parsePrj(str) {
    return parseCrsString(translatePrj(str));
  }

  var Projections = /*#__PURE__*/Object.freeze({
    __proto__: null,
    initProjLibrary: initProjLibrary,
    setProjectionLoader: setProjectionLoader,
    findProjLibs: findProjLibs,
    getProjTransform: getProjTransform,
    getProjTransform2: getProjTransform2,
    toLngLat: toLngLat,
    projectPoint: projectPoint,
    getProjInfo: getProjInfo,
    crsToProj4: crsToProj4,
    crsToPrj: crsToPrj,
    crsAreEqual: crsAreEqual,
    isProjAlias: isProjAlias,
    getProjDefn: getProjDefn,
    looksLikeProj4String: looksLikeProj4String,
    getCrsInfo: getCrsInfo,
    parseCrsString: parseCrsString,
    requireProjectedDataset: requireProjectedDataset,
    setDatasetCrsInfo: setDatasetCrsInfo,
    getDatasetCrsInfo: getDatasetCrsInfo,
    getDatasetCRS: getDatasetCRS,
    requireDatasetsHaveCompatibleCRS: requireDatasetsHaveCompatibleCRS,
    getScaleFactorAtXY: getScaleFactorAtXY,
    isProjectedCRS: isProjectedCRS,
    isInvertibleCRS: isInvertibleCRS,
    isLatLngCRS: isLatLngCRS,
    isWGS84: isWGS84,
    isWebMercator: isWebMercator,
    isLatLngDataset: isLatLngDataset,
    printProjections: printProjections,
    translatePrj: translatePrj,
    parsePrj: parsePrj
  });

  // Coordinate iterators
  //
  // Interface:
  //   properties: x, y
  //   method: hasNext()
  //
  // Usage:
  //   while (iter.hasNext()) {
  //     iter.x, iter.y; // do something w/ x & y
  //   }

  // Iterate over an array of [x, y] points
  //
  function PointIter(points) {
    var n = points.length,
        i = 0,
        iter = {
          x: 0,
          y: 0,
          hasNext: hasNext
        };
    function hasNext() {
      if (i >= n) return false;
      iter.x = points[i][0];
      iter.y = points[i][1];
      i++;
      return true;
    }
    return iter;
  }


  // Constructor takes arrays of coords: xx, yy, zz (optional)
  //
  function ArcIter(xx, yy) {
    this._i = 0;
    this._n = 0;
    this._inc = 1;
    this._xx = xx;
    this._yy = yy;
    this.i = 0;
    this.x = 0;
    this.y = 0;
  }

  ArcIter.prototype.init = function(i, len, fw) {
    if (fw) {
      this._i = i;
      this._inc = 1;
    } else {
      this._i = i + len - 1;
      this._inc = -1;
    }
    this._n = len;
    return this;
  };

  ArcIter.prototype.hasNext = function() {
    var i = this._i;
    if (this._n > 0) {
      this._i = i + this._inc;
      this.x = this._xx[i];
      this.y = this._yy[i];
      this.i = i;
      this._n--;
      return true;
    }
    return false;
  };

  function FilteredArcIter(xx, yy, zz) {
    var _zlim = 0,
        _i = 0,
        _inc = 1,
        _stop = 0;

    this.init = function(i, len, fw, zlim) {
      _zlim = zlim || 0;
      if (fw) {
        _i = i;
        _inc = 1;
        _stop = i + len;
      } else {
        _i = i + len - 1;
        _inc = -1;
        _stop = i - 1;
      }
      return this;
    };

    this.hasNext = function() {
      // using local vars is significantly faster when skipping many points
      var zarr = zz,
          i = _i,
          j = i,
          zlim = _zlim,
          stop = _stop,
          inc = _inc;
      if (i == stop) return false;
      do {
        j += inc;
      } while (j != stop && zarr[j] < zlim);
      _i = j;
      this.x = xx[i];
      this.y = yy[i];
      this.i = i;
      return true;
    };
  }

  function MultiShapeIter(arcs) {
    new ShapeIter(arcs);

  }

  // Iterate along a path made up of one or more arcs.
  //
  function ShapeIter(arcs) {
    this._arcs = arcs;
    this._i = 0;
    this._n = 0;
    this.x = 0;
    this.y = 0;
    // this.i = -1;
  }

  ShapeIter.prototype.hasNext = function() {
    var arc = this._arc;
    if (this._i < this._n === false) {
      return false;
    }
    if (arc.hasNext()) {
      this.x = arc.x;
      this.y = arc.y;
      // this.i = arc.i;
      return true;
    }
    this.nextArc();
    return this.hasNext();
  };

  ShapeIter.prototype.init = function(ids) {
    this._ids = ids;
    this._n = ids.length;
    this.reset();
    return this;
  };

  ShapeIter.prototype.nextArc = function() {
    var i = this._i + 1;
    if (i < this._n) {
      this._arc = this._arcs.getArcIter(this._ids[i]);
      if (i > 0) this._arc.hasNext(); // skip first point
    }
    this._i = i;
  };

  ShapeIter.prototype.reset = function() {
    this._i = -1;
    this.nextArc();
  };

  var ShapeIter$1 = /*#__PURE__*/Object.freeze({
    __proto__: null,
    PointIter: PointIter,
    ArcIter: ArcIter,
    FilteredArcIter: FilteredArcIter,
    MultiShapeIter: MultiShapeIter,
    ShapeIter: ShapeIter
  });

  // Returns a function for converting simplification ratio [0-1] to an interval value.
  // If the dataset is large, the value is an approximation (for speed while using slider)
  function getThresholdFunction(arcs) {
    var size = arcs.getPointCount(),
        nth = Math.ceil(size / 5e5),
        sortedThresholds = arcs.getRemovableThresholds(nth);
        // Sort simplification thresholds for all non-endpoint vertices
        // for quick conversion of simplification percentage to threshold value.
        // For large datasets, use every nth point, for faster sorting.
        // utils.quicksort(sortedThresholds, false); // descending
        utils.quicksort(sortedThresholds, true); // ascending

    return function(pct) {
      var n = sortedThresholds.length;
      var rank = retainedPctToRank(pct, sortedThresholds.length);
      if (rank < 1) return 0;
      if (rank > n) return Infinity;
      return sortedThresholds[rank-1];
    };
  }

  // Return integer rank of n (1-indexed) or 0 if pct <= 0 or n+1 if pct >= 1
  function retainedPctToRank(pct, n) {
    var rank;
    if (n === 0 || pct >= 1) {
      rank = 0;
    } else if (pct <= 0) {
      rank = n + 1;
    } else {
      rank = Math.floor((1 - pct) * (n + 2));
    }
    return rank;
  }

  // nth (optional): sample every nth threshold (use estimate for speed)
  function getThresholdByPct(pct, arcs, nth) {
    var tmp = arcs.getRemovableThresholds(nth),
        rank = retainedPctToRank(pct, tmp.length);
    if (rank < 1) return 0;
    if (rank > tmp.length) return Infinity;
    return utils.findValueByRank(tmp, rank);
  }

  var SimplifyPct = /*#__PURE__*/Object.freeze({
    __proto__: null,
    getThresholdFunction: getThresholdFunction,
    getThresholdByPct: getThresholdByPct
  });

  // An interface for managing a collection of paths.
  // Constructor signatures:
  //
  // ArcCollection(arcs)
  //    arcs is an array of polyline arcs; each arc is an array of points: [[x0, y0], [x1, y1], ... ]
  //
  // ArcCollection(nn, xx, yy)
  //    nn is an array of arc lengths; xx, yy are arrays of concatenated coords;
  function ArcCollection() {
    var _xx, _yy,  // coordinates data
        _ii, _nn,  // indexes, sizes
        _zz, _zlimit = 0, // simplification
        _bb, _allBounds, // bounding boxes
        _arcIter, _filteredArcIter; // path iterators

    if (arguments.length == 1) {
      initLegacyArcs(arguments[0]);  // want to phase this out
    } else if (arguments.length == 3) {
      initXYData.apply(this, arguments);
    } else if (arguments.length === 0) {
      initLegacyArcs([]); // empty collection
    } else {
      error("ArcCollection() Invalid arguments");
    }

    function initLegacyArcs(arcs) {
      var xx = [], yy = [];
      var nn = arcs.map(function(points) {
        var n = points ? points.length : 0;
        for (var i=0; i<n; i++) {
          xx.push(points[i][0]);
          yy.push(points[i][1]);
        }
        return n;
      });
      initXYData(nn, xx, yy);
    }

    function initXYData(nn, xx, yy) {
      var size = nn.length;
      if (nn instanceof Array) nn = new Uint32Array(nn);
      if (xx instanceof Array) xx = new Float64Array(xx);
      if (yy instanceof Array) yy = new Float64Array(yy);
      _xx = xx;
      _yy = yy;
      _nn = nn;
      _zz = null;
      _zlimit = 0;
      _filteredArcIter = null;

      // generate array of starting idxs of each arc
      _ii = new Uint32Array(size);
      for (var idx = 0, j=0; j<size; j++) {
        _ii[j] = idx;
        idx += nn[j];
      }

      if (idx != _xx.length || _xx.length != _yy.length) {
        error("ArcCollection#initXYData() Counting error");
      }

      initBounds();
      // Pre-allocate some path iterators for repeated use.
      _arcIter = new ArcIter(_xx, _yy);
      return this;
    }

    function initZData(zz) {
      if (!zz) {
        _zz = null;
        _zlimit = 0;
        _filteredArcIter = null;
      } else {
        if (zz.length != _xx.length) error("ArcCollection#initZData() mismatched arrays");
        if (zz instanceof Array) zz = new Float64Array(zz);
        _zz = zz;
        _filteredArcIter = new FilteredArcIter(_xx, _yy, _zz);
      }
    }

    function initBounds() {
      var numArcs = _nn.length;
      _bb = new Float64Array(numArcs * 4);
      _allBounds = new Bounds();
      for (var i=0; i<numArcs; i++) {
        initArcBounds(i);
      }
    }

    function initArcBounds(i) {
      var arcLen = _nn[i];
      var arcOffs = _ii[i];
      var j = i * 4;
      var b = calcArcBounds(_xx, _yy, arcOffs, arcLen);
      // NOTE: if arcLen is 0, bounds coords are undefined, coerced to NaN in _bb.
      _bb[j++] = b[0];
      _bb[j++] = b[1];
      _bb[j++] = b[2];
      _bb[j] = b[3];
      _allBounds.mergeBounds(b);
    }

    this.updateArcBounds = function(arcId) {
      initArcBounds(arcId);
    };

    this.updateVertexData = function(nn, xx, yy, zz) {
      initXYData(nn, xx, yy);
      initZData(zz || null);
    };

    this.getCopy = function() {
      var copy = new ArcCollection(new Int32Array(_nn), new Float64Array(_xx),
          new Float64Array(_yy));
      if (_zz) {
        copy.setThresholds(new Float64Array(_zz));
        copy.setRetainedInterval(_zlimit);
      }
      return copy;
    };


    // Give access to raw data arrays...
    this.getVertexData = getVertexData;

    function getVertexData() {
      return {
        xx: _xx,
        yy: _yy,
        zz: _zz,
        bb: _bb,
        nn: _nn,
        ii: _ii
      };
    }

    function getFilteredPointCount() {
      if (!_zz || !_zlimit) return this.getPointCount();
      return countFilteredVertices(_zz, _zlimit);
    }

    function getFilteredVertexData() {
      return filterVertexData(getVertexData(), _zlimit);
    }

    this.getFilteredCopy = function() {
      if (!_zz || _zlimit === 0) return this.getCopy();
      var data = getFilteredVertexData();
      var copy = new ArcCollection(data.nn, data.xx, data.yy);
      copy.setThresholds(data.zz);
      return copy;
    };

    // Return arcs as arrays of [x, y] points (intended for testing).
    this.toArray = function() {
      var arr = [];
      this.forEach(function(iter) {
        var arc = [];
        while (iter.hasNext()) {
          arc.push([iter.x, iter.y]);
        }
        arr.push(arc);
      });
      return arr;
    };

    this.toJSON = function() {
      return this.toArray();
    };

    // @cb function(i, j, xx, yy)
    this.forEachArcSegment = function(arcId, cb) {
      var fw = arcId >= 0,
          absId = fw ? arcId : ~arcId,
          zlim = this.getRetainedInterval(),
          n = _nn[absId],
          step = fw ? 1 : -1,
          v1 = fw ? _ii[absId] : _ii[absId] + n - 1,
          v2 = v1,
          xx = _xx, yy = _yy, zz = _zz,
          count = 0;

      for (var j = 1; j < n; j++) {
        v2 += step;
        if (zlim === 0 || zz[v2] >= zlim) {
          cb(v1, v2, xx, yy);
          v1 = v2;
          count++;
        }
      }
      return count;
    };

    // @cb function(i, j, xx, yy)
    this.forEachSegment = function(cb) {
      var count = 0;
      for (var i=0, n=this.size(); i<n; i++) {
        count += this.forEachArcSegment(i, cb);
      }
      return count;
    };

    this.transformPoints = function(f) {
      var xx = _xx, yy = _yy, arcId = -1, n = 0, p;
      for (var i=0, len=xx.length; i<len; i++, n--) {
        while (n === 0) {
          n = _nn[++arcId];
        }
        p = f(xx[i], yy[i], arcId);
        if (p) {
          xx[i] = p[0];
          yy[i] = p[1];
        }
      }
      initBounds();
    };

    // Return an ArcIter object for each path in the dataset
    //
    this.forEach = function(cb) {
      for (var i=0, n=this.size(); i<n; i++) {
        cb(this.getArcIter(i), i);
      }
    };

    // Iterate over arcs with access to low-level data
    //
    this.forEach2 = function(cb) {
      for (var arcId=0, n=this.size(); arcId<n; arcId++) {
        cb(_ii[arcId], _nn[arcId], _xx, _yy, _zz, arcId);
      }
    };

    this.forEach3 = function(cb) {
      var start, end, xx, yy, zz;
      for (var arcId=0, n=this.size(); arcId<n; arcId++) {
        start = _ii[arcId];
        end = start + _nn[arcId];
        xx = _xx.subarray(start, end);
        yy = _yy.subarray(start, end);
        if (_zz) zz = _zz.subarray(start, end);
        cb(xx, yy, zz, arcId);
      }
    };

    // Remove arcs that don't pass a filter test and re-index arcs
    // Return array mapping original arc ids to re-indexed ids. If arr[n] == -1
    // then arc n was removed. arr[n] == m indicates that the arc at n was
    // moved to index m.
    // Return null if no arcs were re-indexed (and no arcs were removed)
    //
    this.filter = function(cb) {
      var test = function(i) {
        return cb(this.getArcIter(i), i);
      }.bind(this);
      return this.deleteArcs(test);
    };

    this.deleteArcs = function(test) {
      var n = this.size(),
          map = new Int32Array(n),
          goodArcs = 0,
          goodPoints = 0;
      for (var i=0; i<n; i++) {
        if (test(i)) {
          map[i] = goodArcs++;
          goodPoints += _nn[i];
        } else {
          map[i] = -1;
        }
      }
      if (goodArcs < n) {
        condenseArcs(map);
      }
      return map;
    };

    function condenseArcs(map) {
      var goodPoints = 0,
          goodArcs = 0,
          copyElements = utils.copyElements,
          k, arcLen;
      for (var i=0, n=map.length; i<n; i++) {
        k = map[i];
        arcLen = _nn[i];
        if (k > -1) {
          copyElements(_xx, _ii[i], _xx, goodPoints, arcLen);
          copyElements(_yy, _ii[i], _yy, goodPoints, arcLen);
          if (_zz) copyElements(_zz, _ii[i], _zz, goodPoints, arcLen);
          _nn[k] = arcLen;
          goodPoints += arcLen;
          goodArcs++;
        }
      }

      initXYData(_nn.subarray(0, goodArcs), _xx.subarray(0, goodPoints),
          _yy.subarray(0, goodPoints));
      if (_zz) initZData(_zz.subarray(0, goodPoints));
    }

    this.dedupCoords = function() {
      var arcId = 0, i = 0, i2 = 0,
          arcCount = this.size(),
          zz = _zz,
          arcLen, arcLen2;
      while (arcId < arcCount) {
        arcLen = _nn[arcId];
        arcLen2 = dedupArcCoords(i, i2, arcLen, _xx, _yy, zz);
        _nn[arcId] = arcLen2;
        i += arcLen;
        i2 += arcLen2;
        arcId++;
      }
      if (i > i2) {
        initXYData(_nn, _xx.subarray(0, i2), _yy.subarray(0, i2));
        if (zz) initZData(zz.subarray(0, i2));
      }
      return i - i2;
    };

    this.getVertex = function(arcId, nth) {
      var i = this.indexOfVertex(arcId, nth);
      return {
        x: _xx[i],
        y: _yy[i]
      };
    };

    this.getVertex2 = function(i) {
      return [_xx[i], _yy[i]];
    };

    // @nth: index of vertex. ~(idx) starts from the opposite endpoint
    this.indexOfVertex = function(arcId, nth) {
      var absId = arcId < 0 ? ~arcId : arcId,
          len = _nn[absId];
      if (nth < 0) nth = len + nth;
      if (absId != arcId) nth = len - nth - 1;
      if (nth < 0 || nth >= len) {
        error("[ArcCollection] out-of-range vertex id");
      }
      return _ii[absId] + nth;
    };

    // Tests if arc endpoints have same x, y coords
    // (arc may still have collapsed);
    this.arcIsClosed = function(arcId) {
      var i = this.indexOfVertex(arcId, 0),
          j = this.indexOfVertex(arcId, -1);
      return i != j && _xx[i] == _xx[j] && _yy[i] == _yy[j];
    };

    // Tests if first and last segments mirror each other
    // A 3-vertex arc with same endpoints tests true
    this.arcIsLollipop = function(arcId) {
      var len = this.getArcLength(arcId),
          i, j;
      if (len <= 2 || !this.arcIsClosed(arcId)) return false;
      i = this.indexOfVertex(arcId, 1);
      j = this.indexOfVertex(arcId, -2);
      return _xx[i] == _xx[j] && _yy[i] == _yy[j];
    };

    this.arcIsDegenerate = function(arcId) {
      var iter = this.getArcIter(arcId);
      var i = 0,
          x, y;
      while (iter.hasNext()) {
        if (i > 0) {
          if (x != iter.x || y != iter.y) return false;
        }
        x = iter.x;
        y = iter.y;
        i++;
      }
      return true;
    };

    this.getArcLength = function(arcId) {
      return _nn[absArcId(arcId)];
    };

    this.getArcIter = function(arcId) {
      var fw = arcId >= 0,
          i = fw ? arcId : ~arcId,
          iter = _zz && _zlimit ? _filteredArcIter : _arcIter;
      if (i >= _nn.length) {
        error("#getArcId() out-of-range arc id:", arcId);
      }
      return iter.init(_ii[i], _nn[i], fw, _zlimit);
    };

    this.getShapeIter = function(ids) {
      return new ShapeIter(this).init(ids);
    };

    // Add simplification data to the dataset
    // @thresholds is either a single typed array or an array of arrays of removal thresholds for each arc;
    //
    this.setThresholds = function(thresholds) {
      var n = this.getPointCount(),
          zz = null;
      if (!thresholds) ; else if (thresholds.length == n) {
        zz = thresholds;
      } else if (thresholds.length == this.size()) {
        zz = flattenThresholds(thresholds, n);
      } else {
        error("Invalid threshold data");
      }
      initZData(zz);
      return this;
    };

    function flattenThresholds(arr, n) {
      var zz = new Float64Array(n),
          i = 0;
      arr.forEach(function(arr) {
        for (var j=0, n=arr.length; j<n; i++, j++) {
          zz[i] = arr[j];
        }
      });
      if (i != n) error("Mismatched thresholds");
      return zz;
    }

    // bake in current simplification level, if any
    this.flatten = function() {
      if (_zlimit > 0) {
        var data = getFilteredVertexData();
        this.updateVertexData(data.nn, data.xx, data.yy);
        _zlimit = 0;
      } else {
        _zz = null;
      }
    };

    this.isFlat = function() { return !_zz; };

    this.getRetainedInterval = function() {
      return _zlimit;
    };

    this.setRetainedInterval = function(z) {
      _zlimit = z;
      return this;
    };

    this.getRetainedPct = function() {
      return this.getPctByThreshold(_zlimit);
    };

    this.setRetainedPct = function(pct) {
      if (pct >= 1) {
        _zlimit = 0;
      } else {
        _zlimit = this.getThresholdByPct(pct);
        _zlimit = clampIntervalByPct(_zlimit, pct);
      }
      return this;
    };

    // Return array of z-values that can be removed for simplification
    //
    this.getRemovableThresholds = function(nth) {
      if (!_zz) error("[arcs] Missing simplification data.");
      var skip = nth | 1,
          arr = new Float64Array(Math.ceil(_zz.length / skip)),
          z;
      for (var i=0, j=0, n=this.getPointCount(); i<n; i+=skip) {
        z = _zz[i];
        if (z != Infinity) {
          arr[j++] = z;
        }
      }
      return arr.subarray(0, j);
    };

    this.getArcThresholds = function(arcId) {
      if (!(arcId >= 0 && arcId < this.size())) {
        error("[arcs] Invalid arc id:", arcId);
      }
      var start = _ii[arcId],
          end = start + _nn[arcId];
      return _zz.subarray(start, end);
    };

    // nth (optional): sample every nth threshold (use estimate for speed)
    this.getPctByThreshold = function(val, nth) {
      var arr, rank, pct;
      if (val > 0) {
        arr = this.getRemovableThresholds(nth);
        rank = utils.findRankByValue(arr, val);
        pct = arr.length > 0 ? 1 - (rank - 1) / arr.length : 1;
      } else {
        pct = 1;
      }
      return pct;
    };

    // nth (optional): sample every nth threshold (use estimate for speed)
    this.getThresholdByPct = function(pct, nth) {
      return getThresholdByPct(pct, this, nth);
    };

    this.arcIntersectsBBox = function(i, b1) {
      var b2 = _bb,
          j = i * 4;
      // returns false if _bb bounds are NaN
      return b2[j] <= b1[2] && b2[j+2] >= b1[0] && b2[j+3] >= b1[1] && b2[j+1] <= b1[3];
    };

    this.arcIsContained = function(i, b1) {
      var b2 = _bb,
          j = i * 4;
      // returns false if _bb bounds are NaN
      return b2[j] >= b1[0] && b2[j+2] <= b1[2] && b2[j+1] >= b1[1] && b2[j+3] <= b1[3];
    };

    this.arcIsSmaller = function(i, units) {
      var bb = _bb,
          j = i * 4;
      return bb[j+2] - bb[j] < units && bb[j+3] - bb[j+1] < units;
    };

    // TODO: allow datasets in lat-lng coord range to be flagged as planar
    this.isPlanar = function() {
      return !probablyDecimalDegreeBounds(this.getBounds());
    };

    this.size = function() {
      return _ii && _ii.length || 0;
    };

    this.getPointCount = function() {
      return _xx && _xx.length || 0;
    };

    this.getFilteredPointCount = getFilteredPointCount;

    this.getBounds = function() {
      return _allBounds.clone();
    };

    this.getSimpleShapeBounds = function(arcIds, bounds) {
      bounds = bounds || new Bounds();
      for (var i=0, n=arcIds.length; i<n; i++) {
        this.mergeArcBounds(arcIds[i], bounds);
      }
      return bounds;
    };

    this.getSimpleShapeBbox = function(arcIds, arr) {
      var bbox = arr || [],
          bb = _bb,
          arcId, offs;
      bbox[0] = bbox[1] = Infinity;
      bbox[2] = bbox[3] = -Infinity;
      for (var i=0, n=arcIds.length; i<n; i++) {
        arcId = absArcId(arcIds[i]);
        offs = arcId * 4;
        if (bb[offs] < bbox[0]) bbox[0] = bb[offs];
        if (bb[++offs] < bbox[1]) bbox[1] = bb[offs];
        if (bb[++offs] > bbox[2]) bbox[2] = bb[offs];
        if (bb[++offs] > bbox[3]) bbox[3] = bb[offs];
      }
      return bbox[0] == Infinity ? [] : bbox;
    };

    // TODO: move this and similar methods out of ArcCollection
    this.getMultiShapeBounds = function(shp, bounds) {
      bounds = bounds || new Bounds();
      if (shp) { // handle null shapes
        for (var i=0, n=shp.length; i<n; i++) {
          this.getSimpleShapeBounds(shp[i], bounds);
        }
      }
      return bounds;
    };

    this.mergeArcBounds = function(arcId, bounds) {
      if (arcId < 0) arcId = ~arcId;
      var offs = arcId * 4;
      if (_nn[arcId] > 0) {
        bounds.mergeBounds(_bb[offs], _bb[offs+1], _bb[offs+2], _bb[offs+3]);
      }
    };
  }

  // Remove duplicate coords and NaNs
  function dedupArcCoords(src, dest, arcLen, xx, yy, zz) {
    var n = 0, n2 = 0; // counters
    var x, y, i, j, keep;
    while (n < arcLen) {
      j = src + n;
      x = xx[j];
      y = yy[j];
      keep = x == x && y == y && (n2 === 0 || x != xx[j-1] || y != yy[j-1]);
      if (keep) {
        i = dest + n2;
        xx[i] = x;
        yy[i] = y;
        n2++;
      }
      if (zz && n2 > 0 && (keep || zz[j] > zz[i])) {
        zz[i] = zz[j];
      }
      n++;
    }
    return n2 > 1 ? n2 : 0;
  }

  // Get function to Hash an x, y point to a non-negative integer
  function getXYHash(size) {
    var buf = new ArrayBuffer(16),
        floats = new Float64Array(buf),
        uints = new Uint32Array(buf),
        lim = size | 0;
    if (lim > 0 === false) {
      throw new Error("Invalid size param: " + size);
    }

    return function(x, y) {
      var u = uints, h;
      floats[0] = x;
      floats[1] = y;
      h = u[0] ^ u[1];
      h = h << 5 ^ h >> 7 ^ u[2] ^ u[3];
      return (h & 0x7fffffff) % lim;
    };
  }

  // Used for building topology
  //
  function ArcIndex(pointCount) {
    var hashTableSize = Math.floor(pointCount * 0.25 + 1),
        hash = getXYHash(hashTableSize),
        hashTable = new Int32Array(hashTableSize),
        chainIds = [],
        arcs = [],
        arcPoints = 0;

    utils.initializeArray(hashTable, -1);

    this.addArc = function(xx, yy) {
      var end = xx.length - 1,
          key = hash(xx[end], yy[end]),
          chainId = hashTable[key],
          arcId = arcs.length;
      hashTable[key] = arcId;
      arcs.push([xx, yy]);
      arcPoints += xx.length;
      chainIds.push(chainId);
      return arcId;
    };

    // Look for a previously generated arc with the same sequence of coords, but in the
    // opposite direction. (This program uses the convention of CW for space-enclosing rings, CCW for holes,
    // so coincident boundaries should contain the same points in reverse sequence).
    //
    this.findDuplicateArc = function(xx, yy, start, end, getNext, getPrev) {
      // First, look for a reverse match
      var arcId = findArcNeighbor(xx, yy, start, end, getNext);
      if (arcId === null) {
        // Look for forward match
        // (Abnormal topology, but we're accepting it because in-the-wild
        // Shapefiles sometimes have duplicate paths)
        arcId = findArcNeighbor(xx, yy, end, start, getPrev);
      } else {
        arcId = ~arcId;
      }
      return arcId;
    };

    function findArcNeighbor(xx, yy, start, end, getNext) {
      var next = getNext(start),
          key = hash(xx[start], yy[start]),
          arcId = hashTable[key],
          arcX, arcY, len;

      while (arcId != -1) {
        // check endpoints and one segment...
        // it would be more rigorous but slower to identify a match
        // by comparing all segments in the coordinate sequence
        arcX = arcs[arcId][0];
        arcY = arcs[arcId][1];
        len = arcX.length;
        if (arcX[0] === xx[end] && arcX[len-1] === xx[start] && arcX[len-2] === xx[next] &&
            arcY[0] === yy[end] && arcY[len-1] === yy[start] && arcY[len-2] === yy[next]) {
          return arcId;
        }
        arcId = chainIds[arcId];
      }
      return null;
    }

    this.getVertexData = function() {
      var xx = new Float64Array(arcPoints),
          yy = new Float64Array(arcPoints),
          nn = new Uint32Array(arcs.length),
          copied = 0,
          arc, len;
      for (var i=0, n=arcs.length; i<n; i++) {
        arc = arcs[i];
        len = arc[0].length;
        utils.copyElements(arc[0], 0, xx, copied, len);
        utils.copyElements(arc[1], 0, yy, copied, len);
        nn[i] = len;
        copied += len;
      }
      return {
        xx: xx,
        yy: yy,
        nn: nn
      };
    };
  }

  function initPointChains(xx, yy) {
    var chainIds = initHashChains(xx, yy),
        j, next, prevMatchId, prevUnmatchId;

    // disentangle, reverse and close the chains created by initHashChains()
    for (var i = xx.length-1; i>=0; i--) {
      next = chainIds[i];
      if (next >= i) continue;
      prevMatchId = i;
      prevUnmatchId = -1;
      do {
        j = next;
        next = chainIds[j];
        if (yy[j] == yy[i] && xx[j] == xx[i]) {
          chainIds[j] = prevMatchId;
          prevMatchId = j;
        } else {
          if (prevUnmatchId > -1) {
            chainIds[prevUnmatchId] = j;
          }
          prevUnmatchId = j;
        }
      } while (next < j);
      if (prevUnmatchId > -1) {
        // Make sure last unmatched entry is terminated
        chainIds[prevUnmatchId] = prevUnmatchId;
      }
      chainIds[i] = prevMatchId; // close the chain
    }
    return chainIds;
  }

  function initHashChains(xx, yy) {
    // Performance doesn't improve much above ~1.3 * point count
    var n = xx.length,
        m = Math.floor(n * 1.3) || 1,
        hash = getXYHash(m),
        hashTable = new Int32Array(m),
        chainIds = new Int32Array(n), // Array to be filled with chain data
        key, j, i, x, y;

    for (i=0; i<n; i++) {
      x = xx[i];
      y = yy[i];
      if (x != x || y != y) {
        j = -1; // NaN coord: no hash entry, one-link chain
      } else {
        key = hash(x, y);
        j = hashTable[key] - 1; // coord ids are 1-based in hash table; 0 used as null value.
        hashTable[key] = i + 1;
      }
      chainIds[i] = j >= 0 ? j : i; // first item in a chain points to self
    }
    return chainIds;
  }

  // Converts all polygon and polyline paths in a dataset to a topological format
  // (in-place)
  function buildTopology(dataset) {
    if (!dataset.arcs) return;
    var raw = dataset.arcs.getVertexData(),
        cooked = buildPathTopology(raw.nn, raw.xx, raw.yy);
    dataset.arcs.updateVertexData(cooked.nn, cooked.xx, cooked.yy);
    dataset.layers.forEach(function(lyr) {
      if (lyr.geometry_type == 'polyline' || lyr.geometry_type == 'polygon') {
        lyr.shapes = replaceArcIds(lyr.shapes, cooked.paths);
      }
    });
  }

  // buildPathTopology() converts non-topological paths into
  // a topological format
  //
  // Arguments:
  //    xx: [Array|Float64Array],   // x coords of each point in the dataset
  //    yy: [Array|Float64Array],   // y coords ...
  //    nn: [Array]  // length of each path
  //
  // (x- and y-coords of all paths are concatenated into two arrays)
  //
  // Returns:
  // {
  //    xx, yy (array)   // coordinate data
  //    nn: (array)      // points in each arc
  //    paths: (array)   // Paths are arrays of one or more arc id.
  // }
  //
  // Negative arc ids in the paths array indicate a reversal of arc -(id + 1)
  //
  function buildPathTopology(nn, xx, yy) {
    var pointCount = xx.length,
        chainIds = initPointChains(xx, yy),
        pathIds = initPathIds(pointCount, nn),
        index = new ArcIndex(pointCount),
        slice = usingTypedArrays() ? xx.subarray : Array.prototype.slice,
        paths, retn;
    paths = convertPaths(nn);
    retn = index.getVertexData();
    retn.paths = paths;
    return retn;

    function usingTypedArrays() {
      return !!(xx.subarray && yy.subarray);
    }

    function convertPaths(nn) {
      var paths = [],
          pointId = 0,
          pathLen;
      for (var i=0, len=nn.length; i<len; i++) {
        pathLen = nn[i];
        paths.push(pathLen < 2 ? null : convertPath(pointId, pointId + pathLen - 1));
        pointId += pathLen;
      }
      return paths;
    }

    function nextPoint(id) {
      var partId = pathIds[id],
          nextId = id + 1;
      if (nextId < pointCount && pathIds[nextId] === partId) {
        return id + 1;
      }
      var len = nn[partId];
      return sameXY(id, id - len + 1) ? id - len + 2 : -1;
    }

    function prevPoint(id) {
      var partId = pathIds[id],
          prevId = id - 1;
      if (prevId >= 0 && pathIds[prevId] === partId) {
        return id - 1;
      }
      var len = nn[partId];
      return sameXY(id, id + len - 1) ? id + len - 2 : -1;
    }

    function sameXY(a, b) {
      return xx[a] == xx[b] && yy[a] == yy[b];
    }

    // Convert a non-topological path to one or more topological arcs
    // @start, @end are ids of first and last points in the path
    // TODO: don't allow id ~id pairs
    //
    function convertPath(start, end) {
      var arcIds = [],
          firstNodeId = -1,
          arcStartId;

      // Visit each point in the path, up to but not including the last point
      for (var i = start; i < end; i++) {
        if (pointIsArcEndpoint(i)) {
          if (firstNodeId > -1) {
            arcIds.push(addEdge(arcStartId, i));
          } else {
            firstNodeId = i;
          }
          arcStartId = i;
        }
      }

      // Identify the final arc in the path
      if (firstNodeId == -1) {
        // Not in an arc, i.e. no nodes have been found...
        // Assuming that path is either an island or is congruent with one or more rings
        arcIds.push(addRing(start, end));
      }
      else if (firstNodeId == start) {
        // path endpoint is a node;
        if (!pointIsArcEndpoint(end)) {
          error("Topology error"); // TODO: better error handling
        }
        arcIds.push(addEdge(arcStartId, i));
      } else {
        // final arc wraps around
        arcIds.push(addSplitEdge(arcStartId, end, start + 1, firstNodeId));
      }
      return arcIds;
    }

    // Test if a point @id is an endpoint of a topological path
    function pointIsArcEndpoint(id) {
      var id2 = chainIds[id],
          prev = prevPoint(id),
          next = nextPoint(id),
          prev2, next2;
      if (prev == -1 || next == -1) {
        // @id is an endpoint if it is the start or end of an open path
        return true;
      }
      while (id != id2) {
        prev2 = prevPoint(id2);
        next2 = nextPoint(id2);
        if (prev2 == -1 || next2 == -1 || brokenEdge(prev, next, prev2, next2)) {
          // there is a discontinuity at @id -- point is arc endpoint
          return true;
        }
        id2 = chainIds[id2];
      }
      return false;
    }

    // a and b are two vertices with the same x, y coordinates
    // test if the segments on either side of them are also identical
    function brokenEdge(aprev, anext, bprev, bnext) {
      var apx = xx[aprev],
          anx = xx[anext],
          bpx = xx[bprev],
          bnx = xx[bnext],
          apy = yy[aprev],
          any = yy[anext],
          bpy = yy[bprev],
          bny = yy[bnext];
      if (apx == bnx && anx == bpx && apy == bny && any == bpy ||
          apx == bpx && anx == bnx && apy == bpy && any == bny) {
        return false;
      }
      return true;
    }

    function mergeArcParts(src, startId, endId, startId2, endId2) {
      var len = endId - startId + endId2 - startId2 + 2,
          ArrayClass = usingTypedArrays() ? Float64Array : Array,
          dest = new ArrayClass(len),
          j = 0, i;
      for (i=startId; i <= endId; i++) {
        dest[j++] = src[i];
      }
      for (i=startId2; i <= endId2; i++) {
        dest[j++] = src[i];
      }
      return dest;
    }

    function addSplitEdge(start1, end1, start2, end2) {
      var arcId = index.findDuplicateArc(xx, yy, start1, end2, nextPoint, prevPoint);
      if (arcId === null) {
        arcId = index.addArc(mergeArcParts(xx, start1, end1, start2, end2),
            mergeArcParts(yy, start1, end1, start2, end2));
      }
      return arcId;
    }

    function addEdge(start, end) {
      // search for a matching edge that has already been generated
      var arcId = index.findDuplicateArc(xx, yy, start, end, nextPoint, prevPoint);
      if (arcId === null) {
        arcId = index.addArc(slice.call(xx, start, end + 1),
            slice.call(yy, start, end + 1));
      }
      return arcId;
    }

    function addRing(startId, endId) {
      var chainId = chainIds[startId],
          pathId = pathIds[startId],
          arcId;

      while (chainId != startId) {
        if (pathIds[chainId] < pathId) {
          break;
        }
        chainId = chainIds[chainId];
      }

      if (chainId == startId) {
        return addEdge(startId, endId);
      }

      for (var i=startId; i<endId; i++) {
        arcId = index.findDuplicateArc(xx, yy, i, i, nextPoint, prevPoint);
        if (arcId !== null) return arcId;
      }
      error("Unmatched ring; id:", pathId, "len:", nn[pathId]);
    }
  }


  // Create a lookup table for path ids; path ids are indexed by point id
  //
  function initPathIds(size, pathSizes) {
    var pathIds = new Int32Array(size),
        j = 0;
    for (var pathId=0, pathCount=pathSizes.length; pathId < pathCount; pathId++) {
      for (var i=0, n=pathSizes[pathId]; i<n; i++, j++) {
        pathIds[j] = pathId;
      }
    }
    return pathIds;
  }

  function replaceArcIds(src, replacements) {
    return src.map(function(shape) {
      return replaceArcsInShape(shape, replacements);
    });

    function replaceArcsInShape(shape, replacements) {
      if (!shape) return null;
      return shape.map(function(path) {
        return replaceArcsInPath(path, replacements);
      });
    }

    function replaceArcsInPath(path, replacements) {
      return path.reduce(function(memo, id) {
        var abs = absArcId(id);
        var topoPath = replacements[abs];
        if (topoPath) {
          if (id < 0) {
            topoPath = topoPath.concat(); // TODO: need to copy?
            reversePath(topoPath);
          }
          for (var i=0, n=topoPath.length; i<n; i++) {
            memo.push(topoPath[i]);
          }
        }
        return memo;
      }, []);
    }
  }

  var Topology = /*#__PURE__*/Object.freeze({
    __proto__: null,
    buildTopology: buildTopology,
    buildPathTopology: buildPathTopology
  });

  // Merge arcs from one or more source datasets into target dataset
  // return array of layers from the source dataset (instead of adding them to the target dataset)
  function mergeDatasetsIntoDataset(dataset, datasets) {
    var merged = mergeDatasets([dataset].concat(datasets));
    var mergedLayers = datasets.reduce(function(memo, dataset) {
      return memo.concat(dataset.layers);
    }, []);
    dataset.arcs = merged.arcs;
    return mergedLayers;
  }

  // Don't modify input layers (mergeDatasets() updates arc ids in-place)
  function mergeDatasetsForExport(arr) {
    // copy layers but not arcs, which get copied in mergeDatasets()
    var copy = arr.map(function(dataset) {
      return utils.defaults({
        layers: dataset.layers.map(copyLayerShapes)
      }, dataset);
    });
    return mergeDatasets(copy);
  }

  function mergeCommandTargets(targets, catalog) {
    var targetLayers = [];
    var targetDatasets = [];
    var datasetsWithArcs = 0;
    var merged;

    targets.forEach(function(target) {
      targetLayers = targetLayers.concat(target.layers);
      targetDatasets = targetDatasets.concat(target.dataset);
      if (target.dataset.arcs && target.dataset.arcs.size() > 0) datasetsWithArcs++;
    });

    merged = mergeDatasets(targetDatasets);

    // Rebuild topology, if multiple datasets contain arcs
    if (datasetsWithArcs > 1) {
      buildTopology(merged);
    }

    // remove old datasets after merging, so catalog is not affected if merge throws an error
    targetDatasets.forEach(catalog.removeDataset);
    catalog.addDataset(merged); // sets default target to all layers in merged dataset
    catalog.setDefaultTarget(targetLayers, merged); // reset default target
    return [{
      layers: targetLayers,
      dataset: merged
    }];
  }

  // Combine multiple datasets into one using concatenation
  // (any shared topology is ignored)
  function mergeDatasets(arr) {
    var arcSources = [],
        arcCount = 0,
        merged = {
          info: {},
          layers: []
        };

    // Error if incompatible CRS
    requireDatasetsHaveCompatibleCRS(arr);

    arr.forEach(function(dataset) {
      var n = dataset.arcs ? dataset.arcs.size() : 0;
      if (n > 0) {
        arcSources.push(dataset.arcs);
      }

      mergeDatasetInfo$1(merged, dataset);
      dataset.layers.forEach(function(lyr) {
        if (lyr.geometry_type == 'polygon' || lyr.geometry_type == 'polyline') {
          forEachArcId(lyr.shapes, function(id) {
            return id < 0 ? id - arcCount : id + arcCount;
          });
        }
        merged.layers.push(lyr);
      });
      arcCount += n;
    });

    if (arcSources.length > 0) {
      merged.arcs = mergeArcs(arcSources);
      if (merged.arcs.size() != arcCount) {
        error("[mergeDatasets()] Arc indexing error");
      }
    }

    return merged;
  }

  function mergeDatasetInfo$1(merged, dataset) {
    var src = dataset.info || {};
    var dest = merged.info || (merged.info = {});
    dest.input_files = utils.uniq((dest.input_files || []).concat(src.input_files || []));
    dest.input_formats = utils.uniq((dest.input_formats || []).concat(src.input_formats || []));
    // merge other info properties (e.g. input_geojson_crs, input_delimiter, prj, crs)
    utils.defaults(dest, src);
  }

  function mergeArcs(arr) {
    // Returning the original causes a test to fail
    // if (arr.length < 2) return arr[0];
    var dataArr = arr.map(function(arcs) {
      if (arcs.getRetainedInterval() > 0) {
        verbose("Baking-in simplification setting.");
        arcs.flatten();
      }
      return arcs.getVertexData();
    });
    var xx = mergeArrays(utils.pluck(dataArr, 'xx'), Float64Array),
        yy = mergeArrays(utils.pluck(dataArr, 'yy'), Float64Array),
        nn = mergeArrays(utils.pluck(dataArr, 'nn'), Int32Array);

    return new ArcCollection(nn, xx, yy);
  }

  function countElements(arrays) {
    return arrays.reduce(function(memo, arr) {
      return memo + (arr.length || 0);
    }, 0);
  }

  function mergeArrays(arrays, TypedArr) {
    var size = countElements(arrays),
        Arr = TypedArr || Array,
        merged = new Arr(size),
        offs = 0;
    arrays.forEach(function(src) {
      var n = src.length;
      for (var i = 0; i<n; i++) {
        merged[i + offs] = src[i];
      }
      offs += n;
    });
    return merged;
  }

  var Merging = /*#__PURE__*/Object.freeze({
    __proto__: null,
    mergeDatasetsIntoDataset: mergeDatasetsIntoDataset,
    mergeDatasetsForExport: mergeDatasetsForExport,
    mergeCommandTargets: mergeCommandTargets,
    mergeDatasets: mergeDatasets,
    mergeDatasetInfo: mergeDatasetInfo$1,
    mergeArcs: mergeArcs
  });

  // Test if the second endpoint of an arc is the endpoint of any path in any layer
  function getPathEndpointTest(layers, arcs) {
    var index = new Uint8Array(arcs.size());
    layers.forEach(function(lyr) {
      if (layerHasPaths(lyr)) {
        lyr.shapes.forEach(addShape);
      }
    });

    function addShape(shape) {
      forEachShapePart(shape, addPath);
    }

    function addPath(path) {
      addEndpoint(~path[0]);
      addEndpoint(path[path.length - 1]);
    }

    function addEndpoint(arcId) {
      var absId = absArcId(arcId);
      var fwd = absId == arcId;
      index[absId] |= fwd ? 1 : 2;
    }

    return function(arcId) {
      var absId = absArcId(arcId);
      var fwd = absId == arcId;
      var code = index[absId];
      return fwd ? (code & 1) == 1 : (code & 2) == 2;
    };
  }

  var PathEndpoints = /*#__PURE__*/Object.freeze({
    __proto__: null,
    getPathEndpointTest: getPathEndpointTest
  });

  // @arcs ArcCollection
  // @filter Optional filter function, arcIds that return false are excluded
  //
  function NodeCollection(arcs, filter) {
    if (Array.isArray(arcs)) {
      arcs = new ArcCollection(arcs);
    }
    var arcData = arcs.getVertexData(),
        nn = arcData.nn,
        xx = arcData.xx,
        yy = arcData.yy,
        nodeData,
        globalFilter;

    // Accessor function for arcs
    Object.defineProperty(this, 'arcs', {value: arcs});

    this.setArcFilter = function(f) {
      globalFilter = f;
    };

    this.toArray = function() {
      var chains = getNodeChains(),
          flags = new Uint8Array(chains.length),
          arr = [];
      utils.forEach(chains, function(nextIdx, thisIdx) {
        var node, p;
        if (flags[thisIdx] == 1) return;
        p = getEndpoint(thisIdx);
        if (!p) return; // endpoints of an excluded arc
        node = {coordinates: p, arcs: []};
        arr.push(node);
        while (flags[thisIdx] != 1) {
          node.arcs.push(chainToArcId(thisIdx));
          flags[thisIdx] = 1;
          thisIdx = chains[thisIdx];
        }
      });
      return arr;
    };

    this.size = function() {
      return this.toArray().length;
    };

    this.findDanglingEndpoints = function() {
      var chains = getNodeChains(),
          arr = [], p;
      for (var i=0, n=chains.length; i<n; i++) {
        if (chains[i] != i) continue; // endpoint attaches to a node
        p = getEndpoint(i);
        if (!p) continue; // endpoint belongs to an excluded arc
        arr.push({
          point: p,
          arc: chainToArcId(i)
        });
      }
      return arr;
    };

    this.detachAcyclicArcs = function() {
      var chains = getNodeChains(),
          count = 0,
          fwd, rev;
      for (var i=0, n=chains.length; i<n; i+= 2) {
        fwd = i == chains[i];
        rev = i + 1 == chains[i + 1];
        // detach arcs that are disconnected at one end or the other
        if ((fwd || rev) && !linkIsDetached(i)) {
          this.detachArc(chainToArcId(i));
          count++;
        }
      }
      if (count > 0) {
        // removing one acyclic arc could expose another -- need another pass
        count += this.detachAcyclicArcs();
      }
      return count;
    };

    this.detachArc = function(arcId) {
      unlinkDirectedArc(arcId);
      unlinkDirectedArc(~arcId);
    };

    this.forEachConnectedArc = function(arcId, cb) {
      var nextId = nextConnectedArc(arcId),
          i = 0;
      while (nextId != arcId) {
        cb(nextId, i++);
        nextId = nextConnectedArc(nextId);
      }
    };

    // Receives an arc id for an arc that enters a node.
    // Returns an array of ids of all other arcs that are connected to the same node.
    //    Returned ids lead into the node (as opposed to outwards from it)
    // An optional filter function receives the directed id (positive or negative)
    //    of each connected arc and excludes arcs for which the filter returns false.
    //    // removed: The filter is also applied to the initial arc; if false, no arcs are returned.
    //
    this.getConnectedArcs = function(arcId, localFilter) {
      var ids = [];
      var nextId = nextConnectedArc(arcId);
      // kludge: return empty result if arc fails global test
      // ... applying the local filter causes tests to fail
      if (globalFilter && !globalFilter(arcId)) {
        return [];
      }
      while (nextId != arcId) {
        // if (!filtered || filter && filter(nextId) ) {
        if ((!localFilter || localFilter(nextId)) && (!globalFilter || globalFilter(nextId))) {
          ids.push(nextId);
        }
        nextId = nextConnectedArc(nextId);
      }
      return ids;
    };

    // Returns the id of the first identical arc or @arcId if none found
    // TODO: find a better function name
    this.findDuplicateArc = function(arcId) {
      var nextId = nextConnectedArc(arcId),
          match = arcId;
      while (nextId != arcId) {
        if (testArcMatch(arcId, nextId)) {
          if (absArcId(nextId) < absArcId(match)) match = nextId;
        }
        nextId = nextConnectedArc(nextId);
      }
      return match;
    };

    // returns null if link has been removed from node collection
    function getEndpoint(chainId) {
      return linkIsDetached(chainId) ? null : [nodeData.xx[chainId], nodeData.yy[chainId]];
    }

    function linkIsDetached(chainId) {
      return isNaN(nodeData.xx[chainId]);
    }

    function unlinkDirectedArc(arcId) {
      var chainId = arcToChainId(arcId),
          chains = getNodeChains(),
          nextId = chains[chainId],
          prevId = prevChainId(chainId);
      nodeData.xx[chainId] = NaN;
      nodeData.yy[chainId] = NaN;
      chains[chainId] = chainId;
      chains[prevId] = nextId;
    }

    function chainToArcId(chainId) {
      var absId = chainId >> 1;
      return chainId & 1 == 1 ? absId : ~absId;
    }

    function arcToChainId(arcId) {
      var fw = arcId >= 0;
      return fw ? arcId * 2 + 1 : (~arcId) * 2; // if fw, use end, if rev, use start
    }

    function getNodeChains() {
      if (!nodeData) {
        nodeData = findNodeTopology(arcs, filter);
        if (nn.length * 2 != nodeData.chains.length) error("[NodeCollection] count error");
      }
      return nodeData.chains;
    }

    function testArcMatch(a, b) {
      var absA = a >= 0 ? a : ~a,
          absB = b >= 0 ? b : ~b,
          lenA = nn[absA];
      if (lenA < 2) {
        // Don't throw error on collapsed arcs -- assume they will be handled
        //   appropriately downstream.
        // error("[testArcMatch() defective arc; len:", lenA);
        return false;
      }
      if (lenA != nn[absB]) return false;
      if (testVertexMatch(a, b, -1) &&
          testVertexMatch(a, b, 1) &&
          testVertexMatch(a, b, -2)) {
        return true;
      }
      return false;
    }

    function testVertexMatch(a, b, i) {
      var ai = arcs.indexOfVertex(a, i),
          bi = arcs.indexOfVertex(b, i);
      return xx[ai] == xx[bi] && yy[ai] == yy[bi];
    }

    // return arcId of next arc in the chain, pointed towards the shared vertex
    function nextConnectedArc(arcId) {
      var chainId = arcToChainId(arcId),
          chains =  getNodeChains(),
          nextChainId = chains[chainId];
      if (!(nextChainId >= 0 && nextChainId < chains.length)) {
        // console.log('arcId:', arcId, 'chainId:', chainId, 'next chain id:', nextChainId)
        error("out-of-range chain id");
      }
      return chainToArcId(nextChainId);
    }

    function prevChainId(chainId) {
      var chains = getNodeChains(),
          prevId = chainId,
          nextId = chains[chainId];
      while (nextId != chainId) {
        prevId = nextId;
        nextId = chains[nextId];
        if (nextId == prevId) error("Node indexing error");
      }
      return prevId;
    }

    // expose functions for testing
    this.internal = {
      testArcMatch: testArcMatch,
      testVertexMatch: testVertexMatch
    };
  }

  function findNodeTopology(arcs, filter) {
    var n = arcs.size() * 2,
        xx2 = new Float64Array(n),
        yy2 = new Float64Array(n),
        ids2 = new Int32Array(n);

    arcs.forEach2(function(i, n, xx, yy, zz, arcId) {
      var start = i,
          end = i + n - 1,
          start2 = arcId * 2,
          end2 = start2 + 1,
          ax = xx[start],
          ay = yy[start],
          bx = xx[end],
          by = yy[end];
      if (filter && !filter(arcId)) {
        ax = ay = bx = by = NaN;
      }

      xx2[start2] = ax;
      yy2[start2] = ay;
      ids2[start2] = arcId;
      xx2[end2] = bx;
      yy2[end2] = by;
      ids2[end2] = arcId;
    });

    var chains = initPointChains(xx2, yy2);
    return {
      xx: xx2,
      yy: yy2,
      ids: ids2,
      chains: chains
    };
  }

  // Dissolve arcs that can be merged without affecting topology of layers
  // remove arcs that are not referenced by any layer; remap arc ids
  // in layers. (dataset.arcs is replaced).
  function dissolveArcs(dataset) {
    var arcs = dataset.arcs,
        layers = dataset.layers.filter(layerHasPaths);

    if (!arcs || !layers.length) {
      dataset.arcs = null;
      return;
    }

    var arcsCanDissolve = getArcDissolveTest(layers, arcs),
        newArcs = [],
        totalPoints = 0,
        arcIndex = new Int32Array(arcs.size()), // maps old arc ids to new ids
        arcStatus = new Uint8Array(arcs.size());
        // arcStatus: 0 = unvisited, 1 = dropped, 2 = remapped, 3 = remapped + reversed
    layers.forEach(function(lyr) {
      // modify copies of the original shapes; original shapes should be unmodified
      // (need to test this)
      lyr.shapes = lyr.shapes.map(function(shape) {
        return editShapeParts(shape && shape.concat(), translatePath);
      });
    });
    dataset.arcs = dissolveArcCollection(arcs, newArcs, totalPoints);

    function translatePath(path) {
      var pointCount = 0;
      var newPath = [];
      var newArc, arcId, absId, arcLen, fw, newArcId;

      for (var i=0, n=path.length; i<n; i++) {
        arcId = path[i];
        absId = absArcId(arcId);
        fw = arcId === absId;

        if (arcs.arcIsDegenerate(arcId)) ; else if (arcStatus[absId] !== 0) {
          // arc has already been translated -- skip
          newArc = null;
        } else {
          arcLen = arcs.getArcLength(arcId);

          if (newArc && arcsCanDissolve(path[i-1], arcId)) {
            if (arcLen > 0) {
              arcLen--; // shared endpoint not counted;
            }
            newArc.push(arcId);  // arc data is appended to previous arc
            arcStatus[absId] = 1; // arc is dropped from output
          } else {
            // start a new dissolved arc
            newArc = [arcId];
            arcIndex[absId] = newArcs.length;
            newArcs.push(newArc);
            arcStatus[absId] = fw ? 2 : 3; // 2: unchanged; 3: reversed
          }
          pointCount += arcLen;
        }

        if (arcStatus[absId] > 1) {
          // arc is retained (and renumbered) in the dissolved path -- add to path
          newArcId = arcIndex[absId];
          if (fw && arcStatus[absId] == 3 || !fw && arcStatus[absId] == 2) {
            newArcId = ~newArcId;
          }
          newPath.push(newArcId);
        }
      }
      totalPoints += pointCount;
      return newPath;
    }
  }

  function dissolveArcCollection(arcs, newArcs, newLen) {
    var nn2 = new Uint32Array(newArcs.length),
        xx2 = new Float64Array(newLen),
        yy2 = new Float64Array(newLen),
        src = arcs.getVertexData(),
        zz2 = src.zz ? new Float64Array(newLen) : null,
        interval = arcs.getRetainedInterval(),
        offs = 0;

    newArcs.forEach(function(newArc, newId) {
      newArc.forEach(function(oldId, i) {
        extendDissolvedArc(oldId, newId);
      });
    });

    return new ArcCollection(nn2, xx2, yy2).setThresholds(zz2).setRetainedInterval(interval);

    function extendDissolvedArc(oldId, newId) {
      var absId = absArcId(oldId),
          rev = oldId < 0,
          n = src.nn[absId],
          i = src.ii[absId],
          n2 = nn2[newId];

      if (n > 0) {
        if (n2 > 0) {
          n--;
          if (!rev) i++;
        }
        utils.copyElements(src.xx, i, xx2, offs, n, rev);
        utils.copyElements(src.yy, i, yy2, offs, n, rev);
        if (zz2) utils.copyElements(src.zz, i, zz2, offs, n, rev);
        nn2[newId] += n;
        offs += n;
      }
    }
  }

  // Test whether two arcs can be merged together
  function getArcDissolveTest(layers, arcs) {
    var nodes = new NodeCollection(arcs, getArcPresenceTest2(layers, arcs)),
        // don't allow dissolving through endpoints of polyline paths
        lineLayers = layers.filter(function(lyr) {return lyr.geometry_type == 'polyline';}),
        testLineEndpoint = getPathEndpointTest(lineLayers, arcs),
        linkCount, lastId;

    return function(id1, id2) {
      if (id1 == id2 || id1 == ~id2) {
        verbose("Unexpected arc sequence:", id1, id2);
        return false; // This is unexpected; don't try to dissolve, anyway
      }
      linkCount = 0;
      nodes.forEachConnectedArc(id1, countLink);
      return linkCount == 1 && lastId == ~id2 && !testLineEndpoint(id1) && !testLineEndpoint(~id2);
    };

    function countLink(arcId, i) {
      linkCount++;
      lastId = arcId;
    }
  }

  var ArcDissolve = /*#__PURE__*/Object.freeze({
    __proto__: null,
    dissolveArcs: dissolveArcs,
    getArcDissolveTest: getArcDissolveTest
  });

  // utility functions for datasets

  // Split into datasets with one layer each
  function splitDataset(dataset) {
    return dataset.layers.map(function(lyr) {
      var split = {
        arcs: dataset.arcs,
        layers: [lyr],
        info: utils.extend({}, dataset.info)
      };
      dissolveArcs(split); // replace arcs with filtered + dissolved copy
      return split;
    });
  }

  // dest: destination dataset
  // src: source dataset
  function mergeDatasetInfo(dest, src) {
    var srcInfo = src.info || {};
    var destInfo = dest.info || (dest.info = {});
    destInfo.input_files = utils.uniq((destInfo.input_files || []).concat(srcInfo.input_files || []));
    destInfo.input_formats = utils.uniq((destInfo.input_formats || []).concat(srcInfo.input_formats || []));
    // merge other info properties (e.g. input_geojson_crs, input_delimiter, prj, crs)
    utils.defaults(destInfo, srcInfo);
  }

  function copyDatasetInfo(info) {
    // not a deep copy... objects like info.crs are read-only, so copy-by-reference
    // should be ok
    var info2 = Object.assign({}, info);
    if (Array.isArray(info.input_files)) {
      info2.input_files = info.input_files.concat();
    }
    return info2;
  }

  function splitApartLayers(dataset, layers) {
    var datasets = [];
    dataset.layers = dataset.layers.filter(function(lyr) {
      if (!layers.includes(lyr)) {
        return true;
      }
      var split = {
        arcs: dataset.arcs,
        layers: [lyr],
        info: utils.extend({}, dataset.info)
      };
      dissolveArcs(split); // replace arcs with filtered + dissolved copy
      datasets.push(split);
      return false;
    });
    if (dataset.layers.length) {
      dissolveArcs(dataset);
      datasets.push(dataset);
    }
    return datasets;
  }

  // clone all layers, make a filtered copy of arcs
  function copyDataset(dataset) {
    var d2 = utils.extend({}, dataset);
    d2.layers = d2.layers.map(copyLayer);
    if (d2.arcs) {
      d2.arcs = d2.arcs.getFilteredCopy();
    }
    return d2;
  }

  // clone coordinate data, shallow-copy attribute data
  function copyDatasetForExport(dataset) {
    var d2 = utils.extend({}, dataset);
    d2.layers = d2.layers.map(copyLayerShapes);
    if (d2.arcs) {
      d2.arcs = d2.arcs.getFilteredCopy();
    }
    return d2;
  }

  // shallow-copy layers, so they can be renamed (for export)
  function copyDatasetForRenaming(dataset) {
    return utils.defaults({
      layers: dataset.layers.map(function(lyr) {return utils.extend({}, lyr);})
    }, dataset);
  }

  function getDatasetBounds(dataset) {
    var bounds = new Bounds();
    dataset.layers.forEach(function(lyr) {
      var lyrbb = getLayerBounds(lyr, dataset.arcs);
      if (lyrbb) bounds.mergeBounds(lyrbb);
    });
    return bounds;
  }

  function datasetIsEmpty(dataset) {
    return dataset.layers.every(function(lyr) {
      return layerIsEmpty(lyr);
    });
  }

  function datasetHasGeometry(dataset) {
    return utils.some(dataset.layers, function(lyr) {
      return layerHasGeometry(lyr);
    });
  }

  function datasetHasPaths(dataset) {
    return utils.some(dataset.layers, function(lyr) {
      return layerHasPaths(lyr);
    });
  }

  // Remove ArcCollection of a dataset if not referenced by any layer
  // TODO: consider doing arc dissolve, or just removing unreferenced arcs
  // (currently cleanupArcs() is run after every command, so be mindful of performance)
  function cleanupArcs(dataset) {
    if (dataset.arcs && !utils.some(dataset.layers, layerHasPaths)) {
      dataset.arcs = null;
      return true;
    }
  }

  // Remove unused arcs from a dataset
  // Warning: using dissolveArcs() means that adjacent arcs are combined when possible
  function pruneArcs(dataset) {
    cleanupArcs(dataset);
    if (dataset.arcs) {
      dissolveArcs(dataset);
    }
  }

  // replace cut layers in-sequence (to maintain layer indexes)
  // append any additional new layers
  function replaceLayers(dataset, cutLayers, newLayers) {
    // modify a copy in case cutLayers == dataset.layers
    var currLayers = dataset.layers.concat();
    utils.repeat(Math.max(cutLayers.length, newLayers.length), function(i) {
      var cutLyr = cutLayers[i],
          newLyr = newLayers[i],
          idx = cutLyr ? currLayers.indexOf(cutLyr) : currLayers.length;

      if (cutLyr) {
        currLayers.splice(idx, 1);
      }
      if (newLyr) {
        currLayers.splice(idx, 0, newLyr);
      }
    });
    dataset.layers = currLayers;
  }

  // Replace a layer with a layer from a second dataset
  // (in-place)
  // (Typically, the second dataset is imported from dynamically generated GeoJSON and contains one layer)
  function replaceLayerContents(lyr, dataset, dataset2) {
    var lyr2 = mergeOutputLayerIntoDataset(lyr, dataset, dataset2, {});
    if (layerHasPaths(lyr2)) {
      buildTopology(dataset);
    }
  }

  function mergeOutputLayerIntoDataset(lyr, dataset, dataset2, opts) {
    if (!dataset2 || dataset2.layers.length != 1) {
      error('Invalid source dataset');
    }
    if (dataset.layers.includes(lyr) === false) {
      error('Invalid target layer');
    }
    // this command returns merged layers instead of adding them to target dataset
    var outputLayers = mergeDatasetsIntoDataset(dataset, [dataset2]);
    var lyr2 = outputLayers[0];

    // TODO: find a more reliable way of knowing when to copy data
    var copyData = !lyr2.data && lyr.data && getFeatureCount(lyr2) == lyr.data.size();

    if (copyData) {
      lyr2.data = opts.no_replace ? lyr.data.clone() : lyr.data;
    }
    if (opts.no_replace) ; else {
      lyr2 = Object.assign(lyr, {data: null, shapes: null}, lyr2);
      if (layerHasPaths(lyr)) {
        // Remove unused arcs from replaced layer
        // TODO: consider using clean insead of this
        dissolveArcs(dataset);
      }
    }

    lyr2.name = opts.name || lyr2.name;
    return lyr2;
  }

  // Transform the points in a dataset in-place; don't clean up corrupted shapes
  function transformPoints(dataset, f) {
    if (dataset.arcs) {
      dataset.arcs.transformPoints(f);
    }
    dataset.layers.forEach(function(lyr) {
      if (layerHasPoints(lyr)) {
        transformPointsInLayer(lyr, f);
      }
    });
  }

  var DatasetUtils = /*#__PURE__*/Object.freeze({
    __proto__: null,
    splitDataset: splitDataset,
    mergeDatasetInfo: mergeDatasetInfo,
    copyDatasetInfo: copyDatasetInfo,
    splitApartLayers: splitApartLayers,
    copyDataset: copyDataset,
    copyDatasetForExport: copyDatasetForExport,
    copyDatasetForRenaming: copyDatasetForRenaming,
    getDatasetBounds: getDatasetBounds,
    datasetIsEmpty: datasetIsEmpty,
    datasetHasGeometry: datasetHasGeometry,
    datasetHasPaths: datasetHasPaths,
    cleanupArcs: cleanupArcs,
    pruneArcs: pruneArcs,
    replaceLayers: replaceLayers,
    replaceLayerContents: replaceLayerContents,
    mergeOutputLayerIntoDataset: mergeOutputLayerIntoDataset,
    transformPoints: transformPoints
  });

  function getPathSep(path) {
    // TODO: improve
    return path.indexOf('/') == -1 && path.indexOf('\\') != -1 ? '\\' : '/';
  }

  // Parse the path to a file without using Node
  // Guess if the path is a directory or file
  function parseLocalPath(path) {
    var obj = {
          filename: '',
          directory: '',
          basename: '',
          extension: ''
        },
        sep = getPathSep(path),
        parts = path.split(sep),
        lastPart = parts.pop(),
        // try to match typical extensions but reject directory names with dots
        extRxp = /\.([a-z][a-z0-9]*)$/i,
        extMatch = extRxp.test(lastPart) ? extRxp.exec(lastPart)[0] : '';

    if (extMatch || lastPart.includes('*')) {
      obj.filename = lastPart;
      obj.extension = extMatch ? extMatch.slice(1) : '';
      obj.basename = lastPart.slice(0, lastPart.length - extMatch.length);
      obj.directory = parts.join(sep);
    } else if (!lastPart) { // path ends with separator
      obj.directory = parts.join(sep);
    } else {
      obj.directory = path;
    }
    return obj;
  }

  function getFileBase(path) {
    return parseLocalPath(path).basename;
  }

  function getFileExtension(path) {
    return parseLocalPath(path).extension;
  }

  function getPathBase(path) {
    var info =  parseLocalPath(path);
    if (!info.extension) return path;
    return path.slice(0, path.length - info.extension.length - 1);
  }

  function replaceFileExtension(path, ext) {
    var base = getPathBase(path);
    return ext ? base + '.' + ext : base;
  }

  function toLowerCaseExtension(name) {
    var ext = getFileExtension(name);
    return ext ? getPathBase(name) + '.' + ext.toLowerCase() : name;
  }

  function getCommonFileBase(names) {
    return names.reduce(function(memo, name, i) {
      if (i === 0) {
        memo = getFileBase(name);
      } else {
        memo = utils.mergeNames(memo, name);
      }
      return memo;
    }, "");
  }

  function getOutputFileBase(dataset) {
    var inputFiles = dataset.info && dataset.info.input_files;
    return inputFiles && getCommonFileBase(inputFiles) || 'output';
  }

  var FilenameUtils = /*#__PURE__*/Object.freeze({
    __proto__: null,
    parseLocalPath: parseLocalPath,
    getFileBase: getFileBase,
    getFileExtension: getFileExtension,
    getPathBase: getPathBase,
    replaceFileExtension: replaceFileExtension,
    toLowerCaseExtension: toLowerCaseExtension,
    getCommonFileBase: getCommonFileBase,
    getOutputFileBase: getOutputFileBase
  });

  var decoder;
  try {
  	decoder = new TextDecoder();
  } catch(error) {}
  var src;
  var srcEnd;
  var position$1 = 0;
  var currentUnpackr = {};
  var currentStructures;
  var srcString;
  var srcStringStart = 0;
  var srcStringEnd = 0;
  var bundledStrings$1;
  var referenceMap;
  var currentExtensions = [];
  var dataView;
  var defaultOptions = {
  	useRecords: false,
  	mapsAsObjects: true
  };
  class C1Type {}
  const C1$1 = new C1Type();
  C1$1.name = 'MessagePack 0xC1';
  var sequentialMode = false;
  var inlineObjectReadThreshold = 2;
  var readStruct;
  // no-eval build
  try {
  	new Function('');
  } catch(error) {
  	// if eval variants are not supported, do not create inline object readers ever
  	inlineObjectReadThreshold = Infinity;
  }

  class Unpackr {
  	constructor(options) {
  		if (options) {
  			if (options.useRecords === false && options.mapsAsObjects === undefined)
  				options.mapsAsObjects = true;
  			if (options.sequential && options.trusted !== false) {
  				options.trusted = true;
  				if (!options.structures && options.useRecords != false) {
  					options.structures = [];
  					if (!options.maxSharedStructures)
  						options.maxSharedStructures = 0;
  				}
  			}
  			if (options.structures)
  				options.structures.sharedLength = options.structures.length;
  			else if (options.getStructures) {
  				(options.structures = []).uninitialized = true; // this is what we use to denote an uninitialized structures
  				options.structures.sharedLength = 0;
  			}
  			if (options.int64AsNumber) {
  				options.int64AsType = 'number';
  			}
  		}
  		Object.assign(this, options);
  	}
  	unpack(source, options) {
  		if (src) {
  			// re-entrant execution, save the state and restore it after we do this unpack
  			return saveState(() => {
  				clearSource();
  				return this ? this.unpack(source, options) : Unpackr.prototype.unpack.call(defaultOptions, source, options)
  			})
  		}
  		if (!source.buffer && source.constructor === ArrayBuffer)
  			source = typeof Buffer !== 'undefined' ? Buffer.from(source) : new Uint8Array(source);
  		if (typeof options === 'object') {
  			srcEnd = options.end || source.length;
  			position$1 = options.start || 0;
  		} else {
  			position$1 = 0;
  			srcEnd = options > -1 ? options : source.length;
  		}
  		srcStringEnd = 0;
  		srcString = null;
  		bundledStrings$1 = null;
  		src = source;
  		// this provides cached access to the data view for a buffer if it is getting reused, which is a recommend
  		// technique for getting data from a database where it can be copied into an existing buffer instead of creating
  		// new ones
  		try {
  			dataView = source.dataView || (source.dataView = new DataView(source.buffer, source.byteOffset, source.byteLength));
  		} catch(error) {
  			// if it doesn't have a buffer, maybe it is the wrong type of object
  			src = null;
  			if (source instanceof Uint8Array)
  				throw error
  			throw new Error('Source must be a Uint8Array or Buffer but was a ' + ((source && typeof source == 'object') ? source.constructor.name : typeof source))
  		}
  		if (this instanceof Unpackr) {
  			currentUnpackr = this;
  			if (this.structures) {
  				currentStructures = this.structures;
  				return checkedRead(options)
  			} else if (!currentStructures || currentStructures.length > 0) {
  				currentStructures = [];
  			}
  		} else {
  			currentUnpackr = defaultOptions;
  			if (!currentStructures || currentStructures.length > 0)
  				currentStructures = [];
  		}
  		return checkedRead(options)
  	}
  	unpackMultiple(source, forEach) {
  		let values, lastPosition = 0;
  		try {
  			sequentialMode = true;
  			let size = source.length;
  			let value = this ? this.unpack(source, size) : defaultUnpackr.unpack(source, size);
  			if (forEach) {
  				if (forEach(value, lastPosition, position$1) === false) return;
  				while(position$1 < size) {
  					lastPosition = position$1;
  					if (forEach(checkedRead(), lastPosition, position$1) === false) {
  						return
  					}
  				}
  			}
  			else {
  				values = [ value ];
  				while(position$1 < size) {
  					lastPosition = position$1;
  					values.push(checkedRead());
  				}
  				return values
  			}
  		} catch(error) {
  			error.lastPosition = lastPosition;
  			error.values = values;
  			throw error
  		} finally {
  			sequentialMode = false;
  			clearSource();
  		}
  	}
  	_mergeStructures(loadedStructures, existingStructures) {
  		loadedStructures = loadedStructures || [];
  		if (Object.isFrozen(loadedStructures))
  			loadedStructures = loadedStructures.map(structure => structure.slice(0));
  		for (let i = 0, l = loadedStructures.length; i < l; i++) {
  			let structure = loadedStructures[i];
  			if (structure) {
  				structure.isShared = true;
  				if (i >= 32)
  					structure.highByte = (i - 32) >> 5;
  			}
  		}
  		loadedStructures.sharedLength = loadedStructures.length;
  		for (let id in existingStructures || []) {
  			if (id >= 0) {
  				let structure = loadedStructures[id];
  				let existing = existingStructures[id];
  				if (existing) {
  					if (structure)
  						(loadedStructures.restoreStructures || (loadedStructures.restoreStructures = []))[id] = structure;
  					loadedStructures[id] = existing;
  				}
  			}
  		}
  		return this.structures = loadedStructures
  	}
  	decode(source, options) {
  		return this.unpack(source, options)
  	}
  }
  function checkedRead(options) {
  	try {
  		if (!currentUnpackr.trusted && !sequentialMode) {
  			let sharedLength = currentStructures.sharedLength || 0;
  			if (sharedLength < currentStructures.length)
  				currentStructures.length = sharedLength;
  		}
  		let result;
  		if (currentUnpackr.randomAccessStructure && src[position$1] < 0x40 && src[position$1] >= 0x20 && readStruct) {
  			result = readStruct(src, position$1, srcEnd, currentUnpackr);
  			src = null; // dispose of this so that recursive unpack calls don't save state
  			if (!(options && options.lazy) && result)
  				result = result.toJSON();
  			position$1 = srcEnd;
  		} else
  			result = read();
  		if (bundledStrings$1) { // bundled strings to skip past
  			position$1 = bundledStrings$1.postBundlePosition;
  			bundledStrings$1 = null;
  		}
  		if (sequentialMode)
  			// we only need to restore the structures if there was an error, but if we completed a read,
  			// we can clear this out and keep the structures we read
  			currentStructures.restoreStructures = null;

  		if (position$1 == srcEnd) {
  			// finished reading this source, cleanup references
  			if (currentStructures && currentStructures.restoreStructures)
  				restoreStructures();
  			currentStructures = null;
  			src = null;
  			if (referenceMap)
  				referenceMap = null;
  		} else if (position$1 > srcEnd) {
  			// over read
  			throw new Error('Unexpected end of MessagePack data')
  		} else if (!sequentialMode) {
  			let jsonView;
  			try {
  				jsonView = JSON.stringify(result, (_, value) => typeof value === "bigint" ? `${value}n` : value).slice(0, 100);
  			} catch(error) {
  				jsonView = '(JSON view not available ' + error + ')';
  			}
  			throw new Error('Data read, but end of buffer not reached ' + jsonView)
  		}
  		// else more to read, but we are reading sequentially, so don't clear source yet
  		return result
  	} catch(error) {
  		if (currentStructures && currentStructures.restoreStructures)
  			restoreStructures();
  		clearSource();
  		if (error instanceof RangeError || error.message.startsWith('Unexpected end of buffer') || position$1 > srcEnd) {
  			error.incomplete = true;
  		}
  		throw error
  	}
  }

  function restoreStructures() {
  	for (let id in currentStructures.restoreStructures) {
  		currentStructures[id] = currentStructures.restoreStructures[id];
  	}
  	currentStructures.restoreStructures = null;
  }

  function read() {
  	let token = src[position$1++];
  	if (token < 0xa0) {
  		if (token < 0x80) {
  			if (token < 0x40)
  				return token
  			else {
  				let structure = currentStructures[token & 0x3f] ||
  					currentUnpackr.getStructures && loadStructures()[token & 0x3f];
  				if (structure) {
  					if (!structure.read) {
  						structure.read = createStructureReader(structure, token & 0x3f);
  					}
  					return structure.read()
  				} else
  					return token
  			}
  		} else if (token < 0x90) {
  			// map
  			token -= 0x80;
  			if (currentUnpackr.mapsAsObjects) {
  				let object = {};
  				for (let i = 0; i < token; i++) {
  					let key = readKey();
  					if (key === '__proto__')
  						key = '__proto_';
  					object[key] = read();
  				}
  				return object
  			} else {
  				let map = new Map();
  				for (let i = 0; i < token; i++) {
  					map.set(read(), read());
  				}
  				return map
  			}
  		} else {
  			token -= 0x90;
  			let array = new Array(token);
  			for (let i = 0; i < token; i++) {
  				array[i] = read();
  			}
  			if (currentUnpackr.freezeData)
  				return Object.freeze(array)
  			return array
  		}
  	} else if (token < 0xc0) {
  		// fixstr
  		let length = token - 0xa0;
  		if (srcStringEnd >= position$1) {
  			return srcString.slice(position$1 - srcStringStart, (position$1 += length) - srcStringStart)
  		}
  		if (srcStringEnd == 0 && srcEnd < 140) {
  			// for small blocks, avoiding the overhead of the extract call is helpful
  			let string = length < 16 ? shortStringInJS(length) : longStringInJS(length);
  			if (string != null)
  				return string
  		}
  		return readFixedString(length)
  	} else {
  		let value;
  		switch (token) {
  			case 0xc0: return null
  			case 0xc1:
  				if (bundledStrings$1) {
  					value = read(); // followed by the length of the string in characters (not bytes!)
  					if (value > 0)
  						return bundledStrings$1[1].slice(bundledStrings$1.position1, bundledStrings$1.position1 += value)
  					else
  						return bundledStrings$1[0].slice(bundledStrings$1.position0, bundledStrings$1.position0 -= value)
  				}
  				return C1$1; // "never-used", return special object to denote that
  			case 0xc2: return false
  			case 0xc3: return true
  			case 0xc4:
  				// bin 8
  				value = src[position$1++];
  				if (value === undefined)
  					throw new Error('Unexpected end of buffer')
  				return readBin(value)
  			case 0xc5:
  				// bin 16
  				value = dataView.getUint16(position$1);
  				position$1 += 2;
  				return readBin(value)
  			case 0xc6:
  				// bin 32
  				value = dataView.getUint32(position$1);
  				position$1 += 4;
  				return readBin(value)
  			case 0xc7:
  				// ext 8
  				return readExt(src[position$1++])
  			case 0xc8:
  				// ext 16
  				value = dataView.getUint16(position$1);
  				position$1 += 2;
  				return readExt(value)
  			case 0xc9:
  				// ext 32
  				value = dataView.getUint32(position$1);
  				position$1 += 4;
  				return readExt(value)
  			case 0xca:
  				value = dataView.getFloat32(position$1);
  				if (currentUnpackr.useFloat32 > 2) {
  					// this does rounding of numbers that were encoded in 32-bit float to nearest significant decimal digit that could be preserved
  					let multiplier = mult10[((src[position$1] & 0x7f) << 1) | (src[position$1 + 1] >> 7)];
  					position$1 += 4;
  					return ((multiplier * value + (value > 0 ? 0.5 : -0.5)) >> 0) / multiplier
  				}
  				position$1 += 4;
  				return value
  			case 0xcb:
  				value = dataView.getFloat64(position$1);
  				position$1 += 8;
  				return value
  			// uint handlers
  			case 0xcc:
  				return src[position$1++]
  			case 0xcd:
  				value = dataView.getUint16(position$1);
  				position$1 += 2;
  				return value
  			case 0xce:
  				value = dataView.getUint32(position$1);
  				position$1 += 4;
  				return value
  			case 0xcf:
  				if (currentUnpackr.int64AsType === 'number') {
  					value = dataView.getUint32(position$1) * 0x100000000;
  					value += dataView.getUint32(position$1 + 4);
  				} else if (currentUnpackr.int64AsType === 'string') {
  					value = dataView.getBigUint64(position$1).toString();
  				} else if (currentUnpackr.int64AsType === 'auto') {
  					value = dataView.getBigUint64(position$1);
  					if (value<=BigInt(2)<<BigInt(52)) value=Number(value);
  				} else
  					value = dataView.getBigUint64(position$1);
  				position$1 += 8;
  				return value

  			// int handlers
  			case 0xd0:
  				return dataView.getInt8(position$1++)
  			case 0xd1:
  				value = dataView.getInt16(position$1);
  				position$1 += 2;
  				return value
  			case 0xd2:
  				value = dataView.getInt32(position$1);
  				position$1 += 4;
  				return value
  			case 0xd3:
  				if (currentUnpackr.int64AsType === 'number') {
  					value = dataView.getInt32(position$1) * 0x100000000;
  					value += dataView.getUint32(position$1 + 4);
  				} else if (currentUnpackr.int64AsType === 'string') {
  					value = dataView.getBigInt64(position$1).toString();
  				} else if (currentUnpackr.int64AsType === 'auto') {
  					value = dataView.getBigInt64(position$1);
  					if (value>=BigInt(-2)<<BigInt(52)&&value<=BigInt(2)<<BigInt(52)) value=Number(value);
  				} else
  					value = dataView.getBigInt64(position$1);
  				position$1 += 8;
  				return value

  			case 0xd4:
  				// fixext 1
  				value = src[position$1++];
  				if (value == 0x72) {
  					return recordDefinition(src[position$1++] & 0x3f)
  				} else {
  					let extension = currentExtensions[value];
  					if (extension) {
  						if (extension.read) {
  							position$1++; // skip filler byte
  							return extension.read(read())
  						} else if (extension.noBuffer) {
  							position$1++; // skip filler byte
  							return extension()
  						} else
  							return extension(src.subarray(position$1, ++position$1))
  					} else
  						throw new Error('Unknown extension ' + value)
  				}
  			case 0xd5:
  				// fixext 2
  				value = src[position$1];
  				if (value == 0x72) {
  					position$1++;
  					return recordDefinition(src[position$1++] & 0x3f, src[position$1++])
  				} else
  					return readExt(2)
  			case 0xd6:
  				// fixext 4
  				return readExt(4)
  			case 0xd7:
  				// fixext 8
  				return readExt(8)
  			case 0xd8:
  				// fixext 16
  				return readExt(16)
  			case 0xd9:
  			// str 8
  				value = src[position$1++];
  				if (srcStringEnd >= position$1) {
  					return srcString.slice(position$1 - srcStringStart, (position$1 += value) - srcStringStart)
  				}
  				return readString8(value)
  			case 0xda:
  			// str 16
  				value = dataView.getUint16(position$1);
  				position$1 += 2;
  				if (srcStringEnd >= position$1) {
  					return srcString.slice(position$1 - srcStringStart, (position$1 += value) - srcStringStart)
  				}
  				return readString16(value)
  			case 0xdb:
  			// str 32
  				value = dataView.getUint32(position$1);
  				position$1 += 4;
  				if (srcStringEnd >= position$1) {
  					return srcString.slice(position$1 - srcStringStart, (position$1 += value) - srcStringStart)
  				}
  				return readString32(value)
  			case 0xdc:
  			// array 16
  				value = dataView.getUint16(position$1);
  				position$1 += 2;
  				return readArray$1(value)
  			case 0xdd:
  			// array 32
  				value = dataView.getUint32(position$1);
  				position$1 += 4;
  				return readArray$1(value)
  			case 0xde:
  			// map 16
  				value = dataView.getUint16(position$1);
  				position$1 += 2;
  				return readMap(value)
  			case 0xdf:
  			// map 32
  				value = dataView.getUint32(position$1);
  				position$1 += 4;
  				return readMap(value)
  			default: // negative int
  				if (token >= 0xe0)
  					return token - 0x100
  				if (token === undefined) {
  					let error = new Error('Unexpected end of MessagePack data');
  					error.incomplete = true;
  					throw error
  				}
  				throw new Error('Unknown MessagePack token ' + token)

  		}
  	}
  }
  const validName = /^[a-zA-Z_$][a-zA-Z\d_$]*$/;
  function createStructureReader(structure, firstId) {
  	function readObject() {
  		// This initial function is quick to instantiate, but runs slower. After several iterations pay the cost to build the faster function
  		if (readObject.count++ > inlineObjectReadThreshold) {
  			let readObject = structure.read = (new Function('r', 'return function(){return ' + (currentUnpackr.freezeData ? 'Object.freeze' : '') +
  				'({' + structure.map(key => key === '__proto__' ? '__proto_:r()' : validName.test(key) ? key + ':r()' : ('[' + JSON.stringify(key) + ']:r()')).join(',') + '})}'))(read);
  			if (structure.highByte === 0)
  				structure.read = createSecondByteReader(firstId, structure.read);
  			return readObject() // second byte is already read, if there is one so immediately read object
  		}
  		let object = {};
  		for (let i = 0, l = structure.length; i < l; i++) {
  			let key = structure[i];
  			if (key === '__proto__')
  				key = '__proto_';
  			object[key] = read();
  		}
  		if (currentUnpackr.freezeData)
  			return Object.freeze(object);
  		return object
  	}
  	readObject.count = 0;
  	if (structure.highByte === 0) {
  		return createSecondByteReader(firstId, readObject)
  	}
  	return readObject
  }

  const createSecondByteReader = (firstId, read0) => {
  	return function() {
  		let highByte = src[position$1++];
  		if (highByte === 0)
  			return read0()
  		let id = firstId < 32 ? -(firstId + (highByte << 5)) : firstId + (highByte << 5);
  		let structure = currentStructures[id] || loadStructures()[id];
  		if (!structure) {
  			throw new Error('Record id is not defined for ' + id)
  		}
  		if (!structure.read)
  			structure.read = createStructureReader(structure, firstId);
  		return structure.read()
  	}
  };

  function loadStructures() {
  	let loadedStructures = saveState(() => {
  		// save the state in case getStructures modifies our buffer
  		src = null;
  		return currentUnpackr.getStructures()
  	});
  	return currentStructures = currentUnpackr._mergeStructures(loadedStructures, currentStructures)
  }

  var readFixedString = readStringJS;
  var readString8 = readStringJS;
  var readString16 = readStringJS;
  var readString32 = readStringJS;
  function readStringJS(length) {
  	let result;
  	if (length < 16) {
  		if (result = shortStringInJS(length))
  			return result
  	}
  	if (length > 64 && decoder)
  		return decoder.decode(src.subarray(position$1, position$1 += length))
  	const end = position$1 + length;
  	const units = [];
  	result = '';
  	while (position$1 < end) {
  		const byte1 = src[position$1++];
  		if ((byte1 & 0x80) === 0) {
  			// 1 byte
  			units.push(byte1);
  		} else if ((byte1 & 0xe0) === 0xc0) {
  			// 2 bytes
  			const byte2 = src[position$1++] & 0x3f;
  			units.push(((byte1 & 0x1f) << 6) | byte2);
  		} else if ((byte1 & 0xf0) === 0xe0) {
  			// 3 bytes
  			const byte2 = src[position$1++] & 0x3f;
  			const byte3 = src[position$1++] & 0x3f;
  			units.push(((byte1 & 0x1f) << 12) | (byte2 << 6) | byte3);
  		} else if ((byte1 & 0xf8) === 0xf0) {
  			// 4 bytes
  			const byte2 = src[position$1++] & 0x3f;
  			const byte3 = src[position$1++] & 0x3f;
  			const byte4 = src[position$1++] & 0x3f;
  			let unit = ((byte1 & 0x07) << 0x12) | (byte2 << 0x0c) | (byte3 << 0x06) | byte4;
  			if (unit > 0xffff) {
  				unit -= 0x10000;
  				units.push(((unit >>> 10) & 0x3ff) | 0xd800);
  				unit = 0xdc00 | (unit & 0x3ff);
  			}
  			units.push(unit);
  		} else {
  			units.push(byte1);
  		}

  		if (units.length >= 0x1000) {
  			result += fromCharCode.apply(String, units);
  			units.length = 0;
  		}
  	}

  	if (units.length > 0) {
  		result += fromCharCode.apply(String, units);
  	}

  	return result
  }

  function readArray$1(length) {
  	let array = new Array(length);
  	for (let i = 0; i < length; i++) {
  		array[i] = read();
  	}
  	if (currentUnpackr.freezeData)
  		return Object.freeze(array)
  	return array
  }

  function readMap(length) {
  	if (currentUnpackr.mapsAsObjects) {
  		let object = {};
  		for (let i = 0; i < length; i++) {
  			let key = readKey();
  			if (key === '__proto__')
  				key = '__proto_';
  			object[key] = read();
  		}
  		return object
  	} else {
  		let map = new Map();
  		for (let i = 0; i < length; i++) {
  			map.set(read(), read());
  		}
  		return map
  	}
  }

  var fromCharCode = String.fromCharCode;
  function longStringInJS(length) {
  	let start = position$1;
  	let bytes = new Array(length);
  	for (let i = 0; i < length; i++) {
  		const byte = src[position$1++];
  		if ((byte & 0x80) > 0) {
  				position$1 = start;
  				return
  			}
  			bytes[i] = byte;
  		}
  		return fromCharCode.apply(String, bytes)
  }
  function shortStringInJS(length) {
  	if (length < 4) {
  		if (length < 2) {
  			if (length === 0)
  				return ''
  			else {
  				let a = src[position$1++];
  				if ((a & 0x80) > 1) {
  					position$1 -= 1;
  					return
  				}
  				return fromCharCode(a)
  			}
  		} else {
  			let a = src[position$1++];
  			let b = src[position$1++];
  			if ((a & 0x80) > 0 || (b & 0x80) > 0) {
  				position$1 -= 2;
  				return
  			}
  			if (length < 3)
  				return fromCharCode(a, b)
  			let c = src[position$1++];
  			if ((c & 0x80) > 0) {
  				position$1 -= 3;
  				return
  			}
  			return fromCharCode(a, b, c)
  		}
  	} else {
  		let a = src[position$1++];
  		let b = src[position$1++];
  		let c = src[position$1++];
  		let d = src[position$1++];
  		if ((a & 0x80) > 0 || (b & 0x80) > 0 || (c & 0x80) > 0 || (d & 0x80) > 0) {
  			position$1 -= 4;
  			return
  		}
  		if (length < 6) {
  			if (length === 4)
  				return fromCharCode(a, b, c, d)
  			else {
  				let e = src[position$1++];
  				if ((e & 0x80) > 0) {
  					position$1 -= 5;
  					return
  				}
  				return fromCharCode(a, b, c, d, e)
  			}
  		} else if (length < 8) {
  			let e = src[position$1++];
  			let f = src[position$1++];
  			if ((e & 0x80) > 0 || (f & 0x80) > 0) {
  				position$1 -= 6;
  				return
  			}
  			if (length < 7)
  				return fromCharCode(a, b, c, d, e, f)
  			let g = src[position$1++];
  			if ((g & 0x80) > 0) {
  				position$1 -= 7;
  				return
  			}
  			return fromCharCode(a, b, c, d, e, f, g)
  		} else {
  			let e = src[position$1++];
  			let f = src[position$1++];
  			let g = src[position$1++];
  			let h = src[position$1++];
  			if ((e & 0x80) > 0 || (f & 0x80) > 0 || (g & 0x80) > 0 || (h & 0x80) > 0) {
  				position$1 -= 8;
  				return
  			}
  			if (length < 10) {
  				if (length === 8)
  					return fromCharCode(a, b, c, d, e, f, g, h)
  				else {
  					let i = src[position$1++];
  					if ((i & 0x80) > 0) {
  						position$1 -= 9;
  						return
  					}
  					return fromCharCode(a, b, c, d, e, f, g, h, i)
  				}
  			} else if (length < 12) {
  				let i = src[position$1++];
  				let j = src[position$1++];
  				if ((i & 0x80) > 0 || (j & 0x80) > 0) {
  					position$1 -= 10;
  					return
  				}
  				if (length < 11)
  					return fromCharCode(a, b, c, d, e, f, g, h, i, j)
  				let k = src[position$1++];
  				if ((k & 0x80) > 0) {
  					position$1 -= 11;
  					return
  				}
  				return fromCharCode(a, b, c, d, e, f, g, h, i, j, k)
  			} else {
  				let i = src[position$1++];
  				let j = src[position$1++];
  				let k = src[position$1++];
  				let l = src[position$1++];
  				if ((i & 0x80) > 0 || (j & 0x80) > 0 || (k & 0x80) > 0 || (l & 0x80) > 0) {
  					position$1 -= 12;
  					return
  				}
  				if (length < 14) {
  					if (length === 12)
  						return fromCharCode(a, b, c, d, e, f, g, h, i, j, k, l)
  					else {
  						let m = src[position$1++];
  						if ((m & 0x80) > 0) {
  							position$1 -= 13;
  							return
  						}
  						return fromCharCode(a, b, c, d, e, f, g, h, i, j, k, l, m)
  					}
  				} else {
  					let m = src[position$1++];
  					let n = src[position$1++];
  					if ((m & 0x80) > 0 || (n & 0x80) > 0) {
  						position$1 -= 14;
  						return
  					}
  					if (length < 15)
  						return fromCharCode(a, b, c, d, e, f, g, h, i, j, k, l, m, n)
  					let o = src[position$1++];
  					if ((o & 0x80) > 0) {
  						position$1 -= 15;
  						return
  					}
  					return fromCharCode(a, b, c, d, e, f, g, h, i, j, k, l, m, n, o)
  				}
  			}
  		}
  	}
  }

  function readOnlyJSString() {
  	let token = src[position$1++];
  	let length;
  	if (token < 0xc0) {
  		// fixstr
  		length = token - 0xa0;
  	} else {
  		switch(token) {
  			case 0xd9:
  			// str 8
  				length = src[position$1++];
  				break
  			case 0xda:
  			// str 16
  				length = dataView.getUint16(position$1);
  				position$1 += 2;
  				break
  			case 0xdb:
  			// str 32
  				length = dataView.getUint32(position$1);
  				position$1 += 4;
  				break
  			default:
  				throw new Error('Expected string')
  		}
  	}
  	return readStringJS(length)
  }


  function readBin(length) {
  	return currentUnpackr.copyBuffers ?
  		// specifically use the copying slice (not the node one)
  		Uint8Array.prototype.slice.call(src, position$1, position$1 += length) :
  		src.subarray(position$1, position$1 += length)
  }
  function readExt(length) {
  	let type = src[position$1++];
  	if (currentExtensions[type]) {
  		let end;
  		return currentExtensions[type](src.subarray(position$1, end = (position$1 += length)), (readPosition) => {
  			position$1 = readPosition;
  			try {
  				return read();
  			} finally {
  				position$1 = end;
  			}
  		})
  	}
  	else
  		throw new Error('Unknown extension type ' + type)
  }

  var keyCache = new Array(4096);
  function readKey() {
  	let length = src[position$1++];
  	if (length >= 0xa0 && length < 0xc0) {
  		// fixstr, potentially use key cache
  		length = length - 0xa0;
  		if (srcStringEnd >= position$1) // if it has been extracted, must use it (and faster anyway)
  			return srcString.slice(position$1 - srcStringStart, (position$1 += length) - srcStringStart)
  		else if (!(srcStringEnd == 0 && srcEnd < 180))
  			return readFixedString(length)
  	} else { // not cacheable, go back and do a standard read
  		position$1--;
  		return asSafeString(read())
  	}
  	let key = ((length << 5) ^ (length > 1 ? dataView.getUint16(position$1) : length > 0 ? src[position$1] : 0)) & 0xfff;
  	let entry = keyCache[key];
  	let checkPosition = position$1;
  	let end = position$1 + length - 3;
  	let chunk;
  	let i = 0;
  	if (entry && entry.bytes == length) {
  		while (checkPosition < end) {
  			chunk = dataView.getUint32(checkPosition);
  			if (chunk != entry[i++]) {
  				checkPosition = 0x70000000;
  				break
  			}
  			checkPosition += 4;
  		}
  		end += 3;
  		while (checkPosition < end) {
  			chunk = src[checkPosition++];
  			if (chunk != entry[i++]) {
  				checkPosition = 0x70000000;
  				break
  			}
  		}
  		if (checkPosition === end) {
  			position$1 = checkPosition;
  			return entry.string
  		}
  		end -= 3;
  		checkPosition = position$1;
  	}
  	entry = [];
  	keyCache[key] = entry;
  	entry.bytes = length;
  	while (checkPosition < end) {
  		chunk = dataView.getUint32(checkPosition);
  		entry.push(chunk);
  		checkPosition += 4;
  	}
  	end += 3;
  	while (checkPosition < end) {
  		chunk = src[checkPosition++];
  		entry.push(chunk);
  	}
  	// for small blocks, avoiding the overhead of the extract call is helpful
  	let string = length < 16 ? shortStringInJS(length) : longStringInJS(length);
  	if (string != null)
  		return entry.string = string
  	return entry.string = readFixedString(length)
  }

  function asSafeString(property) {
  	if (typeof property === 'string') return property;
  	if (typeof property === 'number') return property.toString();
  	throw new Error('Invalid property type for record', typeof property);
  }
  // the registration of the record definition extension (as "r")
  const recordDefinition = (id, highByte) => {
  	let structure = read().map(asSafeString); // ensure that all keys are strings and
  	// that the array is mutable
  	let firstByte = id;
  	if (highByte !== undefined) {
  		id = id < 32 ? -((highByte << 5) + id) : ((highByte << 5) + id);
  		structure.highByte = highByte;
  	}
  	let existingStructure = currentStructures[id];
  	// If it is a shared structure, we need to restore any changes after reading.
  	// Also in sequential mode, we may get incomplete reads and thus errors, and we need to restore
  	// to the state prior to an incomplete read in order to properly resume.
  	if (existingStructure && (existingStructure.isShared || sequentialMode)) {
  		(currentStructures.restoreStructures || (currentStructures.restoreStructures = []))[id] = existingStructure;
  	}
  	currentStructures[id] = structure;
  	structure.read = createStructureReader(structure, firstByte);
  	return structure.read()
  };
  currentExtensions[0] = () => {}; // notepack defines extension 0 to mean undefined, so use that as the default here
  currentExtensions[0].noBuffer = true;

  currentExtensions[0x42] = (data) => {
  	// decode bigint
  	let length = data.length;
  	let value = BigInt(data[0] & 0x80 ? data[0] - 0x100 : data[0]);
  	for (let i = 1; i < length; i++) {
  		value <<= 8n;
  		value += BigInt(data[i]);
  	}
  	return value;
  };

  let errors = { Error, TypeError, ReferenceError };
  currentExtensions[0x65] = () => {
  	let data = read();
  	return (errors[data[0]] || Error)(data[1])
  };

  currentExtensions[0x69] = (data) => {
  	// id extension (for structured clones)
  	if (currentUnpackr.structuredClone === false) throw new Error('Structured clone extension is disabled')
  	let id = dataView.getUint32(position$1 - 4);
  	if (!referenceMap)
  		referenceMap = new Map();
  	let token = src[position$1];
  	let target;
  	// TODO: handle Maps, Sets, and other types that can cycle; this is complicated, because you potentially need to read
  	// ahead past references to record structure definitions
  	if (token >= 0x90 && token < 0xa0 || token == 0xdc || token == 0xdd)
  		target = [];
  	else
  		target = {};

  	let refEntry = { target }; // a placeholder object
  	referenceMap.set(id, refEntry);
  	let targetProperties = read(); // read the next value as the target object to id
  	if (refEntry.used) // there is a cycle, so we have to assign properties to original target
  		return Object.assign(target, targetProperties)
  	refEntry.target = targetProperties; // the placeholder wasn't used, replace with the deserialized one
  	return targetProperties // no cycle, can just use the returned read object
  };

  currentExtensions[0x70] = (data) => {
  	// pointer extension (for structured clones)
  	if (currentUnpackr.structuredClone === false) throw new Error('Structured clone extension is disabled')
  	let id = dataView.getUint32(position$1 - 4);
  	let refEntry = referenceMap.get(id);
  	refEntry.used = true;
  	return refEntry.target
  };

  currentExtensions[0x73] = () => new Set(read());

  const typedArrays = ['Int8','Uint8','Uint8Clamped','Int16','Uint16','Int32','Uint32','Float32','Float64','BigInt64','BigUint64'].map(type => type + 'Array');

  let glbl = typeof globalThis === 'object' ? globalThis : window;
  currentExtensions[0x74] = (data) => {
  	let typeCode = data[0];
  	let typedArrayName = typedArrays[typeCode];
  	if (!typedArrayName)
  		throw new Error('Could not find typed array for code ' + typeCode)
  	// we have to always slice/copy here to get a new ArrayBuffer that is word/byte aligned
  	return new glbl[typedArrayName](Uint8Array.prototype.slice.call(data, 1).buffer)
  };
  currentExtensions[0x78] = () => {
  	let data = read();
  	return new RegExp(data[0], data[1])
  };
  const TEMP_BUNDLE = [];
  currentExtensions[0x62] = (data) => {
  	let dataSize = (data[0] << 24) + (data[1] << 16) + (data[2] << 8) + data[3];
  	let dataPosition = position$1;
  	position$1 += dataSize - data.length;
  	bundledStrings$1 = TEMP_BUNDLE;
  	bundledStrings$1 = [readOnlyJSString(), readOnlyJSString()];
  	bundledStrings$1.position0 = 0;
  	bundledStrings$1.position1 = 0;
  	bundledStrings$1.postBundlePosition = position$1;
  	position$1 = dataPosition;
  	return read()
  };

  currentExtensions[0xff] = (data) => {
  	// 32-bit date extension
  	if (data.length == 4)
  		return new Date((data[0] * 0x1000000 + (data[1] << 16) + (data[2] << 8) + data[3]) * 1000)
  	else if (data.length == 8)
  		return new Date(
  			((data[0] << 22) + (data[1] << 14) + (data[2] << 6) + (data[3] >> 2)) / 1000000 +
  			((data[3] & 0x3) * 0x100000000 + data[4] * 0x1000000 + (data[5] << 16) + (data[6] << 8) + data[7]) * 1000)
  	else if (data.length == 12)// TODO: Implement support for negative
  		return new Date(
  			((data[0] << 24) + (data[1] << 16) + (data[2] << 8) + data[3]) / 1000000 +
  			(((data[4] & 0x80) ? -0x1000000000000 : 0) + data[6] * 0x10000000000 + data[7] * 0x100000000 + data[8] * 0x1000000 + (data[9] << 16) + (data[10] << 8) + data[11]) * 1000)
  	else
  		return new Date('invalid')
  }; // notepack defines extension 0 to mean undefined, so use that as the default here
  // registration of bulk record definition?
  // currentExtensions[0x52] = () =>

  function saveState(callback) {
  	let savedSrcEnd = srcEnd;
  	let savedPosition = position$1;
  	let savedSrcStringStart = srcStringStart;
  	let savedSrcStringEnd = srcStringEnd;
  	let savedSrcString = srcString;
  	let savedReferenceMap = referenceMap;
  	let savedBundledStrings = bundledStrings$1;

  	// TODO: We may need to revisit this if we do more external calls to user code (since it could be slow)
  	let savedSrc = new Uint8Array(src.slice(0, srcEnd)); // we copy the data in case it changes while external data is processed
  	let savedStructures = currentStructures;
  	let savedStructuresContents = currentStructures.slice(0, currentStructures.length);
  	let savedPackr = currentUnpackr;
  	let savedSequentialMode = sequentialMode;
  	let value = callback();
  	srcEnd = savedSrcEnd;
  	position$1 = savedPosition;
  	srcStringStart = savedSrcStringStart;
  	srcStringEnd = savedSrcStringEnd;
  	srcString = savedSrcString;
  	referenceMap = savedReferenceMap;
  	bundledStrings$1 = savedBundledStrings;
  	src = savedSrc;
  	sequentialMode = savedSequentialMode;
  	currentStructures = savedStructures;
  	currentStructures.splice(0, currentStructures.length, ...savedStructuresContents);
  	currentUnpackr = savedPackr;
  	dataView = new DataView(src.buffer, src.byteOffset, src.byteLength);
  	return value
  }
  function clearSource() {
  	src = null;
  	referenceMap = null;
  	currentStructures = null;
  }

  const mult10 = new Array(147); // this is a table matching binary exponents to the multiplier to determine significant digit rounding
  for (let i = 0; i < 256; i++) {
  	mult10[i] = +('1e' + Math.floor(45.15 - i * 0.30103));
  }
  var defaultUnpackr = new Unpackr({ useRecords: false });
  const unpack = defaultUnpackr.unpack;
  defaultUnpackr.unpackMultiple;
  defaultUnpackr.unpack;
  let f32Array = new Float32Array(1);
  new Uint8Array(f32Array.buffer, 0, 4);

  let textEncoder;
  try {
  	textEncoder = new TextEncoder();
  } catch (error) {}
  let extensions, extensionClasses;
  const hasNodeBuffer = typeof Buffer !== 'undefined';
  const ByteArrayAllocate = hasNodeBuffer ?
  	function(length) { return Buffer.allocUnsafeSlow(length) } : Uint8Array;
  const ByteArray = hasNodeBuffer ? Buffer : Uint8Array;
  const MAX_BUFFER_SIZE = hasNodeBuffer ? 0x100000000 : 0x7fd00000;
  let target, keysTarget;
  let targetView;
  let position = 0;
  let safeEnd;
  let bundledStrings = null;
  let writeStructSlots;
  const MAX_BUNDLE_SIZE = 0x5500; // maximum characters such that the encoded bytes fits in 16 bits.
  const hasNonLatin = /[\u0080-\uFFFF]/;
  const RECORD_SYMBOL = Symbol('record-id');
  class Packr extends Unpackr {
  	constructor(options) {
  		super(options);
  		this.offset = 0;
  		let start;
  		let hasSharedUpdate;
  		let structures;
  		let referenceMap;
  		let encodeUtf8 = ByteArray.prototype.utf8Write ? function(string, position) {
  			return target.utf8Write(string, position, 0xffffffff)
  		} : (textEncoder && textEncoder.encodeInto) ?
  			function(string, position) {
  				return textEncoder.encodeInto(string, target.subarray(position)).written
  			} : false;

  		let packr = this;
  		if (!options)
  			options = {};
  		let isSequential = options && options.sequential;
  		let hasSharedStructures = options.structures || options.saveStructures;
  		let maxSharedStructures = options.maxSharedStructures;
  		if (maxSharedStructures == null)
  			maxSharedStructures = hasSharedStructures ? 32 : 0;
  		if (maxSharedStructures > 8160)
  			throw new Error('Maximum maxSharedStructure is 8160')
  		if (options.structuredClone && options.moreTypes == undefined) {
  			this.moreTypes = true;
  		}
  		let maxOwnStructures = options.maxOwnStructures;
  		if (maxOwnStructures == null)
  			maxOwnStructures = hasSharedStructures ? 32 : 64;
  		if (!this.structures && options.useRecords != false)
  			this.structures = [];
  		// two byte record ids for shared structures
  		let useTwoByteRecords = maxSharedStructures > 32 || (maxOwnStructures + maxSharedStructures > 64);		
  		let sharedLimitId = maxSharedStructures + 0x40;
  		let maxStructureId = maxSharedStructures + maxOwnStructures + 0x40;
  		if (maxStructureId > 8256) {
  			throw new Error('Maximum maxSharedStructure + maxOwnStructure is 8192')
  		}
  		let recordIdsToRemove = [];
  		let transitionsCount = 0;
  		let serializationsSinceTransitionRebuild = 0;

  		this.pack = this.encode = function(value, encodeOptions) {
  			if (!target) {
  				target = new ByteArrayAllocate(8192);
  				targetView = target.dataView || (target.dataView = new DataView(target.buffer, 0, 8192));
  				position = 0;
  			}
  			safeEnd = target.length - 10;
  			if (safeEnd - position < 0x800) {
  				// don't start too close to the end, 
  				target = new ByteArrayAllocate(target.length);
  				targetView = target.dataView || (target.dataView = new DataView(target.buffer, 0, target.length));
  				safeEnd = target.length - 10;
  				position = 0;
  			} else
  				position = (position + 7) & 0x7ffffff8; // Word align to make any future copying of this buffer faster
  			start = position;
  			if (encodeOptions & RESERVE_START_SPACE) position += (encodeOptions & 0xff);
  			referenceMap = packr.structuredClone ? new Map() : null;
  			if (packr.bundleStrings && typeof value !== 'string') {
  				bundledStrings = [];
  				bundledStrings.size = Infinity; // force a new bundle start on first string
  			} else
  				bundledStrings = null;
  			structures = packr.structures;
  			if (structures) {
  				if (structures.uninitialized)
  					structures = packr._mergeStructures(packr.getStructures());
  				let sharedLength = structures.sharedLength || 0;
  				if (sharedLength > maxSharedStructures) {
  					//if (maxSharedStructures <= 32 && structures.sharedLength > 32) // TODO: could support this, but would need to update the limit ids
  					throw new Error('Shared structures is larger than maximum shared structures, try increasing maxSharedStructures to ' + structures.sharedLength)
  				}
  				if (!structures.transitions) {
  					// rebuild our structure transitions
  					structures.transitions = Object.create(null);
  					for (let i = 0; i < sharedLength; i++) {
  						let keys = structures[i];
  						if (!keys)
  							continue
  						let nextTransition, transition = structures.transitions;
  						for (let j = 0, l = keys.length; j < l; j++) {
  							let key = keys[j];
  							nextTransition = transition[key];
  							if (!nextTransition) {
  								nextTransition = transition[key] = Object.create(null);
  							}
  							transition = nextTransition;
  						}
  						transition[RECORD_SYMBOL] = i + 0x40;
  					}
  					this.lastNamedStructuresLength = sharedLength;
  				}
  				if (!isSequential) {
  					structures.nextId = sharedLength + 0x40;
  				}
  			}
  			if (hasSharedUpdate)
  				hasSharedUpdate = false;
  			let encodingError;
  			try {
  				if (packr.randomAccessStructure && value && value.constructor && value.constructor === Object)
  					writeStruct(value);
  				else
  					pack(value);
  				let lastBundle = bundledStrings;
  				if (bundledStrings)
  					writeBundles(start, pack, 0);
  				if (referenceMap && referenceMap.idsToInsert) {
  					let idsToInsert = referenceMap.idsToInsert.sort((a, b) => a.offset > b.offset ? 1 : -1);
  					let i = idsToInsert.length;
  					let incrementPosition = -1;
  					while (lastBundle && i > 0) {
  						let insertionPoint = idsToInsert[--i].offset + start;
  						if (insertionPoint < (lastBundle.stringsPosition + start) && incrementPosition === -1)
  							incrementPosition = 0;
  						if (insertionPoint > (lastBundle.position + start)) {
  							if (incrementPosition >= 0)
  								incrementPosition += 6;
  						} else {
  							if (incrementPosition >= 0) {
  								// update the bundle reference now
  								targetView.setUint32(lastBundle.position + start,
  									targetView.getUint32(lastBundle.position + start) + incrementPosition);
  								incrementPosition = -1; // reset
  							}
  							lastBundle = lastBundle.previous;
  							i++;
  						}
  					}
  					if (incrementPosition >= 0 && lastBundle) {
  						// update the bundle reference now
  						targetView.setUint32(lastBundle.position + start,
  							targetView.getUint32(lastBundle.position + start) + incrementPosition);
  					}
  					position += idsToInsert.length * 6;
  					if (position > safeEnd)
  						makeRoom(position);
  					packr.offset = position;
  					let serialized = insertIds(target.subarray(start, position), idsToInsert);
  					referenceMap = null;
  					return serialized
  				}
  				packr.offset = position; // update the offset so next serialization doesn't write over our buffer, but can continue writing to same buffer sequentially
  				if (encodeOptions & REUSE_BUFFER_MODE) {
  					target.start = start;
  					target.end = position;
  					return target
  				}
  				return target.subarray(start, position) // position can change if we call pack again in saveStructures, so we get the buffer now
  			} catch(error) {
  				encodingError = error;
  				throw error;
  			} finally {
  				if (structures) {
  					resetStructures();
  					if (hasSharedUpdate && packr.saveStructures) {
  						let sharedLength = structures.sharedLength || 0;
  						// we can't rely on start/end with REUSE_BUFFER_MODE since they will (probably) change when we save
  						let returnBuffer = target.subarray(start, position);
  						let newSharedData = prepareStructures(structures, packr);
  						if (!encodingError) { // TODO: If there is an encoding error, should make the structures as uninitialized so they get rebuilt next time
  							if (packr.saveStructures(newSharedData, newSharedData.isCompatible) === false) {
  								// get updated structures and try again if the update failed
  								return packr.pack(value, encodeOptions)
  							}
  							packr.lastNamedStructuresLength = sharedLength;
  							return returnBuffer
  						}
  					}
  				}
  				if (encodeOptions & RESET_BUFFER_MODE)
  					position = start;
  			}
  		};
  		const resetStructures = () => {
  			if (serializationsSinceTransitionRebuild < 10)
  				serializationsSinceTransitionRebuild++;
  			let sharedLength = structures.sharedLength || 0;
  			if (structures.length > sharedLength && !isSequential)
  				structures.length = sharedLength;
  			if (transitionsCount > 10000) {
  				// force a rebuild occasionally after a lot of transitions so it can get cleaned up
  				structures.transitions = null;
  				serializationsSinceTransitionRebuild = 0;
  				transitionsCount = 0;
  				if (recordIdsToRemove.length > 0)
  					recordIdsToRemove = [];
  			} else if (recordIdsToRemove.length > 0 && !isSequential) {
  				for (let i = 0, l = recordIdsToRemove.length; i < l; i++) {
  					recordIdsToRemove[i][RECORD_SYMBOL] = 0;
  				}
  				recordIdsToRemove = [];
  			}
  		};
  		const packArray = (value) => {
  			var length = value.length;
  			if (length < 0x10) {
  				target[position++] = 0x90 | length;
  			} else if (length < 0x10000) {
  				target[position++] = 0xdc;
  				target[position++] = length >> 8;
  				target[position++] = length & 0xff;
  			} else {
  				target[position++] = 0xdd;
  				targetView.setUint32(position, length);
  				position += 4;
  			}
  			for (let i = 0; i < length; i++) {
  				pack(value[i]);
  			}
  		};
  		const pack = (value) => {
  			if (position > safeEnd)
  				target = makeRoom(position);

  			var type = typeof value;
  			var length;
  			if (type === 'string') {
  				let strLength = value.length;
  				if (bundledStrings && strLength >= 4 && strLength < 0x1000) {
  					if ((bundledStrings.size += strLength) > MAX_BUNDLE_SIZE) {
  						let extStart;
  						let maxBytes = (bundledStrings[0] ? bundledStrings[0].length * 3 + bundledStrings[1].length : 0) + 10;
  						if (position + maxBytes > safeEnd)
  							target = makeRoom(position + maxBytes);
  						let lastBundle;
  						if (bundledStrings.position) { // here we use the 0x62 extension to write the last bundle and reserve space for the reference pointer to the next/current bundle
  							lastBundle = bundledStrings;
  							target[position] = 0xc8; // ext 16
  							position += 3; // reserve for the writing bundle size
  							target[position++] = 0x62; // 'b'
  							extStart = position - start;
  							position += 4; // reserve for writing bundle reference
  							writeBundles(start, pack, 0); // write the last bundles
  							targetView.setUint16(extStart + start - 3, position - start - extStart);
  						} else { // here we use the 0x62 extension just to reserve the space for the reference pointer to the bundle (will be updated once the bundle is written)
  							target[position++] = 0xd6; // fixext 4
  							target[position++] = 0x62; // 'b'
  							extStart = position - start;
  							position += 4; // reserve for writing bundle reference
  						}
  						bundledStrings = ['', '']; // create new ones
  						bundledStrings.previous = lastBundle;
  						bundledStrings.size = 0;
  						bundledStrings.position = extStart;
  					}
  					let twoByte = hasNonLatin.test(value);
  					bundledStrings[twoByte ? 0 : 1] += value;
  					target[position++] = 0xc1;
  					pack(twoByte ? -strLength : strLength);
  					return
  				}
  				let headerSize;
  				// first we estimate the header size, so we can write to the correct location
  				if (strLength < 0x20) {
  					headerSize = 1;
  				} else if (strLength < 0x100) {
  					headerSize = 2;
  				} else if (strLength < 0x10000) {
  					headerSize = 3;
  				} else {
  					headerSize = 5;
  				}
  				let maxBytes = strLength * 3;
  				if (position + maxBytes > safeEnd)
  					target = makeRoom(position + maxBytes);

  				if (strLength < 0x40 || !encodeUtf8) {
  					let i, c1, c2, strPosition = position + headerSize;
  					for (i = 0; i < strLength; i++) {
  						c1 = value.charCodeAt(i);
  						if (c1 < 0x80) {
  							target[strPosition++] = c1;
  						} else if (c1 < 0x800) {
  							target[strPosition++] = c1 >> 6 | 0xc0;
  							target[strPosition++] = c1 & 0x3f | 0x80;
  						} else if (
  							(c1 & 0xfc00) === 0xd800 &&
  							((c2 = value.charCodeAt(i + 1)) & 0xfc00) === 0xdc00
  						) {
  							c1 = 0x10000 + ((c1 & 0x03ff) << 10) + (c2 & 0x03ff);
  							i++;
  							target[strPosition++] = c1 >> 18 | 0xf0;
  							target[strPosition++] = c1 >> 12 & 0x3f | 0x80;
  							target[strPosition++] = c1 >> 6 & 0x3f | 0x80;
  							target[strPosition++] = c1 & 0x3f | 0x80;
  						} else {
  							target[strPosition++] = c1 >> 12 | 0xe0;
  							target[strPosition++] = c1 >> 6 & 0x3f | 0x80;
  							target[strPosition++] = c1 & 0x3f | 0x80;
  						}
  					}
  					length = strPosition - position - headerSize;
  				} else {
  					length = encodeUtf8(value, position + headerSize);
  				}

  				if (length < 0x20) {
  					target[position++] = 0xa0 | length;
  				} else if (length < 0x100) {
  					if (headerSize < 2) {
  						target.copyWithin(position + 2, position + 1, position + 1 + length);
  					}
  					target[position++] = 0xd9;
  					target[position++] = length;
  				} else if (length < 0x10000) {
  					if (headerSize < 3) {
  						target.copyWithin(position + 3, position + 2, position + 2 + length);
  					}
  					target[position++] = 0xda;
  					target[position++] = length >> 8;
  					target[position++] = length & 0xff;
  				} else {
  					if (headerSize < 5) {
  						target.copyWithin(position + 5, position + 3, position + 3 + length);
  					}
  					target[position++] = 0xdb;
  					targetView.setUint32(position, length);
  					position += 4;
  				}
  				position += length;
  			} else if (type === 'number') {
  				if (value >>> 0 === value) {// positive integer, 32-bit or less
  					// positive uint
  					if (value < 0x20 || (value < 0x80 && this.useRecords === false) || (value < 0x40 && !this.randomAccessStructure)) {
  						target[position++] = value;
  					} else if (value < 0x100) {
  						target[position++] = 0xcc;
  						target[position++] = value;
  					} else if (value < 0x10000) {
  						target[position++] = 0xcd;
  						target[position++] = value >> 8;
  						target[position++] = value & 0xff;
  					} else {
  						target[position++] = 0xce;
  						targetView.setUint32(position, value);
  						position += 4;
  					}
  				} else if (value >> 0 === value) { // negative integer
  					if (value >= -0x20) {
  						target[position++] = 0x100 + value;
  					} else if (value >= -0x80) {
  						target[position++] = 0xd0;
  						target[position++] = value + 0x100;
  					} else if (value >= -0x8000) {
  						target[position++] = 0xd1;
  						targetView.setInt16(position, value);
  						position += 2;
  					} else {
  						target[position++] = 0xd2;
  						targetView.setInt32(position, value);
  						position += 4;
  					}
  				} else {
  					let useFloat32;
  					if ((useFloat32 = this.useFloat32) > 0 && value < 0x100000000 && value >= -0x80000000) {
  						target[position++] = 0xca;
  						targetView.setFloat32(position, value);
  						let xShifted;
  						if (useFloat32 < 4 ||
  								// this checks for rounding of numbers that were encoded in 32-bit float to nearest significant decimal digit that could be preserved
  								((xShifted = value * mult10[((target[position] & 0x7f) << 1) | (target[position + 1] >> 7)]) >> 0) === xShifted) {
  							position += 4;
  							return
  						} else
  							position--; // move back into position for writing a double
  					}
  					target[position++] = 0xcb;
  					targetView.setFloat64(position, value);
  					position += 8;
  				}
  			} else if (type === 'object' || type === 'function') {
  				if (!value)
  					target[position++] = 0xc0;
  				else {
  					if (referenceMap) {
  						let referee = referenceMap.get(value);
  						if (referee) {
  							if (!referee.id) {
  								let idsToInsert = referenceMap.idsToInsert || (referenceMap.idsToInsert = []);
  								referee.id = idsToInsert.push(referee);
  							}
  							target[position++] = 0xd6; // fixext 4
  							target[position++] = 0x70; // "p" for pointer
  							targetView.setUint32(position, referee.id);
  							position += 4;
  							return
  						} else 
  							referenceMap.set(value, { offset: position - start });
  					}
  					let constructor = value.constructor;
  					if (constructor === Object) {
  						writeObject(value, true);
  					} else if (constructor === Array) {
  						packArray(value);
  					} else if (constructor === Map) {
  						if (this.mapAsEmptyObject) target[position++] = 0x80;
  						else {
  							length = value.size;
  							if (length < 0x10) {
  								target[position++] = 0x80 | length;
  							} else if (length < 0x10000) {
  								target[position++] = 0xde;
  								target[position++] = length >> 8;
  								target[position++] = length & 0xff;
  							} else {
  								target[position++] = 0xdf;
  								targetView.setUint32(position, length);
  								position += 4;
  							}
  							for (let [key, entryValue] of value) {
  								pack(key);
  								pack(entryValue);
  							}
  						}
  					} else {	
  						for (let i = 0, l = extensions.length; i < l; i++) {
  							let extensionClass = extensionClasses[i];
  							if (value instanceof extensionClass) {
  								let extension = extensions[i];
  								if (extension.write) {
  									if (extension.type) {
  										target[position++] = 0xd4; // one byte "tag" extension
  										target[position++] = extension.type;
  										target[position++] = 0;
  									}
  									let writeResult = extension.write.call(this, value);
  									if (writeResult === value) { // avoid infinite recursion
  										if (Array.isArray(value)) {
  											packArray(value);
  										} else {
  											writeObject(value);
  										}
  									} else {
  										pack(writeResult);
  									}
  									return
  								}
  								let currentTarget = target;
  								let currentTargetView = targetView;
  								let currentPosition = position;
  								target = null;
  								let result;
  								try {
  									result = extension.pack.call(this, value, (size) => {
  										// restore target and use it
  										target = currentTarget;
  										currentTarget = null;
  										position += size;
  										if (position > safeEnd)
  											makeRoom(position);
  										return {
  											target, targetView, position: position - size
  										}
  									}, pack);
  								} finally {
  									// restore current target information (unless already restored)
  									if (currentTarget) {
  										target = currentTarget;
  										targetView = currentTargetView;
  										position = currentPosition;
  										safeEnd = target.length - 10;
  									}
  								}
  								if (result) {
  									if (result.length + position > safeEnd)
  										makeRoom(result.length + position);
  									position = writeExtensionData(result, target, position, extension.type);
  								}
  								return
  							}
  						}
  						// check isArray after extensions, because extensions can extend Array
  						if (Array.isArray(value)) {
  							packArray(value);
  						} else {
  							// use this as an alternate mechanism for expressing how to serialize
  							if (value.toJSON) {
  								const json = value.toJSON();
  								// if for some reason value.toJSON returns itself it'll loop forever
  								if (json !== value)
  									return pack(json)
  							}
  							
  							// if there is a writeFunction, use it, otherwise just encode as undefined
  							if (type === 'function')
  								return pack(this.writeFunction && this.writeFunction(value));
  							
  							// no extension found, write as object
  							writeObject(value, !value.hasOwnProperty); // if it doesn't have hasOwnProperty, don't do hasOwnProperty checks
  						}
  					}
  				}
  			} else if (type === 'boolean') {
  				target[position++] = value ? 0xc3 : 0xc2;
  			} else if (type === 'bigint') {
  				if (value < (BigInt(1)<<BigInt(63)) && value >= -(BigInt(1)<<BigInt(63))) {
  					// use a signed int as long as it fits
  					target[position++] = 0xd3;
  					targetView.setBigInt64(position, value);
  				} else if (value < (BigInt(1)<<BigInt(64)) && value > 0) {
  					// if we can fit an unsigned int, use that
  					target[position++] = 0xcf;
  					targetView.setBigUint64(position, value);
  				} else {
  					// overflow
  					if (this.largeBigIntToFloat) {
  						target[position++] = 0xcb;
  						targetView.setFloat64(position, Number(value));
  					} else if (this.useBigIntExtension && value < 2n**(1023n) && value > -(2n**(1023n))) {
  						target[position++] = 0xc7;
  						position++;
  						target[position++] = 0x42; // "B" for BigInt
  						let bytes = [];
  						let alignedSign;
  						do {
  							let byte = value & 0xffn;
  							alignedSign = (byte & 0x80n) === (value < 0n ? 0x80n : 0n);
  							bytes.push(byte);
  							value >>= 8n;
  						} while (!((value === 0n || value === -1n) && alignedSign));
  						target[position-2] = bytes.length;
  						for (let i = bytes.length; i > 0;) {
  							target[position++] = Number(bytes[--i]);
  						}
  						return
  					} else {
  						throw new RangeError(value + ' was too large to fit in MessagePack 64-bit integer format, use' +
  							' useBigIntExtension or set largeBigIntToFloat to convert to float-64')
  					}
  				}
  				position += 8;
  			} else if (type === 'undefined') {
  				if (this.encodeUndefinedAsNil)
  					target[position++] = 0xc0;
  				else {
  					target[position++] = 0xd4; // a number of implementations use fixext1 with type 0, data 0 to denote undefined, so we follow suite
  					target[position++] = 0;
  					target[position++] = 0;
  				}
  			} else {
  				throw new Error('Unknown type: ' + type)
  			}
  		};

  		const writePlainObject = (this.variableMapSize || this.coercibleKeyAsNumber) ? (object) => {
  			// this method is slightly slower, but generates "preferred serialization" (optimally small for smaller objects)
  			let keys = Object.keys(object);
  			let length = keys.length;
  			if (length < 0x10) {
  				target[position++] = 0x80 | length;
  			} else if (length < 0x10000) {
  				target[position++] = 0xde;
  				target[position++] = length >> 8;
  				target[position++] = length & 0xff;
  			} else {
  				target[position++] = 0xdf;
  				targetView.setUint32(position, length);
  				position += 4;
  			}
  			let key;
  			if (this.coercibleKeyAsNumber) {
  				for (let i = 0; i < length; i++) {
  					key = keys[i];
  					let num = Number(key);
  					pack(isNaN(num) ? key : num);
  					pack(object[key]);
  				}

  			} else {
  				for (let i = 0; i < length; i++) {
  					pack(key = keys[i]);
  					pack(object[key]);
  				}
  			}
  		} :
  		(object, safePrototype) => {
  			target[position++] = 0xde; // always using map 16, so we can preallocate and set the length afterwards
  			let objectOffset = position - start;
  			position += 2;
  			let size = 0;
  			for (let key in object) {
  				if (safePrototype || object.hasOwnProperty(key)) {
  					pack(key);
  					pack(object[key]);
  					size++;
  				}
  			}
  			target[objectOffset++ + start] = size >> 8;
  			target[objectOffset + start] = size & 0xff;
  		};

  		const writeRecord = this.useRecords === false ? writePlainObject :
  		(options.progressiveRecords && !useTwoByteRecords) ?  // this is about 2% faster for highly stable structures, since it only requires one for-in loop (but much more expensive when new structure needs to be written)
  		(object, safePrototype) => {
  			let nextTransition, transition = structures.transitions || (structures.transitions = Object.create(null));
  			let objectOffset = position++ - start;
  			let wroteKeys;
  			for (let key in object) {
  				if (safePrototype || object.hasOwnProperty(key)) {
  					nextTransition = transition[key];
  					if (nextTransition)
  						transition = nextTransition;
  					else {
  						// record doesn't exist, create full new record and insert it
  						let keys = Object.keys(object);
  						let lastTransition = transition;
  						transition = structures.transitions;
  						let newTransitions = 0;
  						for (let i = 0, l = keys.length; i < l; i++) {
  							let key = keys[i];
  							nextTransition = transition[key];
  							if (!nextTransition) {
  								nextTransition = transition[key] = Object.create(null);
  								newTransitions++;
  							}
  							transition = nextTransition;
  						}
  						if (objectOffset + start + 1 == position) {
  							// first key, so we don't need to insert, we can just write record directly
  							position--;
  							newRecord(transition, keys, newTransitions);
  						} else // otherwise we need to insert the record, moving existing data after the record
  							insertNewRecord(transition, keys, objectOffset, newTransitions);
  						wroteKeys = true;
  						transition = lastTransition[key];
  					}
  					pack(object[key]);
  				}
  			}
  			if (!wroteKeys) {
  				let recordId = transition[RECORD_SYMBOL];
  				if (recordId)
  					target[objectOffset + start] = recordId;
  				else
  					insertNewRecord(transition, Object.keys(object), objectOffset, 0);
  			}
  		} :
  		(object, safePrototype) => {
  			let nextTransition, transition = structures.transitions || (structures.transitions = Object.create(null));
  			let newTransitions = 0;
  			for (let key in object) if (safePrototype || object.hasOwnProperty(key)) {
  				nextTransition = transition[key];
  				if (!nextTransition) {
  					nextTransition = transition[key] = Object.create(null);
  					newTransitions++;
  				}
  				transition = nextTransition;
  			}
  			let recordId = transition[RECORD_SYMBOL];
  			if (recordId) {
  				if (recordId >= 0x60 && useTwoByteRecords) {
  					target[position++] = ((recordId -= 0x60) & 0x1f) + 0x60;
  					target[position++] = recordId >> 5;
  				} else
  					target[position++] = recordId;
  			} else {
  				newRecord(transition, transition.__keys__ || Object.keys(object), newTransitions);
  			}
  			// now write the values
  			for (let key in object)
  				if (safePrototype || object.hasOwnProperty(key)) {
  					pack(object[key]);
  				}
  		};

  		// craete reference to useRecords if useRecords is a function
  		const checkUseRecords = typeof this.useRecords == 'function' && this.useRecords;
  		
  		const writeObject = checkUseRecords ? (object, safePrototype) => {
  			checkUseRecords(object) ? writeRecord(object,safePrototype) : writePlainObject(object,safePrototype);
  		} : writeRecord;

  		const makeRoom = (end) => {
  			let newSize;
  			if (end > 0x1000000) {
  				// special handling for really large buffers
  				if ((end - start) > MAX_BUFFER_SIZE)
  					throw new Error('Packed buffer would be larger than maximum buffer size')
  				newSize = Math.min(MAX_BUFFER_SIZE,
  					Math.round(Math.max((end - start) * (end > 0x4000000 ? 1.25 : 2), 0x400000) / 0x1000) * 0x1000);
  			} else // faster handling for smaller buffers
  				newSize = ((Math.max((end - start) << 2, target.length - 1) >> 12) + 1) << 12;
  			let newBuffer = new ByteArrayAllocate(newSize);
  			targetView = newBuffer.dataView || (newBuffer.dataView = new DataView(newBuffer.buffer, 0, newSize));
  			end = Math.min(end, target.length);
  			if (target.copy)
  				target.copy(newBuffer, 0, start, end);
  			else
  				newBuffer.set(target.slice(start, end));
  			position -= start;
  			start = 0;
  			safeEnd = newBuffer.length - 10;
  			return target = newBuffer
  		};
  		const newRecord = (transition, keys, newTransitions) => {
  			let recordId = structures.nextId;
  			if (!recordId)
  				recordId = 0x40;
  			if (recordId < sharedLimitId && this.shouldShareStructure && !this.shouldShareStructure(keys)) {
  				recordId = structures.nextOwnId;
  				if (!(recordId < maxStructureId))
  					recordId = sharedLimitId;
  				structures.nextOwnId = recordId + 1;
  			} else {
  				if (recordId >= maxStructureId)// cycle back around
  					recordId = sharedLimitId;
  				structures.nextId = recordId + 1;
  			}
  			let highByte = keys.highByte = recordId >= 0x60 && useTwoByteRecords ? (recordId - 0x60) >> 5 : -1;
  			transition[RECORD_SYMBOL] = recordId;
  			transition.__keys__ = keys;
  			structures[recordId - 0x40] = keys;

  			if (recordId < sharedLimitId) {
  				keys.isShared = true;
  				structures.sharedLength = recordId - 0x3f;
  				hasSharedUpdate = true;
  				if (highByte >= 0) {
  					target[position++] = (recordId & 0x1f) + 0x60;
  					target[position++] = highByte;
  				} else {
  					target[position++] = recordId;
  				}
  			} else {
  				if (highByte >= 0) {
  					target[position++] = 0xd5; // fixext 2
  					target[position++] = 0x72; // "r" record defintion extension type
  					target[position++] = (recordId & 0x1f) + 0x60;
  					target[position++] = highByte;
  				} else {
  					target[position++] = 0xd4; // fixext 1
  					target[position++] = 0x72; // "r" record defintion extension type
  					target[position++] = recordId;
  				}

  				if (newTransitions)
  					transitionsCount += serializationsSinceTransitionRebuild * newTransitions;
  				// record the removal of the id, we can maintain our shared structure
  				if (recordIdsToRemove.length >= maxOwnStructures)
  					recordIdsToRemove.shift()[RECORD_SYMBOL] = 0; // we are cycling back through, and have to remove old ones
  				recordIdsToRemove.push(transition);
  				pack(keys);
  			}
  		};
  		const insertNewRecord = (transition, keys, insertionOffset, newTransitions) => {
  			let mainTarget = target;
  			let mainPosition = position;
  			let mainSafeEnd = safeEnd;
  			let mainStart = start;
  			target = keysTarget;
  			position = 0;
  			start = 0;
  			if (!target)
  				keysTarget = target = new ByteArrayAllocate(8192);
  			safeEnd = target.length - 10;
  			newRecord(transition, keys, newTransitions);
  			keysTarget = target;
  			let keysPosition = position;
  			target = mainTarget;
  			position = mainPosition;
  			safeEnd = mainSafeEnd;
  			start = mainStart;
  			if (keysPosition > 1) {
  				let newEnd = position + keysPosition - 1;
  				if (newEnd > safeEnd)
  					makeRoom(newEnd);
  				let insertionPosition = insertionOffset + start;
  				target.copyWithin(insertionPosition + keysPosition, insertionPosition + 1, position);
  				target.set(keysTarget.slice(0, keysPosition), insertionPosition);
  				position = newEnd;
  			} else {
  				target[insertionOffset + start] = keysTarget[0];
  			}
  		};
  		const writeStruct = (object, safePrototype) => {
  			let newPosition = writeStructSlots(object, target, start, position, structures, makeRoom, (value, newPosition, notifySharedUpdate) => {
  				if (notifySharedUpdate)
  					return hasSharedUpdate = true;
  				position = newPosition;
  				let startTarget = target;
  				pack(value);
  				resetStructures();
  				if (startTarget !== target) {
  					return { position, targetView, target }; // indicate the buffer was re-allocated
  				}
  				return position;
  			}, this);
  			if (newPosition === 0) // bail and go to a msgpack object
  				return writeObject(object, true);
  			position = newPosition;
  		};
  	}
  	useBuffer(buffer) {
  		// this means we are finished using our own buffer and we can write over it safely
  		target = buffer;
  		targetView = new DataView(target.buffer, target.byteOffset, target.byteLength);
  		position = 0;
  	}
  	clearSharedData() {
  		if (this.structures)
  			this.structures = [];
  		if (this.typedStructs)
  			this.typedStructs = [];
  	}
  }

  extensionClasses = [ Date, Set, Error, RegExp, ArrayBuffer, Object.getPrototypeOf(Uint8Array.prototype).constructor /*TypedArray*/, C1Type ];
  extensions = [{
  	pack(date, allocateForWrite, pack) {
  		let seconds = date.getTime() / 1000;
  		if ((this.useTimestamp32 || date.getMilliseconds() === 0) && seconds >= 0 && seconds < 0x100000000) {
  			// Timestamp 32
  			let { target, targetView, position} = allocateForWrite(6);
  			target[position++] = 0xd6;
  			target[position++] = 0xff;
  			targetView.setUint32(position, seconds);
  		} else if (seconds > 0 && seconds < 0x100000000) {
  			// Timestamp 64
  			let { target, targetView, position} = allocateForWrite(10);
  			target[position++] = 0xd7;
  			target[position++] = 0xff;
  			targetView.setUint32(position, date.getMilliseconds() * 4000000 + ((seconds / 1000 / 0x100000000) >> 0));
  			targetView.setUint32(position + 4, seconds);
  		} else if (isNaN(seconds)) {
  			if (this.onInvalidDate) {
  				allocateForWrite(0);
  				return pack(this.onInvalidDate())
  			}
  			// Intentionally invalid timestamp
  			let { target, targetView, position} = allocateForWrite(3);
  			target[position++] = 0xd4;
  			target[position++] = 0xff;
  			target[position++] = 0xff;
  		} else {
  			// Timestamp 96
  			let { target, targetView, position} = allocateForWrite(15);
  			target[position++] = 0xc7;
  			target[position++] = 12;
  			target[position++] = 0xff;
  			targetView.setUint32(position, date.getMilliseconds() * 1000000);
  			targetView.setBigInt64(position + 4, BigInt(Math.floor(seconds)));
  		}
  	}
  }, {
  	pack(set, allocateForWrite, pack) {
  		if (this.setAsEmptyObject) {
  			allocateForWrite(0);
  			return pack({})
  		}
  		let array = Array.from(set);
  		let { target, position} = allocateForWrite(this.moreTypes ? 3 : 0);
  		if (this.moreTypes) {
  			target[position++] = 0xd4;
  			target[position++] = 0x73; // 's' for Set
  			target[position++] = 0;
  		}
  		pack(array);
  	}
  }, {
  	pack(error, allocateForWrite, pack) {
  		let { target, position} = allocateForWrite(this.moreTypes ? 3 : 0);
  		if (this.moreTypes) {
  			target[position++] = 0xd4;
  			target[position++] = 0x65; // 'e' for error
  			target[position++] = 0;
  		}
  		pack([ error.name, error.message ]);
  	}
  }, {
  	pack(regex, allocateForWrite, pack) {
  		let { target, position} = allocateForWrite(this.moreTypes ? 3 : 0);
  		if (this.moreTypes) {
  			target[position++] = 0xd4;
  			target[position++] = 0x78; // 'x' for regeXp
  			target[position++] = 0;
  		}
  		pack([ regex.source, regex.flags ]);
  	}
  }, {
  	pack(arrayBuffer, allocateForWrite) {
  		if (this.moreTypes)
  			writeExtBuffer(arrayBuffer, 0x10, allocateForWrite);
  		else
  			writeBuffer(hasNodeBuffer ? Buffer.from(arrayBuffer) : new Uint8Array(arrayBuffer), allocateForWrite);
  	}
  }, {
  	pack(typedArray, allocateForWrite) {
  		let constructor = typedArray.constructor;
  		if (constructor !== ByteArray && this.moreTypes)
  			writeExtBuffer(typedArray, typedArrays.indexOf(constructor.name), allocateForWrite);
  		else
  			writeBuffer(typedArray, allocateForWrite);
  	}
  }, {
  	pack(c1, allocateForWrite) { // specific 0xC1 object
  		let { target, position} = allocateForWrite(1);
  		target[position] = 0xc1;
  	}
  }];

  function writeExtBuffer(typedArray, type, allocateForWrite, encode) {
  	let length = typedArray.byteLength;
  	if (length + 1 < 0x100) {
  		var { target, position } = allocateForWrite(4 + length);
  		target[position++] = 0xc7;
  		target[position++] = length + 1;
  	} else if (length + 1 < 0x10000) {
  		var { target, position } = allocateForWrite(5 + length);
  		target[position++] = 0xc8;
  		target[position++] = (length + 1) >> 8;
  		target[position++] = (length + 1) & 0xff;
  	} else {
  		var { target, position, targetView } = allocateForWrite(7 + length);
  		target[position++] = 0xc9;
  		targetView.setUint32(position, length + 1); // plus one for the type byte
  		position += 4;
  	}
  	target[position++] = 0x74; // "t" for typed array
  	target[position++] = type;
  	target.set(new Uint8Array(typedArray.buffer, typedArray.byteOffset, typedArray.byteLength), position);
  }
  function writeBuffer(buffer, allocateForWrite) {
  	let length = buffer.byteLength;
  	var target, position;
  	if (length < 0x100) {
  		var { target, position } = allocateForWrite(length + 2);
  		target[position++] = 0xc4;
  		target[position++] = length;
  	} else if (length < 0x10000) {
  		var { target, position } = allocateForWrite(length + 3);
  		target[position++] = 0xc5;
  		target[position++] = length >> 8;
  		target[position++] = length & 0xff;
  	} else {
  		var { target, position, targetView } = allocateForWrite(length + 5);
  		target[position++] = 0xc6;
  		targetView.setUint32(position, length);
  		position += 4;
  	}
  	target.set(buffer, position);
  }

  function writeExtensionData(result, target, position, type) {
  	let length = result.length;
  	switch (length) {
  		case 1:
  			target[position++] = 0xd4;
  			break
  		case 2:
  			target[position++] = 0xd5;
  			break
  		case 4:
  			target[position++] = 0xd6;
  			break
  		case 8:
  			target[position++] = 0xd7;
  			break
  		case 16:
  			target[position++] = 0xd8;
  			break
  		default:
  			if (length < 0x100) {
  				target[position++] = 0xc7;
  				target[position++] = length;
  			} else if (length < 0x10000) {
  				target[position++] = 0xc8;
  				target[position++] = length >> 8;
  				target[position++] = length & 0xff;
  			} else {
  				target[position++] = 0xc9;
  				target[position++] = length >> 24;
  				target[position++] = (length >> 16) & 0xff;
  				target[position++] = (length >> 8) & 0xff;
  				target[position++] = length & 0xff;
  			}
  	}
  	target[position++] = type;
  	target.set(result, position);
  	position += length;
  	return position
  }

  function insertIds(serialized, idsToInsert) {
  	// insert the ids that need to be referenced for structured clones
  	let nextId;
  	let distanceToMove = idsToInsert.length * 6;
  	let lastEnd = serialized.length - distanceToMove;
  	while (nextId = idsToInsert.pop()) {
  		let offset = nextId.offset;
  		let id = nextId.id;
  		serialized.copyWithin(offset + distanceToMove, offset, lastEnd);
  		distanceToMove -= 6;
  		let position = offset + distanceToMove;
  		serialized[position++] = 0xd6;
  		serialized[position++] = 0x69; // 'i'
  		serialized[position++] = id >> 24;
  		serialized[position++] = (id >> 16) & 0xff;
  		serialized[position++] = (id >> 8) & 0xff;
  		serialized[position++] = id & 0xff;
  		lastEnd = offset;
  	}
  	return serialized
  }

  function writeBundles(start, pack, incrementPosition) {
  	if (bundledStrings.length > 0) {
  		targetView.setUint32(bundledStrings.position + start, position + incrementPosition - bundledStrings.position - start);
  		bundledStrings.stringsPosition = position - start;
  		let writeStrings = bundledStrings;
  		bundledStrings = null;
  		pack(writeStrings[0]);
  		pack(writeStrings[1]);
  	}
  }
  function prepareStructures(structures, packr) {
  	structures.isCompatible = (existingStructures) => {
  		let compatible = !existingStructures || ((packr.lastNamedStructuresLength || 0) === existingStructures.length);
  		if (!compatible) // we want to merge these existing structures immediately since we already have it and we are in the right transaction
  			packr._mergeStructures(existingStructures);
  		return compatible;
  	};
  	return structures
  }

  let defaultPackr = new Packr({ useRecords: false });
  const pack$1 = defaultPackr.pack;
  defaultPackr.pack;
  const REUSE_BUFFER_MODE = 512;
  const RESET_BUFFER_MODE = 1024;
  const RESERVE_START_SPACE = 2048;

  // DEFLATE is a complex format; to read this code, you should probably check the RFC first:
  // https://tools.ietf.org/html/rfc1951
  // You may also wish to take a look at the guide I made about this program:
  // https://gist.github.com/101arrowz/253f31eb5abc3d9275ab943003ffecad
  // Some of the following code is similar to that of UZIP.js:
  // https://github.com/photopea/UZIP.js
  // However, the vast majority of the codebase has diverged from UZIP.js to increase performance and reduce bundle size.
  // Sometimes 0 will appear where -1 would be more appropriate. This is because using a uint
  // is better for memory in most engines (I *think*).
  var ch2 = {};
  var wk = (function (c, id, msg, transfer, cb) {
      var w = new Worker(ch2[id] || (ch2[id] = URL.createObjectURL(new Blob([
          c + ';addEventListener("error",function(e){e=e.error;postMessage({$e$:[e.message,e.code,e.stack]})})'
      ], { type: 'text/javascript' }))));
      w.onmessage = function (e) {
          var d = e.data, ed = d.$e$;
          if (ed) {
              var err = new Error(ed[0]);
              err['code'] = ed[1];
              err.stack = ed[2];
              cb(err, null);
          }
          else
              cb(null, d);
      };
      w.postMessage(msg, transfer);
      return w;
  });

  // aliases for shorter compressed code (most minifers don't do this)
  var u8 = Uint8Array, u16 = Uint16Array, u32 = Uint32Array;
  // fixed length extra bits
  var fleb = new u8([0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 2, 2, 2, 2, 3, 3, 3, 3, 4, 4, 4, 4, 5, 5, 5, 5, 0, /* unused */ 0, 0, /* impossible */ 0]);
  // fixed distance extra bits
  // see fleb note
  var fdeb = new u8([0, 0, 0, 0, 1, 1, 2, 2, 3, 3, 4, 4, 5, 5, 6, 6, 7, 7, 8, 8, 9, 9, 10, 10, 11, 11, 12, 12, 13, 13, /* unused */ 0, 0]);
  // code length index map
  var clim = new u8([16, 17, 18, 0, 8, 7, 9, 6, 10, 5, 11, 4, 12, 3, 13, 2, 14, 1, 15]);
  // get base, reverse index map from extra bits
  var freb = function (eb, start) {
      var b = new u16(31);
      for (var i = 0; i < 31; ++i) {
          b[i] = start += 1 << eb[i - 1];
      }
      // numbers here are at max 18 bits
      var r = new u32(b[30]);
      for (var i = 1; i < 30; ++i) {
          for (var j = b[i]; j < b[i + 1]; ++j) {
              r[j] = ((j - b[i]) << 5) | i;
          }
      }
      return [b, r];
  };
  var _a = freb(fleb, 2), fl = _a[0], revfl = _a[1];
  // we can ignore the fact that the other numbers are wrong; they never happen anyway
  fl[28] = 258, revfl[258] = 28;
  var _b = freb(fdeb, 0), fd = _b[0], revfd = _b[1];
  // map of value to reverse (assuming 16 bits)
  var rev = new u16(32768);
  for (var i = 0; i < 32768; ++i) {
      // reverse table algorithm from SO
      var x = ((i & 0xAAAA) >>> 1) | ((i & 0x5555) << 1);
      x = ((x & 0xCCCC) >>> 2) | ((x & 0x3333) << 2);
      x = ((x & 0xF0F0) >>> 4) | ((x & 0x0F0F) << 4);
      rev[i] = (((x & 0xFF00) >>> 8) | ((x & 0x00FF) << 8)) >>> 1;
  }
  // create huffman tree from u8 "map": index -> code length for code index
  // mb (max bits) must be at most 15
  // TODO: optimize/split up?
  var hMap = (function (cd, mb, r) {
      var s = cd.length;
      // index
      var i = 0;
      // u16 "map": index -> # of codes with bit length = index
      var l = new u16(mb);
      // length of cd must be 288 (total # of codes)
      for (; i < s; ++i) {
          if (cd[i])
              ++l[cd[i] - 1];
      }
      // u16 "map": index -> minimum code for bit length = index
      var le = new u16(mb);
      for (i = 0; i < mb; ++i) {
          le[i] = (le[i - 1] + l[i - 1]) << 1;
      }
      var co;
      if (r) {
          // u16 "map": index -> number of actual bits, symbol for code
          co = new u16(1 << mb);
          // bits to remove for reverser
          var rvb = 15 - mb;
          for (i = 0; i < s; ++i) {
              // ignore 0 lengths
              if (cd[i]) {
                  // num encoding both symbol and bits read
                  var sv = (i << 4) | cd[i];
                  // free bits
                  var r_1 = mb - cd[i];
                  // start value
                  var v = le[cd[i] - 1]++ << r_1;
                  // m is end value
                  for (var m = v | ((1 << r_1) - 1); v <= m; ++v) {
                      // every 16 bit value starting with the code yields the same result
                      co[rev[v] >>> rvb] = sv;
                  }
              }
          }
      }
      else {
          co = new u16(s);
          for (i = 0; i < s; ++i) {
              if (cd[i]) {
                  co[i] = rev[le[cd[i] - 1]++] >>> (15 - cd[i]);
              }
          }
      }
      return co;
  });
  // fixed length tree
  var flt = new u8(288);
  for (var i = 0; i < 144; ++i)
      flt[i] = 8;
  for (var i = 144; i < 256; ++i)
      flt[i] = 9;
  for (var i = 256; i < 280; ++i)
      flt[i] = 7;
  for (var i = 280; i < 288; ++i)
      flt[i] = 8;
  // fixed distance tree
  var fdt = new u8(32);
  for (var i = 0; i < 32; ++i)
      fdt[i] = 5;
  // fixed length map
  var flm = /*#__PURE__*/ hMap(flt, 9, 0), flrm = /*#__PURE__*/ hMap(flt, 9, 1);
  // fixed distance map
  var fdm = /*#__PURE__*/ hMap(fdt, 5, 0), fdrm = /*#__PURE__*/ hMap(fdt, 5, 1);
  // find max of array
  var max = function (a) {
      var m = a[0];
      for (var i = 1; i < a.length; ++i) {
          if (a[i] > m)
              m = a[i];
      }
      return m;
  };
  // read d, starting at bit p and mask with m
  var bits = function (d, p, m) {
      var o = (p / 8) | 0;
      return ((d[o] | (d[o + 1] << 8)) >> (p & 7)) & m;
  };
  // read d, starting at bit p continuing for at least 16 bits
  var bits16 = function (d, p) {
      var o = (p / 8) | 0;
      return ((d[o] | (d[o + 1] << 8) | (d[o + 2] << 16)) >> (p & 7));
  };
  // get end of byte
  var shft = function (p) { return ((p + 7) / 8) | 0; };
  // typed array slice - allows garbage collector to free original reference,
  // while being more compatible than .slice
  var slc = function (v, s, e) {
      if (s == null || s < 0)
          s = 0;
      if (e == null || e > v.length)
          e = v.length;
      // can't use .constructor in case user-supplied
      var n = new (v.BYTES_PER_ELEMENT == 2 ? u16 : v.BYTES_PER_ELEMENT == 4 ? u32 : u8)(e - s);
      n.set(v.subarray(s, e));
      return n;
  };
  // error codes
  var ec = [
      'unexpected EOF',
      'invalid block type',
      'invalid length/literal',
      'invalid distance',
      'stream finished',
      'no stream handler',
      ,
      'no callback',
      'invalid UTF-8 data',
      'extra field too long',
      'date not in range 1980-2099',
      'filename too long',
      'stream finishing',
      'invalid zip data'
      // determined by unknown compression method
  ];
  var err = function (ind, msg, nt) {
      var e = new Error(msg || ec[ind]);
      e.code = ind;
      if (Error.captureStackTrace)
          Error.captureStackTrace(e, err);
      if (!nt)
          throw e;
      return e;
  };
  // expands raw DEFLATE data
  var inflt = function (dat, buf, st) {
      // source length
      var sl = dat.length;
      if (!sl || (st && st.f && !st.l))
          return buf || new u8(0);
      // have to estimate size
      var noBuf = !buf || st;
      // no state
      var noSt = !st || st.i;
      if (!st)
          st = {};
      // Assumes roughly 33% compression ratio average
      if (!buf)
          buf = new u8(sl * 3);
      // ensure buffer can fit at least l elements
      var cbuf = function (l) {
          var bl = buf.length;
          // need to increase size to fit
          if (l > bl) {
              // Double or set to necessary, whichever is greater
              var nbuf = new u8(Math.max(bl * 2, l));
              nbuf.set(buf);
              buf = nbuf;
          }
      };
      //  last chunk         bitpos           bytes
      var final = st.f || 0, pos = st.p || 0, bt = st.b || 0, lm = st.l, dm = st.d, lbt = st.m, dbt = st.n;
      // total bits
      var tbts = sl * 8;
      do {
          if (!lm) {
              // BFINAL - this is only 1 when last chunk is next
              final = bits(dat, pos, 1);
              // type: 0 = no compression, 1 = fixed huffman, 2 = dynamic huffman
              var type = bits(dat, pos + 1, 3);
              pos += 3;
              if (!type) {
                  // go to end of byte boundary
                  var s = shft(pos) + 4, l = dat[s - 4] | (dat[s - 3] << 8), t = s + l;
                  if (t > sl) {
                      if (noSt)
                          err(0);
                      break;
                  }
                  // ensure size
                  if (noBuf)
                      cbuf(bt + l);
                  // Copy over uncompressed data
                  buf.set(dat.subarray(s, t), bt);
                  // Get new bitpos, update byte count
                  st.b = bt += l, st.p = pos = t * 8, st.f = final;
                  continue;
              }
              else if (type == 1)
                  lm = flrm, dm = fdrm, lbt = 9, dbt = 5;
              else if (type == 2) {
                  //  literal                            lengths
                  var hLit = bits(dat, pos, 31) + 257, hcLen = bits(dat, pos + 10, 15) + 4;
                  var tl = hLit + bits(dat, pos + 5, 31) + 1;
                  pos += 14;
                  // length+distance tree
                  var ldt = new u8(tl);
                  // code length tree
                  var clt = new u8(19);
                  for (var i = 0; i < hcLen; ++i) {
                      // use index map to get real code
                      clt[clim[i]] = bits(dat, pos + i * 3, 7);
                  }
                  pos += hcLen * 3;
                  // code lengths bits
                  var clb = max(clt), clbmsk = (1 << clb) - 1;
                  // code lengths map
                  var clm = hMap(clt, clb, 1);
                  for (var i = 0; i < tl;) {
                      var r = clm[bits(dat, pos, clbmsk)];
                      // bits read
                      pos += r & 15;
                      // symbol
                      var s = r >>> 4;
                      // code length to copy
                      if (s < 16) {
                          ldt[i++] = s;
                      }
                      else {
                          //  copy   count
                          var c = 0, n = 0;
                          if (s == 16)
                              n = 3 + bits(dat, pos, 3), pos += 2, c = ldt[i - 1];
                          else if (s == 17)
                              n = 3 + bits(dat, pos, 7), pos += 3;
                          else if (s == 18)
                              n = 11 + bits(dat, pos, 127), pos += 7;
                          while (n--)
                              ldt[i++] = c;
                      }
                  }
                  //    length tree                 distance tree
                  var lt = ldt.subarray(0, hLit), dt = ldt.subarray(hLit);
                  // max length bits
                  lbt = max(lt);
                  // max dist bits
                  dbt = max(dt);
                  lm = hMap(lt, lbt, 1);
                  dm = hMap(dt, dbt, 1);
              }
              else
                  err(1);
              if (pos > tbts) {
                  if (noSt)
                      err(0);
                  break;
              }
          }
          // Make sure the buffer can hold this + the largest possible addition
          // Maximum chunk size (practically, theoretically infinite) is 2^17;
          if (noBuf)
              cbuf(bt + 131072);
          var lms = (1 << lbt) - 1, dms = (1 << dbt) - 1;
          var lpos = pos;
          for (;; lpos = pos) {
              // bits read, code
              var c = lm[bits16(dat, pos) & lms], sym = c >>> 4;
              pos += c & 15;
              if (pos > tbts) {
                  if (noSt)
                      err(0);
                  break;
              }
              if (!c)
                  err(2);
              if (sym < 256)
                  buf[bt++] = sym;
              else if (sym == 256) {
                  lpos = pos, lm = null;
                  break;
              }
              else {
                  var add = sym - 254;
                  // no extra bits needed if less
                  if (sym > 264) {
                      // index
                      var i = sym - 257, b = fleb[i];
                      add = bits(dat, pos, (1 << b) - 1) + fl[i];
                      pos += b;
                  }
                  // dist
                  var d = dm[bits16(dat, pos) & dms], dsym = d >>> 4;
                  if (!d)
                      err(3);
                  pos += d & 15;
                  var dt = fd[dsym];
                  if (dsym > 3) {
                      var b = fdeb[dsym];
                      dt += bits16(dat, pos) & ((1 << b) - 1), pos += b;
                  }
                  if (pos > tbts) {
                      if (noSt)
                          err(0);
                      break;
                  }
                  if (noBuf)
                      cbuf(bt + 131072);
                  var end = bt + add;
                  for (; bt < end; bt += 4) {
                      buf[bt] = buf[bt - dt];
                      buf[bt + 1] = buf[bt + 1 - dt];
                      buf[bt + 2] = buf[bt + 2 - dt];
                      buf[bt + 3] = buf[bt + 3 - dt];
                  }
                  bt = end;
              }
          }
          st.l = lm, st.p = lpos, st.b = bt, st.f = final;
          if (lm)
              final = 1, st.m = lbt, st.d = dm, st.n = dbt;
      } while (!final);
      return bt == buf.length ? buf : slc(buf, 0, bt);
  };
  // starting at p, write the minimum number of bits that can hold v to d
  var wbits = function (d, p, v) {
      v <<= p & 7;
      var o = (p / 8) | 0;
      d[o] |= v;
      d[o + 1] |= v >>> 8;
  };
  // starting at p, write the minimum number of bits (>8) that can hold v to d
  var wbits16 = function (d, p, v) {
      v <<= p & 7;
      var o = (p / 8) | 0;
      d[o] |= v;
      d[o + 1] |= v >>> 8;
      d[o + 2] |= v >>> 16;
  };
  // creates code lengths from a frequency table
  var hTree = function (d, mb) {
      // Need extra info to make a tree
      var t = [];
      for (var i = 0; i < d.length; ++i) {
          if (d[i])
              t.push({ s: i, f: d[i] });
      }
      var s = t.length;
      var t2 = t.slice();
      if (!s)
          return [et, 0];
      if (s == 1) {
          var v = new u8(t[0].s + 1);
          v[t[0].s] = 1;
          return [v, 1];
      }
      t.sort(function (a, b) { return a.f - b.f; });
      // after i2 reaches last ind, will be stopped
      // freq must be greater than largest possible number of symbols
      t.push({ s: -1, f: 25001 });
      var l = t[0], r = t[1], i0 = 0, i1 = 1, i2 = 2;
      t[0] = { s: -1, f: l.f + r.f, l: l, r: r };
      // efficient algorithm from UZIP.js
      // i0 is lookbehind, i2 is lookahead - after processing two low-freq
      // symbols that combined have high freq, will start processing i2 (high-freq,
      // non-composite) symbols instead
      // see https://reddit.com/r/photopea/comments/ikekht/uzipjs_questions/
      while (i1 != s - 1) {
          l = t[t[i0].f < t[i2].f ? i0++ : i2++];
          r = t[i0 != i1 && t[i0].f < t[i2].f ? i0++ : i2++];
          t[i1++] = { s: -1, f: l.f + r.f, l: l, r: r };
      }
      var maxSym = t2[0].s;
      for (var i = 1; i < s; ++i) {
          if (t2[i].s > maxSym)
              maxSym = t2[i].s;
      }
      // code lengths
      var tr = new u16(maxSym + 1);
      // max bits in tree
      var mbt = ln(t[i1 - 1], tr, 0);
      if (mbt > mb) {
          // more algorithms from UZIP.js
          // TODO: find out how this code works (debt)
          //  ind    debt
          var i = 0, dt = 0;
          //    left            cost
          var lft = mbt - mb, cst = 1 << lft;
          t2.sort(function (a, b) { return tr[b.s] - tr[a.s] || a.f - b.f; });
          for (; i < s; ++i) {
              var i2_1 = t2[i].s;
              if (tr[i2_1] > mb) {
                  dt += cst - (1 << (mbt - tr[i2_1]));
                  tr[i2_1] = mb;
              }
              else
                  break;
          }
          dt >>>= lft;
          while (dt > 0) {
              var i2_2 = t2[i].s;
              if (tr[i2_2] < mb)
                  dt -= 1 << (mb - tr[i2_2]++ - 1);
              else
                  ++i;
          }
          for (; i >= 0 && dt; --i) {
              var i2_3 = t2[i].s;
              if (tr[i2_3] == mb) {
                  --tr[i2_3];
                  ++dt;
              }
          }
          mbt = mb;
      }
      return [new u8(tr), mbt];
  };
  // get the max length and assign length codes
  var ln = function (n, l, d) {
      return n.s == -1
          ? Math.max(ln(n.l, l, d + 1), ln(n.r, l, d + 1))
          : (l[n.s] = d);
  };
  // length codes generation
  var lc = function (c) {
      var s = c.length;
      // Note that the semicolon was intentional
      while (s && !c[--s])
          ;
      var cl = new u16(++s);
      //  ind      num         streak
      var cli = 0, cln = c[0], cls = 1;
      var w = function (v) { cl[cli++] = v; };
      for (var i = 1; i <= s; ++i) {
          if (c[i] == cln && i != s)
              ++cls;
          else {
              if (!cln && cls > 2) {
                  for (; cls > 138; cls -= 138)
                      w(32754);
                  if (cls > 2) {
                      w(cls > 10 ? ((cls - 11) << 5) | 28690 : ((cls - 3) << 5) | 12305);
                      cls = 0;
                  }
              }
              else if (cls > 3) {
                  w(cln), --cls;
                  for (; cls > 6; cls -= 6)
                      w(8304);
                  if (cls > 2)
                      w(((cls - 3) << 5) | 8208), cls = 0;
              }
              while (cls--)
                  w(cln);
              cls = 1;
              cln = c[i];
          }
      }
      return [cl.subarray(0, cli), s];
  };
  // calculate the length of output from tree, code lengths
  var clen = function (cf, cl) {
      var l = 0;
      for (var i = 0; i < cl.length; ++i)
          l += cf[i] * cl[i];
      return l;
  };
  // writes a fixed block
  // returns the new bit pos
  var wfblk = function (out, pos, dat) {
      // no need to write 00 as type: TypedArray defaults to 0
      var s = dat.length;
      var o = shft(pos + 2);
      out[o] = s & 255;
      out[o + 1] = s >>> 8;
      out[o + 2] = out[o] ^ 255;
      out[o + 3] = out[o + 1] ^ 255;
      for (var i = 0; i < s; ++i)
          out[o + i + 4] = dat[i];
      return (o + 4 + s) * 8;
  };
  // writes a block
  var wblk = function (dat, out, final, syms, lf, df, eb, li, bs, bl, p) {
      wbits(out, p++, final);
      ++lf[256];
      var _a = hTree(lf, 15), dlt = _a[0], mlb = _a[1];
      var _b = hTree(df, 15), ddt = _b[0], mdb = _b[1];
      var _c = lc(dlt), lclt = _c[0], nlc = _c[1];
      var _d = lc(ddt), lcdt = _d[0], ndc = _d[1];
      var lcfreq = new u16(19);
      for (var i = 0; i < lclt.length; ++i)
          lcfreq[lclt[i] & 31]++;
      for (var i = 0; i < lcdt.length; ++i)
          lcfreq[lcdt[i] & 31]++;
      var _e = hTree(lcfreq, 7), lct = _e[0], mlcb = _e[1];
      var nlcc = 19;
      for (; nlcc > 4 && !lct[clim[nlcc - 1]]; --nlcc)
          ;
      var flen = (bl + 5) << 3;
      var ftlen = clen(lf, flt) + clen(df, fdt) + eb;
      var dtlen = clen(lf, dlt) + clen(df, ddt) + eb + 14 + 3 * nlcc + clen(lcfreq, lct) + (2 * lcfreq[16] + 3 * lcfreq[17] + 7 * lcfreq[18]);
      if (flen <= ftlen && flen <= dtlen)
          return wfblk(out, p, dat.subarray(bs, bs + bl));
      var lm, ll, dm, dl;
      wbits(out, p, 1 + (dtlen < ftlen)), p += 2;
      if (dtlen < ftlen) {
          lm = hMap(dlt, mlb, 0), ll = dlt, dm = hMap(ddt, mdb, 0), dl = ddt;
          var llm = hMap(lct, mlcb, 0);
          wbits(out, p, nlc - 257);
          wbits(out, p + 5, ndc - 1);
          wbits(out, p + 10, nlcc - 4);
          p += 14;
          for (var i = 0; i < nlcc; ++i)
              wbits(out, p + 3 * i, lct[clim[i]]);
          p += 3 * nlcc;
          var lcts = [lclt, lcdt];
          for (var it = 0; it < 2; ++it) {
              var clct = lcts[it];
              for (var i = 0; i < clct.length; ++i) {
                  var len = clct[i] & 31;
                  wbits(out, p, llm[len]), p += lct[len];
                  if (len > 15)
                      wbits(out, p, (clct[i] >>> 5) & 127), p += clct[i] >>> 12;
              }
          }
      }
      else {
          lm = flm, ll = flt, dm = fdm, dl = fdt;
      }
      for (var i = 0; i < li; ++i) {
          if (syms[i] > 255) {
              var len = (syms[i] >>> 18) & 31;
              wbits16(out, p, lm[len + 257]), p += ll[len + 257];
              if (len > 7)
                  wbits(out, p, (syms[i] >>> 23) & 31), p += fleb[len];
              var dst = syms[i] & 31;
              wbits16(out, p, dm[dst]), p += dl[dst];
              if (dst > 3)
                  wbits16(out, p, (syms[i] >>> 5) & 8191), p += fdeb[dst];
          }
          else {
              wbits16(out, p, lm[syms[i]]), p += ll[syms[i]];
          }
      }
      wbits16(out, p, lm[256]);
      return p + ll[256];
  };
  // deflate options (nice << 13) | chain
  var deo = /*#__PURE__*/ new u32([65540, 131080, 131088, 131104, 262176, 1048704, 1048832, 2114560, 2117632]);
  // empty
  var et = /*#__PURE__*/ new u8(0);
  // compresses data into a raw DEFLATE buffer
  var dflt = function (dat, lvl, plvl, pre, post, lst) {
      var s = dat.length;
      var o = new u8(pre + s + 5 * (1 + Math.ceil(s / 7000)) + post);
      // writing to this writes to the output buffer
      var w = o.subarray(pre, o.length - post);
      var pos = 0;
      if (!lvl || s < 8) {
          for (var i = 0; i <= s; i += 65535) {
              // end
              var e = i + 65535;
              if (e >= s) {
                  // write final block
                  w[pos >> 3] = lst;
              }
              pos = wfblk(w, pos + 1, dat.subarray(i, e));
          }
      }
      else {
          var opt = deo[lvl - 1];
          var n = opt >>> 13, c = opt & 8191;
          var msk_1 = (1 << plvl) - 1;
          //    prev 2-byte val map    curr 2-byte val map
          var prev = new u16(32768), head = new u16(msk_1 + 1);
          var bs1_1 = Math.ceil(plvl / 3), bs2_1 = 2 * bs1_1;
          var hsh = function (i) { return (dat[i] ^ (dat[i + 1] << bs1_1) ^ (dat[i + 2] << bs2_1)) & msk_1; };
          // 24576 is an arbitrary number of maximum symbols per block
          // 424 buffer for last block
          var syms = new u32(25000);
          // length/literal freq   distance freq
          var lf = new u16(288), df = new u16(32);
          //  l/lcnt  exbits  index  l/lind  waitdx  bitpos
          var lc_1 = 0, eb = 0, i = 0, li = 0, wi = 0, bs = 0;
          for (; i < s; ++i) {
              // hash value
              // deopt when i > s - 3 - at end, deopt acceptable
              var hv = hsh(i);
              // index mod 32768    previous index mod
              var imod = i & 32767, pimod = head[hv];
              prev[imod] = pimod;
              head[hv] = imod;
              // We always should modify head and prev, but only add symbols if
              // this data is not yet processed ("wait" for wait index)
              if (wi <= i) {
                  // bytes remaining
                  var rem = s - i;
                  if ((lc_1 > 7000 || li > 24576) && rem > 423) {
                      pos = wblk(dat, w, 0, syms, lf, df, eb, li, bs, i - bs, pos);
                      li = lc_1 = eb = 0, bs = i;
                      for (var j = 0; j < 286; ++j)
                          lf[j] = 0;
                      for (var j = 0; j < 30; ++j)
                          df[j] = 0;
                  }
                  //  len    dist   chain
                  var l = 2, d = 0, ch_1 = c, dif = (imod - pimod) & 32767;
                  if (rem > 2 && hv == hsh(i - dif)) {
                      var maxn = Math.min(n, rem) - 1;
                      var maxd = Math.min(32767, i);
                      // max possible length
                      // not capped at dif because decompressors implement "rolling" index population
                      var ml = Math.min(258, rem);
                      while (dif <= maxd && --ch_1 && imod != pimod) {
                          if (dat[i + l] == dat[i + l - dif]) {
                              var nl = 0;
                              for (; nl < ml && dat[i + nl] == dat[i + nl - dif]; ++nl)
                                  ;
                              if (nl > l) {
                                  l = nl, d = dif;
                                  // break out early when we reach "nice" (we are satisfied enough)
                                  if (nl > maxn)
                                      break;
                                  // now, find the rarest 2-byte sequence within this
                                  // length of literals and search for that instead.
                                  // Much faster than just using the start
                                  var mmd = Math.min(dif, nl - 2);
                                  var md = 0;
                                  for (var j = 0; j < mmd; ++j) {
                                      var ti = (i - dif + j + 32768) & 32767;
                                      var pti = prev[ti];
                                      var cd = (ti - pti + 32768) & 32767;
                                      if (cd > md)
                                          md = cd, pimod = ti;
                                  }
                              }
                          }
                          // check the previous match
                          imod = pimod, pimod = prev[imod];
                          dif += (imod - pimod + 32768) & 32767;
                      }
                  }
                  // d will be nonzero only when a match was found
                  if (d) {
                      // store both dist and len data in one Uint32
                      // Make sure this is recognized as a len/dist with 28th bit (2^28)
                      syms[li++] = 268435456 | (revfl[l] << 18) | revfd[d];
                      var lin = revfl[l] & 31, din = revfd[d] & 31;
                      eb += fleb[lin] + fdeb[din];
                      ++lf[257 + lin];
                      ++df[din];
                      wi = i + l;
                      ++lc_1;
                  }
                  else {
                      syms[li++] = dat[i];
                      ++lf[dat[i]];
                  }
              }
          }
          pos = wblk(dat, w, lst, syms, lf, df, eb, li, bs, i - bs, pos);
          // this is the easiest way to avoid needing to maintain state
          if (!lst && pos & 7)
              pos = wfblk(w, pos + 1, et);
      }
      return slc(o, 0, pre + shft(pos) + post);
  };
  // CRC32 table
  var crct = /*#__PURE__*/ (function () {
      var t = new Int32Array(256);
      for (var i = 0; i < 256; ++i) {
          var c = i, k = 9;
          while (--k)
              c = ((c & 1) && -306674912) ^ (c >>> 1);
          t[i] = c;
      }
      return t;
  })();
  // CRC32
  var crc = function () {
      var c = -1;
      return {
          p: function (d) {
              // closures have awful performance
              var cr = c;
              for (var i = 0; i < d.length; ++i)
                  cr = crct[(cr & 255) ^ d[i]] ^ (cr >>> 8);
              c = cr;
          },
          d: function () { return ~c; }
      };
  };
  // deflate with opts
  var dopt = function (dat, opt, pre, post, st) {
      return dflt(dat, opt.level == null ? 6 : opt.level, opt.mem == null ? Math.ceil(Math.max(8, Math.min(13, Math.log(dat.length))) * 1.5) : (12 + opt.mem), pre, post, !st);
  };
  // Walmart object spread
  var mrg = function (a, b) {
      var o = {};
      for (var k in a)
          o[k] = a[k];
      for (var k in b)
          o[k] = b[k];
      return o;
  };
  // worker clone
  // This is possibly the craziest part of the entire codebase, despite how simple it may seem.
  // The only parameter to this function is a closure that returns an array of variables outside of the function scope.
  // We're going to try to figure out the variable names used in the closure as strings because that is crucial for workerization.
  // We will return an object mapping of true variable name to value (basically, the current scope as a JS object).
  // The reason we can't just use the original variable names is minifiers mangling the toplevel scope.
  // This took me three weeks to figure out how to do.
  var wcln = function (fn, fnStr, td) {
      var dt = fn();
      var st = fn.toString();
      var ks = st.slice(st.indexOf('[') + 1, st.lastIndexOf(']')).replace(/\s+/g, '').split(',');
      for (var i = 0; i < dt.length; ++i) {
          var v = dt[i], k = ks[i];
          if (typeof v == 'function') {
              fnStr += ';' + k + '=';
              var st_1 = v.toString();
              if (v.prototype) {
                  // for global objects
                  if (st_1.indexOf('[native code]') != -1) {
                      var spInd = st_1.indexOf(' ', 8) + 1;
                      fnStr += st_1.slice(spInd, st_1.indexOf('(', spInd));
                  }
                  else {
                      fnStr += st_1;
                      for (var t in v.prototype)
                          fnStr += ';' + k + '.prototype.' + t + '=' + v.prototype[t].toString();
                  }
              }
              else
                  fnStr += st_1;
          }
          else
              td[k] = v;
      }
      return [fnStr, td];
  };
  var ch = [];
  // clone bufs
  var cbfs = function (v) {
      var tl = [];
      for (var k in v) {
          if (v[k].buffer) {
              tl.push((v[k] = new v[k].constructor(v[k])).buffer);
          }
      }
      return tl;
  };
  // use a worker to execute code
  var wrkr = function (fns, init, id, cb) {
      var _a;
      if (!ch[id]) {
          var fnStr = '', td_1 = {}, m = fns.length - 1;
          for (var i = 0; i < m; ++i)
              _a = wcln(fns[i], fnStr, td_1), fnStr = _a[0], td_1 = _a[1];
          ch[id] = wcln(fns[m], fnStr, td_1);
      }
      var td = mrg({}, ch[id][1]);
      return wk(ch[id][0] + ';onmessage=function(e){for(var k in e.data)self[k]=e.data[k];onmessage=' + init.toString() + '}', id, td, cbfs(td), cb);
  };
  // base async inflate fn
  var bInflt = function () { return [u8, u16, u32, fleb, fdeb, clim, fl, fd, flrm, fdrm, rev, ec, hMap, max, bits, bits16, shft, slc, err, inflt, inflateSync, pbf, gu8]; };
  var bDflt = function () { return [u8, u16, u32, fleb, fdeb, clim, revfl, revfd, flm, flt, fdm, fdt, rev, deo, et, hMap, wbits, wbits16, hTree, ln, lc, clen, wfblk, wblk, shft, slc, dflt, dopt, deflateSync, pbf]; };
  // gzip extra
  var gze = function () { return [gzh, gzhl, wbytes, crc, crct]; };
  // gunzip extra
  var guze = function () { return [gzs, gzl]; };
  // post buf
  var pbf = function (msg) { return postMessage(msg, [msg.buffer]); };
  // get u8
  var gu8 = function (o) { return o && o.size && new u8(o.size); };
  // async helper
  var cbify = function (dat, opts, fns, init, id, cb) {
      var w = wrkr(fns, init, id, function (err, dat) {
          w.terminate();
          cb(err, dat);
      });
      w.postMessage([dat, opts], opts.consume ? [dat.buffer] : []);
      return function () { w.terminate(); };
  };
  // read 2 bytes
  var b2 = function (d, b) { return d[b] | (d[b + 1] << 8); };
  // read 4 bytes
  var b4 = function (d, b) { return (d[b] | (d[b + 1] << 8) | (d[b + 2] << 16) | (d[b + 3] << 24)) >>> 0; };
  var b8 = function (d, b) { return b4(d, b) + (b4(d, b + 4) * 4294967296); };
  // write bytes
  var wbytes = function (d, b, v) {
      for (; v; ++b)
          d[b] = v, v >>>= 8;
  };
  // gzip header
  var gzh = function (c, o) {
      var fn = o.filename;
      c[0] = 31, c[1] = 139, c[2] = 8, c[8] = o.level < 2 ? 4 : o.level == 9 ? 2 : 0, c[9] = 3; // assume Unix
      if (o.mtime != 0)
          wbytes(c, 4, Math.floor(new Date(o.mtime || Date.now()) / 1000));
      if (fn) {
          c[3] = 8;
          for (var i = 0; i <= fn.length; ++i)
              c[i + 10] = fn.charCodeAt(i);
      }
  };
  // gzip footer: -8 to -4 = CRC, -4 to -0 is length
  // gzip start
  var gzs = function (d) {
      if (d[0] != 31 || d[1] != 139 || d[2] != 8)
          err(6, 'invalid gzip data');
      var flg = d[3];
      var st = 10;
      if (flg & 4)
          st += d[10] | (d[11] << 8) + 2;
      for (var zs = (flg >> 3 & 1) + (flg >> 4 & 1); zs > 0; zs -= !d[st++])
          ;
      return st + (flg & 2);
  };
  // gzip length
  var gzl = function (d) {
      var l = d.length;
      return ((d[l - 4] | d[l - 3] << 8 | d[l - 2] << 16) | (d[l - 1] << 24)) >>> 0;
  };
  // gzip header length
  var gzhl = function (o) { return 10 + ((o.filename && (o.filename.length + 1)) || 0); };
  function deflate(data, opts, cb) {
      if (!cb)
          cb = opts, opts = {};
      if (typeof cb != 'function')
          err(7);
      return cbify(data, opts, [
          bDflt,
      ], function (ev) { return pbf(deflateSync(ev.data[0], ev.data[1])); }, 0, cb);
  }
  /**
   * Compresses data with DEFLATE without any wrapper
   * @param data The data to compress
   * @param opts The compression options
   * @returns The deflated version of the data
   */
  function deflateSync(data, opts) {
      return dopt(data, opts || {}, 0, 0);
  }
  function inflate(data, opts, cb) {
      if (!cb)
          cb = opts, opts = {};
      if (typeof cb != 'function')
          err(7);
      return cbify(data, opts, [
          bInflt
      ], function (ev) { return pbf(inflateSync(ev.data[0], gu8(ev.data[1]))); }, 1, cb);
  }
  /**
   * Expands DEFLATE data with no wrapper
   * @param data The data to decompress
   * @param out Where to write the data. Saves memory if you know the decompressed size and provide an output buffer of that length.
   * @returns The decompressed version of the data
   */
  function inflateSync(data, out) {
      return inflt(data, out);
  }
  function gzip(data, opts, cb) {
      if (!cb)
          cb = opts, opts = {};
      if (typeof cb != 'function')
          err(7);
      return cbify(data, opts, [
          bDflt,
          gze,
          function () { return [gzipSync$1]; }
      ], function (ev) { return pbf(gzipSync$1(ev.data[0], ev.data[1])); }, 2, cb);
  }
  /**
   * Compresses data with GZIP
   * @param data The data to compress
   * @param opts The compression options
   * @returns The gzipped version of the data
   */
  function gzipSync$1(data, opts) {
      if (!opts)
          opts = {};
      var c = crc(), l = data.length;
      c.p(data);
      var d = dopt(data, opts, gzhl(opts), 8), s = d.length;
      return gzh(d, opts), wbytes(d, s - 8, c.d()), wbytes(d, s - 4, l), d;
  }
  function gunzip(data, opts, cb) {
      if (!cb)
          cb = opts, opts = {};
      if (typeof cb != 'function')
          err(7);
      return cbify(data, opts, [
          bInflt,
          guze,
          function () { return [gunzipSync$1]; }
      ], function (ev) { return pbf(gunzipSync$1(ev.data[0])); }, 3, cb);
  }
  /**
   * Expands GZIP data
   * @param data The data to decompress
   * @param out Where to write the data. GZIP already encodes the output size, so providing this doesn't save memory.
   * @returns The decompressed version of the data
   */
  function gunzipSync$1(data, out) {
      return inflt(data.subarray(gzs(data), -8), out || new u8(gzl(data)));
  }
  // flatten a directory structure
  var fltn = function (d, p, t, o) {
      for (var k in d) {
          var val = d[k], n = p + k, op = o;
          if (Array.isArray(val))
              op = mrg(o, val[1]), val = val[0];
          if (val instanceof u8)
              t[n] = [val, op];
          else {
              t[n += '/'] = [new u8(0), op];
              fltn(val, n, t, o);
          }
      }
  };
  // text encoder
  var te = typeof TextEncoder != 'undefined' && /*#__PURE__*/ new TextEncoder();
  // text decoder
  var td = typeof TextDecoder != 'undefined' && /*#__PURE__*/ new TextDecoder();
  // text decoder stream
  var tds = 0;
  try {
      td.decode(et, { stream: true });
      tds = 1;
  }
  catch (e) { }
  // decode UTF8
  var dutf8 = function (d) {
      for (var r = '', i = 0;;) {
          var c = d[i++];
          var eb = (c > 127) + (c > 223) + (c > 239);
          if (i + eb > d.length)
              return [r, slc(d, i - 1)];
          if (!eb)
              r += String.fromCharCode(c);
          else if (eb == 3) {
              c = ((c & 15) << 18 | (d[i++] & 63) << 12 | (d[i++] & 63) << 6 | (d[i++] & 63)) - 65536,
                  r += String.fromCharCode(55296 | (c >> 10), 56320 | (c & 1023));
          }
          else if (eb & 1)
              r += String.fromCharCode((c & 31) << 6 | (d[i++] & 63));
          else
              r += String.fromCharCode((c & 15) << 12 | (d[i++] & 63) << 6 | (d[i++] & 63));
      }
  };
  /**
   * Converts a string into a Uint8Array for use with compression/decompression methods
   * @param str The string to encode
   * @param latin1 Whether or not to interpret the data as Latin-1. This should
   *               not need to be true unless decoding a binary string.
   * @returns The string encoded in UTF-8/Latin-1 binary
   */
  function strToU8(str, latin1) {
      if (latin1) {
          var ar_1 = new u8(str.length);
          for (var i = 0; i < str.length; ++i)
              ar_1[i] = str.charCodeAt(i);
          return ar_1;
      }
      if (te)
          return te.encode(str);
      var l = str.length;
      var ar = new u8(str.length + (str.length >> 1));
      var ai = 0;
      var w = function (v) { ar[ai++] = v; };
      for (var i = 0; i < l; ++i) {
          if (ai + 5 > ar.length) {
              var n = new u8(ai + 8 + ((l - i) << 1));
              n.set(ar);
              ar = n;
          }
          var c = str.charCodeAt(i);
          if (c < 128 || latin1)
              w(c);
          else if (c < 2048)
              w(192 | (c >> 6)), w(128 | (c & 63));
          else if (c > 55295 && c < 57344)
              c = 65536 + (c & 1023 << 10) | (str.charCodeAt(++i) & 1023),
                  w(240 | (c >> 18)), w(128 | ((c >> 12) & 63)), w(128 | ((c >> 6) & 63)), w(128 | (c & 63));
          else
              w(224 | (c >> 12)), w(128 | ((c >> 6) & 63)), w(128 | (c & 63));
      }
      return slc(ar, 0, ai);
  }
  /**
   * Converts a Uint8Array to a string
   * @param dat The data to decode to string
   * @param latin1 Whether or not to interpret the data as Latin-1. This should
   *               not need to be true unless encoding to binary string.
   * @returns The original UTF-8/Latin-1 string
   */
  function strFromU8(dat, latin1) {
      if (latin1) {
          var r = '';
          for (var i = 0; i < dat.length; i += 16384)
              r += String.fromCharCode.apply(null, dat.subarray(i, i + 16384));
          return r;
      }
      else if (td)
          return td.decode(dat);
      else {
          var _a = dutf8(dat), out = _a[0], ext = _a[1];
          if (ext.length)
              err(8);
          return out;
      }
  }
  // skip local zip header
  var slzh = function (d, b) { return b + 30 + b2(d, b + 26) + b2(d, b + 28); };
  // read zip header
  var zh = function (d, b, z) {
      var fnl = b2(d, b + 28), fn = strFromU8(d.subarray(b + 46, b + 46 + fnl), !(b2(d, b + 8) & 2048)), es = b + 46 + fnl, bs = b4(d, b + 20);
      var _a = z && bs == 4294967295 ? z64e(d, es) : [bs, b4(d, b + 24), b4(d, b + 42)], sc = _a[0], su = _a[1], off = _a[2];
      return [b2(d, b + 10), sc, su, fn, es + b2(d, b + 30) + b2(d, b + 32), off];
  };
  // read zip64 extra field
  var z64e = function (d, b) {
      for (; b2(d, b) != 1; b += 4 + b2(d, b + 2))
          ;
      return [b8(d, b + 12), b8(d, b + 4), b8(d, b + 20)];
  };
  // extra field length
  var exfl = function (ex) {
      var le = 0;
      if (ex) {
          for (var k in ex) {
              var l = ex[k].length;
              if (l > 65535)
                  err(9);
              le += l + 4;
          }
      }
      return le;
  };
  // write zip header
  var wzh = function (d, b, f, fn, u, c, ce, co) {
      var fl = fn.length, ex = f.extra, col = co && co.length;
      var exl = exfl(ex);
      wbytes(d, b, ce != null ? 0x2014B50 : 0x4034B50), b += 4;
      if (ce != null)
          d[b++] = 20, d[b++] = f.os;
      d[b] = 20, b += 2; // spec compliance? what's that?
      d[b++] = (f.flag << 1) | (c < 0 && 8), d[b++] = u && 8;
      d[b++] = f.compression & 255, d[b++] = f.compression >> 8;
      var dt = new Date(f.mtime == null ? Date.now() : f.mtime), y = dt.getFullYear() - 1980;
      if (y < 0 || y > 119)
          err(10);
      wbytes(d, b, (y << 25) | ((dt.getMonth() + 1) << 21) | (dt.getDate() << 16) | (dt.getHours() << 11) | (dt.getMinutes() << 5) | (dt.getSeconds() >>> 1)), b += 4;
      if (c != -1) {
          wbytes(d, b, f.crc);
          wbytes(d, b + 4, c < 0 ? -c - 2 : c);
          wbytes(d, b + 8, f.size);
      }
      wbytes(d, b + 12, fl);
      wbytes(d, b + 14, exl), b += 16;
      if (ce != null) {
          wbytes(d, b, col);
          wbytes(d, b + 6, f.attrs);
          wbytes(d, b + 10, ce), b += 14;
      }
      d.set(fn, b);
      b += fl;
      if (exl) {
          for (var k in ex) {
              var exf = ex[k], l = exf.length;
              wbytes(d, b, +k);
              wbytes(d, b + 2, l);
              d.set(exf, b + 4), b += 4 + l;
          }
      }
      if (col)
          d.set(co, b), b += col;
      return b;
  };
  // write zip footer (end of central directory)
  var wzf = function (o, b, c, d, e) {
      wbytes(o, b, 0x6054B50); // skip disk
      wbytes(o, b + 8, c);
      wbytes(o, b + 10, c);
      wbytes(o, b + 12, d);
      wbytes(o, b + 16, e);
  };
  function zip(data, opts, cb) {
      if (!cb)
          cb = opts, opts = {};
      if (typeof cb != 'function')
          err(7);
      var r = {};
      fltn(data, '', r, opts);
      var k = Object.keys(r);
      var lft = k.length, o = 0, tot = 0;
      var slft = lft, files = new Array(lft);
      var term = [];
      var tAll = function () {
          for (var i = 0; i < term.length; ++i)
              term[i]();
      };
      var cbd = function (a, b) {
          mt(function () { cb(a, b); });
      };
      mt(function () { cbd = cb; });
      var cbf = function () {
          var out = new u8(tot + 22), oe = o, cdl = tot - o;
          tot = 0;
          for (var i = 0; i < slft; ++i) {
              var f = files[i];
              try {
                  var l = f.c.length;
                  wzh(out, tot, f, f.f, f.u, l);
                  var badd = 30 + f.f.length + exfl(f.extra);
                  var loc = tot + badd;
                  out.set(f.c, loc);
                  wzh(out, o, f, f.f, f.u, l, tot, f.m), o += 16 + badd + (f.m ? f.m.length : 0), tot = loc + l;
              }
              catch (e) {
                  return cbd(e, null);
              }
          }
          wzf(out, o, files.length, cdl, oe);
          cbd(null, out);
      };
      if (!lft)
          cbf();
      var _loop_1 = function (i) {
          var fn = k[i];
          var _a = r[fn], file = _a[0], p = _a[1];
          var c = crc(), size = file.length;
          c.p(file);
          var f = strToU8(fn), s = f.length;
          var com = p.comment, m = com && strToU8(com), ms = m && m.length;
          var exl = exfl(p.extra);
          var compression = p.level == 0 ? 0 : 8;
          var cbl = function (e, d) {
              if (e) {
                  tAll();
                  cbd(e, null);
              }
              else {
                  var l = d.length;
                  files[i] = mrg(p, {
                      size: size,
                      crc: c.d(),
                      c: d,
                      f: f,
                      m: m,
                      u: s != fn.length || (m && (com.length != ms)),
                      compression: compression
                  });
                  o += 30 + s + exl + l;
                  tot += 76 + 2 * (s + exl) + (ms || 0) + l;
                  if (!--lft)
                      cbf();
              }
          };
          if (s > 65535)
              cbl(err(11, 0, 1), null);
          if (!compression)
              cbl(null, file);
          else if (size < 160000) {
              try {
                  cbl(null, deflateSync(file, p));
              }
              catch (e) {
                  cbl(e, null);
              }
          }
          else
              term.push(deflate(file, p, cbl));
      };
      // Cannot use lft because it can decrease
      for (var i = 0; i < slft; ++i) {
          _loop_1(i);
      }
      return tAll;
  }
  /**
   * Synchronously creates a ZIP file. Prefer using `zip` for better performance
   * with more than one file.
   * @param data The directory structure for the ZIP archive
   * @param opts The main options, merged with per-file options
   * @returns The generated ZIP archive
   */
  function zipSync$1(data, opts) {
      if (!opts)
          opts = {};
      var r = {};
      var files = [];
      fltn(data, '', r, opts);
      var o = 0;
      var tot = 0;
      for (var fn in r) {
          var _a = r[fn], file = _a[0], p = _a[1];
          var compression = p.level == 0 ? 0 : 8;
          var f = strToU8(fn), s = f.length;
          var com = p.comment, m = com && strToU8(com), ms = m && m.length;
          var exl = exfl(p.extra);
          if (s > 65535)
              err(11);
          var d = compression ? deflateSync(file, p) : file, l = d.length;
          var c = crc();
          c.p(file);
          files.push(mrg(p, {
              size: file.length,
              crc: c.d(),
              c: d,
              f: f,
              m: m,
              u: s != fn.length || (m && (com.length != ms)),
              o: o,
              compression: compression
          }));
          o += 30 + s + exl + l;
          tot += 76 + 2 * (s + exl) + (ms || 0) + l;
      }
      var out = new u8(tot + 22), oe = o, cdl = tot - o;
      for (var i = 0; i < files.length; ++i) {
          var f = files[i];
          wzh(out, f.o, f, f.f, f.u, f.c.length);
          var badd = 30 + f.f.length + exfl(f.extra);
          out.set(f.c, f.o + badd);
          wzh(out, o, f, f.f, f.u, f.c.length, f.o, f.m), o += 16 + badd + (f.m ? f.m.length : 0);
      }
      wzf(out, o, files.length, cdl, oe);
      return out;
  }
  var mt = typeof queueMicrotask == 'function' ? queueMicrotask : typeof setTimeout == 'function' ? setTimeout : function (fn) { fn(); };
  function unzip(data, opts, cb) {
      if (!cb)
          cb = opts, opts = {};
      if (typeof cb != 'function')
          err(7);
      var term = [];
      var tAll = function () {
          for (var i = 0; i < term.length; ++i)
              term[i]();
      };
      var files = {};
      var cbd = function (a, b) {
          mt(function () { cb(a, b); });
      };
      mt(function () { cbd = cb; });
      var e = data.length - 22;
      for (; b4(data, e) != 0x6054B50; --e) {
          if (!e || data.length - e > 65558) {
              cbd(err(13, 0, 1), null);
              return tAll;
          }
      }
      var lft = b2(data, e + 8);
      if (lft) {
          var c = lft;
          var o = b4(data, e + 16);
          var z = o == 4294967295 || c == 65535;
          if (z) {
              var ze = b4(data, e - 12);
              z = b4(data, ze) == 0x6064B50;
              if (z) {
                  c = lft = b4(data, ze + 32);
                  o = b4(data, ze + 48);
              }
          }
          var fltr = opts && opts.filter;
          var _loop_3 = function (i) {
              var _a = zh(data, o, z), c_1 = _a[0], sc = _a[1], su = _a[2], fn = _a[3], no = _a[4], off = _a[5], b = slzh(data, off);
              o = no;
              var cbl = function (e, d) {
                  if (e) {
                      tAll();
                      cbd(e, null);
                  }
                  else {
                      if (d)
                          files[fn] = d;
                      if (!--lft)
                          cbd(null, files);
                  }
              };
              if (!fltr || fltr({
                  name: fn,
                  size: sc,
                  originalSize: su,
                  compression: c_1
              })) {
                  if (!c_1)
                      cbl(null, slc(data, b, b + sc));
                  else if (c_1 == 8) {
                      var infl = data.subarray(b, b + sc);
                      if (sc < 320000) {
                          try {
                              cbl(null, inflateSync(infl, new u8(su)));
                          }
                          catch (e) {
                              cbl(e, null);
                          }
                      }
                      else
                          term.push(inflate(infl, { size: su }, cbl));
                  }
                  else
                      cbl(err(14, 'unknown compression type ' + c_1, 1), null);
              }
              else
                  cbl(null, null);
          };
          for (var i = 0; i < c; ++i) {
              _loop_3(i);
          }
      }
      else
          cbd(null, {});
      return tAll;
  }
  /**
   * Synchronously decompresses a ZIP archive. Prefer using `unzip` for better
   * performance with more than one file.
   * @param data The raw compressed ZIP file
   * @param opts The ZIP extraction options
   * @returns The decompressed files
   */
  function unzipSync$1(data, opts) {
      var files = {};
      var e = data.length - 22;
      for (; b4(data, e) != 0x6054B50; --e) {
          if (!e || data.length - e > 65558)
              err(13);
      }
      var c = b2(data, e + 8);
      if (!c)
          return {};
      var o = b4(data, e + 16);
      var z = o == 4294967295 || c == 65535;
      if (z) {
          var ze = b4(data, e - 12);
          z = b4(data, ze) == 0x6064B50;
          if (z) {
              c = b4(data, ze + 32);
              o = b4(data, ze + 48);
          }
      }
      var fltr = opts && opts.filter;
      for (var i = 0; i < c; ++i) {
          var _a = zh(data, o, z), c_2 = _a[0], sc = _a[1], su = _a[2], fn = _a[3], no = _a[4], off = _a[5], b = slzh(data, off);
          o = no;
          if (!fltr || fltr({
              name: fn,
              size: sc,
              originalSize: su,
              compression: c_2
          })) {
              if (!c_2)
                  files[fn] = slc(data, b, b + sc);
              else if (c_2 == 8)
                  files[fn] = inflateSync(data.subarray(b, b + sc), new u8(su));
              else
                  err(14, 'unknown compression type ' + c_2);
          }
      }
      return files;
  }

  function runningInBrowser() {
    return typeof window !== 'undefined' && typeof window.document !== 'undefined';
  }

  var Env = /*#__PURE__*/Object.freeze({
    __proto__: null,
    runningInBrowser: runningInBrowser
  });

  // Checks if @arg is a Uint8Array containing gzipped data
  function isGzipped(arg) {
    return arg.length > 2 && arg.buffer instanceof ArrayBuffer && arg[0] == 0x1f && arg[1] == 0x8b;
  }

  function gzipSync(content, opts) {
    // TODO: use native module in Node if available
    // require('zlib').
    if (typeof content == 'string') {
      content = strToU8(content);
    }
    if (runningInBrowser()) {
      return gzipSync$1(content, opts);
    }
    return require('zlib').gzipSync(content, opts);
  }

  async function gzipAsync(content, opts) {
    if (typeof content == 'string') {
      content = strToU8(content);
    }
    var gzip$1 = runningInBrowser() ? utils.promisify(gzip) : utils.promisify(require('zlib').gzip);
    return gzip$1(content, opts);
  }

  async function gunzipAsync(buf, opts) {
    if (buf instanceof ArrayBuffer) {
      buf = new Uint8Array(buf);
    }
    opts = opts || {};
    var gunzip$1 = runningInBrowser() ? utils.promisify(gunzip) : utils.promisify(require('zlib').gunzip);
    var out = await gunzip$1(buf, opts);
    if (opts.filename && !isImportableAsBinary(opts.filename)) {
      out = strFromU8(out);
    }
    return out;
  }

  function gunzipSync(buf, filename) {
    if (buf instanceof ArrayBuffer) {
      buf = new Uint8Array(buf);
    }
    var out = gunzipSync$1(buf); // returns Uint8Array
    if (filename && !isImportableAsBinary(filename)) {
      out = strFromU8(out);
    }
    return out;
  }

  var Gzip = /*#__PURE__*/Object.freeze({
    __proto__: null,
    isGzipped: isGzipped,
    gzipSync: gzipSync,
    gzipAsync: gzipAsync,
    gunzipAsync: gunzipAsync,
    gunzipSync: gunzipSync
  });

  // Export in a column-first format
  // Faster than exportTable(), and can handle some data that can't be
  // converted to JSON, like Date objects.
  async function exportTable2(table) {
    var fields = table.getFields();
    var records = table.getRecords();
    var types = [];
    var columns = await Promise.all(fields.map(function(name) {
      var type = getColumnType(name, records);
      types.push(type);
      return exportColumn(name, type, records);
    }));
    return ({
      fields: fields,
      types: types,
      data: columns,
      size: records.length
    });
  }

  // Returns array of records
  function importTable(data) {
    if (looksLikeType2Table(data)) {
      return importTable2(data);
    }
    if (isGzipped(data)) {
      return JSON.parse(strFromU8(gunzipSync(data)));
    }
    if (Array.isArray(data)) {
      return data;
    }
    error('Unknown packed table format');
  }

  function looksLikeType2Table(o) {
    return Array.isArray(o.fields) &&
      Array.isArray(o.types) && Array.isArray(o.data) &&
      o.fields.length == o.types.length && o.fields.length == o.data.length &&
      o.size >= 0;
  }

  function importTable2(obj) {
    var n = obj.size;
    var records = [];
    for (var i=0; i<n; i++) {
      records[i] = {};
    }
    for (var j=0, m=obj.fields.length; j<m; j++) {
      importColumn(obj.fields[j], obj.types[j], obj.data[j], records);
      obj.data[j] = null;
    }
    return records;
  }

  function importColumn(field, type, data, records) {
    var arr, rec;
    if (isGzipped(data)) {
      arr = JSON.parse(strFromU8(gunzipSync(data)));
    } else if (Array.isArray(data)) {
      arr = data;
    } else {
      error('Unexpected packed table format');
    }
    for (var i=0, n=records.length; i<n; i++) {
      rec = records[i];
      rec[field] = arr[i];
    }
  }

  async function exportColumn(name, type, records) {
    if (type == 'number' || type == 'string') {
      return gzipAsync(JSON.stringify(getFieldValues(records, name)), {level: 2, consume: true});
    }
    return getFieldValues(records, name);
  }

  // faster for decimal numbers?
  // function exportNumberField(field, records) {
  //   var arr = new Float64Array(records.length);
  //   for (var i=0, n=records.length; i<n; i++) {
  //     arr[i] = records[i][field];
  //   }
  //   return gzipSync(arr, {level: 2});
  // }

  var PACKAGE_EXT = 'msx';

  // libraries
  // https://msgpack.org/index.html
  //

  // session format (including gui state)
  /*
  {
    version: 1,
    created: 'YYYY-MM-DDTHH:mm:ss.sssZ', // ISO string
    datasets: [],
    gui: {} // see gui-session-snapshot-control.mjs
  }
  */

  async function exportPackedDatasets(datasets, opts) {
    var content = pack(await exportDatasetsToPack(datasets, opts));
    return [{
      content: content,
      filename: opts.file || 'mapshaper_snapshot.' + PACKAGE_EXT
    }];
  }

  function pack(obj) {
    // encode options: see https://github.com/msgpack/msgpack-javascript
    // initialBufferSize  number  2048
    // ignoreUndefined boolean false
    return pack$1(obj, {});
  }

  // gui: (optional) gui instance
  // opts examples:
  //    exporting from command line: { compact: true, file: 'tmp.msx', final: true }
  //    exporting from gui export menu: {compact: true, format: 'msx'}
  //    saving gui temp snapshot: {compact: false}
  async function exportDatasetsToPack(datasets, opts) {
    var obj = {
      version: 1,
      created: (new Date).toISOString(),
      datasets: await Promise.all(datasets.map(dataset => exportDataset(dataset, opts)))
    };
    return obj;
  }

  async function exportDataset(dataset, opts) {
    var arcs = dataset.arcs;
    var arcData = null;
    if (arcs) {
      arcData = arcs.getVertexData();
      arcData.zlimit = arcs.getRetainedInterval(); // TODO: add this to getVertexData()
      arcData = await exportArcData(arcData, opts);
    }
    var layers = dataset.layers.map(lyr => exportLayer(lyr, opts));
    return {
      arcs: arcData,
      info: dataset.info ? exportInfo(dataset.info) : null,
      layers: await Promise.all(layers)
    };
  }

  // compress unpacked + uncompressed snapshot data in-place
  async function compressSnapshotForExport(obj) {
    var promises = obj.datasets.map(d => {
      compressDatasetForExport(d);
    });
    await Promise.all(promises);
    return;
  }

  async function compressDatasetForExport(obj) {
    if (!obj.arcs) return;
    var arcData = importArcData(obj.arcs); // convert buffers to typed arrays
    obj.arcs = await exportArcData(arcData, {compact: true}); // re-export to compressed buffers
  }

  function flattenArcs(arcData) {
    if (arcData.zz && arcData.zlimit) {
      // replace unfiltered arc data with flattened arc data
      arcData = filterVertexData(arcData, arcData.zlimit);
      delete arcData.zz;
    }
    return arcData;
  }

  async function gzipArcData(obj, opts) {
    var gzipOpts = Object.assign({level: 1, consume: false}, opts);
    var promises = [gzipAsync(obj.nn, gzipOpts), gzipAsync(obj.xx, gzipOpts), gzipAsync(obj.yy, gzipOpts)];
    if (obj.zz) promises.push(gzipAsync(obj.zz, gzipOpts));
    var results = await Promise.all(promises);
    obj.nn = results.shift();
    obj.xx = results.shift();
    obj.yy = results.shift();
    if (obj.zz) obj.zz = results.shift();
  }

  function importArcData(obj) {
    return {
      nn: new Uint32Array(obj.nn.buffer, 0, obj.nn.length / 4),
      xx: new Float64Array(obj.xx.buffer, 0, obj.xx.length / 8),
      yy: new Float64Array(obj.yy.buffer, 0, obj.yy.length / 8),
      zz: obj.zz ? new Float64Array(obj.zz.buffer, 0, obj.zz.length / 8) : null,
      zlimit: obj.zlimit || 0
    };
  }

  async function exportArcData(data, opts) {
    // TODO: consider removing arcs that are not referenced by any layer
    if (opts.compact && data.zz) {
      data = flattenArcs(data); // bake in any simplification
    }
    var output = {
      nn: typedArrayToBuffer(data.nn),
      xx: typedArrayToBuffer(data.xx),
      yy: typedArrayToBuffer(data.yy),
      zz: data.zz ? typedArrayToBuffer(data.zz) : null,
      zlimit: data.zlimit || 0
    };
    if (opts.compact && data.zz) {
      await gzipArcData(output);
    }
    return output;
  }

  function typedArrayToBuffer(arr) {
    return new Uint8Array(arr.buffer, arr.byteOffset, arr.byteLength);
  }

  async function exportLayer(lyr, opts) {
    var data = null;
    if (lyr.data) {
      data = await exportTable2(lyr.data);
    }
    return {
      name: lyr.name || null,
      geometry_type: lyr.geometry_type || null,
      shapes: lyr.shapes || null,
      data: data,
      menu_order: lyr.menu_order || null,
      pinned: lyr.pinned || false,
      active: !!(lyr.active || lyr == opts.active_layer) // lyr.active: deprecated
    };
  }

  function exportInfo(info) {
    info = Object.assign({}, info);
    if (info.crs && !info.crs_string && !info.prj) {
      info.crs_string = crsToProj4(info.crs);
    }
    delete info.crs; // proj object cannot be serialized (need to reconstitute in unpack)
    return info;
  }

  var Pack = /*#__PURE__*/Object.freeze({
    __proto__: null,
    PACKAGE_EXT: PACKAGE_EXT,
    exportPackedDatasets: exportPackedDatasets,
    pack: pack,
    exportDatasetsToPack: exportDatasetsToPack,
    exportDataset: exportDataset,
    compressSnapshotForExport: compressSnapshotForExport,
    exportInfo: exportInfo
  });

  // Guess the type of a data file from file extension, or return null if not sure
  function guessInputFileType(file) {
    var ext = getFileExtension(file || '').toLowerCase(),
        type = null;
    if (ext == 'dbf' || ext == 'shp' || ext == 'kml') {
      type = ext;
    } else if (isAuxiliaryInputFileType(ext)) {
      type = ext;
    } else if (/json$/.test(ext)) { // matches topojson, geojson, json
      type = 'json';
    } else if (ext == 'csv' || ext == 'tsv' || ext == 'txt' || ext == 'tab') {
      type = 'text';
    } else if (ext == PACKAGE_EXT) {
      type = PACKAGE_EXT;
    }
    return type;
  }

  // File types that can be imported but are not convertible to datasets
  function isAuxiliaryInputFileType(type) {
    return type == 'prj' || type == 'shx' || type == 'cpg';
  }

  function guessInputContentType(content) {
    var type = null;
    if (utils.isString(content)) {
      type = stringLooksLikeJSON(content) && 'json' ||
        stringLooksLikeKML(content) && 'kml' || 'text';
    } else if (utils.isObject(content) && content.type || utils.isArray(content)) {
      type = 'json';
    }
    return type;
  }

  function guessInputType(file, content) {
    return guessInputFileType(file) || guessInputContentType(content);
  }

  function stringLooksLikeJSON(str) {
    return /^\s*[{[]/.test(String(str));
  }

  function stringLooksLikeKML(str) {
    str = String(str);
    return str.includes('<kml ') && str.includes('xmlns="http://www.opengis.net/kml/');
  }

  function couldBeDsvFile(name) {
    var ext = getFileExtension(name).toLowerCase();
    return /csv|tsv|txt$/.test(ext);
  }

  // File looks like an importable file type
  // name: filename or path
  function looksLikeImportableFile(name) {
    return !!guessInputFileType(name) || isImportableAsBinary(name);
  }

  // File looks like a directly readable data file type
  // name: filename or path
  function looksLikeContentFile(name) {
    var type = guessInputFileType(name);
    return !!type && type != 'gz' && type != 'zip';
  }

  function isPackageFile(file) {
    return file.endsWith('.' + PACKAGE_EXT);
  }

  function isZipFile(file) {
    return /\.zip$/i.test(file);
  }

  function isKmzFile(file) {
    return /\.kmz$/i.test(file);
  }

  function isGzipFile(file) {
    return /\.gz$/i.test(file);
  }

  function isSupportedOutputFormat(fmt) {
    var types = ['geojson', 'topojson', 'json', 'dsv', 'dbf', 'shapefile', 'svg', 'kml', PACKAGE_EXT];
    return types.indexOf(fmt) > -1;
  }

  function getFormatName(fmt) {
    return {
      geojson: 'GeoJSON',
      topojson: 'TopoJSON',
      json: 'JSON records',
      dsv: 'CSV',
      dbf: 'DBF',
      kml: 'KML',
      kmz: 'KMZ',
      [PACKAGE_EXT]: 'Snapshot file',
      shapefile: 'Shapefile',
      svg: 'SVG'
    }[fmt] || '';
  }

  // Assumes file at @path is one of Mapshaper's supported file types
  function isSupportedBinaryInputType(path) {
    var ext = getFileExtension(path).toLowerCase();
    return ext == 'shp' || ext == 'shx' || ext == 'dbf' || ext == PACKAGE_EXT; // GUI also supports zip files
  }

  function isImportableAsBinary(path) {
    var type = guessInputFileType(path);
    return isSupportedBinaryInputType(path) || isZipFile(path) ||
      isGzipFile(path) || isKmzFile(path) || isPackageFile(path) ||
      type == 'json' || type == 'text';
  }

  // Detect extensions of some unsupported file types, for cmd line validation
  function filenameIsUnsupportedOutputType(file) {
    var rxp = /\.(shx|prj|xls|xlsx|gdb|sbn|sbx|xml)$/i;
    return rxp.test(file);
  }

  var FileTypes = /*#__PURE__*/Object.freeze({
    __proto__: null,
    guessInputFileType: guessInputFileType,
    isAuxiliaryInputFileType: isAuxiliaryInputFileType,
    guessInputContentType: guessInputContentType,
    guessInputType: guessInputType,
    stringLooksLikeJSON: stringLooksLikeJSON,
    stringLooksLikeKML: stringLooksLikeKML,
    couldBeDsvFile: couldBeDsvFile,
    looksLikeImportableFile: looksLikeImportableFile,
    looksLikeContentFile: looksLikeContentFile,
    isPackageFile: isPackageFile,
    isZipFile: isZipFile,
    isKmzFile: isKmzFile,
    isGzipFile: isGzipFile,
    isSupportedOutputFormat: isSupportedOutputFormat,
    getFormatName: getFormatName,
    isSupportedBinaryInputType: isSupportedBinaryInputType,
    isImportableAsBinary: isImportableAsBinary,
    filenameIsUnsupportedOutputType: filenameIsUnsupportedOutputType
  });

  // input: A file path or a buffer
  function unzipSync(input) {
    if (input instanceof ArrayBuffer) {
      input = new Uint8Array(input);
    }
    if (!runningInBrowser()) {
      return unzipSyncNode(input);
    }
    var obj = unzipSync$1(input, {filter: fflateFilter});
    return fflatePostprocess(obj);
  }

  function unzipAsync(buf, cb) {
    if (!runningInBrowser()) {
      error('Async unzipping only supported in the browser');
    }
    if (buf instanceof ArrayBuffer) {
      buf = new Uint8Array(buf);
    }
    unzip(buf, {filter: fflateFilter}, function(err, data) {
      if (err) cb(err);
      cb(null, fflatePostprocess(data));
    });
  }

  function zipSync(files) {
    if (runningInBrowser()) {
      return zipSync$1(fflatePreprocess(files));
    }
    return zipSyncNode(files);
  }

  function zipAsync(files, cb) {
    zip(fflatePreprocess(files), {}, cb);
  }

  function fflateFilter(file) {
    return isImportableZipPath(file.name);
  }

  function fflatePostprocess(output) {
    return Object.keys(output).reduce(function(memo, path) {
      var file = parseLocalPath(path).filename;
      var content = output[path];
      if (!isImportableAsBinary(file)) {
        content = strFromU8(content);
      }
      memo[file] = content;
      return memo;
    }, {});
  }

  function isImportableZipPath(name) {
    var info = parseLocalPath(name);
    return looksLikeContentFile(name) &&
      !/^__MACOSX/.test(name) && // ignore "resource-fork" files
      info.filename[0] != '.'; // ignore dot files
  }

  // input: input file path or a Buffer containing .zip file bytes
  function unzipSyncNode(input) {
    var zip = new require('adm-zip')(input);
    var index = {};
    zip.getEntries().forEach(function(entry) {
      // entry.entryName // path, including filename
      // entry.name      // filename
      var file = toLowerCaseExtension(entry.name);
      if (isImportableZipPath(file)) {
        index[file] = entry.getData();
      }
    });
    return index;
  }

  function zipSyncNode(files) {
    var zip = new require('adm-zip')();
    files.forEach(function(o) {
      var buf = o.content;
      if (buf instanceof ArrayBuffer) {
        buf = new Uint8Array(buf);
      } else if (!(buf instanceof Buffer || buf instanceof Uint8Array)) {
        buf = Buffer.from(o.content);
      }
      zip.addFile(o.filename, buf);
      // delete o.content; // for gc?
    });
    return zip.toBuffer();
  }

  // Convert array of output file data to input format used by fflate zip
  function fflatePreprocess(files) {
    var obj = {};
    files.forEach(function(file) {
      if (typeof file.content == 'string') {
        file.content = strToU8(file.content);
      } else if (file.content instanceof ArrayBuffer) {
        file.content = new Uint8Array(file.content);
      }
      obj[file.filename] = file.content;
    });
    return obj;
  }

  var Zip = /*#__PURE__*/Object.freeze({
    __proto__: null,
    unzipSync: unzipSync,
    unzipAsync: unzipAsync,
    zipSync: zipSync,
    zipAsync: zipAsync,
    isImportableZipPath: isImportableZipPath
  });

  var cli = {};

  cli.isFile = function(path, cache) {
    if (cache && (path in cache)) return true;
    if (runningInBrowser()) return false;
    var ss = cli.statSync(path);
    return ss && ss.isFile() || false;
  };

  // cli.fileSize = function(path) {
  //   var ss = cli.statSync(path);
  //   return ss && ss.size || 0;
  // };

  cli.isDirectory = function(path) {
    if (runningInBrowser()) return false;
    var ss = cli.statSync(path);
    return ss && ss.isDirectory() || false;
  };

  // @encoding (optional) e.g. 'utf8'
  cli.readFile = function(fname, encoding, cache) {
    var content;
    if (cache && (fname in cache)) {
      content = cache[fname];
      delete cache[fname];
    } else if (fname == '/dev/stdin') {
      content = require$1('rw').readFileSync(fname);
    } else {
      // kludge to prevent overwriting of input files
      (getStashedVar('input_files') || []).push(fname);
      content = require$1('fs').readFileSync(fname);
    }
    if (encoding && B$3.isBuffer(content)) {
      content = trimBOM(decodeString(content, encoding));
    }
    return content;
  };

  cli.createDirIfNeeded = function(fname) {
    var odir = parseLocalPath(fname).directory;
    if (!odir || cli.isDirectory(odir) || fname == '/dev/stdout') return;
    try {
      require$1('fs').mkdirSync(odir, {recursive: true});
      message('Created output directory:', odir);
    } catch(e) {
      stop('Unable to create output directory:', odir);
    }
  };

  // content: Buffer or string
  cli.writeFileSync = function(fname, content) {
    cli.createDirIfNeeded(fname);
    if (utils.isString(content)) {
      require$1('fs').writeFileSync(fname, content);
    } else {
      // as of Node.js v20, on a typical machine, max buffer size is 4gb but the max
      // write buffer size is 2gb. An error is thrown when writing >2gb and <4gb.
      // To support writing files up to 4gb, files are written in chunks.
      cli.writeFileInChunks(fname, content, 1e7);
    }
  };

  cli.writeFileInChunks = function(fname, buffer, chunkSize) {
    var fs = require$1('fs');
    var fd = fs.openSync(fname, 'w');
    var offset = 0;
    var bufLen = buffer.length;
    var bytesWritten, bytesToWrite;
    do {
      bytesToWrite = Math.min(chunkSize, bufLen - offset);
      bytesWritten = fs.writeSync(fd, buffer, offset, bytesToWrite);
      offset += bytesWritten;
    } while (bytesWritten > 0 && offset < bufLen);
    fs.closeSync(fd);
  };

  // Returns Node Buffer
  cli.convertArrayBuffer = function(buf) {
    var src = new Uint8Array(buf),
        dest = utils.createBuffer(src.length);
    for (var i = 0, n=src.length; i < n; i++) {
      dest[i] = src[i];
    }
    return dest;
  };

  // Receives a directory path, in which the final subdirectory may include the
  //   "*" wildcard, e.g. '.' 'data' '*' 'data/*' '2023-*'
  // Returns an array of expanded directory names
  // TODO: add support for wildcards in other subdirectories
  cli.expandDirectoryName = function(name) {
    var info = parseLocalPath(name);
    // final directory name is parsed as info.filename
    if (!info.filename.includes('*')) {
      return [name];
    }
    var rxp = utils.wildcardToRegExp(info.filename);
    var dirs = [];
    require$1('fs').readdirSync(info.directory || '.').forEach(function(item) {
      var path = info.directory ? require$1('path').join(info.directory, item) : item;
      if (rxp.test(item) && cli.isDirectory(path)) {
        dirs.push(path);
      }
    });
    return dirs;
  };

  // Expand any "*" wild cards in file name
  // (For the Windows command line; unix shells do this automatically)
  cli.expandFileName = function(name) {
    var info = parseLocalPath(name),
        rxp = utils.wildcardToRegExp(info.filename),
        dirs = cli.expandDirectoryName(info.directory || '.'),
        files = [];

    try {
      dirs.forEach(function(dir) {
        require$1('fs').readdirSync(dir).forEach(function(item) {
          var path = require$1('path').join(dir, item);
          if (rxp.test(item) && cli.isFile(path)) {
            files.push(path);
          }
        });
      });
    } catch(e) {}

    if (files.length === 0) {
      stop('No files matched (' + name + ')');
    }
    return files;
  };

  // Expand any wildcards.
  cli.expandInputFiles = function(files) {
    return files.reduce(function(memo, name) {
      if (name.indexOf('*') > -1) {
        memo = memo.concat(cli.expandFileName(name));
      } else {
        memo.push(name);
      }
      return memo;
    }, []);
  };

  cli.validateOutputDir = function(name) {
    if (!cli.isDirectory(name) && !runningInBrowser()) {
      error("Output directory not found:", name);
    }
  };

  // TODO: rename and improve
  // Want to test if a path is something readable (e.g. file or stdin)
  cli.checkFileExists = function(path, cache) {
    if (!cli.isFile(path, cache) && path != '/dev/stdin') {
      stop("File not found (" + path + ")");
    }
  };

  cli.statSync = function(fpath) {
    var obj = null;
    try {
      obj = require$1('fs').statSync(fpath);
    } catch(e) {}
    return obj;
  };

  async function writeFiles(exports, opts) {
    return _writeFiles(exports, opts);
  }

  // Used by GUI to replace the CLI version of writeFiles()
  // (so -o can work in the browser console)
  function replaceWriteFiles(func) {
    _writeFiles = func;
  }

  var _writeFiles = function(exports, opts) {
    if (exports.length > 0 === false) {
      message("No files to save");
    } else if (opts.dry_run) ; else if (opts.stdout) {
      // Using async writeFile() function -- synchronous output to stdout can
      // trigger EAGAIN error, e.g. when piped to less.
      require$1('rw').writeFile('/dev/stdout', exports[0].content, function() {});
    } else {
      if (opts.zip) {
        exports = [{
          // TODO: add output subdirectory, if relevant
          filename: opts.zipfile || 'output.zip',
          content: zipSync(exports)
        }];
      }
      var paths = getOutputPaths(utils.pluck(exports, 'filename'), opts);
      var inputFiles = getStashedVar('input_files');
      exports.forEach(function(obj, i) {
        var path = paths[i];
        if (obj.content instanceof ArrayBuffer) {
          // replacing content so ArrayBuffers can be gc'd
          obj.content = cli.convertArrayBuffer(obj.content); // convert to Buffer
        }
        if (opts.output) {
          opts.output.push({filename: path, content: obj.content});
          return;
        }
        if (!opts.force && inputFiles.indexOf(path) > -1) {
          stop('Need to use the "-o force" option to overwrite input files.');
        }
        cli.writeFileSync(path, obj.content);
        message("Wrote " + path);
      });
    }
  };

  function getOutputPaths(files, opts) {
    var odir = opts.directory;
    if (odir) {
      files = files.map(function(file) {
        return require$1('path').join(odir, file);
      });
    }
    return files;
  }

  var FileExport = /*#__PURE__*/Object.freeze({
    __proto__: null,
    writeFiles: writeFiles,
    replaceWriteFiles: replaceWriteFiles,
    getOutputPaths: getOutputPaths
  });

  // Returns a search function
  // Receives array of objects to index; objects must have a 'bounds' member
  //    that is a Bounds object.
  function getBoundsSearchFunction(boxes) {
    var index, Flatbush;
    if (!boxes.length) {
      // Unlike rbush, flatbush doesn't allow size 0 indexes; workaround
      return function() {return [];};
    }
    Flatbush = require$1('flatbush');
    index = new Flatbush(boxes.length);
    boxes.forEach(function(ring) {
      var b = ring.bounds;
      index.add(b.xmin, b.ymin, b.xmax, b.ymax);
    });
    index.finish();

    function idxToObj(i) {
      return boxes[i];
    }

    // Receives xmin, ymin, xmax, ymax parameters
    // Returns subset of original @bounds array
    return function(a, b, c, d) {
      return index.search(a, b, c, d).map(idxToObj);
    };
  }

  // @xx array of x coords
  // @ids an array of segment endpoint ids [a0, b0, a1, b1, ...]
  // Sort @ids in place so that xx[a(n)] <= xx[b(n)] and xx[a(n)] <= xx[a(n+1)]
  function sortSegmentIds(xx, ids) {
    orderSegmentIds(xx, ids);
    quicksortSegmentIds(xx, ids, 0, ids.length-2);
  }

  function orderSegmentIds(xx, ids, spherical) {
    function swap(i, j) {
      var tmp = ids[i];
      ids[i] = ids[j];
      ids[j] = tmp;
    }
    for (var i=0, n=ids.length; i<n; i+=2) {
      if (xx[ids[i]] > xx[ids[i+1]]) {
        swap(i, i+1);
      }
    }
  }

  function insertionSortSegmentIds(arr, ids, start, end) {
    var id, id2;
    for (var j = start + 2; j <= end; j+=2) {
      id = ids[j];
      id2 = ids[j+1];
      for (var i = j - 2; i >= start && arr[id] < arr[ids[i]]; i-=2) {
        ids[i+2] = ids[i];
        ids[i+3] = ids[i+1];
      }
      ids[i+2] = id;
      ids[i+3] = id2;
    }
  }

  function quicksortSegmentIds (a, ids, lo, hi) {
    var i = lo,
        j = hi,
        pivot, tmp;
    while (i < hi) {
      pivot = a[ids[(lo + hi >> 2) << 1]]; // avoid n^2 performance on sorted arrays
      while (i <= j) {
        while (a[ids[i]] < pivot) i+=2;
        while (a[ids[j]] > pivot) j-=2;
        if (i <= j) {
          tmp = ids[i];
          ids[i] = ids[j];
          ids[j] = tmp;
          tmp = ids[i+1];
          ids[i+1] = ids[j+1];
          ids[j+1] = tmp;
          i+=2;
          j-=2;
        }
      }

      if (j - lo < 40) insertionSortSegmentIds(a, ids, lo, j);
      else quicksortSegmentIds(a, ids, lo, j);
      if (hi - i < 40) {
        insertionSortSegmentIds(a, ids, i, hi);
        return;
      }
      lo = i;
      j = hi;
    }
  }

  // PolygonIndex indexes the coordinates in one polygon feature for efficient
  // point-in-polygon tests

  function PolygonIndex(shape, arcs, opts) {
    var data = arcs.getVertexData(),
        polygonBounds = arcs.getMultiShapeBounds(shape),
        boundsLeft,
        xminIds, xmaxIds, // vertex ids of segment endpoints
        bucketCount,
        bucketOffsets,
        bucketWidth;

    init();

    // Return 0 if outside, 1 if inside, -1 if on boundary
    this.pointInPolygon = function(x, y) {
      if (!polygonBounds.containsPoint(x, y)) {
        return false;
      }
      var bucketId = getBucketId(x);
      var count = countCrosses(x, y, bucketId);
      if (bucketId > 0) {
        count += countCrosses(x, y, bucketId - 1);
      }
      count += countCrosses(x, y, bucketCount); // check oflo bucket
      if (isNaN(count)) return -1;
      return count % 2 == 1 ? 1 : 0;
    };

    function countCrosses(x, y, bucketId) {
      var offs = bucketOffsets[bucketId],
          count = 0,
          xx = data.xx,
          yy = data.yy,
          n, a, b;
      if (bucketId == bucketCount) { // oflo bucket
        n = xminIds.length - offs;
      } else {
        n = bucketOffsets[bucketId + 1] - offs;
      }
      for (var i=0; i<n; i++) {
        a = xminIds[i + offs];
        b = xmaxIds[i + offs];
        count += geom.testRayIntersection(x, y, xx[a], yy[a], xx[b], yy[b]);
      }
      return count;
    }

    function getBucketId(x) {
      var i = Math.floor((x - boundsLeft) / bucketWidth);
      if (i < 0) i = 0;
      if (i >= bucketCount) i = bucketCount - 1;
      return i;
    }

    function getBucketCount(segCount) {
      // default is this many segs per bucket (average)
      // var buckets = opts && opts.buckets > 0 ? opts.buckets : segCount / 200;
      // using more segs/bucket for more complex shapes, based on trial and error
      var buckets = Math.pow(segCount, 0.75) / 10;
      return Math.ceil(buckets);
    }

    function init() {
      var xx = data.xx,
          segCount = 0,
          segId = 0,
          bucketId = -1,
          prevBucketId,
          segments,
          head, tail,
          a, b, i, j, xmin, xmax;

      // get array of segments as [s0p0, s0p1, s1p0, s1p1, ...], sorted by xmin coordinate
      forEachSegmentInShape(shape, arcs, function() {
        segCount++;
      });
      segments = new Uint32Array(segCount * 2);
      i = 0;
      forEachSegmentInShape(shape, arcs, function(a, b, xx, yy) {
        segments[i++] = a;
        segments[i++] = b;
      });
      sortSegmentIds(xx, segments);

      // assign segments to buckets according to xmin coordinate
      xminIds = new Uint32Array(segCount);
      xmaxIds = new Uint32Array(segCount);
      bucketCount = getBucketCount(segCount);
      bucketOffsets = new Uint32Array(bucketCount + 1); // add an oflo bucket
      boundsLeft = xx[segments[0]]; // xmin of first segment
      bucketWidth = (xx[segments[segments.length - 2]] - boundsLeft) / bucketCount;
      head = 0; // insertion index for next segment in the current bucket
      tail = segCount - 1; // insertion index for next segment in oflo bucket

      while (segId < segCount) {
        j = segId * 2;
        a = segments[j];
        b = segments[j+1];
        xmin = xx[a];
        xmax = xx[b];
        prevBucketId = bucketId;
        bucketId = getBucketId(xmin);

        while (bucketId > prevBucketId) {
          prevBucketId++;
          bucketOffsets[prevBucketId] = head;
        }

        if (xmax - xmin >= 0 === false) error("Invalid segment");
        if (getBucketId(xmax) - bucketId > 1) {
          // if segment extends to more than two buckets, put it in the oflo bucket
          xminIds[tail] = a;
          xmaxIds[tail] = b;
          tail--; // oflo bucket fills from right to left
        } else {
          // else place segment in a bucket based on x coord of leftmost endpoint
          xminIds[head] = a;
          xmaxIds[head] = b;
          head++;
        }
        segId++;
      }
      bucketOffsets[bucketCount] = head;
      if (head != tail + 1) error("Segment indexing error");
    }
  }

  // PathIndex supports several kinds of spatial query on a layer of polyline or polygon shapes
  function PathIndex(shapes, arcs) {
    var boundsQuery = getBoundsSearchFunction(getRingData(shapes, arcs));
    var totalArea = getPathBounds(shapes, arcs).area();

    function getRingData(shapes, arcs) {
      var arr = [];
      shapes.forEach(function(shp, shpId) {
        var n = shp ? shp.length : 0;
        for (var i=0; i<n; i++) {
          arr.push({
            ids: shp[i],
            id: shpId,
            bounds: arcs.getSimpleShapeBounds(shp[i])
          });
        }
      });
      return arr;
    }

    // Returns shape ids of all polygons that intersect point p
    // (p is inside a ring or on the boundary)
    this.findEnclosingShapes = function(p) {
      var ids = [];
      var cands = findPointHitCandidates(p);
      var groups = groupItemsByShapeId(cands);
      groups.forEach(function(group) {
        if (testPointInRings(p, group)) {
          ids.push(group[0].id);
        }
      });
      return ids;
    };

    // Returns shape id of a polygon that intersects p or -1
    // (If multiple intersections, returns one of the polygons)
    this.findEnclosingShape = function(p) {
      var shpId = -1;
      var groups = groupItemsByShapeId(findPointHitCandidates(p));
      groups.forEach(function(group) {
        if (testPointInRings(p, group)) {
          shpId = group[0].id;
        }
      });
      return shpId;
    };

    // Returns shape ids of polygons that contain an arc
    // (arcs that are )
    // Assumes that input arc is either inside, outside or coterminous with indexed
    // arcs (i.e. input arc does not cross an indexed arc)
    this.findShapesEnclosingArc = function(arcId) {
      var p = getTestPoint([arcId]);
      return this.findEnclosingShapes(p);
    };

    this.findPointEnclosureCandidates = function(p, buffer) {
      var items = findPointHitCandidates(p, buffer);
      return utils.pluck(items, 'id');
    };

    this.pointIsEnclosed = function(p) {
      return testPointInRings(p, findPointHitCandidates(p));
    };

    // Finds the polygon containing the smallest ring that entirely contains @ring
    // Assumes ring boundaries do not cross.
    // Unhandled edge case:
    //   two rings share at least one segment but are not congruent.
    // @ring: array of arc ids
    // Returns id of enclosing polygon or -1 if none found
    this.findSmallestEnclosingPolygon = function(ring) {
      var bounds = arcs.getSimpleShapeBounds(ring);
      var p = getTestPoint(ring);
      var smallest;
      var cands = findPointHitCandidates(p);
      cands.forEach(function(cand) {
        if (cand.bounds.contains(bounds) && // skip partially intersecting bboxes (can't be enclosures)
          !cand.bounds.sameBounds(bounds) && // skip self, congruent and reversed-congruent rings
          !(smallest && smallest.bounds.area() < cand.bounds.area())) {
              if (testPointInRing(p, cand)) {
                smallest = cand;
              }
            }
      });

      return smallest ? smallest.id : -1;
    };

    this.arcIsEnclosed = function(arcId) {
      return this.pointIsEnclosed(getTestPoint([arcId]));
    };

    // Test if a polygon ring is contained within an indexed ring
    // Not a true polygon-in-polygon test
    // Assumes that the target ring does not cross an indexed ring at any point
    // or share a segment with an indexed ring. (Intersecting rings should have
    // been detected previously).
    //
    this.pathIsEnclosed = function(pathIds) {
      return this.pointIsEnclosed(getTestPoint(pathIds));
    };

    // return array of paths that are contained within a path, or null if none
    // @pathIds Array of arc ids comprising a closed path
    this.findEnclosedPaths = function(pathIds) {
      var b = arcs.getSimpleShapeBounds(pathIds),
          cands = boundsQuery(b.xmin, b.ymin, b.xmax, b.ymax),
          paths = [],
          index;

      if (cands.length > 6) {
        index = new PolygonIndex([pathIds], arcs);
      }
      cands.forEach(function(cand) {
        var p = getTestPoint(cand.ids);
        var isEnclosed = b.containsPoint(p[0], p[1]) &&
          // added a bounds-in-bounds test to handle a case where the test point
          // fell along the shared boundary of two rings, but the rings did no overlap
          // (this gave a false positive for the enclosure test)
          // (for speed, the midpoint of an arc is used as the test point; this
          // works well in the typical case where rings to not share an edge.
          // Finding an internal test point would be better, we just need a fast
          // function to find internal points)
          b.contains(cand.bounds) &&
          (index ? index.pointInPolygon(p[0], p[1]) : geom.testPointInRing(p[0], p[1], pathIds, arcs));
        if (isEnclosed) {
          paths.push(cand.ids);
        }
      });
      return paths.length > 0 ? paths : null;
    };

    // return array of indexed paths within a given shape
    this.findPathsInsideShape = function(shape) {
      var paths = []; // list of enclosed paths
      shape.forEach(function(ids) {
        var enclosed = this.findEnclosedPaths(ids);
        if (enclosed) {
          // any paths that are enclosed by an even number of rings are removed from list
          // (given normal topology, such paths are inside holes)
          paths = xorArrays(paths, enclosed);
        }
      }, this);
      return paths.length > 0 ? paths : null;
    };

    function testPointInRing(p, cand) {
      if (!cand.bounds.containsPoint(p[0], p[1])) return false;
      if (!cand.index && cand.bounds.area() > totalArea * 0.01) {
        // index larger polygons (because they are slower to test via pointInRing()
        //    and they are more likely to be involved in repeated hit tests).
        cand.index = new PolygonIndex([cand.ids], arcs);
      }
      return cand.index ?
          cand.index.pointInPolygon(p[0], p[1]) :
          geom.testPointInRing(p[0], p[1], cand.ids, arcs);
    }

    //
    function testPointInRings(p, cands) {
      var isOn = false,
          isIn = false;
      cands.forEach(function(cand) {
        var inRing = testPointInRing(p, cand);
        if (inRing == -1) {
          isOn = true;
        } else if (inRing == 1) {
          isIn = !isIn;
        }
      });
      return isOn || isIn;
    }

    function groupItemsByShapeId(items) {
      var groups = [],
          group, item;
      if (items.length > 0) {
        items.sort(function(a, b) {return a.id - b.id;});
        for (var i=0; i<items.length; i++) {
          item = items[i];
          if (i === 0 || item.id != items[i-1].id) {
            groups.push(group=[]);
          }
          group.push(item);
        }
      }
      return groups;
    }

    function findPointHitCandidates(p, buffer) {
      var b = buffer > 0 ? buffer : 0;
      p[0]; p[1];
      return boundsQuery(p[0] - b, p[1] - b, p[0] + b, p[1] + b);
    }

    // Find a point on a ring to use for point-in-polygon testing
    function getTestPoint(ring) {
      // Use the point halfway along first segment rather than an endpoint
      // (because ring might still be enclosed if a segment endpoint touches an indexed ring.)
      // The returned point should work for point-in-polygon testing if two rings do not
      // share any common segments (which should be true for topological datasets)
      // TODO: consider alternative of finding an internal point of @ring (slower but
      //   potentially more reliable).
      var arcId = ring[0],
          p0 = arcs.getVertex(arcId, 0),
          p1 = arcs.getVertex(arcId, 1);
      return [(p0.x + p1.x) / 2, (p0.y + p1.y) / 2];
    }

    // concatenate arrays, removing elements that are in both
    function xorArrays(a, b) {
      var xor = [], i;
      for (i=0; i<a.length; i++) {
        if (b.indexOf(a[i]) == -1) xor.push(a[i]);
      }
      for (i=0; i<b.length; i++) {
        if (a.indexOf(b[i]) == -1) xor.push(b[i]);
      }
      return xor;
    }
  }

  // Delete rings that are nested directly inside an enclosing ring with the same winding direction
  // Does not remove unenclosed CCW rings (currently this causes problems when
  //   rounding coordinates for SVG and TopoJSON output)
  // Assumes ring boundaries do not overlap (should be true after e.g. dissolving)
  //
  function fixNestingErrors(rings, arcs) {
    if (rings.length <= 1) return rings;
    var ringData = getPathMetadata(rings, arcs, 'polygon');
    // convert rings to shapes for PathIndex
    var shapes = rings.map(function(ids) {return [ids];});
    var index = new PathIndex(shapes, arcs);
    return rings.filter(ringIsValid);

    function ringIsValid(ids, i) {
      var containerId = index.findSmallestEnclosingPolygon(ids);
      var ringIsCW, containerIsCW;
      var valid = true;
      if (containerId > -1) {
        ringIsCW = ringData[i].area > 0;
        containerIsCW = ringData[containerId].area > 0;
        if (containerIsCW == ringIsCW) {
          // reject rings with same chirality as their containing ring
          valid = false;
        }
      }
      return valid;
    }
  }

  // Set winding order of polygon rings so that outer rings are CW, first-order
  // nested rings are CCW, etc.
  function rewindPolygons(lyr, arcs) {
    lyr.shapes = lyr.shapes.map(function(shp) {
      if (!shp) return null;
      return rewindPolygon(shp, arcs);
    });
  }

  // Update winding order of rings in a polygon so that outermost rings are
  // CW and nested rings alternate between CCW and CW.
  function rewindPolygon(rings, arcs) {
    var ringData = getPathMetadata(rings, arcs, 'polygon');

    // Sort rings by area, from large to small
    ringData.sort(function(a, b) {
      return Math.abs(b.area) - Math.abs(a.area);
    });
    // If a ring is contained by one or more rings, set it to the opposite
    //   direction as its immediate parent
    // If a ring is not contained, make it CW.
    ringData.forEach(function(ring, i) {
      var shouldBeCW = true;
      var j = i;
      var largerRing;
      while (--j >= 0) {
        largerRing = ringData[j];
        if (testRingInRing(ring, largerRing, arcs)) {
          // set to opposite of containing ring
          shouldBeCW = largerRing.area > 0 ? false : true;
          break;
        }
      }
      setRingWinding(ring, shouldBeCW);
    });
    return ringData.map(function(data) { return data.ids; });
  }

  // data: a ring data object
  function setRingWinding(data, cw) {
    var isCW = data.area > 0;
    if (isCW != cw) {
      data.area = -data.area;
      reversePath(data.ids);
    }
  }

  // a, b: two ring data objects (from getPathMetadata);
  function testRingInRing(a, b, arcs) {
    if (b.bounds.contains(a.bounds) === false) return false;
    // Don't test with first point -- this may return false if a hole intersects
    // the containing ring at the first vertex.
    // Instead, use the midpoint of the first segment
    var p = getFirstMidpoint(a.ids[0], arcs);
    //// test with first point in the ring
    // var p = arcs.getVertex(a.ids[0], 0);
    return geom.testPointInRing(p.x, p.y, b.ids, arcs) == 1;
  }

  function getFirstMidpoint(arcId, arcs) {
    var p1 = arcs.getVertex(arcId, 0);
    var p2 = arcs.getVertex(arcId, 1);
    return {
      x: (p1.x + p2.x) / 2,
      y: (p1.y + p2.y) / 2
    };
  }

  // Bundle holes with their containing rings for Topo/GeoJSON polygon export.
  // Assumes outer rings are CW and inner (hole) rings are CCW, unless
  //   the reverseWinding flag is set.
  // @paths array of objects with path metadata -- see internal.exportPathData()
  //
  function groupPolygonRings(paths, arcs, reverseWinding) {
    var holes = [],
        groups = [],
        sign = reverseWinding ? -1 : 1,
        boundsQuery;

    (paths || []).forEach(function(path) {
      if (path.area * sign > 0) {
        groups.push([path]);
      } else if (path.area * sign < 0) {
        holes.push(path);
      } else ;
    });

    if (holes.length === 0) {
      return groups;
    }

    // Using a spatial index to improve performance when the current feature
    // contains many holes and space-filling rings.
    // (Thanks to @simonepri for providing an example implementation in PR #248)
    boundsQuery = getBoundsSearchFunction(groups.map(function(group, i) {
      return {
        bounds: group[0].bounds,
        idx: i
      };
    }));

    // Group each hole with its containing ring
    holes.forEach(function(hole) {
      var containerId = -1,
          containerArea = 0,
          holeArea = hole.area * -sign,
          b = hole.bounds,
          // Find rings that might contain this hole
          candidates = boundsQuery(b.xmin, b.ymin, b.xmax, b.ymax),
          ring, ringId, ringArea, isContained;

      // Group this hole with the smallest-area ring that contains it.
      // (Assumes that if a ring's bbox contains a hole, then the ring also
      //  contains the hole).
      for (var i=0, n=candidates.length; i<n; i++) {
        ringId = candidates[i].idx;
        ring = groups[ringId][0];
        ringArea = ring.area * sign;
        isContained = ring.bounds.contains(hole.bounds) && ringArea > holeArea;
        if (isContained && candidates.length > 1 && !testRingInRing(hole, ring, arcs)) {
          // Using a more precise ring-in-ring test in the unusual case that
          // this hole is contained within the bounding box of multiple rings.
          // TODO: consider doing a ring-in-ring test even when there is only one
          // candidate ring, based on bbox-in-bbox test (this may affect performance
          // with some datasets).
          continue;
        }
        if (isContained && (containerArea === 0 || ringArea < containerArea)) {
          containerArea = ringArea;
          containerId = ringId;
        }
      }
      if (containerId == -1) {
        debug("[groupPolygonRings()] polygon hole is missing a containing ring, dropping.");
      } else {
        groups[containerId].push(hole);
      }
    });

    return groups;
  }

  function exportPointData(points) {
    var data, path;
    if (!points || points.length === 0) {
      data = {partCount: 0, pointCount: 0};
    } else {
      path = {
        points: points,
        pointCount: points.length,
        bounds: geom.getPathBounds(points)
      };
      data = {
        bounds: path.bounds,
        pathData: [path],
        partCount: 1,
        pointCount: path.pointCount
      };
    }
    return data;
  }

  // TODO: remove duplication with internal.getPathMetadata()
  function exportPathData(shape, arcs, type) {
    // kludge until Shapefile exporting is refactored
    if (type == 'point') return exportPointData(shape);

    var pointCount = 0,
        bounds = new Bounds(),
        paths = [];

    if (shape && (type == 'polyline' || type == 'polygon')) {
      shape.forEach(function(arcIds, i) {
        var iter = arcs.getShapeIter(arcIds),
            path = exportPathCoords(iter),
            valid = true;
        path.ids = arcIds;
        if (type == 'polygon') {
          path.area = geom.getPlanarPathArea2(path.points);
          valid = path.pointCount > 3 && path.area !== 0;
        } else if (type == 'polyline') {
          valid = path.pointCount > 1;
        }
        if (valid) {
          pointCount += path.pointCount;
          path.bounds = geom.getPathBounds(path.points);
          bounds.mergeBounds(path.bounds);
          paths.push(path);
        } else {
          verbose("Skipping a collapsed", type, "path");
        }
      });
    }

    return {
      pointCount: pointCount,
      pathData: paths,
      pathCount: paths.length,
      bounds: bounds
    };
  }

  function exportPathCoords(iter) {
    var points = [],
        i = 0,
        x, y, prevX, prevY;
    while (iter.hasNext()) {
      x = iter.x;
      y = iter.y;
      if (i === 0 || prevX != x || prevY != y) {
        points.push([x, y]);
        i++;
      }
      prevX = x;
      prevY = y;
    }
    return {
      points: points,
      pointCount: points.length
    };
  }

  var PathExport = /*#__PURE__*/Object.freeze({
    __proto__: null,
    exportPointData: exportPointData,
    exportPathData: exportPathData
  });

  function stringifyAsNDJSON(o) {
    var str = JSON.stringify(o);
    return str.replace(/\n/g, '\n').replace(/\r/g, '\r');
  }

  function getFormattedStringify(numArrayKeys) {
    var keyIndex = utils.arrayToIndex(numArrayKeys);
    var sentinel = '\u1000\u2FD5\u0310';
    var stripRxp = new RegExp('"' + sentinel + '|' + sentinel + '"', 'g');
    var indentChars = '  ';

    function replace(key, val) {
      // We want to format numerical arrays like [1, 2, 3] instead of
      // the way JSON.stringify() behaves when applying indentation.
      // This kludge converts arrays to strings with sentinel strings inside the
      // surrounding quotes. At the end, the sentinel strings and quotes
      // are replaced by array brackets.
      if (key in keyIndex && utils.isArray(val)) {
        var str = JSON.stringify(val);
        // make sure the array does not contain any strings
        if (str.indexOf('"' == -1)) {
          return sentinel + str.replace(/,/g, ', ') + sentinel;
        }
      }
      return val;
    }

    return function(obj) {
      var json = JSON.stringify(obj, replace, indentChars);
      return json.replace(stripRxp, '');
    };
  }

  var Stringify = /*#__PURE__*/Object.freeze({
    __proto__: null,
    stringifyAsNDJSON: stringifyAsNDJSON,
    getFormattedStringify: getFormattedStringify
  });

  function isValidArc(arcId, arcs) {
    // check for arcs with no vertices
    // TODO: also check for other kinds of degenerate arcs
    // (e.g. collapsed arcs consisting of identical points)
    return arcs.getArcLength(arcId) > 1;
  }

  // Return id of rightmost connected arc in relation to @fromArcId
  // Return @fromArcId if no arcs can be found
  function getRightmostArc(fromArcId, nodes, filter) {
    var arcs = nodes.arcs,
        coords = arcs.getVertexData(),
        xx = coords.xx,
        yy = coords.yy,
        ids = nodes.getConnectedArcs(fromArcId),
        toArcId = fromArcId; // initialize to fromArcId -- an error condition
    if (filter) {
      ids = ids.filter(filter);
    }

    if (!isValidArc(fromArcId, arcs) || ids.length === 0) {
      return fromArcId;
    }

    var inode = arcs.indexOfVertex(fromArcId, -1),
        nodeX = xx[inode],
        nodeY = yy[inode],
        ifrom = arcs.indexOfVertex(fromArcId, -2),
        fromX = xx[ifrom],
        fromY = yy[ifrom],
        ito, candId, icand, code, j;

    /*if (x == ax && y == ay) {
      error("Duplicate point error");
    }*/


    for (j=0; j<ids.length; j++) {
      candId = ids[j];
      if (!isValidArc(candId, arcs)) {
        // skip empty arcs
        continue;
      }
      icand = arcs.indexOfVertex(candId, -2);
      if (toArcId == fromArcId) {
        // first valid candidate
        ito = icand;
        toArcId = candId;
        continue;
      }
      code = chooseRighthandPath(fromX, fromY, nodeX, nodeY, xx[ito], yy[ito], xx[icand], yy[icand]);
      if (code == 2) {
        ito = icand;
        toArcId = candId;
      }
    }


    if (toArcId == fromArcId) {
      // This shouldn't occur, assuming that other arcs are present
      error("Pathfinder error");
    }
    return toArcId;
  }

  // TODO: consider using simpler internal.chooseRighthandPath2()
  // Returns 1 if node->a, return 2 if node->b, else return 0
  // TODO: better handling of identical angles (better -- avoid creating them)
  function chooseRighthandPath(fromX, fromY, nodeX, nodeY, ax, ay, bx, by) {
    var angleA = geom.signedAngle(fromX, fromY, nodeX, nodeY, ax, ay);
    var angleB = geom.signedAngle(fromX, fromY, nodeX, nodeY, bx, by);
    var code;
    if (angleA <= 0 || angleB <= 0) {
      debug("[chooseRighthandPath()] 0 angle(s):", angleA, angleB);
      if (angleA <= 0) {
        debug('  A orient2D:', geom.orient2D(fromX, fromY, nodeX, nodeY, ax, ay));
      }
      if (angleB <= 0) {
        debug('  B orient2D:', geom.orient2D(fromX, fromY, nodeX, nodeY, bx, by));
      }
      // TODO: test against "from" segment
      if (angleA > 0) {
        code = 1;
      } else if (angleB > 0) {
        code = 2;
      } else {
        code = 0;
      }
    } else if (angleA < angleB) {
      code = 1;
    } else if (angleB < angleA) {
      code = 2;
    } else if (isNaN(angleA) || isNaN(angleB)) {
      // probably a duplicate point, which should not occur
      error('Invalid node geometry');
    } else {
      // Equal angles: use fallback test that is less sensitive to rounding error
      code = chooseRighthandVector(ax - nodeX, ay - nodeY, bx - nodeX, by - nodeY);
      debug('[chooseRighthandPath()] equal angles:', angleA, 'fallback test:', code);
    }
    return code;
  }

  function chooseRighthandVector(ax, ay, bx, by) {
    var orient = geom.orient2D(ax, ay, 0, 0, bx, by);
    var code;
    if (orient > 0) {
      code = 2;
    } else if (orient < 0) {
      code = 1;
    } else {
      code = 0;
    }
    return code;
  }

  var PathfinderUtils = /*#__PURE__*/Object.freeze({
    __proto__: null,
    getRightmostArc: getRightmostArc,
    chooseRighthandVector: chooseRighthandVector
  });

  var FWD_USED = 0x8;
  var REV_USED = 0x80;

  function setBits(bits, arcBits, mask) {
    return (bits & ~mask) | (arcBits & mask);
  }

  function andBits(bits, arcBits, mask) {
    return bits & (~mask | arcBits);
  }

  function setRouteBits(arcBits, arcId, routesArr) {
    var idx = absArcId(arcId), // get index of path in
        mask;
    if (idx == arcId) { // arcBits controls fwd path
      mask = ~3; // target fwd bits
    } else { // arcBits controls rev. path
      mask = ~0x30; // target rev bits
      arcBits = arcBits << 4; // shift code to target rev path
    }
    routesArr[idx] &= (arcBits | mask);
  }

  function getRouteBits(arcId, routesArr) {
    var idx = absArcId(arcId),
        bits = routesArr[idx];
    if (idx != arcId) bits = bits >> 4;
    return bits & 7;
  }

  function markPathsAsUsed(paths, routesArr) {
    forEachArcId(paths, function(arcId) {
      if (arcId < 0) {
        routesArr[~arcId] |= REV_USED;
      } else {
        routesArr[arcId] |= FWD_USED;
      }
    });
  }

  // Open arc pathways in a single shape or array of shapes
  //
  function openArcRoutes(paths, arcColl, routesArr, fwd, rev, dissolve, orBits) {
    forEachArcId(paths, function(arcId) {
      var isInv = arcId < 0,
          idx = isInv ? ~arcId : arcId,
          currBits = routesArr[idx],
          openFwd = isInv ? rev : fwd,
          openRev = isInv ? fwd : rev,
          newBits = currBits;

      // error condition: lollipop arcs can cause problems; ignore these
      if (arcColl.arcIsLollipop(arcId)) {
        debug('lollipop');
        newBits = 0; // unset (i.e. make invisible)
      } else {
        if (openFwd) {
          newBits |= 3; // set fwd path to visible and open
        }
        if (openRev) {
          newBits |= 0x30; // set rev. path to visible and open
        }

        // placing this in front of dissolve - dissolve has to be able to hide
        // pathways that are made visible by orBits
        if (orBits > 0) {
          newBits |= orBits;
        }

        // dissolve hides arcs that have both fw and rev pathways open
        // (these arcs represent shared borders and will not be part of the dissolved path)
        //
        if (dissolve && (newBits & 0x22) === 0x22) {
          newBits &= ~0x11; // make invisible
        }
      }

      routesArr[idx] = newBits;
    });
  }

  function closeArcRoutes(arcIds, arcs, routesArr, fwd, rev, hide) {
    forEachArcId(arcIds, function(arcId) {
      var isInv = arcId < 0,
          idx = isInv ? ~arcId : arcId,
          currBits = routesArr[idx],
          mask = 0xff,
          closeFwd = isInv ? rev : fwd,
          closeRev = isInv ? fwd : rev;

      if (closeFwd) {
        if (hide) mask &= ~1;
        mask ^= 0x2;
      }
      if (closeRev) {
        if (hide) mask &= ~0x10;
        mask ^= 0x20;
      }
      routesArr[idx] = currBits & mask;
    });
  }

  // Return a function for generating a path across a graph of connected arcs
  // useRoute: function(arcId) {}
  //           Tries to extend path to the given arc
  //           Returns true and extends path by one arc on success
  //           Returns false and rejects the entire path on failure
  // routeIsUsable (optional): function(arcId) {}
  //           An optional filter function; pathfinder ignores the given arc if
  //           this function returns false;
  // TODO: add option to use spherical geometry for lat-lng coords
  //
  function getPathFinder(nodes, useRoute, routeIsUsable) {
    var testArc = null;
    if (routeIsUsable) {
      testArc = function(arcId) {
        return routeIsUsable(~arcId); // outward path must be traversable
      };
    }

    function getNextArc(prevId) {
      // reverse arc to point onwards
      return ~getRightmostArc(prevId, nodes, testArc);
    }

    function isEmptyArc(id) {
      return nodes.arcs.getArcLength(id) > 1 === false;
    }

    return function(startId) {
      var path = [],
          nextId, candId = startId;

      if (isEmptyArc(startId)) {
        return null;
      }

      do {
        if (useRoute(candId)) {
          path.push(candId);
          nextId = candId;
          candId = getNextArc(nextId);
        } else {
          return null;
        }

        if (candId == ~nextId) {
          // TODO: handle or prevent this error condition
          debug("Pathfinder warning: dead-end path");
          return null;
        }
      } while (candId != startId);
      return path.length === 0 ? null : path;
    };
  }

  // Returns a function for flattening or dissolving a collection of rings
  // Assumes rings are oriented in CW direction
  //
  function getRingIntersector(nodes, flagsArr) {
    var arcs = nodes.arcs;
    var findPath = getPathFinder(nodes, useRoute, routeIsActive);
    flagsArr = flagsArr || new Uint8Array(arcs.size());

    // types: "dissolve" "flatten"
    return function(rings, type) {
      var dissolve = type == 'dissolve',
          openFwd = true,
          openRev = type == 'flatten',
          output;
      // even single rings get transformed (e.g. to remove spikes)
      if (rings.length > 0) {
        output = [];
        openArcRoutes(rings, arcs, flagsArr, openFwd, openRev, dissolve);
        forEachShapePart(rings, function(ids) {
          var path;
          for (var i=0, n=ids.length; i<n; i++) {
            path = findPath(ids[i]);
            if (path) {
              output.push(path);
            }
          }
        });
        closeArcRoutes(rings, arcs, flagsArr, openFwd, openRev, true);
      } else {
        output = rings;
      }
      return output;
    };

    function routeIsActive(arcId) {
      var bits = getRouteBits(arcId, flagsArr);
      return (bits & 1) == 1;
    }

    function useRoute(arcId) {
      var route = getRouteBits(arcId, flagsArr),
          isOpen = false;
      if (route == 3) {
        isOpen = true;
        setRouteBits(1, arcId, flagsArr); // close the path, leave visible
      }
      return isOpen;
    }
  }

  // function debugFlags(flags) {
  //   var arr = [];
  //   utils.forEach(flags, function(flag) {
  //     arr.push(bitsToString(flag));
  //   });
  //   message(arr);

  //   function bitsToString(bits) {
  //     var str = "";
  //     for (var i=0; i<8; i++) {
  //       str += (bits & (1 << i)) > 0 ? "1" : "0";
  //       if (i < 7) str += ' ';
  //       if (i == 3) str += ' ';
  //     }
  //     return str;
  //   }
  // }

  var Pathfinder = /*#__PURE__*/Object.freeze({
    __proto__: null,
    setBits: setBits,
    andBits: andBits,
    setRouteBits: setRouteBits,
    getRouteBits: getRouteBits,
    markPathsAsUsed: markPathsAsUsed,
    openArcRoutes: openArcRoutes,
    closeArcRoutes: closeArcRoutes,
    getPathFinder: getPathFinder,
    getRingIntersector: getRingIntersector
  });

  // Keep track of whether positive or negative integer ids are 'used' or not.


  function SimpleIdTestIndex(n) {
    var index = new Uint8Array(n);
    this.setId = function(id) {
      index[id] = 1;
    };
    this.hasId = function(id) {
      return index[id] === 1;
    };
  }

  function IdTestIndex(n) {
    var index = new Uint8Array(n);
    var setList = [];

    this.setId = function(id) {
      if (!this.hasId(id)) {
        setList.push(id);
      }
      if (id < 0) {
        index[~id] |= 2;
      } else {
        index[id] |= 1;
      }
    };

    this.clear = function() {
      var index = this;
      setList.forEach(function(id) {
        index.clearId(id);
      });
      setList = [];
    };

    this.hasId = function(id) {
      return id < 0 ? (index[~id] & 2) == 2 : (index[id] & 1) == 1;
    };

    // clear a signed id
    this.clearId = function(id) {
      if (id < 0) {
        index[~id] &= 1; // clear reverse arc, preserve fwd arc
      } else {
        index[id] &= 2; // clear fwd arc, preserve rev arc
      }
    };

    this.getIds = function() {
      return setList;
    };

    this.setIds = function(ids) {
      for (var i=0; i<ids.length; i++) {
        this.setId(ids[i]);
      }
    };
  }

  function getIntersectionPoints(intersections) {
    return intersections.map(function(obj) {
          return [obj.x, obj.y];
        });
  }

  function getIntersectionLayer(intersections, lyr, arcs) {
    // return {geometry_type: 'point', shapes: [getIntersectionPoints(XX)]};
    var ii = arcs.getVertexData().ii;
    var index = new SimpleIdTestIndex(arcs.size());
    forEachArcId(lyr.shapes, arcId => {
      index.setId(absArcId(arcId));
    });
    var points = [];
    intersections.forEach(obj => {
      var arc1 = findArcIdFromVertexId(obj.a[0], ii);
      var arc2 = findArcIdFromVertexId(obj.b[0], ii);
      if (index.hasId(arc1) && index.hasId(arc2)) {
        points.push([obj.x, obj.y]);
      }
    });
    return {geometry_type: 'point', shapes: [points]};
  }

  // Identify intersecting segments in an ArcCollection
  //
  // To find all intersections:
  // 1. Assign each segment to one or more horizontal stripes/bins
  // 2. Find intersections inside each stripe
  // 3. Concat and dedup
  //
  // Re-use buffer for temp data -- Chrome's gc starts bogging down
  // if large buffers are repeatedly created.
  var buf;
  function getUint32Array(count) {
    var bytes = count * 4;
    if (!buf || buf.byteLength < bytes) {
      buf = new ArrayBuffer(bytes);
    }
    return new Uint32Array(buf, 0, count);
  }

  function findSegmentIntersections(arcs, optArg) {
    var opts = utils.extend({}, optArg),
        bounds = arcs.getBounds();
        // TODO: handle spherical bounds
        !arcs.isPlanar() &&
            geom.containsBounds(getWorldBounds(), bounds.toArray());
        var ymin = bounds.ymin,
        yrange = bounds.ymax - ymin,
        stripeCount = opts.stripes || calcSegmentIntersectionStripeCount(arcs),
        stripeSizes = new Uint32Array(stripeCount),
        stripeId = stripeCount > 1 && yrange > 0 ? multiStripeId : singleStripeId,
        i, j;

    if (opts.tolerance >= 0 === false) {
      // by default, use a small tolerance when detecting segment intersections
      // (intended to overcome the effects of floating point rounding errors in geometrical formulas)
      opts.tolerance = getHighPrecisionSnapInterval(bounds.toArray());
    }

    function multiStripeId(y) {
      return Math.floor((stripeCount-1) * (y - ymin) / yrange);
    }

    function singleStripeId(y) {return 0;}
    // Count segments in each stripe
    arcs.forEachSegment(function(id1, id2, xx, yy) {
      var s1 = stripeId(yy[id1]),
          s2 = stripeId(yy[id2]);
      while (true) {
        stripeSizes[s1] = stripeSizes[s1] + 2;
        if (s1 == s2) break;
        s1 += s2 > s1 ? 1 : -1;
      }
    });

    // Allocate arrays for segments in each stripe
    var stripeData = getUint32Array(utils.sum(stripeSizes)),
        offs = 0;
    var stripes = [];
    utils.forEach(stripeSizes, function(stripeSize) {
      var start = offs;
      offs += stripeSize;
      stripes.push(stripeData.subarray(start, offs));
    });
    // Assign segment ids to each stripe
    utils.initializeArray(stripeSizes, 0);

    arcs.forEachSegment(function(id1, id2, xx, yy) {
      var s1 = stripeId(yy[id1]),
          s2 = stripeId(yy[id2]),
          count, stripe;
      while (true) {
        count = stripeSizes[s1];
        stripeSizes[s1] = count + 2;
        stripe = stripes[s1];
        stripe[count] = id1;
        stripe[count+1] = id2;
        if (s1 == s2) break;
        s1 += s2 > s1 ? 1 : -1;
      }
    });

    // Detect intersections among segments in each stripe.
    var raw = arcs.getVertexData(),
        intersections = [],
        arr;
    for (i=0; i<stripeCount; i++) {
      arr = intersectSegments(stripes[i], raw.xx, raw.yy, opts);
      for (j=0; j<arr.length; j++) {
        intersections.push(arr[j]);
      }
    }
    return dedupIntersections(intersections, opts.unique ? getUniqueIntersectionKey : null);
  }


  function sortIntersections(arr) {
    arr.sort(function(a, b) {
      return a.x - b.x || a.y - b.y;
    });
  }



  function dedupIntersections(arr, keyFunction) {
    var index = {};
    var getKey = keyFunction || getIntersectionKey;
    return arr.filter(function(o) {
      var key = getKey(o);
      if (key in index) {
        return false;
      }
      index[key] = true;
      return true;
    });
  }

  // Get an indexable key from an intersection object
  // Assumes that vertex ids of o.a and o.b are sorted
  function getIntersectionKey(o) {
    return o.a.join(',') + ';' + o.b.join(',');
  }

  function getUniqueIntersectionKey(o) {
    return o.x + ',' + o.y;
  }

  // Fast method
  // TODO: measure performance using a range of input data
  function calcSegmentIntersectionStripeCount2(arcs) {
    var segs = arcs.getFilteredPointCount() - arcs.size();
    var stripes = Math.pow(segs, 0.4) * 2;
    return Math.ceil(stripes) || 1;
  }

  // Alternate fast method
  function calcSegmentIntersectionStripeCount(arcs) {
    var segs = arcs.getFilteredPointCount() - arcs.size();
    var stripes = Math.ceil(Math.pow(segs * 10, 0.6) / 40);
    return stripes > 0 ? stripes : 1;
  }

  // Find intersections among a group of line segments
  //
  // TODO: handle case where a segment starts and ends at the same point (i.e. duplicate coords);
  //
  // @ids: Array of indexes: [s0p0, s0p1, s1p0, s1p1, ...] where xx[sip0] <= xx[sip1]
  // @xx, @yy: Arrays of x- and y-coordinates
  //
  function intersectSegments(ids, xx, yy, optsArg) {
    var lim = ids.length - 2,
        opts = optsArg || {},
        intersections = [],
        tolerance = opts.tolerance, // may be undefined
        s1p1, s1p2, s2p1, s2p2,
        s1p1x, s1p2x, s2p1x, s2p2x,
        s1p1y, s1p2y, s2p1y, s2p2y,
        hit, seg1, seg2, i, j;

    // Sort segments by xmin, to allow efficient exclusion of segments with
    // non-overlapping x extents.
    sortSegmentIds(xx, ids); // sort by ascending xmin

    i = 0;
    while (i < lim) {
      s1p1 = ids[i];
      s1p2 = ids[i+1];
      s1p1x = xx[s1p1];
      s1p2x = xx[s1p2];
      s1p1y = yy[s1p1];
      s1p2y = yy[s1p2];
      // count++;

      j = i;
      while (j < lim) {
        j += 2;
        s2p1 = ids[j];
        s2p1x = xx[s2p1];

        if (s1p2x < s2p1x) break; // x extent of seg 2 is greater than seg 1: done with seg 1
        //if (s1p2x <= s2p1x) break; // this misses point-segment intersections when s1 or s2 is vertical

        s2p1y = yy[s2p1];
        s2p2 = ids[j+1];
        s2p2x = xx[s2p2];
        s2p2y = yy[s2p2];

        // skip segments with non-overlapping y ranges
        if (s1p1y >= s2p1y) {
          if (s1p1y > s2p2y && s1p2y > s2p1y && s1p2y > s2p2y) continue;
        } else {
          if (s1p1y < s2p2y && s1p2y < s2p1y && s1p2y < s2p2y) continue;
        }

        // skip segments that are adjacent in a path (optimization)
        // TODO: consider if this eliminates some cases that should
        // be detected, e.g. spikes formed by unequal segments
        if (s1p1 == s2p1 || s1p1 == s2p2 || s1p2 == s2p1 || s1p2 == s2p2) {
          continue;
        }

        // test two candidate segments for intersection
        hit = geom.segmentIntersection(s1p1x, s1p1y, s1p2x, s1p2y,
            s2p1x, s2p1y, s2p2x, s2p2y, tolerance);
        if (hit) {
          seg1 = [s1p1, s1p2];
          seg2 = [s2p1, s2p2];
          intersections.push(formatIntersection(hit, seg1, seg2, xx, yy));
          if (hit.length == 4) {
            // two collinear segments may have two endpoint intersections
            intersections.push(formatIntersection(hit.slice(2), seg1, seg2, xx, yy));
          }
        }
      }
      i += 2;
    }
    return intersections;
  }

  function formatIntersection(xy, s1, s2, xx, yy) {
    var x = xy[0],
        y = xy[1],
        a, b;
    s1 = formatIntersectingSegment(x, y, s1[0], s1[1], xx, yy);
    s2 = formatIntersectingSegment(x, y, s2[0], s2[1], xx, yy);
    a = s1[0] < s2[0] ? s1 : s2;
    b = a == s1 ? s2 : s1;
    return {x: x, y: y, a: a, b: b};
  }

  // Receives:
  //   x, y: coordinates of intersection
  //   i, j: two segment endpoints, as indexes in xx and yy arrays
  // Returns:
  //   if x,y falls within the segment, returns ascending indexes
  //   if x,y coincides with an endpoint, returns the id of that endpoint twice
  function formatIntersectingSegment(x, y, i, j, xx, yy) {
    if (xx[i] == x && yy[i] == y) {
      return [i, i];
    }
    if (xx[j] == x && yy[j] == y) {
      return [j, j];
    }
    return i < j ? [i, j] : [j, i];
  }

  var SegmentIntersection = /*#__PURE__*/Object.freeze({
    __proto__: null,
    getIntersectionPoints: getIntersectionPoints,
    getIntersectionLayer: getIntersectionLayer,
    findSegmentIntersections: findSegmentIntersections,
    sortIntersections: sortIntersections,
    dedupIntersections: dedupIntersections,
    calcSegmentIntersectionStripeCount2: calcSegmentIntersectionStripeCount2,
    calcSegmentIntersectionStripeCount: calcSegmentIntersectionStripeCount,
    intersectSegments: intersectSegments,
    formatIntersection: formatIntersection,
    formatIntersectingSegment: formatIntersectingSegment
  });

  function findNearestVertices(p, shp, arcs) {
    var p2 = findNearestVertex(p[0], p[1], shp, arcs);
    return findVertexIds(p2.x, p2.y, arcs);
  }

  function snapVerticesToPoint(ids, p, arcs) {
    var data = arcs.getVertexData();
    ids.forEach(function(idx) {
      setVertexCoords(p[0], p[1], idx, arcs);
      arcs.updateArcBounds(findArcIdFromVertexId(idx, data.ii));
    });
  }


  // p: point to snap
  // ids: ids of nearby vertices, possibly including an arc endpoint
  function snapPointToArcEndpoint(p, ids, arcs) {
    var p2, dx, dy;
    ids.forEach(function(idx) {
      if (vertexIsArcStart(idx, arcs)) {
        p2 = getVertexCoords(idx + 1, arcs);
      } else if (vertexIsArcEnd(idx, arcs)) {
        p2 = getVertexCoords(idx - 1, arcs);
      }
    });
    if (!p2) return;
    dx = p2[0] - p[0];
    dy = p2[1] - p[1];
    if (Math.abs(dx) > Math.abs(dy)) {
      p[1] = p2[1]; // snap y coord
    } else {
      p[0] = p2[0];
    }
  }

  // Find ids of vertices with identical coordinates to x,y in an ArcCollection
  // Caveat: does not exclude vertices that are not visible at the
  //   current level of simplification.
  function findVertexIds(x, y, arcs) {
    var data = arcs.getVertexData(),
        xx = data.xx,
        yy = data.yy,
        ids = [];
    for (var i=0, n=xx.length; i<n; i++) {
      if (xx[i] == x && yy[i] == y) ids.push(i);
    }
    return ids;
  }

  function getVertexCoords(i, arcs) {
    var data = arcs.getVertexData();
    return [data.xx[i], data.yy[i]];
  }

  function vertexIsArcEnd(idx, arcs) {
    // Test whether the vertex at index @idx is the endpoint of an arc
    var data = arcs.getVertexData(),
        ii = data.ii,
        nn = data.nn;
    for (var j=0, n=ii.length; j<n; j++) {
      if (idx === ii[j] + nn[j] - 1) return true;
    }
    return false;
  }

  function vertexIsArcEndpoint(idx, arcs) {
    return vertexIsArcStart(idx, arcs) || vertexIsArcEnd(idx, arcs);
  }

  function vertexIsArcStart(idx, arcs) {
    var ii = arcs.getVertexData().ii;
    for (var j=0, n=ii.length; j<n; j++) {
      if (idx === ii[j]) return true;
    }
    return false;
  }

  function getArcStartCoords(arcId, arcs) {
    var coords = getArcEndpointCoords(arcId, arcs);
    return coords[0];
  }

  function getArcEndCoords(arcId, arcs) {
    var coords = getArcEndpointCoords(arcId, arcs);
    return coords[1];
  }

  function getArcEndpointCoords(arcId, arcs) {
    if (arcId < 0) {
      return getArcEndpointCoords(~arcId, arcs).reverse();
    }
    var data = arcs.getVertexData();
    var i = data.ii[arcId];
    var n = data.nn[arcId];
    var a = [data.xx[i], data.yy[i]];
    var b = [data.xx[i + n - 1], data.yy[i + n - 1]];
    return [a, b];
  }

  function setVertexCoords(x, y, i, arcs) {
    var data = arcs.getVertexData();
    data.xx[i] = x;
    data.yy[i] = y;
  }

  function findNearestVertex(x, y, shp, arcs, spherical) {
    var calcLen = spherical ? geom.greatCircleDistance : geom.distance2D,
        minLen = Infinity,
        minX, minY, dist, iter;
    for (var i=0; i<shp.length; i++) {
      iter = arcs.getShapeIter(shp[i]);
      while (iter.hasNext()) {
        dist = calcLen(x, y, iter.x, iter.y);
        if (dist < minLen) {
          minLen = dist;
          minX = iter.x;
          minY = iter.y;
        }
      }
    }
    return minLen < Infinity ? {x: minX, y: minY} : null;
  }

  var VertexUtils = /*#__PURE__*/Object.freeze({
    __proto__: null,
    findNearestVertices: findNearestVertices,
    snapVerticesToPoint: snapVerticesToPoint,
    snapPointToArcEndpoint: snapPointToArcEndpoint,
    findVertexIds: findVertexIds,
    getVertexCoords: getVertexCoords,
    vertexIsArcEnd: vertexIsArcEnd,
    vertexIsArcEndpoint: vertexIsArcEndpoint,
    vertexIsArcStart: vertexIsArcStart,
    getArcStartCoords: getArcStartCoords,
    getArcEndCoords: getArcEndCoords,
    getArcEndpointCoords: getArcEndpointCoords,
    setVertexCoords: setVertexCoords,
    findNearestVertex: findNearestVertex
  });

  // arcs: ArcCollection containing original coordinates
  function getRepairFunction(arcs) {
    var arcsOrig = arcs.getCopy();
    // updatedArcs: same ArcCollection, with snapped or rounded coords
    return function(updatedArcs) {
      repairSegmentIntersections(updatedArcs, arcsOrig);
    };
  }

  // TODO: test with duplicate coordinates
  // arcs: modified arcs (rounded coordinates)
  // arcsOrig: original, unmodified arcs
  function repairSegmentIntersections(arcs, arcsOrig) {
    // Check for intersections in the original data
    var xxOrig = findSegmentIntersections(arcsOrig);
    if (xxOrig.length > 0) {
      message('Original layer contains intersections -- unable to repair.');
      return;
    }
    var intersections = findSegmentIntersections(arcs);
    var maxLoops = 10;
    var startCount = intersections.length;
    for (var i=0; i<maxLoops && intersections.length > 0; i++) {
      revertIntersectionCoordinates(intersections, arcs, arcsOrig);
      intersections = findSegmentIntersections(arcs);
    }
    var finalCount = intersections.length;
    if (finalCount > 0) {
      message('Unable to remove', finalCount, `intersection${finalCount > 1 ? 's' : ''}`);
    } else if (startCount > 0) {
      message('Fix-geometry removed', startCount,  `intersection${startCount > 1 ? 's' : ''}`);
    }
  }

  // arcs: modified (rounded) coords
  // arcsOrig: original coords
  function revertIntersectionCoordinates(intersections, arcs, arcsOrig) {
    intersections.forEach(function(o) {
      replaceVertexCoords(o.a[0], arcs, arcsOrig);
      replaceVertexCoords(o.a[1], arcs, arcsOrig);
      replaceVertexCoords(o.b[0], arcs, arcsOrig);
      replaceVertexCoords(o.b[1], arcs, arcsOrig);
    });
  }

  // idx: index of vertex to replace
  // arcs: target arcs
  // arcs2: arcs with replacement coordinates
  function replaceVertexCoords(idx, arcs, arcs2) {
    var data = arcs.getVertexData();
    var data2 = arcs2.getVertexData();
    var idxx = [idx];
    if (vertexIsArcEndpoint(idx, arcs)) {
      idxx = idxx.concat(findMatchingEndpoints(idx, data));
    }
    idxx.forEach(function(idx) {
      data.xx[idx] = data2.xx[idx];
      data.yy[idx] = data2.yy[idx];
    });
  }

  // idx: index of an arc endpoint
  function findMatchingEndpoints(idx, data) {
    var ii = data.ii, nn = data.nn, xx = data.xx, yy = data.yy;
    var x = xx[idx], y = yy[idx];
    var a, b;
    var matches = [];
    for (var j=0; j<ii.length; j++) {
      a = ii[j];
      b = a + nn[j] - 1;
      if (a != idx && xx[a] == x && yy[a] == y) {
        matches.push(a);
      }
      if (b != idx && xx[b] == x && yy[b] == y) {
        matches.push(b);
      }
    }
    return matches;
  }

  function roundToSignificantDigits(n, d) {
    return +n.toPrecision(d);
  }

  function roundToDigits(n, d) {
    return +n.toFixed(d); // string conversion makes this slow
  }

  // Used in mapshaper-expression-utils.js
  // TODO: choose between this and the above function
  function roundToDigits2(n, d) {
    var k = 1;
    if (!n && n !== 0) return n; // don't coerce null to 0
    d = d | 0;
    while (d-- > 0) k *= 10;
    return Math.round(n * k) / k;
  }

  function roundToTenths(n) {
    return (Math.round(n * 10)) / 10;
  }

  // inc: Rounding increment (e.g. 0.001 rounds to thousandths)
  function getRoundingFunction(inc) {
    if (!utils.isNumber(inc) || inc === 0) {
      error("Rounding increment must be a non-zero number.");
    }
    var inv = 1 / inc;
    if (inv > 1) inv = Math.round(inv);
    return function(x) {
      return Math.round(x * inv) / inv;
      // these alternatives show rounding error after JSON.stringify()
      // return Math.round(x / inc) / inv;
      // return Math.round(x / inc) * inc;
      // return Math.round(x * inv) * inc;
    };
  }

  function getBoundsPrecisionForDisplay(bbox) {
    var w = Math.abs(bbox[2] - bbox[0]),
        h = Math.abs(bbox[3] - bbox[1]),
        // switched to max bound, based on experience with shift-drag box info
        // range = Math.min(w, h) + 1e-8,
        range = Math.max(w, h) + 1e-8,
        digits = 0;
    while (range < 2000 && digits < 1) {
      range *= 10;
      digits++;
    }
    return digits;
  }

  function getRoundedCoordString(coords, decimals) {
    return coords.map(function(n) {return n.toFixed(decimals);}).join(',');
  }

  function getRoundedCoords(coords, decimals) {
    return getRoundedCoordString(coords, decimals).split(',').map(parseFloat);
  }

  function roundPoints(lyr, round) {
    forEachPoint(lyr.shapes, function(p) {
      p[0] = round(p[0]);
      p[1] = round(p[1]);
    });
  }

  const fround2 = (function() {
    var arr = new Float32Array(1);
    return function(x) {
      arr[0] = x;
      return arr[0];
    };
  })();

  // This function rounds towards 0 (i.e. floor). TODO: round properly
  // @bits: number of bits to round
  // performance: about 3x slower than Math.fround()
  function getBinaryRoundingFunction(bits) {
    // double: sign (1) exponent (11) fraction (52)
    // single: sign (1) exponent (8) fraction (23)
    if ((bits >= 1 && bits <= 32) === false) {
      error('Invalid bits argument:', bits);
    }
    var isLE = require('os').endianness() == 'LE';
    var fp = new Float64Array(1);
    var leastBits = new Uint32Array(fp.buffer, isLE ? 0 : 4, 1);
    var mask = 2 ** 32 - 2 ** bits;  // e.g. bits = 4 -> 0b11110000
    return function(x) {
      fp[0] = x;
      leastBits[0] = leastBits[0] & mask;
      return fp[0];
    };
  }

  // "round to even" on the 23rd bit of the mantissa
  const fround = Math.fround || fround2;

  function setCoordinatePrecision(dataset, precision, fixGeom) {
    var round = getRoundingFunction(precision);
    var repairArcs = dataset.arcs && fixGeom ? getRepairFunction(dataset.arcs) : null;
    transformPoints(dataset, function(x, y) {
      return [round(x), round(y)];
    });
    if (repairArcs) {
      repairArcs(dataset.arcs);
    }

    // v0.4.52 removing polygon dissolve - see issue #219
    /*
    if (dataset.arcs) {
      nodes = internal.addIntersectionCuts(dataset);
      dissolvePolygon = internal.getPolygonDissolver(nodes);
    }
    dataset.layers.forEach(function(lyr) {
      if (lyr.geometry_type == 'polygon' && dissolvePolygon) {
        // clean each polygon -- use dissolve function to remove spikes
        // TODO: better handling of corrupted polygons
        lyr.shapes = lyr.shapes.map(dissolvePolygon);
      }
    });
    */
    return dataset;
  }

  var Rounding = /*#__PURE__*/Object.freeze({
    __proto__: null,
    roundToSignificantDigits: roundToSignificantDigits,
    roundToDigits: roundToDigits,
    roundToDigits2: roundToDigits2,
    roundToTenths: roundToTenths,
    getRoundingFunction: getRoundingFunction,
    getBoundsPrecisionForDisplay: getBoundsPrecisionForDisplay,
    getRoundedCoordString: getRoundedCoordString,
    getRoundedCoords: getRoundedCoords,
    roundPoints: roundPoints,
    fround2: fround2,
    getBinaryRoundingFunction: getBinaryRoundingFunction,
    fround: fround,
    setCoordinatePrecision: setCoordinatePrecision
  });

  var UNITS_LOOKUP = {
    m: 'meters',
    meter: 'meters',
    meters: 'meters',
    mi: 'miles',
    mile: 'miles',
    miles: 'miles',
    km: 'kilometers',
    ft: 'feet',
    feet: 'feet'
  };

  // From pj_units.js in mapshaper-proj
  var TO_METERS = {
    meters: 1,
    kilometers: 1000,
    feet: 0.3048, // International Standard Foot
    miles: 1609.344 // International Statute Mile
  };

  // str: display size in px, pt or in
  // using: 72pt per inch, 1pt per pixel.
  function parseSizeParam(p) {
    var str = String(p),
        num = parseFloat(str),
        units = /px|pix/.test(str) && 'px' ||
        /pt|point/.test(str) && 'pt' ||
        /in/.test(str) && 'in' ||
        /cm/.test(str) && 'cm' ||
        !isNaN(+str) && 'px' || // px is the default
        null;
    var px = units == 'in' && num * 72 ||
        units == 'cm' && Math.round(num * 28.3465) ||
        num;
    if (px >= 0 === false || !units) {
      stop('Invalid size:', str);
    }
    return px;
  }

  // Return coeff. for converting a distance measure to dataset coordinates
  // @paramUnits: units code of distance param, or null if units are not specified
  // @crs: Proj.4 CRS object, or null (unknown latlong CRS);
  //
  function getIntervalConversionFactor(paramUnits, crs) {
    var fromParam = 0,
        fromCRS = 0,
        k;

    if (crs) {
      if (crs.is_latlong) {
        // calculations on latlong coordinates typically use meters
        fromCRS = 1;
      } else if (crs.to_meter > 0) {
        fromCRS = crs.to_meter;
      } else {
        error('Invalid CRS');
      }
    }
    if (paramUnits) {
      fromParam = TO_METERS[paramUnits];
      if (!fromParam) error('Unknown units:', paramUnits);
    }

    if (fromParam && fromCRS) {
      // known param units, known CRS conversion
      k = fromParam / fromCRS;
    } else if (!fromParam && !fromCRS) {
      // unknown param units, unknown (projected) CRS -- no scaling
      k = 1;
    } else if (fromParam && !fromCRS) {
      // known param units, unknown CRS -- error condition, not convertible
      stop('Unable to convert', paramUnits, 'to unknown coordinates');
    } else if (!fromParam && fromCRS) {
      // unknown param units, known CRS -- assume param in meters (bw compatibility)
      k = 1 / fromCRS;
    }
    return k;
  }

  // throws an error if measure is non-parsable
  function parseMeasure(m) {
    var o = parseMeasure2(m);
    if (isNaN(o.value)) {
      stop('Invalid parameter:', m);
    }
    return o;
  }

  // returns NaN value if value is non-parsable
  function parseMeasure2(m) {
    var s = utils.isString(m) ? m : '';
    var match = /(sq|)([a-z]+)(2|)$/i.exec(s); // units rxp
    var o = {};
    if (utils.isNumber(m)) {
      o.value = m;
    } else if (s === '') {
      o.value = NaN;
    } else if (match) {
      o.units = UNITS_LOOKUP[match[2].toLowerCase()];
      o.areal = !!(match[1] || match[3]);
      o.value = Number(s.substring(0, s.length - match[0].length));
      if (!o.units && !isNaN(o.value)) {
        // throw error if string contains a number followed by unrecognized units string
        stop('Unknown units: ' + match[0]);
      }
    } else {
      o.value = Number(s);
    }
    return o;
  }

  function convertAreaParam(opt, crs) {
    var o = parseMeasure(opt);
    var k = getIntervalConversionFactor(o.units, crs);
    return o.value * k * k;
  }

  function convertDistanceParam(opt, crs) {
    var o = parseMeasure(opt);
    var k = getIntervalConversionFactor(o.units, crs);
    if (o.areal) {
      stop('Expected a distance, received an area:', opt);
    }
    return o.value * k;
  }

  // Same as convertDistanceParam(), except:
  //   in the case of latlong datasets, coordinates are unitless (instead of meters),
  //   and parameters with units trigger an error
  function convertIntervalParam(opt, crs) {
    var o = parseMeasure(opt);
    var k = getIntervalConversionFactor(o.units, crs);
    if (o.units && crs && crs.is_latlong) {
      stop('Parameter does not support distance units with latlong datasets');
    }
    if (o.areal) {
      stop('Expected a distance, received an area:', opt);
    }
    return o.value * k;
  }

  function convertIntervalPair(opt, crs) {
    var a, b;
    if (!Array.isArray(opt) || opt.length != 2) {
      stop('Expected two distance parameters, received', opt);
    }
    a = parseMeasure(opt[0]);
    b = parseMeasure(opt[1]);
    if (a.units && !b.units || b.units && !a.units) {
      stop('Both parameters should have units:', opt);
    }
    return [convertIntervalParam(opt[0], crs),
            convertIntervalParam(opt[1], crs)];
  }

  // Accepts a single value or a list of four values. List order is l,b,r,t
  function convertFourSides(opt, crs, bounds) {
    var arr = opt.includes(',') ? opt.split(',') : opt.split(' ');
    if (arr.length == 1) {
      arr = [arr[0], arr[0], arr[0], arr[0]];
    } else if (arr.length != 4) {
      stop("Expected a distance parameter or a list of four params");
    }
    return arr.map(function(param, i) {
      var tmp;
      if (param.indexOf('%') > 0) {
        tmp = parseFloat(param) / 100 || 0;
        return tmp * (i == 1 || i == 3 ? bounds.height() : bounds.width());
      }
      return convertIntervalParam(param, crs);
    });
  }

  // Convert an area measure to a label in sqkm or sqm
  function getAreaLabel(area, crs) {
    var sqm = crs && crs.to_meter ? area * crs.to_meter * crs.to_meter : area;
    var sqkm = sqm / 1e6;
    return sqkm < 0.01 ? Math.round(sqm) + ' sqm' : sqkm + ' sqkm';
  }

  var Units = /*#__PURE__*/Object.freeze({
    __proto__: null,
    parseSizeParam: parseSizeParam,
    getIntervalConversionFactor: getIntervalConversionFactor,
    parseMeasure: parseMeasure,
    parseMeasure2: parseMeasure2,
    convertAreaParam: convertAreaParam,
    convertDistanceParam: convertDistanceParam,
    convertIntervalParam: convertIntervalParam,
    convertIntervalPair: convertIntervalPair,
    convertFourSides: convertFourSides,
    getAreaLabel: getAreaLabel
  });

  // Used by -clean -dissolve2 -filter-slivers -filter-islands to generate area filters
  // for removing small polygon rings.
  // Assumes lyr is a polygon layer.
  function getSliverFilter(lyr, dataset, opts) {
    var areaArg = opts.min_gap_area || opts.min_area || opts.gap_fill_area;
    if (+areaArg == 0) {
      return {
        filter: function() {return false;}, // don't fill any gaps
        threshold: 0
      };
    }
    var sliverControl = opts.sliver_control >= 0 ? opts.sliver_control : 0; // 0 is default
    var crs = getDatasetCRS(dataset);
    var threshold = areaArg && areaArg != 'auto' ?
        convertAreaParam(areaArg, crs) :
        getDefaultSliverThreshold(lyr, dataset.arcs);
    var filter = sliverControl > 0 ?
        getSliverTest(dataset.arcs, threshold, sliverControl) :
        getMinAreaTest(threshold, dataset);
    var label = getSliverLabel(getAreaLabel(threshold, crs), sliverControl > 0);
    return {
      threshold: threshold,
      filter: filter,
      label: label
    };
  }

  function getSliverLabel(areaStr, variable) {
    if (variable) {
      areaStr = areaStr.replace(' ', '+ ') + ' variable';
    }
    return areaStr + ' threshold';
  }

  function getMinAreaTest(minArea, dataset) {
    var pathArea = dataset.arcs.isPlanar() ? geom.getPlanarPathArea : geom.getSphericalPathArea;
    return function(path) {
      var area = pathArea(path, dataset.arcs);
      return Math.abs(area) < minArea;
    };
  }

  function getSliverTest(arcs, threshold, strength) {
    if (strength >= 0 === false) {
      strength = 1; // default is 1 (full-strength)
    }
    if (strength > 1 || threshold >= 0 === false) {
      error('Invalid parameter');
    }
    var calcEffectiveArea = getSliverAreaFunction(arcs, strength);
    return function(ring) {
      return Math.abs(calcEffectiveArea(ring)) < threshold;
    };
  }

  // Strength: 0-1
  function getSliverAreaFunction(arcs, strength) {
    var k = Math.sqrt(strength); // more sensible than linear weighted avg.
    return function(ring) {
      var area = geom.getPathArea(ring, arcs);
      var perim = geom.getPathPerimeter(ring, arcs);
      var compactness = geom.calcPolsbyPopperCompactness(area, perim);
      var effectiveArea = area * (k * compactness + 1 - k);
      return effectiveArea;
    };
  }

  // Calculate a default area threshold using average segment length,
  // but increase the threshold for high-detail datasets and decrease it for
  // low-detail datasets (using segments per ring as a measure of detail).
  //
  function getDefaultSliverThreshold(lyr, arcs) {
    var ringCount = 0;
    var calcLen = arcs.isPlanar() ? geom.distance2D : geom.greatCircleDistance;
    var avgSegLen = 0;
    var segCount = 0;
    var onSeg = function(i, j, xx, yy) {
      var len = calcLen(xx[i], yy[i], xx[j], yy[j]);
      segCount++;
      avgSegLen += (len - avgSegLen) / segCount;
    };
    editShapes(lyr.shapes, function(path) {
      ringCount++;
      forEachSegmentInPath(path, arcs, onSeg);
    });
    var segPerRing = segCount / ringCount || 0;
    var complexityFactor = Math.pow(segPerRing, 0.75); // use seg/ring as a proxy for complexity
    var threshold = avgSegLen * avgSegLen / 50 * complexityFactor;
    threshold = roundToSignificantDigits(threshold, 2); // round for display
    return threshold;
  }


  // Original function for calculating default area threshold
  function calcMaxSliverArea(arcs) {
    var k = 2,
        dxMax = arcs.getBounds().width() / k,
        dyMax = arcs.getBounds().height() / k,
        count = 0,
        mean = 0;
    arcs.forEachSegment(function(i, j, xx, yy) {
      var dx = Math.abs(xx[i] - xx[j]),
          dy = Math.abs(yy[i] - yy[j]);
      if (dx < dxMax && dy < dyMax) {
        // TODO: write utility function for calculating mean this way
        mean += (Math.sqrt(dx * dx + dy * dy) - mean) / ++count;
      }
    });
    return mean * mean;
  }

  var Slivers = /*#__PURE__*/Object.freeze({
    __proto__: null,
    getSliverFilter: getSliverFilter,
    getSliverTest: getSliverTest,
    getSliverAreaFunction: getSliverAreaFunction,
    getDefaultSliverThreshold: getDefaultSliverThreshold,
    calcMaxSliverArea: calcMaxSliverArea
  });

  // Returns undefined if not found
  function lookupColorName(str) {
    return colors$1[str.toLowerCase().replace(/[ -]+/g, '')];
  }

  var colors$1 = {
    aliceblue: '#f0f8ff',
    antiquewhite: '#faebd7',
    aqua: '#00ffff',
    aquamarine: '#7fffd4',
    azure: '#f0ffff',
    beige: '#f5f5dc',
    bisque: '#ffe4c4',
    black: '#000000',
    blanchedalmond: '#ffebcd',
    blue: '#0000ff',
    blueviolet: '#8a2be2',
    brown: '#a52a2a',
    burlywood: '#deb887',
    cadetblue: '#5f9ea0',
    chartreuse: '#7fff00',
    chocolate: '#d2691e',
    coral: '#ff7f50',
    cornflowerblue: '#6495ed',
    cornsilk: '#fff8dc',
    crimson: '#dc143c',
    cyan: '#00ffff',
    darkblue: '#00008b',
    darkcyan: '#008b8b',
    darkgoldenrod: '#b8860b',
    darkgray: '#a9a9a9',
    darkgreen: '#006400',
    darkgrey: '#a9a9a9',
    darkkhaki: '#bdb76b',
    darkmagenta: '#8b008b',
    darkolivegreen: '#556b2f',
    darkorange: '#ff8c00',
    darkorchid: '#9932cc',
    darkred: '#8b0000',
    darksalmon: '#e9967a',
    darkseagreen: '#8fbc8f',
    darkslateblue: '#483d8b',
    darkslategray: '#2f4f4f',
    darkslategrey: '#2f4f4f',
    darkturquoise: '#00ced1',
    darkviolet: '#9400d3',
    deeppink: '#ff1493',
    deepskyblue: '#00bfff',
    dimgray: '#696969',
    dimgrey: '#696969',
    dodgerblue: '#1e90ff',
    firebrick: '#b22222',
    floralwhite: '#fffaf0',
    forestgreen: '#228b22',
    fuchsia: '#ff00ff',
    gainsboro: '#dcdcdc',
    ghostwhite: '#f8f8ff',
    gold: '#ffd700',
    goldenrod: '#daa520',
    gray: '#808080',
    green: '#008000',
    greenyellow: '#adff2f',
    grey: '#808080',
    honeydew: '#f0fff0',
    hotpink: '#ff69b4',
    indianred: '#cd5c5c',
    indigo: '#4b0082',
    ivory: '#fffff0',
    khaki: '#f0e68c',
    lavender: '#e6e6fa',
    lavenderblush: '#fff0f5',
    lawngreen: '#7cfc00',
    lemonchiffon: '#fffacd',
    lightblue: '#add8e6',
    lightcoral: '#f08080',
    lightcyan: '#e0ffff',
    lightgoldenrodyellow: '#fafad2',
    lightgray: '#d3d3d3',
    lightgreen: '#90ee90',
    lightgrey: '#d3d3d3',
    lightpink: '#ffb6c1',
    lightsalmon: '#ffa07a',
    lightseagreen: '#20b2aa',
    lightskyblue: '#87cefa',
    lightslategray: '#778899',
    lightslategrey: '#778899',
    lightsteelblue: '#b0c4de',
    lightyellow: '#ffffe0',
    lime: '#00ff00',
    limegreen: '#32cd32',
    linen: '#faf0e6',
    magenta: '#ff00ff',
    maroon: '#800000',
    mediumaquamarine: '#66cdaa',
    mediumblue: '#0000cd',
    mediumorchid: '#ba55d3',
    mediumpurple: '#9370db',
    mediumseagreen: '#3cb371',
    mediumslateblue: '#7b68ee',
    mediumspringgreen: '#00fa9a',
    mediumturquoise: '#48d1cc',
    mediumvioletred: '#c71585',
    midnightblue: '#191970',
    mintcream: '#f5fffa',
    mistyrose: '#ffe4e1',
    moccasin: '#ffe4b5',
    navajowhite: '#ffdead',
    navy: '#000080',
    oldlace: '#fdf5e6',
    olive: '#808000',
    olivedrab: '#6b8e23',
    orange: '#ffa500',
    orangered: '#ff4500',
    orchid: '#da70d6',
    palegoldenrod: '#eee8aa',
    palegreen: '#98fb98',
    paleturquoise: '#afeeee',
    palevioletred: '#db7093',
    papayawhip: '#ffefd5',
    peachpuff: '#ffdab9',
    peru: '#cd853f',
    pink: '#ffc0cb',
    plum: '#dda0dd',
    powderblue: '#b0e0e6',
    purple: '#800080',
    rebeccapurple: '#663399',
    red: '#ff0000',
    rosybrown: '#bc8f8f',
    royalblue: '#4169e1',
    saddlebrown: '#8b4513',
    salmon: '#fa8072',
    sandybrown: '#f4a460',
    seagreen: '#2e8b57',
    seashell: '#fff5ee',
    sienna: '#a0522d',
    silver: '#c0c0c0',
    skyblue: '#87ceeb',
    slateblue: '#6a5acd',
    slategray: '#708090',
    slategrey: '#708090',
    snow: '#fffafa',
    springgreen: '#00ff7f',
    steelblue: '#4682b4',
    tan: '#d2b48c',
    teal: '#008080',
    thistle: '#d8bfd8',
    tomato: '#ff6347',
    turquoise: '#40e0d0',
    violet: '#ee82ee',
    wheat: '#f5deb3',
    white: '#ffffff',
    whitesmoke: '#f5f5f5',
    yellow: '#ffff00',
    yellowgreen: '#9acd32'
  };

  var rgbaRxp = /^rgba?\(([^)]+)\)/;
  var hexRxp = /^#([a-f0-9]{3,8})/i;

  function parseColor(arg) {
    arg = arg ? String(arg) : '';
    var hexStr = hexRxp.test(arg) ? arg : lookupColorName(arg);
    var rgb = null;
    if (hexStr) {
      rgb = parseHexColor(hexStr);
    } else if (rgbaRxp.test(arg)) {
      rgb = parseRGBA(arg);
    }
    if (rgb && !testRGB(rgb)) {
      rgb = null;
    }
    return rgb;
  }

  function validateColor(arg) {
    if (!parseColor(arg)) {
      stop("Unsupported color:", arg);
    }
    return true;
  }

  function testRGB(o) {
    return !!o && testChannel(o.r) && testChannel(o.g) && testChannel(o.b) &&
      testAlpha(o.a);
  }

  function testAlpha(a) {
    return a >= 0 && a <= 1;
  }

  function testChannel(c) {
    return c >= 0 && c < 256; // allow fractional values
  }

  function parseRGBA(arg) {
    var str = rgbaRxp.exec(arg)[1];
    var parts = str.split(',').map(function(part) { return parseFloat(part); });
    return {
      r: parts[0],
      g: parts[1],
      b: parts[2],
      a: parts[3] >= 0 ? parts[3] : 1
    };
  }

  function formatColor(o) {
    return o.a < 1 ? formatRGBA(o) : formatHexColor(o);
  }

  function formatHexColor(o) {
    return "#" + formatHexChannel(o.r) + formatHexChannel(o.g) + formatHexChannel(o.b);

  }

  function formatRGBA(o) {
    var rgb = snapHexChannel(o.r) + ',' + snapHexChannel(o.g) + ',' + snapHexChannel(o.b);
    return o.a < 1 ?
      'rgba(' + rgb + ',' + snapAlpha(o.a) + ')' :
      'rgb(' + rgb + ')';
  }

  function snapAlpha(a) {
    a = +a || 0;
    a = Math.round(a * 1000) / 1000; // round to thousandths
    return utils.clamp(a, 0, 1);
  }

  function snapHexChannel(arg) {
    return Math.round(utils.clamp(+arg || 0, 0, 255));
  }

  // arg: should be number in 0-255 range
  function formatHexChannel(arg) {
    return snapHexChannel(arg).toString(16).padStart(2, '0');
  }

  // returns {r, g, b} object
  function parseHexColor(str) {
    var hex = hexRxp.exec(str)[1];
    if (hex.length == 3 || hex.length == 4) {
      hex = hex.split('').map(function(c) { return c + c; });
    }
    if (hex.length != 6 && hex.length != 8) return null;
    return {
      r: parseInt(hex.substr(0, 2), 16),
      g: parseInt(hex.substr(2, 2), 16),
      b: parseInt(hex.substr(4, 2), 16),
      a: hex.length == 8 ? parseInt(hex.substr(7, 2), 16) / 255 : 1
    };
  }

  function blend(a, b) {
    var colors, weights, args;
    if (Array.isArray(a)) {
      colors = a;
      weights = b;
    } else {
      colors = [];
      weights = [];
      args = Array.from(arguments);
      for (var i=0; i<args.length; i+= 2) {
        colors.push(args[i]);
        weights.push(args[i + 1]);
      }
    }
    weights = normalizeWeights(weights);
    if (!weights) return '#eee';
    var blended = colors.reduce(function(memo, col, i) {
      var rgb = validateColor(col) && parseColor(col);
      var w = +weights[i] || 0;
      memo.r += rgb.r * w;
      memo.g += rgb.g * w;
      memo.b += rgb.b * w;
      return memo;
    }, {r: 0, g: 0, b: 0});
    return formatColor(blended);
  }


  function normalizeWeights(weights) {
    var sum = utils.sum(weights);
    if (sum > 0 === false) {
      return null;
    }
    return weights.map(function(w) {
      return w / sum;
    });
  }

  // Parse a formatted value in DMS DM or D to a numeric value. Returns NaN if unparsable.
  // Delimiters: degrees: D|d|; minutes: '; seconds: "
  function parseDMS(str, fmt) {
    var defaultRxp = /^(?<prefix>[nsew+-]?)(?<d>[0-9.]+)[d]? ?(?<m>[0-9.]*)[m']? ?(?<s>[0-9.]*)["]? ?(?<suffix>[nsew]?)$/i;
    var rxp = fmt ? getParseRxp(fmt) : defaultRxp;
    var match = rxp.exec(str.trim());
    var d = NaN;
    var deg, min, sec;
    if (match) {
      deg = match.groups.d || '0';
      min = match.groups.m || '0';
      sec = match.groups.s || '0';
      d = (+deg) + (+min) / 60 + (+sec) / 3600;
      if (/[sw-]/i.test(match.groups.prefix || '') || /[sw]/i.test(match.groups.suffix || '')) {
        d = -d;
      }
    }
    return d;
  }

  var cache$1 = {};

  function getParseRxp(fmt) {
    if (fmt in cache$1) return cache$1[fmt];
    var rxp = fmt;
    rxp = rxp.replace('[-]', '(?<prefix>-)?'); // optional -
    rxp = rxp.replace(/\[[NSEW, +-]{2,}\]/, '(?<prefix>$&)');
    // TODO: validate that if there are degree decimals, there are no M or S codes
    rxp = rxp.replace(/D+(\.D+)?/, (m, g1) => {
      var s = '[0-9]+';
      if (g1) s += `\\.[0-9]+`;
      return `(?<d>${s})`;
    });
    // TODO: validate that if there are minutes decimals, there are no S codes
    rxp = rxp.replace(/(MM?)(\.M+)?/, (m, g1, g2) => {
      var s = g1.length == 1 ? '[0-9]+' : '[0-9][0-9]';
      if (g2) s += '\\.[0-9]+';
      return `(?<m>${s})`;
    });
    rxp = rxp.replace(/(SS?)(\.S+)?/, (m, g1, g2) => {
      var s = g1.length == 1 ? '[0-9]+' : '[0-9][0-9]';
      if (g2) s += '\\.[0-9]+';
      return `(?<s>${s})`;
    });
    rxp = '^' + rxp + '$';
    try {
      // TODO: make sure all DMS codes have been matched
      cache$1[fmt] = new RegExp(rxp);
    } catch(e) {
      stop('Invalid DMS format string:', fmt);
    }
    return cache$1[fmt];
  }

  function formatNumber(val, integers, decimals) {
    var str = val.toFixed(decimals);
    var parts = str.split('.');
    if (parts.length > 0) {
      parts[0] = parts[0].padStart(integers, '0');
      str = parts.join('.');
    }
    return str;
  }

  function formatDMS(coord, fmt) {
    if (!fmt) fmt = '[-]DM\'S.SSS';
    var str = fmt;
    var dstr, mstr, sstr;
    var match = /(D+)[^M]*(M+)?[^S[\]]*(S+)?/.exec(fmt);
    var gotSeconds = match && !!match[3];
    var gotMinutes = match && !!match[2];
    if (!match || gotSeconds && !gotMinutes) {
      stop('Invalid DMS format string:', fmt);
    }
    var integers = gotSeconds && match[3].length || gotMinutes && match[2].length || match[1].length;
    var decimalRxp = gotSeconds && /S\.(S+)/ || gotMinutes && /M\.(M+)/ || /D\.(D+)/;
    var decimals = decimalRxp.test(fmt) ? decimalRxp.exec(fmt)[1].length : 0;
    if (gotMinutes) {
      var RES = Math.pow(10, decimals);
      var CONV = gotSeconds ? 3600 * RES : 60 * RES;
      var r = Math.floor(Math.abs(coord) * CONV + 0.5);
      var lastPart = formatNumber((r / RES) % 60, integers, decimals);
      if (gotSeconds) {
        r = Math.floor(r / (RES * 60));
        sstr = lastPart;
        mstr = String(r % 60).padStart(match[2].length, '0');
      } else {
        r = Math.floor(r / RES);
        mstr = lastPart;
      }
      dstr = String(Math.floor(r / 60)).padStart(match[1].length, '0');
    } else {
      dstr = Math.abs(coord).toFixed(decimals);
    }
    str = str.replace(/\[-\]/, s => coord < 0 ? '-' : '');
    str = str.replace(/\[[+-]+\]/, s => coord < 0 ? '-' : '+');
    str = str.replace(/\[[NS, ]+\]/, s => coord < 0 ? 'S' : 'N');
    str = str.replace(/\[[EW, ]+\]/, s => coord < 0 ? 'W' : 'E');
    str = str.replace(/D+(\.D+)?/, dstr);
    if (gotMinutes) str = str.replace(/M+(\.M+)?/, mstr);
    if (gotSeconds) str = str.replace(/S+(\.S+)?/, sstr);
    return str;
  }

  function addFeatureExpressionUtils(env) {
    Object.assign(env, {
      round: roundToDigits2,
      int_median: interpolated_median,
      sprintf: utils.format,
      blend: blend,
      format_dms: formatDMS,
      parse_dms: parseDMS
    });
  }

  function requireBooleanResult(val, msg) {
    if (val !== true && val !== false) {
      stop(msg || 'Filter expression must return true or false');
    }
  }

  // piecewise linear interpolation (for a special project)
  function interpolated_median(counts, breaks) {
    if (!counts || !breaks || counts.length != breaks.length - 1) return null;
    var total = utils.sum(counts);
    var medianIdx = Math.floor(total / 2);
    var lowerCount = 0, upperCount, lowerValue, upperValue, t;
    for (var i=1; i<breaks.length; i++) {
      lowerValue = breaks[i-1];
      upperValue = breaks[i];
      upperCount = lowerCount + counts[i-1];
      if (medianIdx <= upperCount) {
        t = (medianIdx - lowerCount) / (upperCount - lowerCount);
        return lowerValue + t * (upperValue - lowerValue);
      }
      lowerCount = upperCount;
    }
    return null;
  }

  function addGetters(obj, getters) {
    Object.keys(getters).forEach(function(name) {
      var val = getters[name];
      var o = typeof val == 'function' ?
        {get: val} :
        {value: val, writable: false};
      Object.defineProperty(obj, name, o);
    });
  }

  function simplifyArcsFast(arcs, dist) {
    var xx = [],
        yy = [],
        nn = [],
        count;
    for (var i=0, n=arcs.size(); i<n; i++) {
      count = simplifyPathFast([i], arcs, dist, xx, yy);
      if (count == 1) {
        count = 0;
        xx.pop();
        yy.pop();
      }
      nn.push(count);
    }
    return new ArcCollection(nn, xx, yy);
  }

  function simplifyPolygonFast(shp, arcs, dist) {
    if (!shp || !dist) return null;
    var xx = [],
        yy = [],
        nn = [],
        shp2 = [];

    shp.forEach(function(path) {
      var count = simplifyPathFast(path, arcs, dist, xx, yy);
      while (count < 4 && count > 0) {
        xx.pop();
        yy.pop();
        count--;
      }
      if (count > 0) {
        shp2.push([nn.length]);
        nn.push(count);
      }
    });
    return {
      shape: shp2.length > 0 ? shp2 : null,
      arcs: new ArcCollection(nn, xx, yy)
    };
  }

  function simplifyPathFast(path, arcs, dist, xx, yy) {
    var iter = arcs.getShapeIter(path),
        count = 0,
        prevX, prevY, x, y;
    while (iter.hasNext()) {
      x = iter.x;
      y = iter.y;
      if (count === 0 || geom.distance2D(x, y, prevX, prevY) > dist) {
        xx.push(x);
        yy.push(y);
        prevX = x;
        prevY = y;
        count++;
      }
    }
    if (x != prevX || y != prevY) {
      xx.push(x);
      yy.push(y);
      count++;
    }
    return count;
  }

  var SimplifyFast = /*#__PURE__*/Object.freeze({
    __proto__: null,
    simplifyArcsFast: simplifyArcsFast,
    simplifyPolygonFast: simplifyPolygonFast
  });

  // Find a point inside a polygon and located away from the polygon edge
  // Method:
  // - get the largest ring of the polygon
  // - get an array of x-values distributed along the horizontal extent of the ring
  // - for each x:
  //     intersect a vertical line with the polygon at x
  //     find midpoints of each intersecting segment
  // - for each midpoint:
  //     adjust point vertically to maximize weighted distance from polygon edge
  // - return the adjusted point having the maximum weighted distance from the edge
  //
  // (distance is weighted to slightly favor points near centroid)
  //
  function findAnchorPoint(shp, arcs) {
    var maxPath = shp && geom.getMaxPath(shp, arcs),
        pathBounds = maxPath && arcs.getSimpleShapeBounds(maxPath),
        thresh, simple;
    if (!pathBounds || !pathBounds.hasBounds() || pathBounds.area() === 0) {
      return null;
    }
    // Optimization: quickly simplify using a relatively small distance threshold.
    // (testing multiple candidate points can be very slow for large and detailed
    //   polgons; simplification alleviates this)
    // Caveat: In rare cases this could cause poor point placement, e.g. if
    //   simplification causes small holes to be removed.
    thresh = Math.sqrt(pathBounds.area()) * 0.01;
    simple = simplifyPolygonFast(shp, arcs, thresh);
    if (!simple.shape) {
      return null; // collapsed shape
    }
    return findAnchorPoint2(simple.shape, simple.arcs);
  }

  // Assumes: shp is a polygon with at least one space-enclosing ring
  function findAnchorPoint2(shp, arcs) {
    var maxPath = geom.getMaxPath(shp, arcs);
    var pathBounds = arcs.getSimpleShapeBounds(maxPath);
    var centroid = geom.getPathCentroid(maxPath, arcs);
    var weight = getPointWeightingFunction(centroid, pathBounds);
    var area = geom.getPlanarPathArea(maxPath, arcs);
    var hrange, lbound, rbound, focus, htics, hstep, p, p2;

    // Limit test area if shape is simple and squarish
    if (shp.length == 1 && area * 1.2 > pathBounds.area()) {
      htics = 5;
      focus = 0.2;
    } else if (shp.length == 1 && area * 1.7 > pathBounds.area()) {
      htics = 7;
      focus = 0.4;
    } else {
      htics = 11;
      focus = 0.5;
    }
    hrange = pathBounds.width() * focus;
    lbound = centroid.x - hrange / 2;
    rbound = lbound + hrange;
    hstep = hrange / htics;

    // Find a best-fit point
    p = probeForBestAnchorPoint(shp, arcs, lbound, rbound, htics, weight);
    if (!p) {
      verbose("[points inner] failed, falling back to centroid");
     p = centroid;
    } else {
      // Look for even better fit close to best-fit point
      p2 = probeForBestAnchorPoint(shp, arcs, p.x - hstep / 2,
          p.x + hstep / 2, 2, weight);
      if (p2.distance > p.distance) {
        p = p2;
      }
    }
    return p;
  }

  function getPointWeightingFunction(centroid, pathBounds) {
    // Get a factor for weighting a candidate point
    // Points closer to the centroid are slightly preferred
    var referenceDist = Math.max(pathBounds.width(), pathBounds.height()) / 2;
    return function(x, y) {
      var offset = geom.distance2D(centroid.x, centroid.y, x, y);
      return 1 - Math.min(0.6 * offset / referenceDist, 0.25);
    };
  }

  function findAnchorPointCandidates(shp, arcs, xx) {
    var ymin = arcs.getBounds().ymin - 1;
    return xx.reduce(function(memo, x) {
      var cands = findHitCandidates(x, ymin, shp, arcs);
      return memo.concat(cands);
    }, []);
  }

  function probeForBestAnchorPoint(shp, arcs, lbound, rbound, htics, weight) {
    var tics = getInnerTics(lbound, rbound, htics);
    var interval = (rbound - lbound) / htics;
    // Get candidate points, distributed along x-axis
    var candidates = findAnchorPointCandidates(shp, arcs, tics);
    var bestP, adjustedP, candP;

    // Sort candidates so points at the center of longer segments are tried first
    candidates.forEach(function(p) {
      p.interval *= weight(p.x, p.y);
    });
    candidates.sort(function(a, b) {
      return b.interval - a.interval;
    });

    for (var i=0; i<candidates.length; i++) {
      candP = candidates[i];
      // Optimization: Stop searching if weighted half-segment length of remaining
      //   points is less than the weighted edge distance of the best candidate
      if (bestP && bestP.distance > candP.interval) {
        break;
      }
      adjustedP = getAdjustedPoint(candP.x, candP.y, shp, arcs, interval, weight);

      if (!bestP || adjustedP.distance > bestP.distance) {
        bestP = adjustedP;
      }
    }
    return bestP;
  }

  // [x, y] is a point assumed to be inside a polygon @shp
  // Try to move the point farther from the polygon edge
  function getAdjustedPoint(x, y, shp, arcs, vstep, weight) {
    var p = {
      x: x,
      y: y,
      distance: geom.getPointToShapeDistance(x, y, shp, arcs) * weight(x, y)
    };
    scanForBetterPoint(p, shp, arcs, vstep, weight); // scan up
    scanForBetterPoint(p, shp, arcs, -vstep, weight); // scan down
    return p;
  }

  // Try to find a better-fit point than @p by scanning vertically
  // Modify p in-place
  function scanForBetterPoint(p, shp, arcs, vstep, weight) {
    var x = p.x,
        y = p.y,
        dmax = p.distance,
        d;

    while (true) {
      y += vstep;
      d = geom.getPointToShapeDistance(x, y, shp, arcs) * weight(x, y);
      // overcome vary small local minima
      if (d > dmax * 0.90 && geom.testPointInPolygon(x, y, shp, arcs)) {
        if (d > dmax) {
          p.distance = dmax = d;
          p.y = y;
        }
      } else {
        break;
      }
    }
  }

  // Return array of points at the midpoint of each line segment formed by the
  //   intersection of a vertical ray at [x, y] and a polygon shape
  function findHitCandidates(x, y, shp, arcs) {
    var yy = findRayShapeIntersections(x, y, shp, arcs);
    var cands = [], y1, y2, interval;

    // sorting by y-coord organizes y-intercepts into interior segments
    utils.genericSort(yy);
    for (var i=0; i<yy.length; i+=2) {
      y1 = yy[i];
      y2 = yy[i+1];
      interval = (y2 - y1) / 2;
      if (interval > 0) {
        cands.push({
          y: (y1 + y2) / 2,
          x: x,
          interval: interval
        });
      }
    }
    return cands;
  }

  // Return array of y-intersections between vertical ray with origin at [x, y]
  //   and a polygon
  function findRayShapeIntersections(x, y, shp, arcs) {
    if (!shp) return [];
    return shp.reduce(function(memo, path) {
      var yy = findRayRingIntersections(x, y, path, arcs);
      return memo.concat(yy);
    }, []);
  }

  // Return array of y-intersections between vertical ray and a polygon ring
  function findRayRingIntersections(x, y, path, arcs) {
    var yints = [];
    forEachSegmentInPath(path, arcs, function(a, b, xx, yy) {
      var result = geom.getRayIntersection(x, y, xx[a], yy[a], xx[b], yy[b]);
      if (result > -Infinity) {
        yints.push(result);
      }
    });
    // Ignore odd number of intersections -- probably caused by a ray that touches
    //   but doesn't cross the ring
    // TODO: improve method to handle edge case with two touches and no crosses.
    if (yints.length % 2 === 1) {
      yints = [];
    }
    return yints;
  }

  // TODO: find better home + name for this
  function getInnerTics(min, max, steps) {
    var range = max - min,
        step = range / (steps + 1),
        arr = [];
    for (var i = 1; i<=steps; i++) {
      arr.push(min + step * i);
    }
    return arr;
  }

  var AnchorPoints = /*#__PURE__*/Object.freeze({
    __proto__: null,
    findAnchorPoint: findAnchorPoint
  });

  // Returns a function for calculating the percentage of a shape's perimeter by length that
  // is composed of inner (shared) boundaries
  function getInnerPctCalcFunction(arcs, shapes) {
    var calcSegLen = arcs.isPlanar() ? geom.distance2D : geom.greatCircleDistance;
    var arcIndex = new ArcTopologyIndex(arcs, shapes);
    var outerLen, innerLen, arcLen; // temp variables

    return function(shp) {
      outerLen = 0;
      innerLen = 0;
      if (shp) shp.forEach(procRing);
      return innerLen > 0 ? innerLen / (innerLen + outerLen) : 0;
    };

    function procRing(ids) {
      ids.forEach(procArc);
    }

    function procArc(id) {
      arcLen = 0;
      arcs.forEachArcSegment(id, addSegLen);
      if (arcIndex.isInnerArc(id)) {
        innerLen += arcLen;
      } else {
        outerLen += arcLen;
      }
    }

    function addSegLen(i, j, xx, yy) {
      arcLen += calcSegLen(xx[i], yy[i], xx[j], yy[j]);
    }
  }

  function ArcTopologyIndex(arcs, shapes) {
    var index = new Uint8Array(arcs.size());
    forEachArcId(shapes, function(arcId) {
      if (arcId < 0) index[~arcId] |= 2;
      else (index[arcId] |= 1);
    });

    this.isInnerArc = function(arcId) {
      var i = absArcId(arcId);
      return index[i] == 3;
    };
  }

  // convert targets from [{layers: [...], dataset: <>}, ...] format to
  // [{layer: <>, dataset: <>}, ...] format
  function expandCommandTargets(targets) {
    return targets.reduce(function(memo, target) {
      target.layers.forEach(function(lyr) {
        memo.push({layer: lyr, dataset: target.dataset});
      });
      return memo;
    }, []);
  }



  function findCommandTargets(layers, pattern, type) {
    var matches = findMatchingLayers(layers, pattern, true);
    if (type) {
      matches = matches.filter(function(o) {return o.layer.geometry_type == type;});
    }
    // assign target_id to matched layers
    // (kludge so layers can be sorted in the order that they match; used by -o command)
    layers.forEach(function(o) {o.layer.target_id = -1;});
    matches.forEach(function(o, i) {o.layer.target_id = i;});
    return groupLayersByDataset(matches);
  }

  // arr: array of {layer: <>, dataset: <>} objects
  function groupLayersByDataset(arr) {
    var datasets = [];
    var targets = [];
    arr.forEach(function(o) {
      var i = datasets.indexOf(o.dataset);
      if (i == -1) {
        datasets.push(o.dataset);
        targets.push({layers: [o.layer], dataset: o.dataset});
      } else {
        targets[i].layers.push(o.layer);
      }
    });
    return targets;
  }

  // layers: array of {layer: <>, dataset: <>} objects
  // pattern: is a layer identifier or a comma-sep. list of identifiers.
  // An identifier is a literal name, a pattern containing "*" wildcard or
  // a 1-based index (1..n)
  function findMatchingLayers(layers, pattern, throws) {
    var matchedLayers = [];
    var unmatchedIds = [];
    var index = {};
    pattern.split(',').forEach(function(subpattern, i) {
      var test = getLayerMatch(subpattern);
      var matched = false;
      layers.forEach(function(o, layerId) {
        // if (matchedLayers.indexOf(lyr) > -1) return; // performance bottleneck with 1000s of layers
        if (layerId in index) {
          matched = true;
        } else if (test(o.layer, layerId + 1)) {  // layers are 1-indexed
          matchedLayers.push(o);
          index[layerId] = true;
          matched = true;
        }
      });
      if (matched == false) {
        unmatchedIds.push(subpattern);
      }
    });
    if (throws && unmatchedIds.length) {
      stop(utils.format('Missing layer%s: %s', unmatchedIds.length == 1 ? '' : 's', unmatchedIds.join(',')));
    }
    return matchedLayers;
  }

  function getLayerMatch(pattern) {
    var isIndex = utils.isInteger(Number(pattern));
    var nameRxp = isIndex ? null : utils.wildcardToRegExp(pattern);
    return function(lyr, i) {
      return isIndex ? String(i) == pattern : nameRxp.test(lyr.name || '');
    };
  }

  function countTargetLayers(targets) {
    return targets.reduce(function(memo, target) {
      return memo + target.layers.length;
    }, 0);
  }

  // get an identifier for a layer that can be used in a target= option
  // (returns name if layer has a unique name, or a numerical id)
  function getLayerTargetId(catalog, lyr) {
    var nameCount = 0;
        lyr.name;
        var id;
    catalog.getLayers().forEach(function(o, i) {
      if (lyr.name && o.layer.name == lyr.name) nameCount++;
      if (lyr == o.layer) id = String(i + 1);
    });
    if (!id) error('Layer not found');
    return nameCount == 1 ? lyr.name : id;
  }

  var TargetUtils = /*#__PURE__*/Object.freeze({
    __proto__: null,
    expandCommandTargets: expandCommandTargets,
    findCommandTargets: findCommandTargets,
    groupLayersByDataset: groupLayersByDataset,
    findMatchingLayers: findMatchingLayers,
    getLayerMatch: getLayerMatch,
    countTargetLayers: countTargetLayers,
    getLayerTargetId: getLayerTargetId
  });

  function getNullLayerProxy(targets) {
    var obj = {};
    var n = countTargetLayers(targets);
    var getters = {
      name: error,
      data: error,
      type: error,
      size: error,
      empty: error,
      bbox: error
    };
    addGetters(obj, getters);
    obj.field_exists = error;
    obj.field_type = error;
    obj.field_includes = error;
    return obj;
    function error() {
      throw Error(`This expression requires a single target layer; Received ${n} layers.`);
    }
  }



  // Returns an object representing a layer in a JS expression
  function getLayerProxy(lyr, arcs) {
    var obj = {};
    var records = lyr.data ? lyr.data.getRecords() : null;
    var getters = {
      name: lyr.name,
      data: records,
      type: lyr.geometry_type,
      size: getFeatureCount(lyr),
      empty: getFeatureCount(lyr) === 0,
      bbox: getBBoxGetter(obj, lyr, arcs)
    };
    addGetters(obj, getters);
    obj.field_exists = function(name) {
      return lyr.data && lyr.data.fieldExists(name) ? true : false;
    };
    obj.field_type = function(name) {
      return lyr.data && getColumnType(name, lyr.data.getRecords()) || null;
    };
    obj.field_includes = function(name, val) {
      if (!lyr.data) return false;
      return lyr.data.getRecords().some(function(rec) {
        return rec && (rec[name] === val);
      });
    };
    return obj;
  }

  function addLayerGetters(ctx, lyr, arcs) {
    var layerProxy;
    addGetters(ctx, {
      layer_name: lyr.name || '', // consider removing this
      layer: function() {
        // init on first access (to avoid overhead if not used)
        if (!layerProxy) layerProxy = getLayerProxy(lyr, arcs);
        return layerProxy;
      }
    });
    return ctx;
  }

  function getBBoxGetter(obj, lyr, arcs) {
    var bbox;
    return function() {
      if (!bbox) {
        bbox = getBBox$1(lyr, arcs);
      }
      return bbox;
    };
  }

  function getBBox$1(lyr, arcs) {
    var bounds = getLayerBounds(lyr, arcs); // TODO: avoid this overhead if bounds is not used
    if (!bounds) return null;
    var bbox = bounds.toArray();
    Object.assign(bbox, {
      cx: bounds.centerX(),
      cy: bounds.centerY(),
      height: bounds.height(),
      width: bounds.width(),
      left: bounds.xmin,
      bottom: bounds.ymin,
      top: bounds.ymax,
      right: bounds.xmax
    });
    return bbox;
  }

  // Returns a function to return a feature proxy by id
  // (the proxy appears as "this" or "$" in a feature expression)
  function initFeatureProxy(lyr, arcs, optsArg) {
    var opts = optsArg || {},
        hasPoints = layerHasPoints(lyr),
        hasPaths = arcs && layerHasPaths(lyr),
        _records = lyr.data ? lyr.data.getRecords() : null,
        _isPlanar = hasPaths && arcs.isPlanar(),
        ctx = {},
        calcInnerPct,
        _bounds, _centroid, _innerXY, _xy, _ids, _id;

    // all contexts have this.id and this.layer
    addGetters(ctx, {
      id: function() { return _id; }
    });
    addLayerGetters(ctx, lyr, arcs);

    if (opts.geojson_editor) {
      Object.defineProperty(ctx, 'geojson', {
        set: function(o) {
          opts.geojson_editor.set(o, _id);
        },
        get: function() {
          return opts.geojson_editor.get(_id);
        }
      });

      Object.defineProperty(ctx, 'feature', {
        set: function(o) {
          opts.geojson_editor.set(o, _id);
        },
        get: function() {
          return opts.geojson_editor.get(_id);
        }
      });

      Object.defineProperty(ctx, 'geometry', {
        set: function(o) {
          opts.geojson_editor.setGeometry(o, _id);
        },
        get: function() {
          return opts.geojson_editor.getGeometry(_id);
        }
      });
    }

    if (_records) {
      // add r/w member "properties"
      Object.defineProperty(ctx, 'properties',
        {set: function(obj) {
          if (utils.isObject(obj)) {
            _records[_id] = obj;
          } else {
            stop("Can't assign non-object to $.properties");
          }
        }, get: function() {
          var rec = _records[_id];
          if (!rec) {
            rec = _records[_id] = {};
          }
          return rec;
        }});
    }

    if (hasPaths || hasPoints) {
      addGetters(ctx, {
        // TODO: count hole/s + containing ring as one part
        partCount: function() {
          var shp = lyr.shapes[_id];
          return shp ? shp.length : 0;
        },
        isNull: function() {
          return ctx.partCount === 0;
        },
        bounds: function() {
          return shapeBounds().toArray();
        },
        bbox: function() {
          return shapeBounds().toArray();
        },
        height: function() {
          return shapeBounds().height();
        },
        width: function() {
          return shapeBounds().width();
        }
      });
    }

    if (hasPaths) {

      ctx.bboxContainsPoint = function(x, y) {
        var bounds = arcs.getMultiShapeBounds(_ids);
        return bounds.containsPoint(x, y);
      };

      ctx.bboxIntersectsRectangle = function(a, b, c, d) {
        var bbox = arcs.getMultiShapeBounds(_ids);
        var rect = Bounds.from(a, b, c, d);
        return rect.intersects(bbox);
      };

      ctx.bboxContainsRectangle = function(a, b, c, d) {
        var bbox = arcs.getMultiShapeBounds(_ids);
        var rect = Bounds.from(a, b, c, d);
        return bbox.contains(rect);
      };

      ctx.bboxContainedByRectangle = function(a, b, c, d) {
        var bbox = arcs.getMultiShapeBounds(_ids);
        var rect = Bounds.from(a, b, c, d);
        return rect.contains(bbox);
      };

      // TODO
      // ctx.intersectsRectangle = function(a, b, c, d) {}; // paths... points too?
      // ctx.containsPoint = function(x, y) {}; // polygon only
      // ctx.containedByRectangle(a, b, c, d); // paths and points... how do multipart points work?

      if (lyr.geometry_type == 'polyline') {
        addGetters(ctx, {
          'length': function() {
            return geom.getShapePerimeter(_ids, arcs);
          }
        });
      }

      if (lyr.geometry_type == 'polygon') {
        addGetters(ctx, {
          area: function() {
            return _isPlanar ? ctx.planarArea : geom.getSphericalShapeArea(_ids, arcs);
          },
          // area2: function() {
          //   return _isPlanar ? ctx.planarArea : geom.getSphericalShapeArea(_ids, arcs, WGS84.SEMIMINOR_RADIUS);
          // },
          // area3: function() {
          //   return _isPlanar ? ctx.planarArea : geom.getSphericalShapeArea(_ids, arcs, WGS84.AUTHALIC_RADIUS);
          // },
          perimeter: function() {
            return geom.getShapePerimeter(_ids, arcs);
          },
          compactness: function() {
            return geom.calcPolsbyPopperCompactness(ctx.area, ctx.perimeter);
          },
          planarArea: function() {
            return geom.getPlanarShapeArea(_ids, arcs);
          },
          innerPct: function() {
            if (!calcInnerPct) calcInnerPct = getInnerPctCalcFunction(arcs, lyr.shapes);
            return calcInnerPct(_ids);
          },
          originalArea: function() {
            // Get area
            var i = arcs.getRetainedInterval(),
                area;
            arcs.setRetainedInterval(0);
            area = ctx.area;
            arcs.setRetainedInterval(i);
            return area;
          },
          centroidX: function() {
            var p = centroid();
            return p ? p.x : null;
          },
          centroidY: function() {
            var p = centroid();
            return p ? p.y : null;
          },
          innerX: function() {
            var p = innerXY();
            return p ? p.x : null;
          },
          innerY: function() {
            var p = innerXY();
            return p ? p.y : null;
          }
        });
      }

    } else if (hasPoints) {

      Object.defineProperty(ctx, 'coordinates',
        {set: function(obj) {
          if (!obj || utils.isArray(obj)) {
            lyr.shapes[_id] = obj || null;
          } else {
            stop("Can't assign non-array to $.coordinates");
          }
        }, get: function() {
          return lyr.shapes[_id] || null;
        }});
      Object.defineProperty(ctx, 'x', {
        get: function() { xy(); return _xy ? _xy[0] : null;},
        set: function(val) { xy(); if (_xy) _xy[0] = Number(val);}
      });
      Object.defineProperty(ctx, 'y', {
        get: function() { xy(); return _xy ? _xy[1] : null;},
        set: function(val) { xy(); if (_xy) _xy[1] = Number(val);}
      });
    }

    function xy() {
      var shape = lyr.shapes[_id];
      if (!_xy) {
        _xy = shape && shape[0] || null;
      }
    }

    function centroid() {
      _centroid = _centroid || geom.getShapeCentroid(_ids, arcs);
      return _centroid;
    }

    function innerXY() {
      _innerXY = _innerXY || findAnchorPoint(_ids, arcs);
      return _innerXY;
    }

    function shapeBounds() {
      if (_bounds) return _bounds;
      if (hasPaths) {
        _bounds = arcs.getMultiShapeBounds(_ids);
      } else if (hasPoints) {
        _bounds = getPointFeatureBounds(lyr.shapes[_id]);
      } else {
        _bounds = new Bounds();
      }
      return _bounds;
    }

    return function(id) {
      _id = id;
      // reset stored values
      _bounds = null;
      if (hasPaths) {
        _centroid = null;
        _innerXY = null;
        _ids = lyr.shapes[id];
      }
      if (hasPoints) {
        _xy = null;
      }
      return ctx;
    };
  }

  // Return array of objects with properties assigned via dot notation
  // e.g.  'd.value = 45' ->  ['d']
  // export function getAssignmentObjects(exp) {
  //   var matches = getAssignedVars(exp, true),
  //       names = [];
  //   matches.forEach(function(s) {
  //     var match = /^([^.]+)\.[^.]+$/.exec(s);
  //     var name = match ? match[1] : null;
  //     if (name && name != 'this') {
  //       names.push(name);
  //     }
  //   });
  //   return utils.uniq(names);
  // }

  function getExpressionFunction(exp, ctxArg, optsArg) {
    var opts = optsArg || {};
    var ctx = ctxArg || getBaseContext();
    var func = compileExpressionToFunction(exp, opts);
    var vars = getAssignedVars(exp);
    var mutable = !opts.no_assign && vars.length > 0;

    if (opts.no_assign) {
      // protect global object from assigned values when not captured by data record
      nullifyUnsetProperties(vars, ctx);
    }

    // "_" is used as an alias for the expression context, so functions can still
    // be used when masked by variables of the same name.
    ctx._ = ctx;

    return function(rec) {
      var thisVal = ctx.$ || null;
      var val;
      if (mutable) {
        // initialize assigned variables to rec.null so rec can capture them
        nullifyUnsetProperties(vars, rec);
      }
      try {
        val = func.call(thisVal, rec, ctx);
      } catch(e) {
        stop(e.name, "in expression [" + exp + "]:", e.message);
      }
      return val;
    };
  }

  function compileExpressionToFunction(exp, opts) {
    var functionBody;
    exp = cleanExpression(exp);

    if (opts.no_return) {
      functionBody = exp;
    } else {
      // functionBody = 'return ' + functionBody;
      // $$ added to avoid duplication with data field variables (an error condition)
      functionBody = 'var $$retn = ' + exp + '; return $$retn;';
    }
    functionBody = 'with($$env){with($$record){ ' + functionBody + '}}';
    try {
      return new Function('$$record,$$env',  functionBody);
    } catch(e) {
      // if (opts.quiet) throw e;
      stop(e.name, 'in expression [' + exp + ']');
    }
  }

  // Return array of variables on the left side of assignment operations
  // @hasDot (bool) Return property assignments via dot notation
  function getAssignedVars(exp, hasDot) {
    var rxp = /[a-z_$][.a-z0-9_$]*(?= *=[^>=])/ig; // ignore arrow functions and comparisons
    var matches = exp.match(rxp) || [];
    var f = function(s) {
      var i = s.indexOf('.');
      return hasDot ? i > -1 : i == -1;
    };
    var vars = utils.uniq(matches.filter(f));
    return vars;
  }

  function getBaseContext(ctx) {
    ctx = ctx || {};
    // Mask global properties (is this effective/worth doing?)
    ctx.globalThis = void 0; // some globals are not iterable
    (function() {
      for (var key in this) {
        ctx[key] = void 0;
      }
    }());
    ctx.console = console;
    return ctx;
  }

  function nullifyUnsetProperties(vars, obj) {
    for (var i=0; i<vars.length; i++) {
      if (vars[i] in obj === false) {
        obj[vars[i]] = null;
      }
    }
  }

  function cleanExpression(exp) {
    // workaround for problem in GNU Make v4: end-of-line backslashes inside
    // quoted strings are left in the string (other shell environments remove them)
    return exp.replace(/\\\n/g, ' ');
  }

  var Expressions = /*#__PURE__*/Object.freeze({
    __proto__: null,
    getExpressionFunction: getExpressionFunction,
    compileExpressionToFunction: compileExpressionToFunction,
    getAssignedVars: getAssignedVars,
    getBaseContext: getBaseContext,
    nullifyUnsetProperties: nullifyUnsetProperties
  });

  function compileFeatureExpression(exp, lyr, arcs, optsArg) {
    var opts = optsArg || {},
        vars = getAssignedVars(exp);

    if (vars.length > 0 && !lyr.data) {
      initDataTable(lyr);
    }

    var records = lyr.data ? lyr.data.getRecords() : [];
    var getFeatureById = initFeatureProxy(lyr, arcs, opts);
    var layerOnlyProxy = addLayerGetters({}, lyr, arcs);
    var ctx = getFeatureExpressionContext(lyr, opts.context || {}, opts);
    var func = getExpressionFunction(exp, ctx, opts);

    // recId: index of a data record in the records array.
    // destRec: (optional argument, used by -calc) an object used to capture assignments
    //   By default, assignments are captured by records[recId]
    //
    return function(recId, destRec) {
      var rec = destRec || records[recId] || (records[recId] = {});
      // Assigning feature/layer proxy to '$' ... ctx.$ is also exposed as 'this'
      // in the expression context.
      ctx.$ = recId >= 0 ? getFeatureById(recId) : layerOnlyProxy;
      // Expose data properties using "d", like d3 does. (data propertries are
      // also available as "this.properties")
      ctx.d = rec;

      return func(rec);
    };
  }

  function compileFeaturePairFilterExpression(exp, lyr, arcs) {
    var func = compileFeaturePairExpression(exp, lyr, arcs);
    return function(idA, idB) {
      var val = func(idA, idB);
      requireBooleanResult(val, '"where" expression must return true or false');
      return val;
    };
  }

  function compileFeaturePairExpression(exp, lyr, arcs) {
    // don't add layer data to the context
    // (fields are not added to the pair expression context)
    var ctx = getFeatureExpressionContext({});
    var getA = getProxyFactory(lyr, arcs);
    var getB = getProxyFactory(lyr, arcs);
    var func = getExpressionFunction(exp, ctx, {});

    function getProxyFactory(lyr, arcs) {
      var records = lyr.data ? lyr.data.getRecords() : [];
      var getFeatureById = initFeatureProxy(lyr, arcs);
      function Proxy() {}

      return function(id) {
        var proxy;
        if (id == -1) return null;
        Proxy.prototype = records[id] || {};
        proxy = new Proxy();
        proxy.$ = getFeatureById(id);
        return proxy;
      };
    }

    // idA - id of a record
    // idB - id of a record, or -1
    // rec - optional data record
    return function(idA, idB, rec) {
      ctx.A = getA(idA);
      ctx.B = getB(idB);
      return func(rec || {});
    };
  }


  function getFeatureExpressionContext(lyr, mixins, opts) {
    var defs = getStashedVar('defs');
    var env = getBaseContext();
    var ctx = {};
    var fields = lyr.data ? lyr.data.getFields() : [];
    opts = opts || {};
    addFeatureExpressionUtils(env); // mix in round(), sprintf(), etc.
    if (fields.length > 0) {
      // default to null values, so assignments to missing data properties
      // are applied to the data record, not the global object
      nullifyUnsetProperties(fields, env);
    }
    // Add global 'defs' to the expression context
    mixins = utils.defaults(mixins || {}, defs);
    // also add defs as 'global' object
    env.global = defs;
    Object.keys(mixins).forEach(function(key) {
      // Catch name collisions between data fields and user-defined functions
      var d = Object.getOwnPropertyDescriptor(mixins, key);
      if (d.get) {
        // copy accessor function from mixins to context
        Object.defineProperty(ctx, key, {get: d.get}); // copy getter function to context
      } else {
        // copy regular property from mixins to context, but make it non-writable
        Object.defineProperty(ctx, key, {value: mixins[key]});
      }
    });
    // make context properties non-writable, so they can't be replaced by an expression
    return Object.keys(env).reduce(function(memo, key) {
      if (key in memo) {
        // property has already been set (probably by a mixin, above): skip
        // "no_warn" option used in calc= expressions
        if (!opts.no_warn) {
          if (typeof memo[key] == 'function' && fields.indexOf(key) > -1) {
            message('Warning: ' + key + '() function is hiding a data field with the same name');
          } else {
            message('Warning: "' + key + '" has multiple definitions');
          }
        }
      } else {
        Object.defineProperty(memo, key, {value: env[key]}); // writable: false is default
      }
      return memo;
    }, ctx);
  }

  var FeatureExpressions = /*#__PURE__*/Object.freeze({
    __proto__: null,
    compileFeatureExpression: compileFeatureExpression,
    compileFeaturePairFilterExpression: compileFeaturePairFilterExpression,
    compileFeaturePairExpression: compileFeaturePairExpression
  });

  function getMode(values) {
    var data = getModeData(values);
    return data.modes[0];
  }

  function getValueCountData(values) {
    var uniqValues = [],
        uniqIndex = {},
        counts = [];
    var i, val;
    for (i=0; i<values.length; i++) {
      val = values[i];
      if (val in uniqIndex === false) {
        uniqIndex[val] = uniqValues.length;
        uniqValues.push(val);
        counts.push(1);
      } else {
        counts[uniqIndex[val]]++;
      }
    }
    return {
      values: uniqValues,
      counts: counts
    };
  }

  function getMaxValue(values) {
    var max = -Infinity;
    var i;
    for (i=0; i<values.length; i++) {
      if (values[i] > max) max = values[i];
    }
    return max;
  }

  function getCountDataSummary(o) {
    var counts = o.counts;
    var values = o.values;
    var maxCount = counts.length > 0 ? getMaxValue(counts) : 0;
    var nextCount = 0;
    var modes = [];
    var i, count;
    for (i=0; i<counts.length; i++) {
      count = counts[i];
      if (count === maxCount) {
        modes.push(values[i]);
      } else if (count > nextCount) {
        nextCount = count;
      }
    }
    return {
      modes: modes,
      margin: modes.length > 1 ? 0 : maxCount - nextCount,
      count: maxCount
    };
  }

  function getModeData(values, verbose) {
    var counts = getValueCountData(values);
    var modes = getCountDataSummary(counts);
    if (verbose) {
      modes.counts = counts.counts;
      modes.values = counts.values;
    }
    return modes;
  }

  var CalcUtils = /*#__PURE__*/Object.freeze({
    __proto__: null,
    getMode: getMode,
    getModeData: getModeData
  });

  var cmd = {}; // command functions get added to this object

  // Get a copy of a layer containing a subset of the layer's features,
  // given a "where" expression in the options object
  function getLayerSelection(lyr, arcs, opts) {
    var lyr2 = utils.extend({}, lyr);
    var filterOpts = {
          expression: opts.where,
          invert: !!opts.invert,
          verbose: false,   // don't print status message
          no_replace: opts.no_replace // copy features if original features will be retained
        };
    return cmd.filterFeatures(lyr2, arcs, filterOpts);
  }

  // Used to run -dissolve with the where= option; could be generalized to support
  // other commands
  function applyCommandToLayerSelection(commandFunc, lyr, arcs, opts) {
    if (!opts || !opts.where) {
      error('Missing required "where" parameter');
    }
    var subsetLyr = getLayerSelection(lyr, arcs, opts);
    var cmdOpts = utils.defaults({where: null}, opts); // prevent infinite recursion
    var outputLyr = commandFunc(subsetLyr, arcs, cmdOpts);
    var filterOpts = utils.defaults({invert: true}, opts);
    var filteredLyr = getLayerSelection(lyr, arcs, filterOpts);
    var merged = cmd.mergeLayers([filteredLyr, outputLyr], {verbose: false, force: true});
    return merged[0];
  }

  cmd.calc = function(layers, arcs, opts) {
    var arr = layers.map(lyr => applyCalcExpression(lyr, arcs, opts));
    if (!opts.to_layer) return null;
    return {
      info: {},
      layers: [{
        name: opts.name || 'info',
        data: new DataTable(arr)
      }]
    };
  };

  // Calculate an expression across a group of features, print and return the result
  // Supported functions include sum(), average(), max(), min(), median(), count()
  // Functions receive an expression to be applied to each feature (like the -each command)
  // Examples: 'sum($.area)' 'min(income)'
  // opts.expression  Expression to evaluate
  // opts.where  Optional filter expression (see -filter command)
  //
  function applyCalcExpression(lyr, arcs, opts) {
    var msg = opts.expression,
        result, compiled, defs, d;
    if (opts.where) {
      // TODO: implement no_replace option for filter() instead of this
      lyr = getLayerSelection(lyr, arcs, opts);
      msg += ' where ' + opts.where;
    }
    // Save any assigned variables to the defs object, so they will be available
    // for later -each expressions to use.
    defs = getStashedVar('defs');
    compiled = compileCalcExpression(lyr, arcs, opts.expression);
    result = compiled(null, defs);
    if (!opts.to_layer) {
      message(msg + ":  " + result);
    }
    d = {
      expression: opts.expression,
      value: result
    };
    if (opts.where) d.where = opts.where;
    if (lyr.name) d.layer_name = lyr.name;
    return d;
  }

  function evalCalcExpression(lyr, arcs, exp) {
    return compileCalcExpression(lyr, arcs, exp)();
  }

  function compileCalcExpression(lyr, arcs, exp) {
    var rowNo = 0, colNo = 0, recId = -1, cols = [];
    var ctx1 = { // context for first phase (capturing values for each feature)
          count: assign, // dummy function - first pass does nothing
          sum: captureNum,
          sums: capture,
          average: captureNum,
          mean: captureNum,
          median: captureNum,
          quantile: captureNum,
          iqr: captureNum,
          quartile1: captureNum,
          quartile2: captureNum,
          quartile3: captureNum,
          min: captureNum,
          max: captureNum,
          mode: capture,
          collect: capture,
          collectIds: captureId,
          first: assignOnce,
          every: every,
          some: some,
          last: assign
        },
        ctx2 = { // context for second phase (calculating results)
          count: wrap(function() {return rowNo;}, 0),
          sum: wrap(utils.sum, 0),
          sums: wrap(sums),
          median: wrap(utils.findMedian),
          quantile: wrap2(utils.findQuantile),
          iqr: wrap(function(arr) {
            return utils.findQuantile(arr, 0.75) - utils.findQuantile(arr, 0.25);
          }),
          quartile1: wrap(function(arr) { return utils.findQuantile(arr, 0.25); }),
          quartile2: wrap(utils.findMedian),
          quartile3: wrap(function(arr) { return utils.findQuantile(arr, 0.75); }),
          min: wrap(min),
          max: wrap(max),
          average: wrap(utils.mean),
          mean: wrap(utils.mean),
          mode: wrap(getMode),
          collect: wrap(pass),
          collectIds: wrap(pass),
          first: wrap(pass),
          every: wrap(pass, false),
          some: wrap(pass, false),
          last: wrap(pass)
        },
        len = getFeatureCount(lyr),
        calc1, calc2;

    if (lyr.geometry_type) {
      // add functions related to layer geometry (e.g. for subdivide())
      ctx1.width = ctx1.height = noop;
      ctx2.width = function() {return getLayerBounds(lyr, arcs).width();};
      ctx2.height = function() {return getLayerBounds(lyr, arcs).height();};
    }

    calc1 = compileFeatureExpression(exp, lyr, arcs, {context: ctx1,
        no_assign: true, no_warn: true, no_return: true});
    // changed data-only layer to full layer to expose layer geometry, etc
    // (why not do this originally?)
    // calc2 = compileFeatureExpression(exp, {data: lyr.data}, null,
    //     {returns: true, context: ctx2, no_warn: true});
    calc2 = compileFeatureExpression(exp, lyr, arcs, {context: ctx2, no_warn: true});

    // @destRec: optional destination record for assignments
    return function(ids, destRec) {
      var result;
      // phase 1: capture data
      if (ids) procRecords(ids);
      else procAll();
      // phase 2: calculate
      result = calc2(undefined, destRec);
      reset();
      return result;
    };

    function pass(o) {return o;}

    function max(arr) {
      return utils.getArrayBounds(arr).max;
    }

    function sums(arr) {
      var n = arr && arr.length ? arr[0].length : 0;
      var output = utils.initializeArray(Array(n), 0);
      arr.forEach(function(arr) {
        if (!arr || !arr.length) return;
        for (var i=0; i<n; i++) {
          output[i] += +arr[i] || 0;
        }
      });
      return output;
    }

    function min(arr) {
      return utils.getArrayBounds(arr).min;
    }

    // process captured data, or return nodata value if no records have been captured
    function wrap(proc, nullVal) {
      var nodata = arguments.length > 1 ? nullVal : null;
      return function() {
        var c = colNo++;
        return rowNo > 0 ? proc(cols[c]) : nodata;
      };
    }

    function wrap2(proc) {
      return function(arg1, arg2) {
        var c = colNo++;
        return rowNo > 0 ? proc(cols[c], arg2) : null;
      };
    }

    function procAll() {
      for (var i=0; i<len; i++) {
        procRecord(i);
      }
    }

    function procRecords(ids) {
      ids.forEach(procRecord);
    }

    function procRecord(i) {
      if (i < 0 || i >= len) error("Invalid record index");
      recId = i;
      calc1(i);
      rowNo++;
      colNo = 0;
    }

    function noop() {}

    function reset() {
      recId = -1;
      rowNo = 0;
      colNo = 0;
      cols = [];
    }

    function captureNum(val) {
      if (isNaN(val) && val) { // accepting falsy values (be more strict?)
        stop("Expected a number, received:", val);
      }
      return capture(val);
    }

    function assignOnce(val) {
      if (rowNo === 0) cols[colNo] = val;
      colNo++;
      return val;
    }

    function every(val) {
      val = !!val;
      cols[colNo] = rowNo === 0 ? val : cols[colNo] && val;
      colNo++;
    }

    function some(val) {
      val = !!val;
      cols[colNo] = cols[colNo] || val;
      colNo++;
    }

    function assign(val) {
      cols[colNo++] = val;
      return val;
    }
    /*
    function captureArr(val) {
      capture(val);
      return [];
    }
    */

    function captureId() {
      capture(recId);
    }

    function capture(val) {
      var col;
      if (rowNo === 0) {
        cols[colNo] = [];
      }
      col = cols[colNo];
      if (col.length != rowNo) {
        // make sure all functions are called each time
        // (if expression contains a condition, it will throw off the calculation)
        // TODO: allow conditions
        stop("Evaluation failed");
      }
      col.push(val);
      colNo++;
      return val;
    }
  }

  var Calc = /*#__PURE__*/Object.freeze({
    __proto__: null,
    applyCalcExpression: applyCalcExpression,
    evalCalcExpression: evalCalcExpression,
    compileCalcExpression: compileCalcExpression
  });

  // get function that returns an object containing calculated values
  function getJoinCalc(src, exp) {
    var calc = compileCalcExpression({data: src}, null, exp);
    return function(ids, destRec) {
      if (!ids) ids = [];
      calc(ids, destRec);
    };
  }

  var JoinCalc = /*#__PURE__*/Object.freeze({
    __proto__: null,
    getJoinCalc: getJoinCalc
  });

  // Return a function to convert indexes of original features into indexes of grouped features
  // Uses categorical classification (a different id for each unique combination of values)
  function getCategoryClassifier(fields, data) {
    if (!fields || fields.length === 0) return function() {return 0;};
    fields.forEach(function(f) {
      requireDataField(data, f);
    });
    var index = {},
        count = 0,
        records = data.getRecords(),
        getKey = getMultiFieldKeyFunction(fields);
    return function(i) {
      var key = getKey(records[i]);
      if (key in index === false) {
        index[key] = count++;
      }
      return index[key];
    };
  }

  function getMultiFieldKeyFunction(fields) {
    return fields.reduce(function(partial, field) {
      // TODO: consider using JSON.stringify for fields that contain objects
      var strval = function(rec) {return String(rec[field]);};
      return partial ? function(rec) {return partial(rec) + '~~' + strval(rec);} : strval;
    }, null);
  }

  // Performs many-to-one data record aggregation on an array of data records
  // Returns an array of data records for a set of aggregated features
  //
  // @records input records
  // @getGroupId()  converts input record id to id of aggregated record
  //
  function aggregateDataRecords(records, getGroupId, opts) {
    var groups = groupIds(getGroupId, records.length);
    return aggregateDataRecords2(records, groups, opts);
  }

  // Performs many-to-many data record aggregation on an array of data records
  // (used by the -mosaic command)
  // getSourceIds()  receives the id of an output record and returns
  //    an array of input record ids
  //
  function recombineDataRecords(records, getSourceIds, n, opts) {
    var groups = [];
    for (var i=0; i<n; i++) {
      groups.push(getSourceIds(i));
    }
    return aggregateDataRecords2(records, groups, opts);
  }

  function aggregateDataRecords2(records, groups, opts) {
    var sumFields = opts.sum_fields || [],
        copyFields = opts.copy_fields || [],
        calc;

    if (opts.fields) {
      copyFields = copyFields.concat(opts.fields);
    }

    if (opts.calc) {
      calc = getJoinCalc(new DataTable(records), opts.calc);
    }

    function sum(field, group) {
      var tot = 0, rec;
      for (var i=0; i<group.length; i++) {
        rec = records[group[i]];
        tot += rec && rec[field] || 0;
      }
      return tot;
    }

    return groups.map(function(group) {
      var rec = {},
          j, first;
      group = group || [];
      first = records[group[0]];
      for (j=0; j<sumFields.length; j++) {
        rec[sumFields[j]] = sum(sumFields[j], group);
      }
      for (j=0; j<copyFields.length; j++) {
        rec[copyFields[j]] = first ? first[copyFields[j]] : null;
      }
      if (calc) {
        calc(group, rec);
      }
      return rec;
    });
  }

  // Returns array containing groups of feature indexes
  // @getId() (function) converts feature index into group index
  // @n number of features
  //
  function groupIds(getId, n) {
    var groups = [], id;
    for (var i=0; i<n; i++) {
      id = getId(i);
      if (id in groups) {
        groups[id].push(i);
      } else {
        groups[id] = [i];
      }
    }
    return groups;
  }

  var DataAggregation = /*#__PURE__*/Object.freeze({
    __proto__: null,
    getCategoryClassifier: getCategoryClassifier,
    getMultiFieldKeyFunction: getMultiFieldKeyFunction,
    aggregateDataRecords: aggregateDataRecords,
    recombineDataRecords: recombineDataRecords
  });

  function dissolvePointGeometry(lyr, getGroupId, opts) {
    var useSph = !opts.planar && probablyDecimalDegreeBounds(getLayerBounds(lyr));
    var getWeight = opts.weight ? compileFeatureExpression(opts.weight, lyr, null) : null;
    var groups = [];

    // TODO: support multipoints
    if (countMultiPartFeatures(lyr.shapes) !== 0) {
      stop("Dissolving multi-part points is not supported");
    }

    lyr.shapes.forEach(function(shp, i) {
      var groupId = getGroupId(i);
      var weight = getWeight ? getWeight(i) : 1;
      var p = shp && shp[0]; // Using first point (TODO: handle multi-point features)
      var tmp;
      if (!p) return;
      if (useSph) {
        tmp = [];
        geom.lngLatToXYZ(p[0], p[1], tmp);
        p = tmp;
      }
      groups[groupId] = reducePointCentroid(groups[groupId], p, weight);
    });

    return groups.map(function(memo) {
      var p1, p2;
      if (!memo) return null;
      if (useSph) {
        p1 = memo.centroid;
        p2 = [];
        geom.xyzToLngLat(p1[0], p1[1], p1[2], p2);
      } else {
        p2 = memo.centroid;
      }
      return memo ? [p2] : null;
    });
  }

  function reducePointCentroid(memo, p, weight) {
    var x = p[0],
        y = p[1],
        sum, k;

    if (x == x && y == y && weight > 0) {
      if (!memo) {
        memo = {sum: weight, centroid: p.concat()};
      } else {
        sum = memo.sum + weight;
        k = memo.sum / sum;
        memo.centroid[0] = k * memo.centroid[0] + weight * x / sum;
        memo.centroid[1] = k * memo.centroid[1] + weight * y / sum;
        if (p.length == 3) {
          memo.centroid[2] = k * memo.centroid[2] + weight * p[2] / sum;
        }
        memo.sum = sum;
      }
    }
    return memo;
  }

  // Dissolve polyline features
  function dissolvePolylineGeometry(lyr, getGroupId, arcs, opts) {
    var groups = getPolylineDissolveGroups(lyr.shapes, getGroupId);
    var dissolve = getPolylineDissolver(arcs);
    return groups.map(dissolve);
  }

  // Create one array of arc ids for each group
  function getPolylineDissolveGroups(shapes, getGroupId) {
    var groups = [];
    traversePaths(shapes, function(o) {
      var groupId = getGroupId(o.shapeId);
      if (groupId in groups === false) {
        groups[groupId] = [];
      }
      groups[groupId].push(o.arcId);
    });
    return groups;
  }

  function getPolylineDissolver(arcs) {
    var flags = new Uint8Array(arcs.size());
    var testArc = function(id) {return flags[absArcId(id)] > 0;};
    var useArc = function(id) {flags[absArcId(id)] = 0;};
    var nodes = new NodeCollection(arcs);
    return function(ids) {
      ids.forEach(function(id) {flags[absArcId(id)] = 1;});
      var ends = findPolylineEnds(ids, nodes, testArc);
      var straightParts = collectPolylineArcs(ends, nodes, testArc, useArc);
      var ringParts = collectPolylineArcs(ids, nodes, testArc, useArc);
      var allParts = straightParts.concat(ringParts);
      ids.forEach(function(id) {flags[absArcId(id)] = 0;}); // may not be necessary
      return allParts;
    };
  }

  /*



  */

  // TODO: use polygon pathfinder shared code
  function collectPolylineArcs(ids, nodes, testArc, useArc) {
    var parts = [];
    ids.forEach(function(startId) {
      var part = [];
      var nextId = startId;
      var nextIds;
      while (testArc(nextId)) {
        part.push(nextId);
        nextIds = testArc(nextId) ? nodes.getConnectedArcs(nextId, testArc) : [];
        useArc(nextId); // use (unset) arc after connections have been found
        if (nextIds.length > 0) {
          nextId = ~nextIds[0]; // switch arc direction to lead away from node
        } else {
          break;
        }
      }
      if (part.length > 0) parts.push(part);
    });
    return parts;
  }

  // Return array of dead-end arcs for a dissolved group.
  function findPolylineEnds(ids, nodes, filter) {
    var ends = [];
    ids.forEach(function(arcId) {
      if (nodes.getConnectedArcs(arcId, filter).length === 0) {
        ends.push(~arcId); // arc points away from terminus
      }
      if (nodes.getConnectedArcs(~arcId, filter).length === 0) {
        ends.push(arcId);
      }
    });
    return ends;
  }

  function dissolvePolygonGeometry(shapes, getGroupId) {
    var segments = dissolveFirstPass(shapes, getGroupId);
    return dissolveSecondPass(segments, shapes, getGroupId);
  }

  // First pass -- identify pairs of segments that can be dissolved
  function dissolveFirstPass(shapes, getGroupId) {
    var groups = [],
        largeGroups = [],
        segments = [],
        ids = shapes.map(function(shp, i) {
          return getGroupId(i);
        });

    traversePaths(shapes, procArc);
    largeGroups.forEach(splitGroup);
    return segments;

    function procArc(obj) {
      var arcId = obj.arcId,
          idx = arcId < 0 ? ~arcId : arcId,
          segId = segments.length,
          group = groups[idx];
      if (!group) {
        group = [];
        groups[idx] = group;
      }
      group.push(segId);
      obj.group = group;
      segments.push(obj);

      // Three or more segments sharing the same arc is abnormal topology...
      // Need to try to identify pairs of matching segments in each of these
      // groups.
      //
      if (group.length == 3) {
        largeGroups.push(group);
      }
    }

    function findMatchingPair(group, cb) {
      var arc1, arc2;
      for (var i=0; i<group.length - 1; i++) {
        arc1 = segments[group[i]];
        for (var j=i+1; j<group.length; j++) {
          arc2 = segments[group[j]];
          if (cb(arc1, arc2)) {
            return [arc1.segId, arc2.segId];
          }
        }
      }
      return null;
    }

    function checkFwExtension(arc1, arc2) {
      return getNextSegment(arc1, segments, shapes).arcId ===
          ~getNextSegment(arc2, segments, shapes).arcId;
    }

    function checkBwExtension(arc1, arc2) {
      return getPrevSegment(arc1, segments, shapes).arcId ===
          ~getPrevSegment(arc2, segments, shapes).arcId;
    }

    function checkDoubleExtension(arc1, arc2) {
      return checkPairwiseMatch(arc1, arc2) &&
          checkFwExtension(arc1, arc2) &&
          checkBwExtension(arc1, arc2);
    }

    function checkSingleExtension(arc1, arc2) {
      return checkPairwiseMatch(arc1, arc2) &&
          (checkFwExtension(arc1, arc2) ||
          checkBwExtension(arc1, arc2));
    }

    function checkPairwiseMatch(arc1, arc2) {
      return arc1.arcId === ~arc2.arcId && ids[arc1.shapeId] ===
          ids[arc2.shapeId];
    }

    function updateGroupIds(ids) {
      ids.forEach(function(id) {
        segments[id].group = ids;
      });
    }

    // split a group of segments into pairs of matching segments + a residual group
    // @group Array of segment ids
    //
    function splitGroup(group) {
      // find best-match segment pair
      var group2 = findMatchingPair(group, checkDoubleExtension) ||
          findMatchingPair(group, checkSingleExtension) ||
          findMatchingPair(group, checkPairwiseMatch);
      if (group2) {
        group = group.filter(function(i) {
          return !utils.contains(group2, i);
        });
        updateGroupIds(group);
        updateGroupIds(group2);
        // Split again if reduced group is still large
        if (group.length > 2) splitGroup(group);
      }
    }
  }

  // Second pass -- generate dissolved shapes
  //
  function dissolveSecondPass(segments, shapes, getGroupId) {
    var dissolveShapes = [];
    segments.forEach(procSegment);
    return dissolveShapes;

    // @obj is an arc instance
    function procSegment(obj) {
      if (obj.used) return;
      var match = findDissolveArc(obj);
      if (!match) buildRing(obj);
    }

    function addRing(arcs, i) {
      if (i in dissolveShapes === false) {
        dissolveShapes[i] = [];
      }
      dissolveShapes[i].push(arcs);
    }

    // Generate a dissolved ring
    // @firstArc the first arc instance in the ring
    //
    function buildRing(firstArc) {
      var newArcs = [firstArc.arcId],
          nextArc = getNextArc(firstArc);
          firstArc.used = true;

      while (nextArc && nextArc != firstArc) {
        newArcs.push(nextArc.arcId);
        nextArc.used = true;
        nextArc = getNextArc(nextArc);
        if (nextArc && nextArc != firstArc && nextArc.used) error("buildRing() topology error");
      }

      if (!nextArc) error("buildRing() traversal error");
      firstArc.used = true;
      addRing(newArcs, getGroupId(firstArc.shapeId));
    }

    // Get the next arc in a dissolved polygon ring
    // @obj an undissolvable arc instance
    //
    function getNextArc(obj, depth) {
      var next = getNextSegment(obj, segments, shapes),
          match;
      depth = depth || 0;
      if (next != obj) {
        match = findDissolveArc(next);
        if (match) {
          if (depth > 100) {
            error ('deep recursion -- unhandled topology problem');
          }
          // if (match.part.arcs.length == 1) {
          if (shapes[match.shapeId][match.partId].length == 1) {
            // case: @obj has an island inclusion -- keep traversing @obj
            // TODO: test case if @next is first arc in the ring
            next = getNextArc(next, depth + 1);
          } else {
            next = getNextArc(match, depth + 1);
          }
        }
      }
      return next;
    }

    // Look for an arc instance that can be dissolved with segment @obj
    // (must be going the opposite direction and have same dissolve key, etc)
    // Return matching segment or null if no match
    //
    function findDissolveArc(obj) {
      var dissolveId = getGroupId(obj.shapeId), // obj.shape.dissolveKey,
          match, matchId;
      matchId = utils.find(obj.group, function(i) {
        var a = obj,
            b = segments[i];
        if (a == b ||
            b.used ||
            getGroupId(b.shapeId) !== dissolveId ||
            // don't prevent rings from dissolving with themselves (risky?)
            // a.shapeId == b.shapeId && a.partId == b.partId ||
            a.arcId != ~b.arcId) return false;
        return true;
      });
      match = matchId === null ? null : segments[matchId];
      return match;
    }
  }

  function getNextSegment(seg, segments, shapes) {
    return getSegmentByOffs(seg, segments, shapes, 1);
  }

  function getPrevSegment(seg, segments, shapes) {
    return getSegmentByOffs(seg, segments, shapes, -1);
  }

  function getSegmentByOffs(seg, segments, shapes, offs) {
    var arcs = shapes[seg.shapeId][seg.partId],
        partLen = arcs.length,
        nextOffs = (seg.i + offs) % partLen,
        nextSeg;
    if (nextOffs < 0) nextOffs += partLen;
    nextSeg = segments[seg.segId - seg.i + nextOffs];
    if (!nextSeg || nextSeg.shapeId != seg.shapeId) error("index error");
    return nextSeg;
  }

  var PolygonDissolve = /*#__PURE__*/Object.freeze({
    __proto__: null,
    dissolvePolygonGeometry: dissolvePolygonGeometry
  });

  // Generate a dissolved layer
  // @opts.fields (optional) names of data fields (dissolves all if falsy)
  // @opts.sum-fields (Array) (optional)
  // @opts.copy-fields (Array) (optional)
  //
  cmd.dissolve = function(lyr, arcs, opts) {
    var dissolveShapes, getGroupId;
    opts = utils.extend({}, opts);
    if (opts.where) {
      return applyCommandToLayerSelection(cmd.dissolve, lyr, arcs, opts);
    }
    if (opts.field) opts.fields = [opts.field]; // support old "field" parameter
    getGroupId = getCategoryClassifier(opts.fields, lyr.data);
    if (opts.multipart || opts.group_points) {
      dissolveShapes = makeMultipartShapes(lyr, getGroupId);
    } else if (lyr.geometry_type == 'polygon') {
      dissolveShapes = dissolvePolygonGeometry(lyr.shapes, getGroupId);
    } else if (lyr.geometry_type == 'polyline') {
      dissolveShapes = dissolvePolylineGeometry(lyr, getGroupId, arcs);
    } else if (lyr.geometry_type == 'point') {
      dissolveShapes = dissolvePointGeometry(lyr, getGroupId, opts);
    }
    return composeDissolveLayer(lyr, dissolveShapes, getGroupId, opts);
  };

  function makeMultipartShapes(lyr, getGroupId) {
    if (!lyr.shapes || !lyr.geometry_type) {
      stop('Layer is missing geometry');
    }
    cloneShapes(lyr.shapes);
    var shapes2 = [];
    lyr.shapes.forEach(function(shp, i) {
      var groupId = getGroupId(i);
      if (!shp) return;
      if (!shapes2[groupId]) {
        shapes2[groupId] = shp;
      } else {
        shapes2[groupId].push.apply(shapes2[groupId], shp);
      }
    });
    return shapes2;
  }

  // @lyr: original undissolved layer
  // @shapes: dissolved shapes
  function composeDissolveLayer(lyr, shapes, getGroupId, opts) {
    var records = null;
    var lyr2;
    if (lyr.data) {
      records = aggregateDataRecords(lyr.data.getRecords(), getGroupId, opts);
      // replace missing shapes with nulls
      for (var i=0, n=records.length; i<n; i++) {
        if (shapes && !shapes[i]) {
          shapes[i] = null;
        }
      }
    }
    lyr2 = {
      name: opts.no_replace ? null : lyr.name,
      shapes: shapes,
      data: records ? new DataTable(records) : null,
      geometry_type: lyr.geometry_type
    };
    if (!opts.silent) {
      printDissolveMessage(lyr, lyr2);
    }
    return lyr2;
  }

  function printDissolveMessage(pre, post) {
    var n1 = getFeatureCount(pre),
        n2 = getFeatureCount(post),
        msg = utils.format('Dissolved %,d feature%s into %,d feature%s',
          n1, utils.pluralSuffix(n1), n2,
          utils.pluralSuffix(n2));
    message(msg);
  }

  // Maps tile ids to shape ids (both are non-negative integers). Supports
  //    one-to-many mapping (a tile may belong to multiple shapes)
  // Also maps shape ids to tile ids. A shape may contain multiple tiles
  // Also supports 'flattening' -- removing one-to-many tile-shape mappings by
  //    removing all but one shape from a tile.
  // Supports one-to-many mapping
  function TileShapeIndex(mosaic, opts) {
    // indexes for mapping tile ids to shape ids
    var singleIndex = new Int32Array(mosaic.length);
    utils.initializeArray(singleIndex, -1);
    var multipleIndex = [];
    // index that maps shape ids to tile ids
    var shapeIndex = [];

    this.getTileIdsByShapeId = function(shapeId) {
      var ids = shapeIndex[shapeId];
      // need to filter out tile ids that have been set to -1 (indicating removal)
      return ids ? ids.filter(function(id) {return id >= 0;}) : [];
    };

    // assumes index has been flattened
    this.getShapeIdByTileId = function(id) {
      var shapeId = singleIndex[id];
      return shapeId >= 0 ? shapeId : -1;
    };

    // return ids of all shapes that include a tile
    this.getShapeIdsByTileId = function(id) {
      var singleId = singleIndex[id];
      if (singleId >= 0) {
        return [singleId];
      }
      if (singleId == -1) {
        return [];
      }
      return multipleIndex[id];
    };

    this.indexTileIdsByShapeId = function(shapeId, tileIds, weightFunction) {
      shapeIndex[shapeId] = [];
      for (var i=0; i<tileIds.length; i++) {
        indexShapeIdByTileId(shapeId, tileIds[i], weightFunction);
      }
    };

    // remove many-to-one tile=>shape mappings
    this.flatten = function() {
      multipleIndex.forEach(function(shapeIds, tileId) {
        flattenStackedTile(tileId);
      });
      multipleIndex = [];
    };

    this.getUnusedTileIds = function() {
      var ids = [];
      for (var i=0, n=singleIndex.length; i<n; i++) {
        if (singleIndex[i] == -1) ids.push(i);
      }
      return ids;
    };

    // used by gap fill; assumes that flatten() has been called
    this.addTileToShape = function(shapeId, tileId) {
      if (shapeId in shapeIndex === false || singleIndex[tileId] != -1) {
        error('Internal error');
      }
      singleIndex[tileId] = shapeId;
      shapeIndex[shapeId].push(tileId);
    };

    // add a shape id to a tile
    function indexShapeIdByTileId(shapeId, tileId, weightFunction) {
      var singleId = singleIndex[tileId];
      if (singleId != -1 && opts.flat) {
        // pick the best shape if we have a weight function
        if (weightFunction && weightFunction(shapeId) > weightFunction(singleId)) {
          // replace existing shape reference
          removeTileFromShape(tileId, singleId); // bottleneck when overlaps are many
          singleIndex[tileId] = singleId;
          singleId = -1;
        } else {
          // keep existing shape reference
          return;
        }
      }
      if (singleId == -1) {
        singleIndex[tileId] = shapeId;
      } else if (singleId == -2) {
        multipleIndex[tileId].push(shapeId);
      } else {
        multipleIndex[tileId] = [singleId, shapeId];
        singleIndex[tileId] = -2;
      }
      shapeIndex[shapeId].push(tileId);
    }


    function flattenStackedTile(tileId) {
      // TODO: select the best shape (using some metric)
      var shapeIds = multipleIndex[tileId];
      // if (!shapeIds || shapeIds.length > 1 === false) error('flattening error');
      var selectedId = shapeIds[0];
      var shapeId;
      singleIndex[tileId] = selectedId; // add shape to single index
      // remove tile from other stacked shapes
      for (var i=0; i<shapeIds.length; i++) {
        shapeId = shapeIds[i];
        if (shapeId != selectedId) {
          removeTileFromShape(tileId, shapeId);
        }
      }
    }

    function removeTileFromShape(tileId, shapeId) {
      var tileIds = shapeIndex[shapeId];
      for (var i=0; i<tileIds.length; i++) {
        if (tileIds[i] === tileId) {
          tileIds[i] = -1;
          break;
        }
      }
    }
  }

  // Clean polygon or polyline shapes (in-place)
  //
  function cleanShapes(shapes, arcs, type) {
    for (var i=0, n=shapes.length; i<n; i++) {
      shapes[i] = cleanShape(shapes[i], arcs, type);
    }
  }

  // Remove defective arcs and zero-area polygon rings
  // Remove simple polygon spikes of form: [..., id, ~id, ...]
  // Don't remove duplicate points
  // Don't check winding order of polygon rings
  function cleanShape(shape, arcs, type) {
    return editShapeParts(shape, function(path) {
      var cleaned = cleanPath(path, arcs);
      if (type == 'polygon' && cleaned) {
        removeSpikesInPath(cleaned); // assumed by addIntersectionCuts()
        if (geom.getPlanarPathArea(cleaned, arcs) === 0) {
          cleaned = null;
        }
      }
      return cleaned;
    });
  }

  function cleanPath(path, arcs) {
    var nulls = 0;
    for (var i=0, n=path.length; i<n; i++) {
      if (arcs.arcIsDegenerate(path[i])) {
        nulls++;
        path[i] = null;
      }
    }
    return nulls > 0 ? path.filter(function(id) {return id !== null;}) : path;
  }


  // Remove pairs of ids where id[n] == ~id[n+1] or id[0] == ~id[n-1];
  // (in place)
  function removeSpikesInPath(ids) {
    var n = ids.length;
    if (n >= 2) {
      if (ids[0] == ~ids[n-1]) {
        ids.pop();
        ids.shift();
      } else {
        for (var i=1; i<n; i++) {
          if (ids[i-1] == ~ids[i]) {
            ids.splice(i-1, 2);
            break;
          }
        }
      }
      if (ids.length < n) {
        removeSpikesInPath(ids);
      }
    }
  }


  // Returns a function for splitting self-intersecting polygon rings
  // The splitter function receives a single polygon ring represented as an array
  // of arc ids, and returns an array of split-apart rings.
  //
  // Self-intersections in the input ring are assumed to occur at vertices, not along segments.
  // This requires that internal.addIntersectionCuts() has already been run.
  //
  // The rings output by this function may overlap each other, but each ring will
  // be non-self-intersecting. For example, a figure-eight shaped ring will be
  // split into two rings that touch each other where the original ring crossed itself.
  //
  function getSelfIntersectionSplitter(nodes) {
    var pathIndex = new IdTestIndex(nodes.arcs.size(), true);
    var filter = function(arcId) {
      return pathIndex.hasId(~arcId);
    };
    return function(path) {
      pathIndex.setIds(path);
      var paths = dividePath(path);
      pathIndex.clear();
      return paths;
    };

    // Returns array of 0 or more divided paths
    function dividePath(path) {
      var subPaths = null;
      for (var i=0, n=path.length; i < n - 1; i++) { // don't need to check last arc
        subPaths = dividePathAtNode(path, path[i]);
        if (subPaths !== null) {
          return subPaths;
        }
      }
      // indivisible path -- clean it by removing any spikes
      removeSpikesInPath(path);
      return path.length > 0 ? [path] : [];
    }

    // If arc @enterId enters a node with more than one open routes leading out:
    //   return array of sub-paths
    // else return null
    function dividePathAtNode(path, enterId) {
      var nodeIds = nodes.getConnectedArcs(enterId, filter),
          exitArcIndexes, exitArcId, idx;
      if (nodeIds.length < 2) return null;
      exitArcIndexes = [];
      for (var i=0; i<nodeIds.length; i++) {
        exitArcId = ~nodeIds[i];
        idx = indexOf(path, exitArcId);
        if (idx > -1) { // repeated scanning may be bottleneck
          // important optimization (TODO: explain this)
          // TODO: test edge case: exitArcId occurs twice in the path
          pathIndex.clearId(exitArcId);
          exitArcIndexes.push(idx);
        }
      }
      if (exitArcIndexes.length < 2) {
        return null;
      }
      // path forks -- recursively subdivide
      var subPaths = splitPathByIds(path, exitArcIndexes);
      return subPaths.reduce(accumulatePaths, null);
    }

    function accumulatePaths(memo, path) {
      var subPaths = dividePath(path);
      if (memo === null) {
        return subPaths;
      }
      memo.push.apply(memo, subPaths);
      return memo;
    }

    // Added as an optimization -- faster than using Array#indexOf()
    function indexOf(arr, el) {
      for (var i=0, n=arr.length; i<n; i++) {
        if (arr[i] === el) return i;
      }
      return -1;
    }

  }

  // Function returns an array of split-apart rings
  // @path An array of arc ids describing a self-intersecting polygon ring
  // @ids An array of two or more indexes of arcs that originate from a single vertex
  //      where @path intersects itself -- assumes indexes are in ascending sequence
  function splitPathByIds(path, indexes) {
    var subPaths = [];
    utils.genericSort(indexes, true); // sort ascending
    if (indexes[0] > 0) {
      subPaths.push(path.slice(0, indexes[0]));
    }
    for (var i=0, n=indexes.length; i<n; i++) {
      if (i < n-1) {
        subPaths.push(path.slice(indexes[i], indexes[i+1]));
      } else {
        subPaths.push(path.slice(indexes[i]));
      }
    }
    // handle case where first subring is split across endpoint of @path
    if (subPaths.length > indexes.length) {
      utils.merge(subPaths[0], subPaths.pop());
    }
    return subPaths;
  }

  var PathRepair = /*#__PURE__*/Object.freeze({
    __proto__: null,
    cleanShapes: cleanShapes,
    removeSpikesInPath: removeSpikesInPath,
    getSelfIntersectionSplitter: getSelfIntersectionSplitter,
    splitPathByIds: splitPathByIds
  });

  // TODO: also delete positive-space rings nested inside holes
  function deleteHoles(lyr, arcs) {
    editShapes(lyr.shapes, function(path) {
      if (geom.getPathArea(path, arcs) <= 0) {
        return null; // null deletes the path
      }
    });
  }

  // Returns a function that separates rings in a polygon into space-enclosing rings
  // and holes. Also fixes self-intersections.
  //
  function getHoleDivider(nodes, spherical) {
    var split = getSelfIntersectionSplitter(nodes);
    // var split = internal.getSelfIntersectionSplitter_v1(nodes); console.log('split')

    return function(rings, cw, ccw) {
      var pathArea = spherical ? geom.getSphericalPathArea : geom.getPlanarPathArea;
      forEachShapePart(rings, function(ringIds) {
        var splitRings = split(ringIds);
        if (splitRings.length === 0) {
          debug("[getRingDivider()] Defective path:", ringIds);
        }
        splitRings.forEach(function(ringIds, i) {
          var ringArea = pathArea(ringIds, nodes.arcs);
          if (ringArea > 0) {
            cw.push(ringIds);
          } else if (ringArea < 0) {
            ccw.push(ringIds);
          }
        });
      });
    };
  }

  var PolygonHoles = /*#__PURE__*/Object.freeze({
    __proto__: null,
    deleteHoles: deleteHoles,
    getHoleDivider: getHoleDivider
  });

  // Remap any references to duplicate arcs in paths to use the same arcs
  // Remove any unused arcs from the dataset's ArcCollection.
  // Return a NodeCollection
  function cleanArcReferences(dataset) {
    var nodes = new NodeCollection(dataset.arcs);
    var map = findDuplicateArcs(nodes);
    var dropCount;
    if (map) {
      replaceIndexedArcIds(dataset, map);
    }
    dropCount = deleteUnusedArcs(dataset);
    if (dropCount > 0) {
      // rebuild nodes if arcs have changed
      nodes = new NodeCollection(dataset.arcs);
    }
    return nodes;
  }

  function deleteUnusedArcs(dataset) {
    var test = getArcPresenceTest2(dataset.layers, dataset.arcs);
    var count1 = dataset.arcs.size();
    var map = dataset.arcs.deleteArcs(test); // condenses arcs
    var count2 = dataset.arcs.size();
    var deleteCount = count1 - count2;
    if (deleteCount > 0) {
      replaceIndexedArcIds(dataset, map);
    }
    return deleteCount;
  }

  // @map an Object mapping old to new ids
  function replaceIndexedArcIds(dataset, map) {
    var remapPath = function(ids) {
      var arcId, absId, id2;
      for (var i=0; i<ids.length; i++) {
        arcId = ids[i];
        absId = absArcId(arcId);
        id2 = map[absId];
        ids[i] = arcId == absId ? id2 : ~id2;
      }
      return ids;
    };
    dataset.layers.forEach(function(lyr) {
      if (layerHasPaths(lyr)) {
        editShapes(lyr.shapes, remapPath);
      }
    });
  }

  function findDuplicateArcs(nodes) {
    var map = new Int32Array(nodes.arcs.size()),
        count = 0,
        i2;
    for (var i=0, n=nodes.arcs.size(); i<n; i++) {
      i2 = nodes.findDuplicateArc(i);
      map[i] = i2;
      if (i != i2) count++;
    }
    return count > 0 ? map : null;
  }

  // Functions for dividing polygons and polygons at points where arc-segments intersect

  // TODO:
  //    Consider inserting cut points on import, when building initial topology
  //    Improve efficiency (e.g. only update ArcCollection once)
  //    Remove junk arcs (collapsed and duplicate arcs) instead of just removing
  //       references to them

  // Divide a collection of arcs at points where segments intersect
  // and re-index the paths of all the layers that reference the arc collection.
  // (in-place)
  function addIntersectionCuts(dataset, _opts) {
    var opts = _opts || {};
    var arcs = dataset.arcs;
    var arcBounds = arcs && arcs.getBounds();
    var snapDist, nodes;
    if (!arcBounds || !arcBounds.hasBounds()) {
      return new NodeCollection([]);
    }

    if (opts.snap_interval) {
      snapDist = convertIntervalParam(opts.snap_interval, getDatasetCRS(dataset));
    } else if (!opts.no_snap && arcBounds.hasBounds()) {
      snapDist = getHighPrecisionSnapInterval(arcBounds.toArray());
    } else {
      snapDist = 0;
    }
    debug('addIntersectionCuts() snap dist:', snapDist);

    // bake-in any simplification (bug fix; before, -simplify followed by dissolve2
    // used to reset simplification)
    arcs.flatten();

    var changed = snapAndCut(dataset, snapDist);
    // Detect topology again if coordinates have changed
    if (changed || opts.rebuild_topology) {
      buildTopology(dataset);
    }

    // Clean shapes by removing collapsed arc references, etc.
    // TODO: consider alternative -- avoid creating degenerate arcs
    // in insertCutPoints()
    dataset.layers.forEach(function(lyr) {
      if (layerHasPaths(lyr)) {
        cleanShapes(lyr.shapes, arcs, lyr.geometry_type);
      }
    });

    // Further clean-up -- remove duplicate and missing arcs
    nodes = cleanArcReferences(dataset);
    return nodes;
  }

  function snapAndCut(dataset, snapDist) {
    var arcs = dataset.arcs;
    var cutOpts = snapDist > 0 ? {} : {tolerance: 0};
    var coordsHaveChanged = false;
    var snapCount, dupeCount, cutCount;
    snapCount = snapCoordsByInterval(arcs, snapDist);
    dupeCount = arcs.dedupCoords();

    // why was topology built here previously????
    // if (snapCount > 0 || dupeCount > 0) {
    //   // Detect topology again if coordinates have changed
    //   internal.buildTopology(dataset);
    // }

    // cut arcs at points where segments intersect
    cutCount = cutPathsAtIntersections(dataset, cutOpts);
    if (cutCount > 0 || snapCount > 0 || dupeCount > 0) {
      coordsHaveChanged = true;
    }
    // perform a second snap + cut pass if needed
    if (cutCount > 0) {
      cutCount = 0;
      snapCount = snapCoordsByInterval(arcs, snapDist);
      arcs.dedupCoords(); // need to do this here?
      if (snapCount > 0) {
        cutCount = cutPathsAtIntersections(dataset, cutOpts);
      }
      if (cutCount > 0) {
        arcs.dedupCoords(); // need to do this here?
        debug('Second-pass vertices added:', cutCount, 'consider third pass?');
      }
    }
    return coordsHaveChanged;
  }


  // Return a function for updating a path (array of arc ids)
  // @map array generated by insertCutPoints()
  // @arcCount number of arcs in divided collection (kludge)
  function getDividedArcUpdater(map, arcCount) {
    return function(ids) {
      var ids2 = [];
      for (var j=0; j<ids.length; j++) {
        remapArcId2(ids[j], ids2);
      }
      return ids2;
    };

    function remapArcId2(id, ids) {
      var rev = id < 0,
          absId = rev ? ~id : id,
          min = map[absId],
          max = (absId >= map.length - 1 ? arcCount : map[absId + 1]) - 1,
          id2;
      do {
        if (rev) {
          id2 = ~max;
          max--;
        } else {
          id2 = min;
          min++;
        }
        ids.push(id2);
      } while (max - min >= 0);
    }
  }

  // Divides a collection of arcs at points where arc paths cross each other
  // Returns array for remapping arc ids
  function divideArcs(arcs, opts) {
    var points = findClippingPoints(arcs, opts);
    // TODO: avoid the following if no points need to be added
    var map = insertCutPoints(points, arcs);
    // segment-point intersections currently create duplicate points
    // TODO: consider dedup in a later cleanup pass?
    // arcs.dedupCoords();
    return map;
  }

  function cutPathsAtIntersections(dataset, opts) {
    var n = dataset.arcs.getPointCount();
    var map = divideArcs(dataset.arcs, opts);
    var n2 = dataset.arcs.getPointCount();
    remapDividedArcs(dataset, map);
    return n2 - n;
  }

  function remapDividedArcs(dataset, map) {
    var remapPath = getDividedArcUpdater(map, dataset.arcs.size());
    dataset.layers.forEach(function(lyr) {
      if (layerHasPaths(lyr)) {
        editShapes(lyr.shapes, remapPath);
      }
    });
  }

  // Inserts array of cutting points into an ArcCollection
  // Returns array for remapping arc ids
  function insertCutPoints(unfilteredPoints, arcs) {
    var data = arcs.getVertexData(),
        xx0 = data.xx,
        yy0 = data.yy,
        nn0 = data.nn,
        i0 = 0,
        i1 = 0,
        nn1 = [],
        srcArcTotal = arcs.size(),
        map = new Uint32Array(srcArcTotal),
        points = filterSortedCutPoints(sortCutPoints(unfilteredPoints, xx0, yy0), arcs),
        destPointTotal = arcs.getPointCount() + points.length * 2,
        xx1 = new Float64Array(destPointTotal),
        yy1 = new Float64Array(destPointTotal),
        n0, n1, arcLen, p;

    points.reverse(); // reverse sorted order to use pop()
    p = points.pop();

    for (var srcArcId=0, destArcId=0; srcArcId < srcArcTotal; srcArcId++) {
      // start merging an arc
      arcLen = nn0[srcArcId];
      map[srcArcId] = destArcId;
      n0 = 0;
      n1 = 0;
      while (n0 < arcLen) {
        // copy another point
        xx1[i1] = xx0[i0];
        yy1[i1] = yy0[i0];
        i1++;
        n1++;
        while (p && p.i == i0) {
          // interpolate any clip points that fall within the current segment
          xx1[i1] = p.x;
          yy1[i1] = p.y;
          i1++;
          n1++;
          nn1[destArcId++] = n1; // end current arc at intersection
          n1 = 0; // begin new arc
          xx1[i1] = p.x;
          yy1[i1] = p.y;
          i1++;
          n1++;
          p = points.pop();
        }
        n0++;
        i0++;
      }
      nn1[destArcId++] = n1;
    }

    if (i1 != destPointTotal) error("[insertCutPoints()] Counting error");
    arcs.updateVertexData(nn1, xx1, yy1, null);
    return map;
  }

  function convertIntersectionsToCutPoints(intersections, xx, yy) {
    var points = [], ix, a, b;
    for (var i=0, n=intersections.length; i<n; i++) {
      ix = intersections[i];
      a = getCutPoint(ix.x, ix.y, ix.a[0], ix.a[1]);
      b = getCutPoint(ix.x, ix.y, ix.b[0], ix.b[1]);
      if (a) points.push(a);
      if (b) points.push(b);
    }
    return points;
  }

  // i, j: indexes of segment endpoints in xx, yy, or of a single endpoint
  //   if point x,y falls on an endpoint
  // Assumes: i <= j
  function getCutPoint(x, y, i, j, xx, yy) {
    if (j < i || j > i + 1) {
      error("Out-of-sequence arc ids:", i, j);
    }

    // Removed out-of-range check: small out-of-range intersection points are now allowed.
    // (Such points may occur due to fp rounding, when intersections occur along
    // vertical or horizontal segments)
    // if (geom.outsideRange(x, ix, jx) || geom.outsideRange(y, iy, jy)) {
      // return null;
    // }

    // Removed endpoint check: intersecting arcs need to be cut both at vertices
    // and between vertices, so pathfinding functions will work correctly.
    // if (x == ix && y == iy || x == jx && y == jy) {
      // return null;
    // }
    return {x: x, y: y, i: i};
  }

  // Sort insertion points in order of insertion
  // Insertion order: ascending id of first endpoint of containing segment and
  //   ascending distance from same endpoint.
  function sortCutPoints(points, xx, yy) {
    points.sort(function(a, b) {
      if (a.i != b.i) return a.i - b.i;
      return geom.distanceSq(xx[a.i], yy[a.i], a.x, a.y) - geom.distanceSq(xx[b.i], yy[b.i], b.x, b.y);
      // The old code below is no longer reliable, now that out-of-range intersection
      // points are allowed.
      // return Math.abs(a.x - xx[a.i]) - Math.abs(b.x - xx[b.i]) ||
      // Math.abs(a.y - yy[a.i]) - Math.abs(b.y - yy[b.i]);
    });
    return points;
  }

  // Removes duplicate points and arc endpoints
  function filterSortedCutPoints(points, arcs) {
    var filtered = [],
        pointId = 0;
    arcs.forEach2(function(i, n, xx, yy) {
      var j = i + n - 1,
          x0 = xx[i],
          y0 = yy[i],
          xn = xx[j],
          yn = yy[j],
          p, pp;

      while (pointId < points.length && points[pointId].i <= j) {
        p = points[pointId];
        pp = filtered[filtered.length - 1]; // previous point
        if (p.x == x0 && p.y == y0 || p.x == xn && p.y == yn) ; else if (pp && pp.x == p.x && pp.y == p.y && pp.i == p.i) ; else {
          filtered.push(p);
        }
        pointId++;
      }
    });
    return filtered;
  }

  function findClippingPoints(arcs, opts) {
    var intersections = findSegmentIntersections(arcs, opts),
        data = arcs.getVertexData();
    return convertIntersectionsToCutPoints(intersections, data.xx, data.yy);
  }

  var IntersectionCuts = /*#__PURE__*/Object.freeze({
    __proto__: null,
    addIntersectionCuts: addIntersectionCuts,
    divideArcs: divideArcs,
    cutPathsAtIntersections: cutPathsAtIntersections,
    remapDividedArcs: remapDividedArcs,
    insertCutPoints: insertCutPoints,
    getCutPoint: getCutPoint,
    sortCutPoints: sortCutPoints,
    filterSortedCutPoints: filterSortedCutPoints,
    findClippingPoints: findClippingPoints
  });

  // Support for timing using T.start() and T.stop()
  var T$1 = {
    stack: [],
    start: function() {
      T$1.stack.push(Date.now());
    },
    stop: function() {
      return (Date.now() - T$1.stack.pop()) + 'ms';
    }
  };

  // Create a mosaic layer from a dataset (useful for debugging commands like -clean
  //    that create a mosaic as an intermediate data structure)
  // Create additional layers if the "debug" flag is present
  //
  function mosaic(dataset, opts) {
    var layers2 = [];
    var nodes, output;
    if (!dataset.arcs) stop("Dataset is missing path data");
    nodes = addIntersectionCuts(dataset, opts);
    output = buildPolygonMosaic(nodes);
    layers2.push({
      name: 'mosaic',
      shapes: output.mosaic,
      geometry_type: 'polygon'
    });
    if (opts.debug) {
      layers2.push({
        geometry_type: 'polygon',
        name: 'mosaic-enclosure',
        shapes: output.enclosures
      });

      if (output.lostArcs.length > 0) {
        layers2 = layers2.concat(getLostArcLayers(output.lostArcs, nodes.arcs));
      }
    }
    return layers2;

    function getLostArcLayers(lostArcs, arcs) {
      var arcLyr = {geometry_type: 'polyline', name: 'lost-arcs', shapes: []};
      var pointLyr = {geometry_type: 'point', name: 'lost-arc-endpoints', shapes: []};
      var arcData = [];
      var pointData = [];
      lostArcs.forEach(function(arcId) {
        var first = arcs.getVertex(arcId, 0);
        var last = arcs.getVertex(arcId, -1);
        arcData.push({ARCID: arcId});
        arcLyr.shapes.push([[arcId]]);
        pointData.push({ARCID: arcId}, {ARCID: arcId});
        pointLyr.shapes.push([[first.x, first.y]], [[last.x, last.y]]);
      });
      arcLyr.data = new DataTable(arcData);
      pointLyr.data = new DataTable(pointData);
      return [arcLyr, pointLyr];
    }
  }

  // Process arc-node topology to generate a layer of indivisible mosaic "tiles" {mosaic}
  //   ... also return a layer of outer-boundary polygons {enclosures}
  //   ... also return an array of arcs that were dropped from the mosaic {lostArcs}
  //
  // Assumes that the arc-node topology of @nodes NodeCollection meets several
  //    conditions (expected to be true if addIntersectionCuts() has just been run)
  // 1. Arcs only touch at endpoints.
  // 2. The angle between any two segments that meet at a node is never zero.
  //      (this should follow from 1... but may occur due to FP errors)
  // TODO: a better job of handling FP errors
  //
  function buildPolygonMosaic(nodes) {
    T$1.start();
    // Detach any acyclic paths (spikes) from arc graph (these would interfere with
    //    the ring finding operation). This modifies @nodes -- a side effect.
    nodes.detachAcyclicArcs();
    var data = findMosaicRings(nodes);

    // Process CW rings: these are indivisible space-enclosing boundaries of mosaic tiles
    var mosaic = data.cw.map(function(ring) {return [ring];});
    debug('Find mosaic rings', T$1.stop());
    T$1.start();

    // Process CCW rings: these are either holes or enclosure
    // TODO: optimize -- testing CCW path of every island is costly
    var enclosures = [];
    var index = new PathIndex(mosaic, nodes.arcs); // index CW rings to help identify holes
    data.ccw.forEach(function(ring) {
      var id = index.findSmallestEnclosingPolygon(ring);
      if (id > -1) {
        // Enclosed CCW rings are holes in the enclosing mosaic tile
        mosaic[id].push(ring);
      } else {
        // Non-enclosed CCW rings are outer boundaries -- add to enclosures layer
        reversePath(ring);
        enclosures.push([ring]);
      }
    });
    debug(utils.format("Detect holes (holes: %d, enclosures: %d)", data.ccw.length - enclosures.length, enclosures.length), T$1.stop());

    return {mosaic: mosaic, enclosures: enclosures, lostArcs: data.lostArcs};
  }

  function findMosaicRings(nodes) {
    var arcs = nodes.arcs,
        cw = [],
        ccw = [],
        empty = [],
        lostArcs = [];

    var flags = new Uint8Array(arcs.size());
    var findPath = getPathFinder(nodes, useRoute);

    for (var i=0, n=flags.length; i<n; i++) {
      tryPath(i);
      // TODO: consider skipping detection of island ccw paths here (if possible)
      tryPath(~i);
    }
    return {
      cw: cw,
      ccw: ccw,
      empty: empty,
      lostArcs: lostArcs
    };

    function tryPath(arcId) {
      var ring, area;
      if (!routeIsOpen(arcId)) return;
      ring = findPath(arcId);
      if (!ring) {
        // arc is unused, but can not be extended to a complete ring
        lostArcs.push(arcId);
        debug("Dead-end arc:", arcId);
        return;
      }
      area = geom.getPlanarPathArea(ring, arcs);
      if (area > 0) {
        cw.push(ring);
      } else if (area < 0) {
        ccw.push(ring);
      } else {
        empty.push(ring);
      }
    }

    function useRoute(arcId) {
      return routeIsOpen(arcId, true);
    }

    function routeIsOpen(arcId, closeRoute) {
      var absId = absArcId(arcId);
      var bit = absId == arcId ? 1 : 2;
      var isOpen = (flags[absId] & bit) === 0;
      if (closeRoute && isOpen) flags[absId] |= bit;
      return isOpen;
    }
  }

  var PolygonMosaic = /*#__PURE__*/Object.freeze({
    __proto__: null,
    mosaic: mosaic,
    buildPolygonMosaic: buildPolygonMosaic
  });

  // Map non-negative integers to non-negative integer ids
  function IdLookupIndex(n) {
    var index = new Uint32Array(n);

    this.setId = function(id, val) {
      if (id >= 0 && val >= 0 && val < n - 1) {
        index[id] = val + 1;
      } else {
        error('Invalid value');
      }
    };

    this.hasId = function(id) {
      return this.getId(id) > -1;
    };

    this.getId = function(id) {
      if (id >= 0 && id < n) {
        return index[id] - 1;
      } else {
        return -1;
        // error('Invalid index');
      }
    };
  }


  // Map positive or negative integer ids to non-negative integer ids
  function ArcLookupIndex(n) {
    var fwdIndex = new Int32Array(n);
    var revIndex = new Int32Array(n);
    utils.initializeArray(fwdIndex, -1);
    utils.initializeArray(revIndex, -1);

    this.setId = function(id, val) {
      if (id < 0) {
        revIndex[~id] = val;
      } else {
        fwdIndex[id] = val;
      }
    };

    this.hasId = function(id) {
      var val = this.getId(id);
      return val > -1;
    };

    this.getId = function(id) {
      var idx = id < 0 ? ~id : id;
      if (idx >= n) {
        return -1; // TODO: consider throwing an error?
      }
      return id < 0 ? revIndex[idx] : fwdIndex[idx];
    };
  }

  // Support clearing the index (for efficient reuse)
  function ClearableArcLookupIndex(n) {
    var setList = [];
    var idx = new ArcLookupIndex(n);
    var _setId = idx.setId;

    idx.setId = function(id, val) {
      if (!idx.hasId(id)) {
        setList.push(id);
      }
      _setId(id, val);
    };

    idx.clear = function() {
      setList.forEach(function(id) {
        _setId(id, -1);
      });
      setList = [];
    };

    this.clearId = function(id) {
      if (!idx.hasId(id)) {
        error('Tried to clear an unset id');
      }
      _setId(id, -1);
    };

    return idx;
  }

  // Associate mosaic tiles with shapes (i.e. identify the groups of tiles that
  //   belong to each shape)
  //
  function PolygonTiler(mosaic, arcTileIndex, nodes, opts) {
    var arcs = nodes.arcs;
    var visitedTileIndex = new IdTestIndex(mosaic.length, true);
    var divide = getHoleDivider(nodes);
    // temp vars
    var currHoles; // arc ids of all holes in shape
    var currRingBbox;
    var tilesInShape; // accumulator for tile ids of tiles in current shape
    var ringIndex = new IdTestIndex(arcs.size(), true);
    var holeIndex = new IdTestIndex(arcs.size(), true);

    // return ids of tiles in shape
    this.getTilesInShape = function(shp, shapeId) {
      var cw = [], ccw = [], retn;
      tilesInShape = [];
      currHoles = [];
      if (opts.no_holes) {
        divide(shp, cw, ccw);
        // ccw.forEach(internal.reversePath);
        // cw = cw.concat(ccw);
      } else {
        // divide shape into rings and holes (splits self-intersecting rings)
        // TODO: rewrite divide() -- it is a performance bottleneck and can convert
        //   space-filling areas into ccw holes
        divide(shp, cw, ccw);
        ccw.forEach(procShapeHole);
        holeIndex.setIds(currHoles);
      }
      cw.forEach(procShapeRing);
      retn = tilesInShape;
      // reset tmp vars, etc
      tilesInShape = null;
      holeIndex.clear();
      currHoles = null;
      return retn;
    };

    function procShapeHole(path) {
      currHoles = currHoles ? currHoles.concat(path) : path;
    }

    function procShapeRing(path) {
      currRingBbox = arcs.getSimpleShapeBbox(path);
      ringIndex.setIds(path);
      procArcIds(path);
      ringIndex.clear();
      // allow overlapping rings to visit the same tiles
      visitedTileIndex.clear();
    }

    // optimized version: traversal without recursion (to avoid call stack oflo, excessive gc, etc)
    function procArcIds(ids) {
      var stack = ids.concat();
      var arcId, tileId;
      while (stack.length > 0) {
        arcId = stack.pop();
        tileId = procRingArc(arcId);
        if (tileId >= 0) {
          accumulateTraversibleArcIds(stack, mosaic[tileId]);
        }
      }
    }

    function accumulateTraversibleArcIds(ids, tile) {
      var arcId, ring;
      for (var j=0, n=tile.length; j<n; j++) {
        ring = tile[j];
        for (var i=0, m=ring.length; i<m; i++) {
          arcId = ring[i];
          if (arcIsTraversible(arcId)) {
            ids.push(~arcId);
          }
        }
      }
    }

    function arcIsTraversible(tileArc) {
      var neighborArc = ~tileArc;
      var traversible = !(ringIndex.hasId(tileArc) || ringIndex.hasId(neighborArc) || holeIndex.hasId(tileArc) || holeIndex.hasId(neighborArc));
      return traversible;
    }

    function procRingArc(arcId) {
      var tileId = arcTileIndex.getShapeIdByArcId(arcId);
      if (tileId == -1 || visitedTileIndex.hasId(tileId)) return -1;
      if (arcs.arcIsContained(absArcId(arcId), currRingBbox) === false) {
        // don't cross boundary of the current ring or of any hole in the current shape
        // TODO: this indicates a geometry bug that should be fixed
        debug('Out-of-bounds ring arc', arcId);
        return -1;
      }
      visitedTileIndex.setId(tileId);
      tilesInShape.push(tileId);
      return tileId;
    }
  }

  var PolygonTiler$1 = /*#__PURE__*/Object.freeze({
    __proto__: null,
    PolygonTiler: PolygonTiler
  });

  function MosaicIndex(lyr, nodes, optsArg) {
    var opts = optsArg || {};
    var shapes = lyr.shapes;
    getHoleDivider(nodes);
    var mosaic = buildPolygonMosaic(nodes).mosaic;
    // map arc ids to tile ids
    var arcTileIndex = new ShapeArcIndex(mosaic, nodes.arcs);
    // keep track of which tiles have been assigned to shapes
    var fetchedTileIndex = new IdTestIndex(mosaic.length, true);
    // bidirection index of tile ids <=> shape ids
    var tileShapeIndex = new TileShapeIndex(mosaic, opts);
    // assign tiles to shapes
    var shapeTiler = new PolygonTiler(mosaic, arcTileIndex, nodes, opts);
    var weightFunction = null;
    if (!opts.simple && opts.flat) {
      // opts.simple is an optimization when dissolving everything into one polygon
      // using -dissolve2. In this situation, we don't need a weight function.
      // Otherwise, if polygons are being dissolved into multiple groups,
      // we use a function to assign tiles in overlapping areas to a single shape.
      weightFunction = getOverlapPriorityFunction(lyr.shapes, nodes.arcs, opts.overlap_rule);
    }
    this.mosaic = mosaic;
    this.nodes = nodes; // kludge
    this.getSourceIdsByTileId = tileShapeIndex.getShapeIdsByTileId; // expose for -mosaic command
    this.getTileIdsByShapeId = tileShapeIndex.getTileIdsByShapeId;

    // Assign shape ids to mosaic tile shapes.
    shapes.forEach(function(shp, shapeId) {
      var tileIds = shapeTiler.getTilesInShape(shp, shapeId);
      tileShapeIndex.indexTileIdsByShapeId(shapeId, tileIds, weightFunction);
    });

    // ensure each tile is assigned to only one shape
    if (opts.flat) {
      tileShapeIndex.flatten();
    }

    // fill gaps
    // (assumes that tiles have been allocated to shapes and mosaic has been flattened)
    this.removeGaps = function(filter) {
      if (!opts.flat) {
        error('MosaicIndex#removeGaps() should only be called with a flat mosaic');
      }
      var remainingIds = tileShapeIndex.getUnusedTileIds();
      var filledIds = remainingIds.filter(function(tileId) {
        var tile = mosaic[tileId];
        return filter(tile[0]); // test tile ring, ignoring any holes (does this matter?)
      });
      filledIds.forEach(assignTileToAdjacentShape);
      return {
        removed: filledIds.length,
        remaining: remainingIds.length - filledIds.length
      };
    };

    this.getUnusedTiles = function() {
      return tileShapeIndex.getUnusedTileIds().map(tileIdToTile);
    };

    this.getTilesByShapeIds = function(shapeIds) {
      return getTileIdsByShapeIds(shapeIds).map(tileIdToTile);
    };

    function getOverlapPriorityFunction(shapes, arcs, rule) {
      var f;
      if (!rule || rule == 'max-area') {
        f = getAreaWeightFunction(shapes, arcs, false);
      } else if (rule == 'min-area') {
        f = getAreaWeightFunction(shapes, arcs, true);
      } else if (rule == 'max-id') {
        f = function(shapeId) {
          return shapeId; };
      } else if (rule == 'min-id') {
        f = function(shapeId) { return -shapeId; };
      } else {
        stop('Unknown overlap rule:', rule);
      }
      return f;
    }

    function getAreaWeightFunction(shapes, arcs, invert) {
      var index = [];
      var sign = invert ? -1 : 1;
      return function(shpId) {
        var weight;
        if (shpId in index) {
          weight = index[shpId];
        } else {
          weight = sign * Math.abs(geom.getShapeArea(shapes[shpId], arcs));
          index[shpId] = weight;
        }
        return weight;
      };
    }

    function tileIdToTile(id, i) {
      return mosaic[id];
    }

    function assignTileToAdjacentShape(tileId) {
      var ring = mosaic[tileId][0];
      var arcs = nodes.arcs;
      var arcId, neighborShapeId, neighborTileId, arcLen;
      var shapeId = -1, maxArcLen = 0;
      for (var i=0; i<ring.length; i++) {
        arcId = ring[i];
        neighborTileId = arcTileIndex.getShapeIdByArcId(~arcId);
        if (neighborTileId < 0) continue;
        neighborShapeId = tileShapeIndex.getShapeIdByTileId(neighborTileId);
        if (neighborShapeId < 0) continue;
        arcLen = geom.getPathPerimeter([arcId], arcs);
        if (arcLen > maxArcLen) {
          shapeId = neighborShapeId;
          maxArcLen = arcLen;
        }
      }
      if (shapeId > -1) {
        tileShapeIndex.addTileToShape(shapeId, tileId);
      }
    }

    function getTileIdsByShapeIds(shapeIds) {
      var uniqIds = [];
      var tileId, tileIds, i, j;
      for (i=0; i<shapeIds.length; i++) {
        tileIds = tileShapeIndex.getTileIdsByShapeId(shapeIds[i]);
        for (j=0; j<tileIds.length; j++) {
          tileId = tileIds[j];
          // uniqify tile ids (in case the shape contains overlapping rings)
          if (fetchedTileIndex.hasId(tileId)) continue;
          fetchedTileIndex.setId(tileId);
          uniqIds.push(tileId);
        }
      }
      // clearing this index allows duplicate tile ids between calls to this function
      // (should not happen in a typical dissolve)
      fetchedTileIndex.clear();
      return uniqIds;
    }
  }

  // Map arc ids to shape ids, assuming perfect topology
  // (an arcId maps to at most one shape)
  // Supports looking up a shape id using an arc id.
  function ShapeArcIndex(shapes, arcs) {
    var n = arcs.size();
    var index = new ArcLookupIndex(n);
    var shapeId;
    shapes.forEach(onShape);

    function onShape(shp, i) {
      shapeId = i;
      shp.forEach(onPart);
    }
    function onPart(path) {
      var arcId;
      for (var i=0, n=path.length; i<n; i++) {
        arcId = path[i];
        index.setId(arcId, shapeId);
      }
    }

    // returns -1 if shape has not been indexed
    this.getShapeIdByArcId = function(arcId) {
      return index.getId(arcId);
    };
  }

  var MosaicIndex$1 = /*#__PURE__*/Object.freeze({
    __proto__: null,
    MosaicIndex: MosaicIndex,
    ShapeArcIndex: ShapeArcIndex
  });

  // Assumes that arcs do not intersect except at endpoints
  function dissolvePolygonLayer2(lyr, dataset, opts) {
    opts = utils.extend({}, opts);
    if (opts.field) {
      opts.fields = [opts.field]; // support old "field" parameter
    }
    var getGroupId = getCategoryClassifier(opts.fields, lyr.data);
    var groups = groupPolygons2(lyr, getGroupId);
    var shapes2 = dissolvePolygonGroups2(groups, lyr, dataset, opts);
    return composeDissolveLayer(lyr, shapes2, getGroupId, opts);
  }

  function composeMosaicLayer(lyr, shapes2) {
    var records = shapes2.map(function(shp, i) {
      return {tile_id: i};
    });
    return utils.defaults({
      shapes: shapes2,
      data: new DataTable(records)
    }, lyr);
  }

  function groupPolygons2(lyr, getGroupId) {
    return lyr.shapes.reduce(function(groups, shape, shapeId) {
      var groupId = getGroupId(shapeId);
      if (groupId in groups === false) {
        groups[groupId] = [];
      }
      groups[groupId].push(shapeId);
      return groups;
    }, []);
  }

  function getGapRemovalMessage(removed, retained, areaLabel) {
    var tot = removed + retained;
    if (removed > 0 === false) return '';
    return utils.format('Removed %,d of %,d sliver%s using %s',
        removed, tot, utils.pluralSuffix(tot), areaLabel);
  }

  function dissolvePolygonGroups2(groups, lyr, dataset, opts) {
    var arcFilter = getArcPresenceTest(lyr.shapes, dataset.arcs);
    var nodes = new NodeCollection(dataset.arcs, arcFilter);
    var mosaicOpts = {
      flat: !opts.allow_overlaps,
      simple: groups.length == 1,
      overlap_rule: opts.overlap_rule
    };
    var mosaicIndex = new MosaicIndex(lyr, nodes, mosaicOpts);
    // gap fill doesn't work yet with overlapping shapes
    var fillGaps = !opts.allow_overlaps && (opts.sliver_control || opts.gap_fill_area);
    var cleanupData, filterData;
    if (fillGaps) {
      var sliverOpts = utils.extend({sliver_control: 1}, opts);
      filterData = getSliverFilter(lyr, dataset, sliverOpts);
      cleanupData = mosaicIndex.removeGaps(filterData.filter);
    }
    var pathfind = getRingIntersector(mosaicIndex.nodes);
    var dissolvedShapes = groups.map(function(shapeIds) {
      var tiles = mosaicIndex.getTilesByShapeIds(shapeIds);
      if (opts.tiles) {
        return tiles.reduce(function(memo, tile) {
          return memo.concat(tile);
        }, []);
      }
      return dissolveTileGroup2(tiles, pathfind);
    });
    // convert self-intersecting rings to outer/inner rings, for OGC
    // Simple Features compliance
    dissolvedShapes = fixTangentHoles(dissolvedShapes, pathfind);

    if (fillGaps && !opts.quiet) {
      var msg = getGapRemovalMessage(cleanupData.removed, cleanupData.remaining, filterData.label);
      if (msg) message(msg);
    }
    return dissolvedShapes;
  }

  function dissolveTileGroup2(tiles, pathfind) {
    var rings = [],
        holes = [],
        dissolved, tile;
    for (var i=0, n=tiles.length; i<n; i++) {
      tile = tiles[i];
      rings.push(tile[0]);
      if (tile.length > 1) {
        holes = holes.concat(tile.slice(1));
      }
    }
    dissolved = pathfind(rings.concat(holes), 'dissolve');
    if (dissolved.length > 1) ;
    return dissolved.length > 0 ? dissolved : null;
  }

  function fixTangentHoles(shapes, pathfind) {
    var onRing = function(memo, ring) {
      reversePath(ring);
      var fixed = pathfind([ring], 'flatten');
      if (fixed.length > 1) {
        fixed.forEach(reversePath);
        memo = memo.concat(fixed);
      } else {
        memo.push(reversePath(ring));
      }
      return memo;
    };
    return shapes.map(function(rings) {
      if (!rings) return null;
      return rings.reduce(onRing, []);
    });
  }

  var PolygonDissolve2 = /*#__PURE__*/Object.freeze({
    __proto__: null,
    dissolvePolygonLayer2: dissolvePolygonLayer2,
    composeMosaicLayer: composeMosaicLayer,
    dissolvePolygonGroups2: dissolvePolygonGroups2
  });

  // Assumes intersection cuts have been added and duplicated points removed
  // TODO: consider closing undershoots (see mapshaper-undershoots.js)
  function cleanPolylineLayerGeometry(lyr, dataset, opts) {
    var arcs = dataset.arcs;
    var filter = getArcPresenceTest(lyr.shapes, arcs);
    var nodes = new NodeCollection(arcs, filter);
    var arcIndex = new ClearableArcLookupIndex(arcs.size());
    lyr.shapes = lyr.shapes.map(function(shp, i) {
      if (!shp) return null;
      // split parts at nodes (where multiple arcs intersect)
      shp = divideShapeAtNodes(shp, nodes);

      // remove multiple references to the same arc within the same part
      // (this could happen if the path doubles back to form a spike)
      // TODO: remove spikes within a single arc
      arcIndex.clear();
      shp = uniqifyArcs(shp, arcIndex);

      // try to combine parts that form a contiguous line
      // (some datasets may use a separate part for each segment)
      arcIndex.clear();
      shp = combineContiguousParts(shp, nodes, arcIndex);
      return shp;
    });
  }

  function uniqifyArcs(shp, index) {
    var shp2 = shp.reduce(function(memo, ids) {
      addUnusedArcs(memo, ids, index);
      return memo;
    }, []);
    return shp2.length > 0 ? shp2 : null;
  }

  function addUnusedArcs(shp, ids, index) {
    var part = [], arcId;
    for (var i=0; i<ids.length; i++) {
      arcId = ids[i];
      if (!index.hasId(arcId)) {
        part.push(arcId);
      } else if (part.length > 0) {
        shp.push(part);
        part = [];
      }
      index.setId(arcId, i);
      index.setId(~arcId, i);
    }
    if (part.length > 0) shp.push(part);
  }


  function divideShapeAtNodes(shp, nodes) {
    var shp2 = [];
    forEachShapePart(shp, onPart);
    return shp2;

    function onPart(ids) {
      var n = ids.length;
      var id;
      var ids2 = [];
      for (var i=0; i<n; i++) {
        // check each segment of the current part (equivalent to a LineString)
        id = ids[i];
        ids2.push(id);
        if (i < n-1 && nodes.getConnectedArcs(id).length > 1) {
          // divide the current part if the front endpoint of the current segment
          // touches any other segment than the next segment in this part
          // TODO: consider not dividing if the intersection does not involve
          // the current feature (ie. it is not a self-intersection).
          shp2.push(ids2);
          ids2 = [];
        }
      }
      if (ids2.length > 0) shp2.push(ids2);
    }
  }

  function combineContiguousParts(parts, nodes, endpointIndex) {
    if (!parts || parts.length < 2) return parts;

    // Index the terminal arcs of this group of polyline parts
    parts.forEach(function(ids, i) {
      var tailId = ~ids[0]; // index the reversed arc (so it points outwards)
      var headId = ids[ids.length - 1];
      // edge case: an endpoint arc is shared by multiple parts
      // only processing the first of such parts, skipping subsequent parts
      // (this should be an exceptional case... should probably investigate
      // why this happens and handle this better)
      if (endpointIndex.hasId(tailId) || endpointIndex.hasId(headId)) {
        error('Indexing error');
      }
      endpointIndex.setId(tailId, i);
      endpointIndex.setId(headId, i);
      procEndpoint(tailId, i);
      procEndpoint(headId, i);
    });

    return parts.filter(function(ids) { return !!ids; });

    function procEndpoint(endpointId, sourcePartId) {
      var joins = 0;
      var partId2 = -1;
      var endpointId2;
      var indexedPartId = endpointIndex.getId(endpointId);
      nodes.forEachConnectedArc(endpointId, function(arcId) {
        if (endpointIndex.hasId(arcId)) {
          partId2 = endpointIndex.getId(arcId);
          endpointId2 = arcId;
        }
        joins++;
      });
      if (joins == 1 && partId2 > -1 && partId2 < sourcePartId) {
        extendPolylinePart(parts, partId2, endpointId2, indexedPartId, endpointId);
        // update indexed part id of joining endpoint
        endpointIndex.setId(endpointId, partId2);
        // update indexed part id of other endpoint
        var ids = parts[indexedPartId];
        var otherEndpointId = getOtherEndpointId(ids, endpointId);
        endpointIndex.setId(otherEndpointId, partId2);
        if (indexedPartId != partId2) {
          parts[indexedPartId] = null;
        }
      }
    }
  }

  function getOtherEndpointId(ids, endpointId) {
    var headId = ~ids[0];
    var tailId = ids[ids.length-1];
    if (endpointId == headId) return tailId;
    else if (endpointId == tailId) return headId;
    error('Indexing error');
  }

  function extendPolylinePart(parts, partId1, endpoint1, partId2, endpoint2) {
    var ids1 = parts[partId1];
    var ids2 = parts[partId2];
    var joinToTail, joinFromTail;
    if (~endpoint1 == ids1[0]) {
      joinToTail = true;
    } else if (endpoint1 == ids1[ids1.length-1]) {
      joinToTail = false;
    } else {
      error('Index error');
    }
    if (~endpoint2 == ids2[0]) {
      joinFromTail = true;
    } else if (endpoint2 == ids2[ids2.length-1]) {
      joinFromTail = false;
    } else {
      error('Index error 2');
    }
    if (!joinFromTail) {
      ids2 = reversePath(ids2.concat());
    }
    if (joinToTail) {
      prependPath(ids1, ids2);
    } else {
      appendPath(ids1, ids2);
    }
  }

  function prependPath(target, source) {
    source = reversePath(source.concat());
    var args = [0, 0].concat(source);
    target.splice.apply(target, args);
  }

  function appendPath(target, source) {
    target.push.apply(target, source);
  }

  cmd.cleanLayers = cleanLayers;

  function cleanLayers(layers, dataset, optsArg) {
    var opts = optsArg || {};
    var deepClean = !opts.only_arcs;
    var pathClean = utils.some(layers, layerHasPaths);
    var nodes;
    if (opts.debug) {
      addIntersectionCuts(dataset, opts);
      return;
    }
    layers.forEach(function(lyr) {
      if (!layerHasGeometry(lyr)) return;
      if (lyr.geometry_type == 'polygon' && opts.rewind) {
        rewindPolygons(lyr, dataset.arcs);
      }
      if (deepClean) {
        if (!nodes) {
          nodes = addIntersectionCuts(dataset, opts);
        }
        if (lyr.geometry_type == 'polygon') {
          cleanPolygonLayerGeometry(lyr, dataset, opts);
        } else if (lyr.geometry_type == 'polyline') {
          cleanPolylineLayerGeometry(lyr, dataset);
        } else if (lyr.geometry_type == 'point') {
          cleanPointLayerGeometry(lyr);
        }
      }
      if (!opts.allow_empty) {
        cmd.filterFeatures(lyr, dataset.arcs, {remove_empty: true, verbose: opts.verbose});
      }
    });

    if (!opts.no_arc_dissolve && pathClean && dataset.arcs) {
      // remove leftover endpoints within contiguous lines
      dissolveArcs(dataset);
    }
  }

  function cleanPolygonLayerGeometry(lyr, dataset, opts) {
    // clean polygons by apply the 'dissolve2' function to each feature
    opts = Object.assign({gap_fill_area: 'auto'}, opts);
    var groups = lyr.shapes.map(function(shp, i) {
      return [i];
    });
    lyr.shapes = dissolvePolygonGroups2(groups, lyr, dataset, opts);
  }

  // Remove duplicate points from multipoint geometries
  // TODO: consider checking for invalid coordinates
  function cleanPointLayerGeometry(lyr, dataset, opts) {
    var index, parts;
    lyr.shapes = lyr.shapes.map(function(shp, i) {
      if (!shp || shp.length > 0 === false) {
        return null;
      }
      if (shp.length == 1) {
        return shp; // single part
      }
      // remove duplicate points from multipoint geometry
      index = {};
      parts = [];
      shp.forEach(onPoint);
      if (parts.length === 0) {
        return null;
      }
      return parts;
    });

    function onPoint(p) {
      var key = p.join('~');
      if (key in index) return;
      index[key] = true;
      parts.push(p);
    }
  }

  // Support the opts.flatten option (for removing polygon overlaps)
  cmd.mergeAndFlattenLayers = function(layers, dataset, opts) {
    if (!opts.flatten) return cmd.mergeLayers(layers, opts);
    layers.forEach(function(lyr) {
      requirePolygonLayer(lyr, 'the flatten option requires polygon layers');
    });
    var output = cmd.mergeLayers(layers, opts);
    replaceLayers(dataset, layers, output);
    cleanLayers(output, dataset, {
      overlap_rule: 'max-id' // later shapes get inlaid in earlier shapes
    });
    replaceLayers(dataset, output, layers);
    return output;
  };

  // Merge layers, checking for incompatible geometries and data fields.
  // Assumes that input layers are members of the same dataset (and therefore
  // share the same ArcCollection, if layers have paths).
  cmd.mergeLayers = function(layersArg, opts) {
    var layers = layersArg.filter(getFeatureCount); // ignore empty layers
    var merged = {};
    opts = opts || {};
    if (!layers.length) return null;
    if (layers.length == 1) {
      message('Use the target= option to specify multiple layers for merging');
      return layers.concat();
    }
    merged.data = mergeDataFromLayers(layers, opts);
    merged.name = mergeLayerNames(layers);
    merged.geometry_type = getMergedLayersGeometryType(layers);
    if (merged.geometry_type) {
      merged.shapes = mergeShapesFromLayers(layers);
    }
    if (merged.shapes && merged.data && merged.shapes.length != merged.data.size()) {
      error("Mismatch between geometry and attribute data");
    }
    return [merged];
  };

  function getMergedLayersGeometryType(layers) {
    var geoTypes = utils.uniq(utils.pluck(layers, 'geometry_type'))
      .filter(function(type) {return !!type;}); // ignore null-type layers
    if (geoTypes.length > 1) {
      stop("Incompatible geometry types:", geoTypes.join(', '));
    }
    return geoTypes[0] || null;
  }

  function mergeShapesFromLayers(layers) {
    return layers.reduce(function(memo, lyr) {
      var shapes = lyr.shapes || [];
      var n = getFeatureCount(lyr);
      var i = -1;
      while (++i < n) memo.push(shapes[i] || null); // add null shapes if layer has no shapes
      return memo;
    }, []);
  }

  function mergeDataFromLayers(layers, opts) {
    var allFields = utils.uniq(layers.reduce(function(memo, lyr) {
      return memo.concat(lyr.data ? lyr.data.getFields() : []);
    }, []));
    if (allFields.length === 0) return null; // no data in any fields
    var mergedRecords = layers.reduce(function(memo, lyr) {
      var records = lyr.data ? lyr.data.getRecords() : new DataTable(getFeatureCount(lyr)).getRecords();
      return memo.concat(records);
    }, []);
    var missingFields = findInconsistentFields(allFields, layers);
    handleMissingFields(missingFields, opts);
    checkInconsistentFieldTypes(allFields, layers);
    if (missingFields.length > 0) {
      fixInconsistentFields(mergedRecords);
    }
    return new DataTable(mergedRecords);
  }

  // handle fields that are missing from one or more layers
  // (warn if force-merging, else error)
  function handleMissingFields(missingFields, opts) {
    var msg;
    if (missingFields.length > 0) {
      msg = '[' + missingFields.join(', ') + ']';
      msg = (missingFields.length == 1 ? 'Field ' + msg + ' is missing' : 'Fields ' + msg + ' are missing') + ' from one or more layers';
      if (!opts.force) {
        stop(msg);
      } else if (opts.verbose !== false) {
        message('Warning: ' + msg);
      }
    }
  }

  function findInconsistentFields(allFields, layers) {
    var missingFields = utils.uniq(layers.reduce(function(memo, lyr) {
      return memo.concat(utils.difference(allFields, lyr.data ? lyr.data.getFields() : []));
    }, []));
    return missingFields;
  }

  // check for fields with incompatible data types (e.g. number, string)
  function checkInconsistentFieldTypes(fields, layers) {
    fields.forEach(function(key) {
      var types = findFieldTypes(key, layers);
      if (types.length > 1) {
        stop("Inconsistent data types in \"" + key + "\" field:", types.join(', '));
      }
    });
  }

  function findFieldTypes(key, layers) {
    // ignores empty-type fields
    return layers.reduce(function(memo, lyr) {
      var type = lyr.data ? getColumnType(key, lyr.data.getRecords()) : null;
      if (type && memo.indexOf(type) == -1) {
        memo.push(type);
      }
      return memo;
    }, []);
  }

  function mergeLayerNames(layers) {
    return layers.reduce(function(memo, lyr) {
      if (memo === null) {
        memo = lyr.name || null;
      } else if (memo && lyr.name) {
        memo = utils.mergeNames(memo, lyr.name);
      }
      return memo;
    }, null) || '';
  }

  var GeoJSON = {};

  GeoJSON.ID_FIELD = "FID"; // default field name of imported *JSON feature ids

  GeoJSON.typeLookup = {
    LineString: 'polyline',
    MultiLineString: 'polyline',
    Polygon: 'polygon',
    MultiPolygon: 'polygon',
    Point: 'point',
    MultiPoint: 'point'
  };

  GeoJSON.translateGeoJSONType = function(type) {
    return GeoJSON.typeLookup[type] || null;
  };

  GeoJSON.pathIsRing = function(coords) {
    var first = coords[0],
        last = coords[coords.length - 1];
    // TODO: consider detecting collapsed rings
    return coords.length >= 4 && first[0] == last[0] && first[1] == last[1];
  };

  GeoJSON.toFeature = function(obj, properties) {
    var type = obj ? obj.type : null;
    var feat;
    if (type == 'Feature') {
      feat = obj;
    } else if (type in GeoJSON.typeLookup) {
      feat = {
        type: 'Feature',
        geometry: obj,
        properties: properties || null
      };
    } else {
      feat = {
        type: 'Feature',
        geometry: null,
        properties: properties || null
      };
    }
    return feat;
  };

  function exportGeoJSON(dataset, opts) {
    opts = utils.extend({}, opts);
    opts.rfc7946 = !opts.gj2008; // use RFC 7946 as the default
    var extension = opts.extension || "json";
    var layerGroups;

    if (opts.rfc7946) {
      warnIfNotWgs84(dataset);
    }

    if (opts.file) {
      // Override default output extension if output filename is given
      extension = getFileExtension(opts.file);
    }
    if (opts.combine_layers) {
      layerGroups = [dataset.layers];
    } else {
      layerGroups = dataset.layers.map(function(lyr) {
        return [lyr];
      });
    }
    return layerGroups.map(function(layers) {
      // Use common part of layer names if multiple layers are being merged
      var name = mergeLayerNames(layers) || 'output';
      var d = utils.defaults({layers: layers}, dataset);
      return {
        content: exportDatasetAsGeoJSON(d, opts, 'buffer'),
        filename: name + '.' + extension
      };
    });
  }

  // Return an array of Features or Geometries as objects or strings
  //
  function exportLayerAsGeoJSON(lyr, dataset, opts, asFeatures, ofmt) {
    var properties = exportProperties(lyr.data, opts),
        shapes = lyr.shapes,
        ids = exportIds(lyr.data, opts),
        stringify;

    if (opts.ndjson) {
      stringify = stringifyAsNDJSON;
    } else if (opts.prettify) {
      stringify = getFormattedStringify(['bbox', 'coordinates']);
    } else {
      stringify = JSON.stringify;
    }

    if (properties && shapes && properties.length !== shapes.length) {
      error("Mismatch between number of properties and number of shapes");
    }

    return (shapes || properties || []).reduce(function(memo, o, i) {
      var shape = shapes ? shapes[i] : null,
          exporter = GeoJSON.exporters[lyr.geometry_type],
          geom = shape ? exporter(shape, dataset.arcs, opts) : null,
          obj = null;

      if (asFeatures) {
        obj = composeFeature(geom, properties ? properties[i] : null, opts);
        if (ids) {
          obj.id = ids[i];
        }
        if (opts.no_null_props && !obj.properties) {
          obj.properties = {};
        }
      } else if (!geom) {
        return memo; // don't add null objects to GeometryCollection
      } else {
        obj = geom;
      }
      if (ofmt) {
        // stringify features as soon as they are generated, to reduce the
        // number of JS objects in memory (so larger files can be exported)
        obj = stringify(obj);
        if (ofmt == 'buffer') {
          obj = encodeString(obj, 'utf8');
          // obj = stringToBuffer(obj);
          // obj = new Buffer(obj, 'utf8');
        }
      }
      memo.push(obj);
      return memo;
    }, []);
  }

  function composeFeature(geom, properties, opts) {
    var feat = GeoJSON.toFeature(geom, properties);
    if (Array.isArray(opts.hoist) && properties) {
      // don't modify properties of source feature
      feat.properties = Object.assign({}, properties);
      opts.hoist.forEach(field => {
        if (properties.hasOwnProperty(field)) {
          feat[field] = properties[field];
          delete feat.properties[field];
        }
      });
    }
    return feat;
  }

  function warnIfNotWgs84(dataset) {
    var P = getDatasetCRS(dataset);
    if (P && isLatLngCRS(P) || datasetIsEmpty(dataset)) return;
    var str = 'RFC 7946 warning: non-WGS84 GeoJSON output.';
    if (P) str += ' Tip: use "-proj wgs84" to convert.';
    message(str);
  }

  function getDatasetBbox(dataset, rfc7946) {
    var P = getDatasetCRS(dataset),
        wrapped = rfc7946 && P && isLatLngCRS(P),
        westBounds = new Bounds(),
        eastBounds = new Bounds(),
        mergedBounds, gutter, margins, bbox;

    dataset.layers.forEach(function(lyr) {
      if (layerHasPaths(lyr)) {
        traversePaths(lyr.shapes, null, function(o) {
          var bounds = dataset.arcs.getSimpleShapeBounds(o.arcs);
          (bounds.centerX() < 0 ? westBounds : eastBounds).mergeBounds(bounds);
        });
      } else if (layerHasPoints(lyr)) {
        forEachPoint(lyr.shapes, function(p) {
          (p[0] < 0 ? westBounds : eastBounds).mergePoint(p[0], p[1]);
        });
      }
    });
    mergedBounds = (new Bounds()).mergeBounds(eastBounds).mergeBounds(westBounds);
    if (mergedBounds.hasBounds()) {
      bbox = mergedBounds.toArray();
    }
    if (wrapped && eastBounds.hasBounds() && westBounds.hasBounds()) {
      gutter = eastBounds.xmin - westBounds.xmax;
      margins = 360 + westBounds.xmin - eastBounds.xmax;
      if (gutter > 0 && gutter > margins) {
        bbox[0] = eastBounds.xmin;
        bbox[2] = westBounds.xmax;
      }
    }
    return bbox || null;
  }

  function exportDatasetAsGeoJSON(dataset, opts, ofmt) {
    var geojson = {};
    var layers = dataset.layers;
    var useFeatures = useFeatureCollection(layers, opts);
    var collection, bbox;

    if (useFeatures) {
      geojson.type = 'FeatureCollection';
    } else {
      geojson.type = 'GeometryCollection';
    }

    if (opts.gj2008) {
      preserveOriginalCRS(dataset, geojson);
    }

    if (opts.bbox) {
      bbox = getDatasetBbox(dataset, opts.rfc7946);
      if (bbox) {
        geojson.bbox = bbox;
      }
    }

    collection = layers.reduce(function(memo, lyr, i) {
      var items = exportLayerAsGeoJSON(lyr, dataset, opts, useFeatures, ofmt);
      return memo.length > 0 ? memo.concat(items) : items;
    }, []);

    if (opts.geojson_type == 'Feature' && collection.length == 1) {
      return collection[0];
    } else if (opts.ndjson) {
      return GeoJSON.formatCollectionAsNDJSON(collection);
    } else if (ofmt) {
      return GeoJSON.formatCollection(geojson, collection);
    } else {
      geojson[collectionName(geojson.type)] = collection;
      return geojson;
    }
  }

  function collectionName(type) {
    if (type == 'FeatureCollection') return 'features';
    if (type == 'GeometryCollection') return 'geometries';
    error('Invalid collection type:', type);
  }

  // collection: an array of Buffers, one per feature
  GeoJSON.formatCollectionAsNDJSON = function(collection) {
    var delim = utils.createBuffer('\n', 'utf8');
    var parts = collection.reduce(function(memo, buf, i) {
      if (i > 0) memo.push(delim);
      memo.push(buf);
      return memo;
    }, []);
    return B$3.concat(parts);
  };

  // collection: an array of individual GeoJSON Features or geometries as strings or buffers
  GeoJSON.formatCollection = function(container, collection) {
    var head = JSON.stringify(container).replace(/\}$/, ', "' + collectionName(container.type) + '": [\n');
    var tail = '\n]}';
    if (utils.isString(collection[0])) {
      return head + collection.join(',\n') + tail;
    }
    // assume buffers
    return GeoJSON.joinOutputBuffers(head, tail, collection);
  };

  GeoJSON.joinOutputBuffers = function(head, tail, collection) {
    var comma = utils.createBuffer(',\n', 'utf8');
    var parts = collection.reduce(function(memo, buf, i) {
      if (i > 0) memo.push(comma);
      memo.push(buf);
      return memo;
    }, [utils.createBuffer(head, 'utf8')]);
    parts.push(utils.createBuffer(tail, 'utf8'));
    return B$3.concat(parts);
  };

  // export GeoJSON or TopoJSON point geometry
  GeoJSON.exportPointGeom = function(points, arcs) {
    var geom = null;
    if (points.length == 1) {
      geom = {
        type: "Point",
        coordinates: points[0]
      };
    } else if (points.length > 1) {
      geom = {
        type: "MultiPoint",
        coordinates: points
      };
    }
    return geom;
  };

  GeoJSON.exportLineGeom = function(ids, arcs) {
    var obj = exportPathData(ids, arcs, "polyline");
    if (obj.pointCount === 0) return null;
    var coords = obj.pathData.map(function(path) {
      return path.points;
    });
    return coords.length == 1 ? {
      type: "LineString",
      coordinates: coords[0]
    } : {
      type: "MultiLineString",
      coordinates: coords
    };
  };

  GeoJSON.exportPolygonGeom = function(ids, arcs, opts) {
    var obj = exportPathData(ids, arcs, "polygon");
    if (obj.pointCount === 0) return null;
    var groups = groupPolygonRings(obj.pathData, arcs, opts.invert_y);
    // invert_y is used internally for SVG generation
    // mapshaper's internal winding order is the opposite of RFC 7946
    var reverse = opts.rfc7946 && !opts.invert_y;
    var coords = groups.map(function(paths) {
      return paths.map(function(path) {
        if (reverse) path.points.reverse();
        return path.points;
      });
    });
    return coords.length == 1 ? {
      type: "Polygon",
      coordinates: coords[0]
    } : {
      type: "MultiPolygon",
      coordinates: coords
    };
  };

  GeoJSON.exporters = {
    polygon: GeoJSON.exportPolygonGeom,
    polyline: GeoJSON.exportLineGeom,
    point: GeoJSON.exportPointGeom
  };

  // To preserve some backwards compatibility with old-style GeoJSON files,
  // pass through any original CRS object if the crs has not been set by mapshaper
  // jsonObj: a top-level GeoJSON or TopoJSON object
  //
  function preserveOriginalCRS(dataset, jsonObj) {
    var info = dataset.info || {};
    if (!info.crs && 'input_geojson_crs' in info) {
      // use input geojson crs if available and coords have not changed
      jsonObj.crs = info.input_geojson_crs;

    }

    // Removing the following (seems ineffectual at best)
    // else if (info.crs && !isLatLngCRS(info.crs)) {
    //   // Setting output crs to null if coords have been projected
    //   // "If the value of CRS is null, no CRS can be assumed"
    //   // source: http://geojson.org/geojson-spec.html#coordinate-reference-system-objects
    //   jsonObj.crs = null;
    // }
  }

  function useFeatureCollection(layers, opts) {
    var type = opts.geojson_type || '';
    if (type == 'Feature' || type == 'FeatureCollection') {
      return true;
    } else if (type == 'GeometryCollection') {
      return false;
    } else if (type) {
      stop("Unsupported GeoJSON type:", opts.geojson_type);
    }
    // default is true iff layers contain attributes
    return utils.some(layers, function(lyr) {
      var fields = lyr.data ? lyr.data.getFields() : [];
      var haveData = useFeatureProperties(fields, opts);
      var haveId = !!getIdField(fields, opts);
      return haveData || haveId;
    });
  }

  function useFeatureProperties(fields, opts) {
    return !(opts.drop_table || opts.cut_table || fields.length === 0 ||
        fields.length == 1 && fields[0] == GeoJSON.ID_FIELD);
  }

  function exportProperties(table, opts) {
    var fields = table ? table.getFields() : [],
        idField = getIdField(fields, opts),
        properties, records;
    if (!useFeatureProperties(fields, opts)) {
      return null;
    }
    records = table.getRecords();
    if (idField == GeoJSON.ID_FIELD) {// delete default id field, not user-set fields
      properties = records.map(function(rec) {
        rec = utils.extend({}, rec); // copy rec;
        delete rec[idField];
        return rec;
      });
    } else {
      properties = records;
    }
    return properties;
  }

  // @opt value of id-field option (empty, string or array of strings)
  // @fields array
  function getIdField(fields, opts) {
    var ids = [];
    var opt = opts.id_field;
    if (utils.isString(opt)) {
      ids.push(opt);
    } else if (utils.isArray(opt)) {
      ids = opt;
    }
    ids.push(GeoJSON.ID_FIELD); // default id field
    return utils.find(ids, function(name) {
      return utils.contains(fields, name);
    });
  }

  function exportIds(table, opts) {
    var fields = table ? table.getFields() : [],
        idField = getIdField(fields, opts);
    if (!idField) return null;
    return table.getRecords().map(function(rec) {
      return idField in rec ? rec[idField] : null;
    });
  }

  var GeojsonExport = /*#__PURE__*/Object.freeze({
    __proto__: null,
    'default': GeoJSON,
    exportGeoJSON: exportGeoJSON,
    exportLayerAsGeoJSON: exportLayerAsGeoJSON,
    warnIfNotWgs84: warnIfNotWgs84,
    getDatasetBbox: getDatasetBbox,
    exportDatasetAsGeoJSON: exportDatasetAsGeoJSON,
    preserveOriginalCRS: preserveOriginalCRS,
    useFeatureCollection: useFeatureCollection,
    exportProperties: exportProperties,
    getIdField: getIdField,
    exportIds: exportIds
  });

  /*
  {
    width: size[0],
    height: size[1],
    bbox: bounds.toArray(),
    type: 'frame'
  }
  */


  function getFrameData(dataset, exportOpts) {
    var frameLyr = findFrameLayerInDataset(dataset);
    var data;
    if (frameLyr) {
      data = getFrameLayerData(frameLyr, dataset.arcs);
    } else {
      data = calcFrameData(dataset, exportOpts);
    }
    data.invert_y = !!exportOpts.invert_y;
    data.crs = getDatasetCRS(dataset);
    return data;
  }

  function fitDatasetToFrame(dataset, frame) {
    var bounds = new Bounds(frame.bbox);
    var bounds2 = frame.bbox2 ? new Bounds(frame.bbox2) : new Bounds(0, 0, frame.width, frame.height);
    bounds.fillOut(bounds2.width() / bounds2.height());
    var fwd = bounds.getTransform(bounds2, frame.invert_y);
    transformPoints(dataset, function(x, y) {
      return fwd.transform(x, y);
    });
  }

  function getFrameLayerData(lyr, arcs) {
    var bounds = getLayerBounds(lyr, arcs);
    var d = lyr.data.getReadOnlyRecordAt(0);
    var w = d.width || 800;
    // prevent rounding errors (like 1000.0000000002)
    var h = Math.round(w * bounds.height() / bounds.width());
    return {
      type: 'frame',
      width: w,
      height: h,
      bbox: bounds.toArray()
    };
  }


  function calcFrameData(dataset, opts) {
    var inputBounds, outputBounds;
    if (opts.svg_bbox) {
      inputBounds = new Bounds(opts.svg_bbox);
      opts = Object.assign({margin: 0}, opts); // prevent default pixel margin around content
    } else {
      inputBounds = getDatasetBounds(dataset);
    }
    // side effect: inputBounds may be expanded to add margins
    outputBounds = calcOutputBounds(inputBounds, opts);
    return {
      bbox: inputBounds.toArray(),
      bbox2: outputBounds.toArray(),
      width: Math.round(outputBounds.width()),
      height: Math.round(outputBounds.height()) || 1,
      type: 'frame'
    };
  }

  // Used by mapshaper-frame  TODO: refactor
  function getFrameSize(bounds, opts) {
    var aspectRatio = bounds.width() / bounds.height();
    var height, width;
    if (opts.pixels) {
      width = Math.sqrt(+opts.pixels * aspectRatio);
    } else {
      width = +opts.width;
    }
    height = width / aspectRatio;
    return [Math.round(width), Math.round(height)];
  }


  // @lyr dataset layer
  function isFrameLayer(lyr, arcs) {
    return getFurnitureLayerType(lyr) == 'frame' &&
      layerIsRectangle(lyr, arcs);
  }

  function findFrameLayerInDataset(dataset) {
    return utils.find(dataset.layers, function(lyr) {
      return isFrameLayer(lyr, dataset.arcs);
    });
  }

  // TODO: handle multiple frames in catalog
  function findFrameDataset(catalog) {
    var target = findFrame(catalog);
    return target && target.dataset || null;
  }

  function findFrameLayer(catalog) {
    var target = findFrame(catalog);
    return target && target.layer || null;
  }

  function findFrame(catalog) {
    return utils.find(catalog.getLayers(), function(o) {
      return isFrameLayer(o.layer, o.dataset.arcs);
    });
  }

  function getFrameLayerBounds(lyr) {
    return new Bounds(getFurnitureLayerData(lyr).bbox);
  }

  // @data frame data, including crs property if available
  // Returns a single value: the ratio or
  function getMapFrameMetersPerPixel(data) {
    var bounds = new Bounds(data.bbox);
    var k, toMeters, metersPerPixel;
    if (data.crs) {
      // TODO: handle CRS without inverse projections
      // scale factor is the ratio of coordinate distance to true distance at a point
      k = getScaleFactorAtXY(bounds.centerX(), bounds.centerY(), data.crs);
      toMeters = data.crs.to_meter;
    } else {
      // Assuming coordinates are meters and k is 1 (not safe)
      // A warning should be displayed when relevant furniture element is created
      k = 1;
      toMeters = 1;
    }
    metersPerPixel = bounds.width() / k * toMeters / data.width;
    return metersPerPixel;
  }


  // bounds: Bounds object containing bounds of content in geographic coordinates
  // returns Bounds object containing output bounds
  // side effect: bounds param is modified to match the output frame
  function calcOutputBounds(bounds, opts) {
    var padX = 0,
        padY = 0,
        offX = 0,
        offY = 0,
        width = bounds.width(),
        height = bounds.height(),
        margins = parseMarginOption(opts.margin),
        marginX = margins[0] + margins[2],
        marginY = margins[1] + margins[3],
        // TODO: add option to tweak alignment of content when both width and height are given
        wx = 0.5, // how padding is distributed horizontally (0: left aligned, 0.5: centered, 1: right aligned)
        wy = 0.5, // vertical padding distribution
        width2, height2, size2, kx, ky;

    if (opts.fit_bbox) {
      // scale + shift content to fit within a bbox
      offX = opts.fit_bbox[0];
      offY = opts.fit_bbox[1];
      width2 = opts.fit_bbox[2] - offX;
      height2 = opts.fit_bbox[3] - offY;
      marginX = marginY = 0; // TODO: support margins

    } else if (opts.svg_scale > 0) {
      // alternative to using a fixed width (e.g. when generating multiple files
      // at a consistent geographic scale)
      width2 = width / opts.svg_scale + marginX;
      height2 = 0;
    } else if (+opts.pixels) {
      size2 = getFrameSize(bounds, opts);
      width2 = size2[0];
      height2 = size2[1];
    } else {
      height2 = opts.height || 0;
      width2 = opts.width || (height2 > 0 ? 0 : 800); // 800 is default width
    }

    if (height2 > 0) {
      // vertical meters per pixel to fit height param
      ky = (height || width || 1) / (height2 - marginY);
    }
    if (width2 > 0) {
      // horizontal meters per pixel to fit width param
      kx = (width || height || 1) / (width2 - marginX);
    }

    if (!width2) { // height2 and ky are defined, set width to match
      kx = ky;
      width2 = width > 0 ? marginX + width / kx : height2; // export square graphic if content has 0 width (reconsider this?)
    } else if (!height2) { // width2 and kx are set, set height to match
      ky = kx;
      height2 = height > 0 ? marginY + height / ky : width2;
      // limit height if max_height is defined
      if (opts.max_height > 0 && height2 > opts.max_height) {
        ky = kx * height2 / opts.max_height;
        height2 = opts.max_height;
      }
    }

    // add padding, if needed
    if (kx > ky) { // content is wide -- need to pad vertically
      ky = kx;
      padY = ky * (height2 - marginY) - height;
    } else if (ky > kx) { // content is tall -- need to pad horizontally
      kx = ky;
      padX = kx * (width2 - marginX) - width;
    }

    bounds.padBounds(
      margins[0] * kx + padX * wx,
      margins[1] * ky + padY * wy,
      margins[2] * kx + padX * (1 - wx),
      margins[3] * ky + padY * (1 - wy));

    if (!(width2 > 0 && height2 > 0)) {
      error("Missing valid height and width parameters");
    }
    if (!(kx === ky && kx > 0)) {
      error("Missing valid margin parameters");
    }

    return new Bounds(offX, offY, width2 + offX, height2 + offY);
  }

  function parseMarginOption(opt) {
    var str = utils.isNumber(opt) ? String(opt) : opt || '';
    var margins = str.trim().split(/[, ] */);
    if (margins.length == 1) margins.push(margins[0]);
    if (margins.length == 2) margins.push(margins[0], margins[1]);
    if (margins.length == 3) margins.push(margins[2]);
    return margins.map(function(str) {
      var px = parseFloat(str);
      return isNaN(px) ? 0 : px; // 0 is default
    });
  }

  var FrameUtils = /*#__PURE__*/Object.freeze({
    __proto__: null,
    getFrameData: getFrameData,
    fitDatasetToFrame: fitDatasetToFrame,
    getFrameLayerData: getFrameLayerData,
    calcFrameData: calcFrameData,
    getFrameSize: getFrameSize,
    isFrameLayer: isFrameLayer,
    findFrameLayerInDataset: findFrameLayerInDataset,
    findFrameDataset: findFrameDataset,
    findFrameLayer: findFrameLayer,
    findFrame: findFrame,
    getFrameLayerBounds: getFrameLayerBounds,
    getMapFrameMetersPerPixel: getMapFrameMetersPerPixel,
    calcOutputBounds: calcOutputBounds,
    parseMarginOption: parseMarginOption
  });

  function addFurnitureLayer(lyr, catalog) {
    var o = {
      info: {},
      layers: [lyr]
    };
    catalog.getDatasets().push(o);
  }

  // Apply rotation, scale and/or shift to some or all of the features in a dataset
  //
  cmd.affine = function(targetLayers, dataset, opts) {
    // Need to separate the targeted shapes from any other shapes that share
    // the same topology. So we duplicate any arcs that are shared by the targeted
    // shapes and their topological neighbors and remap arc references in the
    // neighbors to point to the copies.
    // TODO: explore alternative: if some arcs are shared between transformed and
    //   non-transformed shapes, first remove topology, then tranform, then rebuild topology
    //
    var rotateArg = opts.rotate || 0;
    var scaleArg = opts.scale || 1;
    var shiftArg = opts.shift ? convertIntervalPair(opts.shift, getDatasetCRS(dataset)) : [0, 0];
    var arcs = dataset.arcs;
    var targetShapes = [];
    var otherShapes = [];
    var targetPoints = [];
    var targetFlags, otherFlags, transform;
    dataset.layers.filter(layerHasGeometry).forEach(function(lyr) {
      var hits = [],
          misses = [],
          test;
      if (targetLayers.indexOf(lyr) == -1) {
        misses = lyr.shapes;
      } else if (opts.where) {
        test = compileFeatureExpression(opts.where, lyr, dataset.arcs);
        lyr.shapes.forEach(function(shp, i) {
          (test(i) ? hits : misses).push(shp);
        });
      } else {
        hits = lyr.shapes;
      }
      if (lyr.geometry_type == 'point') {
        targetPoints = targetPoints.concat(hits);
      } else {
        targetShapes = targetShapes.concat(hits);
        otherShapes = otherShapes.concat(misses);
      }
    });
    var anchorArg = getAffineAnchor({arcs: dataset.arcs, layers: [{
      geometry_type: 'point', shapes: targetPoints}, {geometry_type: 'polyline',
      shapes: targetShapes}]}, opts);
    transform = getAffineTransform(rotateArg, scaleArg, shiftArg, anchorArg);
    if (opts.fit_bbox) {
      transform = getFitBoxTransform(opts.fit_bbox, targetPoints, targetShapes, arcs);
    }
    if (targetShapes.length > 0) {
      targetFlags = new Uint8Array(arcs.size());
      otherFlags = new Uint8Array(arcs.size());
      countArcsInShapes(targetShapes, targetFlags);
      if (otherShapes.length > 0) {
        countArcsInShapes(otherShapes, otherFlags);
        applyArrayMask(otherFlags, targetFlags);
        dataset.arcs = duplicateSelectedArcs(otherShapes, arcs, otherFlags);
      }
      dataset.arcs.transformPoints(function(x, y, arcId) {
        if (arcId < targetFlags.length && targetFlags[arcId] > 0) {
          return transform(x, y);
        }
      });
    }
    forEachPoint(targetPoints, function(p) {
      var p2 = transform(p[0], p[1]);
      p[0] = p2[0];
      p[1] = p2[1];
    });
  };

  function getAffineAnchor(dataset, opts) {
    var anchor, bounds;
    if (opts.anchor) {
      anchor = opts.anchor;
    } else {
      // get bounds of selected shapes to calculate center of rotation/scale
      bounds = getDatasetBounds(dataset);
      anchor = [bounds.centerX(), bounds.centerY()];
    }
    return anchor;
  }

  // TODO: handle problems with unprojected datasets
  //   option 1: don't allow affine transformation of unprojected data
  //   option 2: error if transformed data exceeds valid coordinate range
  // source: http://mathworld.wolfram.com/AffineTransformation.html
  function getAffineTransform(rotation, scale, shift, anchor) {
    var angle = rotation * Math.PI / 180;
    var a = scale * Math.cos(angle);
    var b = -scale * Math.sin(angle);
    return function(x, y) {
      var x2 = a * (x - anchor[0]) - b * (y - anchor[1]) + shift[0] + anchor[0];
      var y2 = b * (x - anchor[0]) + a * (y - anchor[1]) + shift[1] + anchor[1];
      return [x2, y2];
    };
  }

  function getFitBoxTransform(bbox, points, shapes, arcs) {
    var dataset = {
      arcs: arcs,
      info: {},
      layers: []
    };
    if (points && points.length) {
      dataset.layers.push({
        geometry_type: 'point',
        shapes: points
      });
    }
    if (shapes && shapes.length) {
      dataset.layers.push({
        geometry_type: 'polyline',
        shapes: shapes
      });
    }
    var frame = calcFrameData(dataset, {fit_bbox: bbox});
    var fromBounds = new Bounds(frame.bbox);
    var toBounds = new Bounds(frame.bbox2);
    var fwd = fromBounds.getTransform(toBounds, false);
    return function(x, y) {
      return fwd.transform(x, y);
    };
  }

  function applyArrayMask(destArr, maskArr) {
    for (var i=0, n=destArr.length; i<n; i++) {
      if (maskArr[i] === 0) destArr[i] = 0;
    }
  }

  function duplicateSelectedArcs(shapes, arcs, flags) {
    var arcCount = 0;
    var vertexCount = 0;
    var data = arcs.getVertexData();
    var xx = [], yy = [], nn = [], map = [], n;
    for (var i=0, len=flags.length; i<len; i++) {
      if (flags[i] > 0) {
        map[i] = arcs.size() + arcCount;
        n = data.nn[i];
        utils.copyElements(data.xx, data.ii[i], xx, vertexCount, n);
        utils.copyElements(data.yy, data.ii[i], yy, vertexCount, n);
        nn.push(n);
        vertexCount += n;
        arcCount++;
      }
    }
    forEachArcId(shapes, function(id) {
      var absId = absArcId(id);
      if (flags[absId] > 0) {
        return id < 0 ? ~map[absId] : map[absId];
      }
    });
    return mergeArcs([arcs, new ArcCollection(nn, xx, yy)]);
  }

  var roundCoord$2 = getRoundingFunction(0.01);

  function stringifyVertex(p) {
    return ' ' + roundCoord$2(p[0]) + ' ' + roundCoord$2(p[1]);
  }

  function isCubicCtrl(p) {
    return p.length > 2 && p[2] == 'C';
  }

  function stringifyPolygonCoords(coords) {
    var parts = [];
    for (var i=0; i<coords.length; i++) {
      parts.push(stringifyLineStringCoords(coords[i]) + ' Z');
    }
    return parts.length > 0 ? parts.join(' ') : '';
  }

  function stringifyLineStringCoords(coords) {
    if (coords.length === 0) return '';
    var d = 'M';
    var fromCurve = false;
    var p, i, n;
    for (i=0, n=coords.length; i<n; i++) {
      p = coords[i];
      if (isCubicCtrl(p)) {
        // TODO: add defensive check
        d += ' C' + stringifyVertex(p) + stringifyVertex(coords[++i]) + stringifyVertex(coords[++i]);
        fromCurve = true;
      } else if (fromCurve) {
        d += ' L' + stringifyVertex(p);
        fromCurve = false;
      } else {
        d += stringifyVertex(p);
      }
    }
    return d;
  }

  var SvgPathUtils = /*#__PURE__*/Object.freeze({
    __proto__: null,
    stringifyPolygonCoords: stringifyPolygonCoords,
    stringifyLineStringCoords: stringifyLineStringCoords
  });

  /* example patterns
  hatches 1px black 1px red 1px white
  1px black 1px red 1px white // same as above (hatches is default)
  45deg 2px black 2px red     // hatch direction
  dots 2px black 5px white    // 2px black dots with 5px spacing on white
  dots 2px blue 2px red 5px white  // blue and red alternating dots
  */
  function parsePattern(str) {
    if (!str) return null;
    var parts = splitPattern(str);
    var first = parts[0] || '';
    var obj = null;
    // accept variations on type names (dot, dots, square, squares, hatch, hatches, hatched)
    if (first.startsWith('dot')) {
      parts[0] = 'dots';
      obj = parseDots(parts);
    } else if (first.startsWith('square')) {
      parts[0] = 'squares';
      obj = parseDots(parts);
    } else if (first.startsWith('hatch')) {
      parts[0] = 'hatches';
      obj = parseHatches(parts);
    } else if (first.startsWith('dash')) {
      obj = parseDashes(parts);
    } else if (!isNaN(parseFloat(first))) {
      parts.unshift('hatches');
      obj = parseHatches(parts); // hatches is the default, name can be omitted
    }
    if (!obj) {
      // consider
      message('Invalid pattern, ignoring:', str);
    }
    return obj;
  }

  function parseDashes(parts) {
    // format:
    // "dashes" dash-len dash-space width color1 [color2...] space bg-color
    // examples:
    // dashes 4px 3px 1px black 4px white
    parts.shift();
    var colors = [];
    var background = parts.pop();
    var spacing = parseNum(parts.pop());
    var tmp;
    while (parts.length > 0) {
      tmp = parts.pop();
      if (isSize(tmp)) {
        parts.push(tmp);
        break;
      } else {
        colors.push(tmp);
      }
    }
    var width = parseNum(parts.pop());
    var dashes = [parseNum(parts.pop()), parseNum(parts.pop())].reverse();
    var rotation = 45;
    if (parts.length > 0) {
      rotation = parseNum(parts.pop());
    }
    if (parts.length > 0) {
      return null;
    }
    if (width > 0 === false) return null;
    return {
      type: 'dashes',
      tileSize: [colors.length * (width + spacing), utils.sum(dashes)],
      colors: colors,
      width: width,
      dashes: dashes,
      spacing: spacing,
      background: background,
      rotation: rotation
    };
  }

  function parseHatches(parts) {
    // format:
    // [hatches] [rotation] width1 color1 [width2 color2 ...]
    // examples:
    // 1px red 1px white 1px black
    // -45deg 3 #eee 3 rgb(0,0,0)
    parts.shift();
    var rot = parts.length % 2 == 1 ? parseNum(parts.shift()) : 45, // default is 45
        colors = [], widths = [];
    for (var i=0; i<parts.length; i+=2) {
      widths.push(parseNum(parts[i]));
      colors.push(parts[i+1]);
    }
    if (Math.min.apply(null, widths) > 0 === false) return null;
    return {
      tileSize: [utils.sum(widths), 10],
      type: 'hatches',
      colors: colors,
      widths: widths,
      rotation: rot
    };
  }

  function isSize(str) {
    return parseNum(str) > 0;
  }

  function parseDots(parts) {
    // format:
    // "dots"|"squares" [rotation] size color1 [color2 ...] spacing bg-color
    // examples:
    // dots 45deg 2px red blue 5px white
    // squares 3px black 1px white
    var colors = [];
    var type = parts.shift();
    var rot = 0;
    if (isSize(parts[1])) { // if rotation is present, there are two numbers
      rot = parseNum(parts.shift());
    }
    var size = parseNum(parts.shift());
    var bg = parts.pop();
    var spacing = parseNum(parts.pop());
    while (parts.length > 0) {
      colors.push(parts.shift());
    }
    if (size > 0 === false || spacing >= 0 === false) return null;
    if (colors.length === 0) return null;
    var side = colors.length * (size + spacing);
    return {
      type: type,
      tileSize: [side, side],
      colors: colors,
      size: size,
      spacing: spacing,
      background: bg,
      rotation: rot
    };
  }

  function parseNum(str) {
    // return parseNum(str);
    // support sub-pixel sizes
    return parseFloat(str) || 0;
  }

  function splitPattern(str) {
    // split apart space and comma-delimited tokens
    // ... but don't split rgb(...) colors
    var splitRxp = /[, ]+(?![^(]*\))/;
    return String(str).trim().split(splitRxp);
  }

  function getHashId(str) {
    return ('hash_' + str).replace(/[()# ,_]+/g, '_'); // replace some chars that occur in colors
  }

  // properties: properties object of a path data object (prior to conversion to SVG)
  // defs: array of definition objects
  //
  function convertFillPattern(properties, defs) {
    var hatchStr = properties['fill-pattern'];
    var hashId = getHashId(hatchStr);
    var hash = utils.find(defs, function(o) { return o.id == hashId; });
    delete properties['fill-pattern'];
    if (!hash) {
      hash = makeSVGPatternFill(hatchStr, hashId);
      if (!hash) return;
      defs.push(hash);
    }
    properties.fill = hash.href;
  }

  function makeSVGPatternFill(str, id) {
    var o = parsePattern(str);
    var svg;
    if (!o) return null;
    if (o.type == 'hatches') {
      svg = makeHatchPatternSVG(o);
    } else if (o.type == 'dots' || o.type == 'squares') {
      svg = makeDotPatternSVG(o);
    } else if (o.type == 'dashes') {
      svg = makeDashPatternSVG(o);
    }
    return {
      svg: wrapSVGPattern(o, id, svg),
      id: id,
      href: `url(#${ id })`
    };
  }

  function wrapSVGPattern(o, id, str) {
    var w = o.tileSize[0];
    var h = o.tileSize[1];
    var svg = `<pattern id="${id}" patternUnits="userSpaceOnUse" width="${ w }" height="${ h }" patternTransform="rotate(${ o.rotation })">`;
    if (o.background) {
      svg += `<rect x="0" y="0" width="${ w }" height="${ h }" fill="${ o.background }"></rect>`;
    }
    return svg + str + '</pattern>';
  }

  function makeDashPatternSVG(o) {
    var svg = '';
    for (var i=0, x=0; i<o.colors.length; i++) {
      svg += `<rect x="${ x }" y="0" width="${ o.width }" height="${ o.dashes[0] }" fill="${ o.colors[i] }"></rect>`;
      x += o.width + o.spacing;
    }
    return svg;
  }

  function makeHatchPatternSVG(o) {
    var h = o.tileSize[1];
    var svg = '';
    for (var i=0, x=0; i<o.widths.length; i++) {
      svg += `<rect x="${ x }" y="0" width="${ o.widths[i] }" height="${ h }" fill="${ o.colors[i] }"></rect>`;
      x += o.widths[i];
    }
    return svg;
  }

  function makeDotPatternSVG(o) {
    var dotSize = o.size;
    var colorCount = o.colors.length;
    var dotDist = dotSize + o.spacing;
    var dotsPerTile = colorCount * colorCount;
    var makeSymbol = o.type == 'squares' ? makeSquare : makeCircle$1;
    var svg = '';
    for (var i=0, x=0, y=0; i<dotsPerTile; i++) {
      svg += makeSymbol(x, y, dotSize, o.colors[(i + Math.floor(i / colorCount)) % colorCount]);
      x = ((i + 1) % colorCount) * dotDist;
      if (x === 0) y += dotDist;
    }
    return svg;
  }

  function makeCircle$1(x, y, size, fill) {
    const r = size / 2;
    return `<circle cx="${x + r}" cy="${y + r}" r="${r}" fill="${ fill }"></circle>`;
  }

  function makeSquare(x, y, size, fill) {
    return `<rect x="${x}" y="${y}" width="${ size }" height="${ size }" fill="${ fill }"></rect>`;
  }

  var SvgHatch = /*#__PURE__*/Object.freeze({
    __proto__: null,
    parsePattern: parsePattern,
    parseDashes: parseDashes,
    parseHatches: parseHatches,
    parseDots: parseDots,
    convertFillPattern: convertFillPattern
  });

  // parsing hints for -style command cli options
  // null values indicate the lack of a function for parsing/identifying this property
  // (in which case a heuristic is used for distinguishing a string literal from an expression)
  var stylePropertyTypes = {
    // css: null,
    css: 'inlinecss',
    class: 'classname',
    dx: 'measure',
    dy: 'measure',
    fill: 'color',
    'fill-pattern': 'pattern',
    'fill-effect': null, // todo: validate effect names
    'font-family': null,
    'font-size': null,
    'font-style': null,
    'font-stretch': null,
    'font-weight': null,
    'label-text': null,  // leaving this null
    'letter-spacing': 'measure',
    'line-height': 'measure',
    opacity: 'number',
    r: 'number',
    stroke: 'color',
    'stroke-dasharray': 'dasharray',
    'stroke-width': 'number',
    'stroke-opacity': 'number',
    'stroke-miterlimit': 'number',
    'fill-opacity': 'number',
    'vector-effect': null,
    'text-anchor': null
  };

  // The -symbols command accepts some options that are not supported by -style
  // (different symbol types accept different combinations of properties...)
  var symbolPropertyTypes = utils.extend({
    type: null,
    length: 'number', // e.g. arrow length
    rotation: 'number',
    radius: 'number',
    radii: null, // string, parsed by function
    flipped: 'boolean',
    rotated: 'boolean',
    direction: 'number',
    sides: 'number', // polygons and stars
    points: 'number', // polygons and stars
    anchor: null, // arrows; takes start, middle, end
    'head-angle': 'number',
    'head-width': 'number',
    'head-length': 'number',
    'stem-width': 'number',
    'stem-curve': 'number', // degrees of arc
    'stem-taper': 'number',
    'stem-length': 'number',
    'min-stem-ratio': 'number',
    'arrow-scaling': 'number',
    effect: null // e.g. "fade"
  }, stylePropertyTypes);

  var commonProperties = 'css,class,opacity,stroke,stroke-width,stroke-dasharray,stroke-opacity,fill-opacity,vector-effect'.split(',');

  var propertiesBySymbolType = {
    polygon: utils.arrayToIndex(commonProperties.concat('fill', 'fill-pattern', 'fill-effect')),
    polyline: utils.arrayToIndex(commonProperties.concat('stroke-linecap', 'stroke-linejoin', 'stroke-miterlimit')),
    point: utils.arrayToIndex(commonProperties.concat('fill', 'r')),
    label: utils.arrayToIndex(commonProperties.concat(
      'fill,font-family,font-size,text-anchor,font-weight,font-style,font-stretch,letter-spacing,dominant-baseline'.split(',')))
  };

  // symType: point, polygon, polyline, label
  function applyStyleAttributes(svgObj, symType, rec, filter) {
    var fields = findPropertiesBySymbolGeom(Object.keys(rec || {}), symType);
    for (var i=0, n=fields.length; i<n; i++) {
      if (filter && !filter(fields[i])) continue;
      setAttribute(svgObj, fields[i], rec[fields[i]]);
    }
    // kludge to prevent default black fill on polygons with stroke styles
    if ((symType == 'polygon' || symType == 'circle') && rec.stroke && !rec.fill) {
      setAttribute(svgObj, 'fill', 'none');
    }
  }

  function setAttribute(obj, k, v) {
    if (!obj.properties) obj.properties = {};
    obj.properties[k] = v;
    if (k == 'stroke-dasharray' && v) {
      // kludge for cleaner dashes... make butt the default?
      obj.properties['stroke-linecap'] = 'butt';
    }
  }

  function isSupportedSvgStyleProperty(name) {
    return name in stylePropertyTypes;
  }

  function isSupportedSvgSymbolProperty(name) {
    return name in symbolPropertyTypes;
  }

  function findPropertiesBySymbolGeom(fields, type) {
    var index = propertiesBySymbolType[type] || {};
    return fields.filter(function(name) {
      return name in index;
    });
  }

  // Returns a function that returns an object containing property values for a single record
  // opts: parsed command line options for the -symbols command
  //
  function getSymbolDataAccessor(lyr, opts) {
    var functions = {};
    var properties = [];
    lyr.data ? lyr.data.getFields() : [];

    Object.keys(opts).forEach(function(optName) {
      var svgName = optName.replace(/_/g, '-');
      if (!isSupportedSvgSymbolProperty(svgName)) {
        return;
      }
      var val = opts[optName];
      functions[svgName] = getSymbolPropertyAccessor(val, svgName, lyr);
      properties.push(svgName);
    });

    // TODO: consider applying values of existing fields with names of symbol properties

    return function(id) {
      var d = {}, name;
      for (var i=0; i<properties.length; i++) {
        name = properties[i];
        d[name] = functions[name](id);
      }
      return d;
    };
  }

  // need a test that identifies any expression but doesn't get triggered by:
  // * invalid patterns: dots 45deg black 3px red
  // * ???
  //
  function mightBeExpression(str, fields) {
    fields = fields || [];
    if (fields.indexOf(str.trim()) > -1) return true;
    return /[(){}./*?:&|=[+-]/.test(str);
  }

  function getSymbolPropertyAccessor(val, svgName, lyr) {
    var strVal = String(val).trim();
    var typeHint = symbolPropertyTypes[svgName];
    var fields = lyr.data ? lyr.data.getFields() : [];
    var literalVal = null;
    var accessor;

    if (typeHint && fields.indexOf(strVal) === -1) {
      literalVal = parseSvgLiteralValue(strVal, typeHint);
    }
    if (literalVal === null && mightBeExpression(strVal, fields)) {
      accessor = parseStyleExpression(strVal, lyr); // no longer throws an error
    }
    if (!accessor && literalVal === null && !typeHint) {
      // We don't have a type rule for detecting an invalid value, so we're
      // treating the string as a literal value
      literalVal = strVal;
    }
    if (accessor) return accessor;
    if (literalVal !== null) return function(id) {return literalVal;};
    stop('Unexpected value for', svgName + ':', strVal);
  }

  function parseStyleExpression(strVal, lyr) {
    var func;
    try {
      func = compileFeatureExpression(strVal, lyr, null, {no_warn: true});
      func(0); // check for runtime errors (e.g. undefined variables)
    } catch(e) {
      func = null;
    }
    return func;
  }

  // returns parsed value or null if @strVal is not recognized as a valid literal value
  function parseSvgLiteralValue(strVal, type) {
    var val = null;
    if (type == 'number') {
      // TODO: handle values with units, like "13px"
      val = isSvgNumber(strVal) ? Number(strVal) : null;
    } else if (type == 'color') {
      val = isSvgColor(strVal) ? strVal : null;
    } else if (type == 'classname') {
      val = isSvgClassName(strVal) ? strVal : null;
    } else if (type == 'measure') { // SVG/CSS length (e.g. 12px, 1em, 4)
      val = isSvgMeasure(strVal) ? parseSvgMeasure(strVal) : null;
    } else if (type == 'dasharray') {
      val = isDashArray(strVal) ? strVal : null;
    } else if (type == 'pattern') {
      val = isPattern(strVal) ? strVal : null;
    } else if (type == 'boolean') {
      val = parseBoolean(strVal);
    } else if (type == 'inlinecss') {
      val = strVal; // TODO: validate
    }
    //  else {
    //   // unknown type -- assume literal value
    //   val = strVal;
    // }
    return val;
  }

  function isPattern(str) {
    return !!parsePattern(str);
  }

  function isDashArray(str) {
    return /^[0-9]+( [0-9]+)*$/.test(str);
  }

  function isSvgClassName(str) {
    return /^( ?[_a-z][-_a-z0-9]*\b)+$/i.test(str);
  }


  function isSvgNumber(o) {
    return utils.isFiniteNumber(o) || utils.isString(o) && /^-?[.0-9]+$/.test(o);
  }

  function parseBoolean(o) {
    if (o === true || o === 'true') return true;
    if (o === false || o === 'false') return false;
    return null;
  }

  function isSvgMeasure(o) {
    return utils.isFiniteNumber(o) || utils.isString(o) && /^-?[.0-9]+[a-z]*$/.test(o);
  }

  // Can be a number or a string
  function parseSvgMeasure(str) {
    return utils.isString(str) && /[a-z]/.test(str) ? str : Number(str);
  }

  function isSvgColor(str) {
    return /^[a-z]+$/i.test(str) ||
      /^#[0-9a-f]+$/i.test(str) || /^rgba?\([0-9,. ]+\)$/.test(str);
  }

  var SvgProperties = /*#__PURE__*/Object.freeze({
    __proto__: null,
    applyStyleAttributes: applyStyleAttributes,
    isSupportedSvgStyleProperty: isSupportedSvgStyleProperty,
    findPropertiesBySymbolGeom: findPropertiesBySymbolGeom,
    getSymbolDataAccessor: getSymbolDataAccessor,
    mightBeExpression: mightBeExpression,
    getSymbolPropertyAccessor: getSymbolPropertyAccessor,
    isSvgClassName: isSvgClassName,
    isSvgNumber: isSvgNumber,
    parseBoolean: parseBoolean,
    isSvgMeasure: isSvgMeasure,
    parseSvgMeasure: parseSvgMeasure,
    isSvgColor: isSvgColor
  });

  var geojsonImporters = {
    Point: importPoint,
    Polygon: importPolygon,
    LineString: importLineString,
    MultiPoint: importMultiPoint,
    MultiLineString: importMultiLineString,
    MultiPolygon: importMultiPolygon
  };

  function importGeoJSONFeatures(features, opts) {
    opts = opts || {};
    return features.map(function(obj) {
      var geom = obj.type == 'Feature' ? obj.geometry : obj; // could be null
      var geomType = geom && geom.type;
      var msType = GeoJSON.translateGeoJSONType(geomType);
      var d = obj.properties || {};
      var svgObj = null;
      if (geomType && geom.coordinates) {
        svgObj = geojsonImporters[geomType](geom.coordinates, d);
      }
      if (!svgObj) {
        return {tag: 'g'}; // empty element
      } else if (msType == 'polyline' || msType == 'polygon') {
        applyStyleAttributes(svgObj, msType, d);
      } else if (msType == 'point' && isSimpleCircle(d)) {
        // kludge -- maintains bw compatibility/passes tests -- style attributes
        // are applied to the <g> container, 'r' property is applied to circle
        applyStyleAttributes(svgObj, msType, d, simpleCircleFilter);
      } else ;
      if ('id' in obj) {
        if (!svgObj.properties) {
          svgObj.properties = {};
        }
        svgObj.properties.id = (opts.id_prefix || '') + obj.id;
      }
      return svgObj;
    });
  }

  function importPoint(coords, rec) {
    rec = rec || {};
    if (isSimpleCircle(rec)) {
      return {
        tag: 'circle',
        properties: {
          cx: coords[0],
          cy: coords[1],
          r: rec.r
        }
      };
    }
    var o = renderPoint(rec);
    if (o) o.properties.transform = getTransform(coords);
    return o;
  }

  function simpleCircleFilter(k) {
    return k != 'r';
  }

  // just a dot, no label or icon
  function isSimpleCircle(rec) {
    return rec && (rec.r > 0 && !rec['svg-symbol'] && !rec['label-text']);
  }

  function importMultiPoint(coords, rec) {
    var children = [], p;
    for (var i=0; i<coords.length; i++) {
      p = importPoint(coords[i], rec);
      if (!p) continue;
      if (p.tag == 'g' && p.children) {
        children = children.concat(p.children);
      } else {
        children.push(p);
      }
    }
    return children.length > 0 ? {tag: 'g', children: children} : null;
  }

  function importLineString(coords) {
    var d = stringifyLineStringCoords(coords);
    return {
      tag: 'path',
      properties: {d: d}
    };
  }

  function importMultiLineString(coords) {
    var d = coords.map(stringifyLineStringCoords).join(' ');
    return {
      tag: 'path',
      properties: {d: d}
    };
  }

  function importMultiPolygon(coords) {
   return importPolygon(flattenMultiPolygonCoords(coords));
  }

  function flattenMultiPolygonCoords(coords) {
    return coords.reduce(function(memo, poly) {
      return memo.concat(poly);
    }, []);
  }

  function importPolygon(coords) {
    if (coords.length === 0) return null;
    var o = {
      tag: 'path',
      properties: {
        d: stringifyPolygonCoords(coords)
      }
    };
    if (coords.length > 1) {
      o.properties['fill-rule'] = 'evenodd'; // support polygons with holes
    }
    return o;
  }

  var GeojsonToSvg = /*#__PURE__*/Object.freeze({
    __proto__: null,
    importGeoJSONFeatures: importGeoJSONFeatures,
    importPoint: importPoint,
    importLineString: importLineString,
    importMultiLineString: importMultiLineString,
    importMultiPolygon: importMultiPolygon,
    flattenMultiPolygonCoords: flattenMultiPolygonCoords,
    importPolygon: importPolygon
  });

  function toLabelString(val) {
    if (val || val === 0 || val === false) return String(val);
    return '';
  }

  // Kludge for applying fill and other styles to a <text> element
  // (for rendering labels in the GUI with the dot in Canvas, not SVG)
  function renderStyledLabel(rec) {
    var o = renderLabel$1(rec);
    applyStyleAttributes(o, 'label', rec);
    return o;
  }

  function renderLabel$1(rec) {
    var line = toLabelString(rec['label-text']);
    var morelines, obj;
    // Accepting \n (two chars) as an alternative to the newline character
    // (sometimes, '\n' is not converted to newline, e.g. in a Makefile)
    // Also accepting <br>
    var newline = /\n|\\n|<br>/i;
    var dx = rec.dx || 0;
    var dy = rec.dy || 0;
    var properties = {
      // using x, y instead of dx, dy for shift, because Illustrator doesn't apply
      // dx value when importing text with text-anchor=end
      y: dy,
      x: dx
    };
    if (newline.test(line)) {
      morelines = line.split(newline);
      line = morelines.shift();
    }
    obj = {
      tag: 'text',
      value: line,
      properties: properties
    };
    if (morelines) {
      // multiline label
      obj.children = [];
      morelines.forEach(function(line) {
        var tspan = {
          tag: 'tspan',
          value: line,
          properties: {
            x: dx,
            dy: rec['line-height'] || '1.1em'
          }
        };
        obj.children.push(tspan);
      });
    }
    return obj;
  }

  var SvgLabels = /*#__PURE__*/Object.freeze({
    __proto__: null,
    renderStyledLabel: renderStyledLabel,
    renderLabel: renderLabel$1
  });

  // convert data records (properties like svg-symbol, label-text, fill, r) to svg symbols

  function getTransform(xy, scale) {
    var str = 'translate(' + roundToTenths(xy[0]) + ' ' + roundToTenths(xy[1]) + ')';
    if (scale && scale != 1) {
      str += ' scale(' + scale + ')';
    }
    return str;
  }

  var symbolRenderers = {
    line: line,
    polygon: polygon,
    polyline: polyline,
    circle: circle,
    square: square,
    image: image,
    group: group,
    label: label,
    offset: offset
  };

  // render label and/or point symbol
  function renderPoint(rec) {
    var children = [];
    // var halfSize = rec.r || 0; // radius or half of symbol size
    if (featureHasSvgSymbol(rec)) {
      children.push(renderSymbol(rec));
    }
    if (featureHasLabel(rec)) {
      children.push(renderStyledLabel(rec));
    }
    var o = children.length > 1 ? {tag: 'g', children: children} : children[0];
    if (!o) return null;
    o.properties = o.properties || {};
    return o;
  }

  function renderSymbol(d) {
    if (d['svg-symbol']) {
      return renderComplexSymbol(d['svg-symbol']);
    }
    if (d.r > 0) {
      return circle(d);
    }
    return empty();
  }

  function renderComplexSymbol(sym, x, y) {
    if (utils.isString(sym)) {
      sym = JSON.parse(sym);
    }
    if (sym.tag) {
      // symbol appears to already use mapshaper's svg notation... pass through
      return sym;
    }
    var renderer = symbolRenderers[sym.type];
    if (!renderer) {
      message(sym.type ? 'Unknown symbol type: ' + sym.type : 'Symbol is missing a type property');
      return empty();
    }
    var o = renderer(sym, x || 0, y || 0);
    if (sym.opacity) {
      o.properties.opacity = sym.opacity;
    }
    return o;
  }

  function empty() {
    return {tag: 'g', properties: {}, children: []};
  }

  function circle(d, x, y) {
    var o = {
      tag: 'circle',
      properties: {
        cx: x || 0,
        cy: y || 0
      }
    };
    applyStyleAttributes(o, 'point', d);
    return o;
  }

  function label(d, x, y) {
    var o = renderStyledLabel(d);
    if (x || y) {
      // set x, y here, rather than adding to dx, dy -- so dy, dy can
      // have CSS units (like ems)
      o.properties.transform = getTransform([x, y]);
    }
    return o;
  }

  function image(d, x, y) {
    var w = d.width || 20,
        h = d.height || 20;
    var o = {
      tag: 'image',
      properties: {
        width: w,
        height: h,
        x: (x || 0) - w / 2,
        y: (y || 0) - h / 2,
        href: d.href || ''
      }
    };
    if (d.fill) o.properties.fill = d.fill;
    return o;
  }

  function square(d, x, y) {
    var r = d.r || 0;
    var o = {
      tag: 'rect',
      properties: {
        x: x - r,
        y: y - r,
        width: r * 2,
        height: r * 2
      }
    };
    applyStyleAttributes(o, 'point', d);
    return o;
  }

  function line(d, x, y) {
    var coords, o;
    coords = [[x, y], [x + (d.dx || 0), y + (d.dy || 0)]];
    o = importLineString(coords);
    applyStyleAttributes(o, 'polyline', d);
    return o;
  }

  // polyline coords are like GeoJSON MultiLineString coords: an array of 0 or more paths
  function polyline(d) {
    var coords = d.coordinates || [];
    var o = importMultiLineString(coords);
    applyStyleAttributes(o, 'polyline', d);
    return o;
  }

  // polygon coords are an array of rings (and holes), like flattened MultiPolygon coords
  function polygon(d) {
    var coords = d.coordinates || [];
    var o = importPolygon(coords);
    applyStyleAttributes(o, 'polygon', d);
    return o;
  }

  function offset(d, x, y) {
    var dx = (x || 0) + (d.dx || 0);
    var dy = (y || 0) + (d.dy || 0);
    return {
      tag: 'g',
      properties: {
        transform: getTransform([dx, dy])
      },
      children: []
    };
  }

  function group(d, x, y) {
    var o = {
      tag: 'g',
      children: []
    };
    var children = o.children;
    (d.parts || []).forEach(function(o) {
      var sym = renderComplexSymbol(o, x, y);
      children.push(sym);
      //if (d.chained) {
      //if (o.chained) {
      if (o.type == 'line') {
        x += (o.dx || 0);
        y += (o.dy || 0);
      }
      if (o.type == 'offset') {
        children = sym.children;
        x = y = 0;
      }
    });
    if (o.children.length == 1 && !o.properties) return o.children[0];
    return o;
  }

  var SvgSymbols = /*#__PURE__*/Object.freeze({
    __proto__: null,
    getTransform: getTransform,
    symbolRenderers: symbolRenderers,
    renderPoint: renderPoint
  });

  cmd.scalebar = function(catalog, opts) {
    var lyr = getScalebarLayer(opts);
    if (opts.label && !parseScalebarUnits(opts.label)) {
      stop(`Expected units of km or miles in scalebar label (received ${opts.label})`);
    }
    addFurnitureLayer(lyr, catalog);
  };

  function getScalebarLayer(opts) {
    var obj = utils.defaults({type: 'scalebar'}, opts);
    return {
      name: opts.name || 'scalebar',
      data: new DataTable([obj])
    };
  }

  function renderScalebar(d, frame) {
    if (!frame.crs) {
      message('Unable to render scalebar: unknown CRS.');
      return [];
    }
    if (frame.width > 0 === false) {
      return [];
    }

    var opts = getScalebarOpts(d);
    var metersPerPx = getMapFrameMetersPerPixel(frame);
    var frameWidthPx = frame.width;
    var labels = d.label ? d.label.split(',') : null;
    var label1 = labels && labels[0] || null;
    var props1 = parseScalebarLabel(label1 || getAutoScalebarLabel(frameWidthPx, metersPerPx, 'mile'));
    var label2 = opts.style == 'b' && labels && labels[1] || null;
    var props2, length2;

    if (props1.km > 0 === false) {
      message('Unusable scalebar label:', label1);
      return [];
    }

    var length1 = Math.round(props1.km / metersPerPx * 1000);
    if (length1 > 0 === false) {
      stop("Null scalebar length");
    }

    if (label2) {
      props2 = parseScalebarLabel(label2);
      length2 = Math.round(props2.km / metersPerPx * 1000);
      if (length2 > length1) {
        stop("First part of a dual-unit scalebar must be longer than the second part.");
      }
    }

    var barPos = getScalebarPosition(opts);
    var labelPos = getLabelPosition(opts);
    var dx = barPos.xpos == 'right' ? frameWidthPx - length1 - opts.margin : opts.margin;
    var dy = barPos.ypos == 'bottom' ? frame.height - opts.margin : opts.margin;

    // vshift to adjust for height above or below the baseline
    var labelHeight = Math.round(opts.label_offset + opts.tic_length + opts.font_size * 0.8 + opts.bar_width / 2);
    var bareHeight = Math.round(opts.bar_width / 2);
    var topHeight = labelPos.ypos == 'top' || label2 ? labelHeight : bareHeight;
    var bottomHeight = labelPos.ypos == 'bottom' || label2 ? labelHeight : bareHeight;
    if (barPos.ypos == 'top') {
      dy += topHeight;
    } else {
      dy -= bottomHeight;
    }

    var g = renderAsSvg(length1, label1, length2, label2, opts);
    g.properties = {
      transform: 'translate(' + dx + ' ' + dy + ')'
    };

    return [g];
  }

  var styleOpts = {
    a: {
      bar_width: 3,
      tic_length: 0
    },
    b: {
      bar_width: 1,
      tic_length: 5
    }
  };

  var defaultOpts = {
    position: 'top-left',
    label_position: 'top',
    label_offset: 4,
    font_size: 12,
    margin: 12
  };

  function getScalebarOpts(d) {
    var style = d.style == 'b' || d.style == 'B' ? 'b' : 'a';
    return Object.assign({}, defaultOpts, styleOpts[style], d, {style: style});
  }

  function renderAsSvg(length, text, length2, text2, opts) {
    var labelPart = renderLabel(text, length, opts);
    var zeroLabelPart = renderLabel('0', length, Object.assign({flipx: true}, opts));
    var barPart = renderBar(length, length2, opts);
    var parts = opts.style == 'b' ? [zeroLabelPart, labelPart, barPart] : [labelPart, barPart];
    if (text2) {
      parts.push(renderLabel(text2, length2, Object.assign({flipy: true}, opts)));
      parts.push(renderLabel('0', length2, Object.assign({flipx: true, flipy: true}, opts)));
    }
    return {
      tag: 'g',
      children: parts
    };
  }

  // TODO: generalize to other kinds of furniture as they are developed
  function getScalebarPosition(opts) {
    var pos = opts.position || 'top-left';
    return {
      ypos: pos.includes('top') ? 'top' : 'bottom',
      xpos: pos.includes('left') ? 'left' : 'right'
    };
  }

  function renderLabel(text, length, opts) {
    var labelPos = getLabelPosition(opts);
    var anchorX = length * labelPos.kx + labelPos.dx;
    var bottomLabelY = opts.bar_width + opts.tic_length + opts.label_offset;
    var topLabelY = -opts.label_offset - opts.tic_length;
    var anchorY = labelPos.ypos == 'top' ? topLabelY : bottomLabelY;
    var labelOpts = {
        'label-text': text,
        'font-size': opts.font_size,
        'text-anchor': labelPos.anchor,
        'dominant-baseline': labelPos.ypos == 'top' ? 'auto' : 'hanging'
        //// 'dominant-baseline': labelPos == 'top' ? 'text-after-edge' : 'text-before-edge'
        // 'text-after-edge' is buggy in Safari and unsupported by Illustrator,
        // so I'm using 'hanging' and 'auto', which seem to be well supported.
        // downside: requires a kludgy multiplier to calculate scalebar height (see above)
      };
    return symbolRenderers.label(labelOpts, anchorX, anchorY);
  }

  function getLabelPosition(opts) {
    var pos = opts.label_position;
    var ypos = pos.includes('bottom') && 'bottom' || 'top';
    var dx = 0;
    var xpos;
    if (opts.style == 'a') {
      xpos = pos.includes('center') && 'center' || pos.includes('right') && 'right' || 'left';
    } else {
      xpos = 'right'; // style b
    }
    if (opts.flipx) {
      xpos = xpos == 'left' && 'right' || xpos == 'right' && 'left' || xpos;
    }
    if (opts.flipy) {
      ypos = ypos == 'top' && 'bottom' || ypos == 'bottom' && 'top' || ypos;
    }
    if (opts.style == 'b') {
      dx = xpos == 'left' && -opts.font_size / 4 || xpos == 'right' && opts.font_size / 4 || 0;
    }
    return {
      xpos,
      ypos,
      dx,
      kx: xpos == 'right' && 1 || xpos == 'center' && 0.5 || 0,
      anchor: xpos == 'center' && 'middle' || xpos == 'left' && 'start' || 'end'
    };
  }

  // length1: length of main bar
  // length2: length of optional second distance (assumes that length2 <= length1)
  function getStyleBCoords(length1, length2, opts) {
    var coords = [];
    var labelPos = getLabelPosition(opts);
    var y = opts.tic_length + opts.bar_width / 2;
    if (labelPos.ypos == "top") {
      y = -y;
    }
    coords.push([[0, y], [0, 0], [length1, 0], [length1, y]]);
    if (length2 > 0) {
      coords.push([[0, 0], [0, -y]]);
      coords.push([[length2, 0], [length2, -y]]);
    }
    return coords;
  }

  // length: length of scale bar in px
  // length2: length of optional dual-units portion of the scalebar
  function renderBar(length, length2, opts) {
    var coords;
    if (opts.style == 'b') {
      coords = getStyleBCoords(length, length2, opts);
    } else {
      coords = [[[0, 0], [length, 0]]];
    }
    var bar = importMultiLineString(coords);
    Object.assign(bar.properties, {
      stroke: 'black',
      fill: 'none',
      'stroke-width': opts.bar_width,
      'stroke-linecap': 'butt',
      'stroke-linejoin': 'miter'
    });
    return bar;
  }

  // unit: 'km' || 'mile'
  function getAutoScalebarLabel(mapWidth, metersPerPx, unit) {
    var minWidth = 70; // 100; // TODO: vary min size based on map width
    var minKm = metersPerPx * minWidth / 1000;
    // note: removed 1.5 12 and 1,200
    var options = ('1/8 1/5 1/4 1/2 1 2 3 4 5 8 10 15 20 25 30 40 50 75 ' +
      '100 150 200 250 300 350 400 500 750 1,000 1,500 2,000 ' +
      '2,500 3,000 4,000 5,000').split(' ');
    return options.reduce(function(memo, str) {
      if (memo) return memo;
      var label = formatDistanceLabel(str, unit);
      if (parseScalebarLabelToKm(label) > minKm) {
         return label;
      }
    }, null) || '';
  }

  function formatDistanceLabel(numStr, unit) {
    var num = parseScalebarNumber(numStr);
    var unitStr = unit == 'km' && 'KM' || num > 1 && 'MILES' || 'MILE';
    return numStr + ' ' + unitStr;
  }

  // See test/mapshaper-scalebar.js for examples of supported formats
  function parseScalebarLabelToKm(str) {
    var units = parseScalebarUnits(str);
    var value = parseScalebarNumber(str);
    if (!units || !value) return NaN;
    return units == 'mile' ? value * 1.60934 : value;
  }

  function parseScalebarLabel(label) {
    var num = label ? parseScalebarNumber(label) : null;
    var units = label ? parseScalebarUnits(label) : 'mile';
    var km = NaN;
    if (units && num) {
      km =  units == 'mile' ? num * 1.60934 : num;
    }
    return {
      number: num,
      units: units,
      km: km
    };
  }

  function parseScalebarUnits(str) {
    var isMiles = /(miles?|mi[.]?|)$/.test(str.toLowerCase());
    var isKm = /(k\.m\.|km|kilometers?|kilom.tres?|)$/.test(str.toLowerCase());
    var units = isMiles && 'mile' || isKm && 'km' || '';
    return units;
  }

  function parseScalebarNumber(str) {
    var fractionRxp = /^([0-9]+) ?\/ ?([0-9]+)/;
    var match, value;
    str = str.replace(/[\s]/g, '').replace(/,/g, '');
    if (fractionRxp.test(str)) {
      match = fractionRxp.exec(str);
      value = +match[1] / +match[2];
    } else {
      value = parseFloat(str);
    }
    return value > 0 && value < Infinity ? value : NaN;
  }

  var Scalebar = /*#__PURE__*/Object.freeze({
    __proto__: null,
    getScalebarLayer: getScalebarLayer,
    renderScalebar: renderScalebar,
    formatDistanceLabel: formatDistanceLabel,
    parseScalebarLabelToKm: parseScalebarLabelToKm
  });

  var furnitureRenderers = {
    scalebar: renderScalebar
    // frame: renderFrame
  };

  // @lyr a layer in a dataset
  function layerHasFurniture(lyr) {
    var type = getFurnitureLayerType(lyr);
    return !!type && (type in furnitureRenderers);
  }

  function isFurnitureLayer(lyr) {
    // return !!mapLayer.furniture;
    return layerHasFurniture(lyr);
  }

  // @lyr dataset layer
  function getFurnitureLayerType(lyr) {
    var rec = lyr.data && lyr.data.getReadOnlyRecordAt(0);
    return rec && rec.type || null;
  }

  function getFurnitureLayerData(lyr) {
    return lyr.data && lyr.data.getReadOnlyRecordAt(0);
  }

  function renderFurnitureLayer(lyr, frame) {
    var d = getFurnitureLayerData(lyr);
    var renderer = furnitureRenderers[d.type];
    if (!renderer) {
      stop('Missing renderer for', d.type, 'element');
    }
    if (!frame.crs) {
      stop(`Unable to render ${d.type} (unknown map projection)`);
    }
    if (!isProjectedCRS(frame.crs)) {
      stop(`Unable to render ${d.type} (map is unprojected)`);
    }
    return renderer(d, frame) || [];
  }

  var Furniture = /*#__PURE__*/Object.freeze({
    __proto__: null,
    layerHasFurniture: layerHasFurniture,
    isFurnitureLayer: isFurnitureLayer,
    getFurnitureLayerType: getFurnitureLayerType,
    getFurnitureLayerData: getFurnitureLayerData,
    renderFurnitureLayer: renderFurnitureLayer
  });

  function stringify(obj) {
    var svg, joinStr;
    if (!obj || !obj.tag) return '';
    svg = '<' + obj.tag;
    // w.s. is significant in text elements
    if (obj.properties) {
      svg += stringifyProperties(obj.properties);
    }
    if (obj.children || obj.value) {
      joinStr = obj.tag == 'text' || obj.tag == 'tspan' ? '' : '\n';
      svg += '>' + joinStr;
      if (obj.value) {
        svg += stringEscape(obj.value);
      }
      if (obj.children) {
        svg += obj.children.map(stringify).join(joinStr);
      }
      svg += joinStr + '</' + obj.tag + '>';
    } else {
      svg += '/>';
    }
    return svg;
  }

  // Replace some chars with XML "predefined entities" to avoid parsing errors
  // https://en.wikipedia.org/wiki/List_of_XML_and_HTML_character_entity_references#Predefined_entities_in_XML
  var rxp = /[&<>"']/g,
      map = {
        '&': '&amp;',
        '<': '&lt;',
        '>': '&gt;',
        '"': '&quot;',
        "'": '&apos;'
      };
  function stringEscape(s) {
    return String(s).replace(rxp, function(match, i) {
      var entity = map[match];
      // don't replace &amp; with &amp;amp;
      if (match == '&' && s.substr(i, entity.length) == entity) {
        return '&';
      }
      return entity;
    });
  }

  function stringifyProperties(o) {
    return Object.keys(o).reduce(function(memo, key) {
      var val = o[key],
          strval;
      if (!val && val !== 0) return memo; // omit undefined / empty / null values
      strval = utils.isString(val) ? val : JSON.stringify(val);
      if (key == 'href') {
        key = 'xlink:href';
      }
      if (key == 'css') {
        key = 'style'; // inline style
      }
      return memo + ' ' + key + '="' + stringEscape(strval) + '"';
    }, '');
  }

  var SvgStringify = /*#__PURE__*/Object.freeze({
    __proto__: null,
    stringify: stringify,
    stringEscape: stringEscape,
    stringifyProperties: stringifyProperties
  });

  // public domain implementation
  // source: https://github.com/jbt/js-crypto
  function sha1(str1){
    for (
      var blockstart = 0,
        i = 0,
        W = [],
        A, B, C, D, F, G,
        H = [A=0x67452301, B=0xEFCDAB89, ~A, ~B, 0xC3D2E1F0],
        word_array = [],
        temp2,
        s = unescape(encodeURI(str1)),
        str_len = s.length;

      i <= str_len;
    ){
      word_array[i >> 2] |= (s.charCodeAt(i)||128) << (8 * (3 - i++ % 4));
    }
    word_array[temp2 = ((str_len + 8) >> 2) | 15] = str_len << 3;

    for (; blockstart <= temp2; blockstart += 16) {
      A = H; i = 0;

      for (; i < 80;
        A = [[
          (G = ((s = A[0]) << 5 | s >>> 27) + A[4] + (W[i] = (i<16) ? ~~word_array[blockstart + i] : G << 1 | G >>> 31) + 1518500249) + ((B = A[1]) & (C = A[2]) | ~B & (D = A[3])),
          F = G + (B ^ C ^ D) + 341275144,
          G + (B & C | B & D | C & D) + 882459459,
          F + 1535694389
        ][0|((i++) / 20)] | 0, s, B << 30 | B >>> 2, C, D]
      ) {
        G = W[i - 3] ^ W[i - 8] ^ W[i - 14] ^ W[i - 16];
      }

      for(i = 5; i; ) H[--i] = H[i] + A[i] | 0;
    }

    for(str1 = ''; i < 40; )str1 += (H[i >> 3] >> (7 - i++ % 8) * 4 & 15).toString(16);
    return str1;
  }

  function getSphereEffectParams() {
    return {
      cx: 0.5,
      cy: 0.5,
      r: 0.57,
      fx: 0.35,
      fy: 0.35,
      stops: [
        {offset: 0.3, opacity: 0},
        {offset: 0.6, opacity: 0.1},
        {offset: 0.78, opacity: 0.25},
        {offset: 0.87, opacity: 0.45},
        {offset: 0.95, opacity: 1}]
    };
  }

  function convertFillEffect(obj, defs) {
    if (obj['fill-effect'] != 'sphere') return; // only "sphere" is supported
    var id = 'mapshaper_sphere_effect';
    var href = `url(#${ id })`;
    var params = getSphereEffectParams();
    var stops = params.stops.map(function(stop) {
        return `<stop offset="${stop.offset}" stop-opacity="${stop.opacity}"/>`;
      });
    var svg =
`<radialGradient id="${id}" cx="${params.cx}" cy="${params.cy}" r="${params.r}" fx="${params.fx}" fy="${params.fy}">${stops.join('')}</radialGradient>`  ;
    if (!utils.find(defs, function(o) { return o.id == id; })) {
      defs.push({svg, id, href});
    }
    obj.fill = href;
    if ('opacity' in obj === false && 'fill-opacity' in obj === false) {
      obj['fill-opacity'] = 0.35;
    }
  }

  var SvgEffect = /*#__PURE__*/Object.freeze({
    __proto__: null,
    getSphereEffectParams: getSphereEffectParams,
    convertFillEffect: convertFillEffect
  });

  var cache = {};
  function fetchFileSync(url) {
    if (url in cache) return cache[url];
    var res  = require$1('sync-request')('GET', url, {timeout: 2000});
    var content = res.getBody().toString();
    cache[url] = content;
    return content;
  }

  // convert object properties to definitions for images and hatch fills
  function convertPropertiesToDefinitions(obj, defs) {
    procNode(obj);

    function procNode(obj) {
      if (obj.tag == 'path' && obj.properties['fill-pattern']) {
        convertFillPattern(obj.properties, defs);
      }
      if (obj.tag == 'path' && obj.properties['fill-effect']) {
        convertFillEffect(obj.properties, defs);
      }
      if (obj.tag == 'image') {
        if (/\.svg/.test(obj.properties.href || '')) {
          convertSvgImage(obj, defs);
        }
      } else if (obj.children) {
        obj.children.forEach(procNode);
      }
    }
  }

  function convertSvgImage(obj, defs) {
    // Same-origin policy prevents embedding images in the web UI
    var href = obj.properties.href;
    // look for a previously added definition to use
    // (assumes that images that share the same href can also use the same defn)
    var item = utils.find(defs, function(item) {return item.href == href;});
    if (!item) {
      item = {
        href: href,
        id: urlToId(href) // generating id from href, to try to support multiple inline svgs on page
      };
      item.svg = serializeSvgImage(href, item.id);
      defs.push(item);
    }
    if (item.svg) {
      obj.tag = 'use';
      obj.properties.href = '#' + item.id;
    }
  }

  // Returns the content of an SVG file from a local path or URL
  // Returns '' if unable to get the content (e.g. due to cross-domain security rules)
  function serializeSvgImage(href, id) {
    var svg = '';
    try {
      // try to download the SVG content and use that
      svg = convertSvgToDefn(getSvgContent(href), id) + '\n';
      svg = '<!-- ' + href + '-->\n' + svg; // add href as a comment, to aid in debugging
    } catch(e) {
      // tried creating a symbol as a fallback... encounted problems with icon
      // size and placement, giving up on this for now
      // svg = `<symbol><image xlink:href="${obj.properties.href}" id="${id}"></image></symbol>`;
    }
    return svg;
  }

  // href: A URL or a local path
  // TODO: download SVG files asynchronously
  // (currently, files are downloaded synchronously, which is obviously undesirable)
  //
  function getSvgContent(href) {
    var content;
    if (href.indexOf('http') === 0) {
      content = fetchFileSync(href);
    } else if (require$1('fs').existsSync(href)) {
      content = require$1('fs').readFileSync(href, 'utf8');
    } else {
      stop("Invalid SVG location:", href);
    }
    return content;
  }

  function convertSvgToDefn(svg, id) {
    // Remove stuff before <svg> tag
    svg = svg.replace(/[^]*<svg/, '<svg');
    return svg.replace(/^<svg[^>]*>/, function(a) {
      // set id property of <svg>
      a = a.replace(/ id="[^"]*"/, '');
      a = a.replace(/<svg/, '<svg id="' + id + '"');
      return a;
    });
  }

  function urlToId(url) {
    return sha1(url).substr(0, 12);
  }

  /*
  function convertSvgToSymbol(svg, id) {
    svg = svg.replace(/[^]*<svg/, '<svg');
    // Remove inkscape tags (there were errors caused when namespaces were
    // stripped when converting <svg> to <symbol> ... this may be futile, may
    // have to go back to embedding entire SVG document instead of using symbols)
    svg = svg.replace(/<metadata[^]*?metadata>/, '');
    svg = svg.replace(/<sodipodi[^>]*>/, '');
    // convert <svg> to <symbol>
    svg = svg.replace(/^<svg[^>]*>/, function(a) {
      var viewBox = a.match(/viewBox=".*?"/)[0];
      return '<symbol id="' + id + '" ' + viewBox + '>';
    });
    svg = svg.replace('svg>', 'symbol>');
    return svg;
  }
  */

  //
  function exportSVG(dataset, opts) {
    var namespace = 'xmlns="http://www.w3.org/2000/svg"';
    var defs = [];
    var frame, svg, layers;
    var style = '';

    // kludge for map keys
    if (opts.crisp_paths) {
      style = `
<style>
  path {shape-rendering: crispEdges;}
</style>`;
    }

    // TODO: consider moving this logic to mapshaper-export.js
    if (opts.final) {
      if (dataset.arcs) dataset.arcs.flatten();
    } else {
      dataset = copyDataset(dataset); // Modify a copy of the dataset
    }

    // use invert_y: 0 setting for screen coordinates and geojson polygon generation
    // use 1px default margin so typical strokes don't get cut off on the sides
    opts = Object.assign({invert_y: true, margin: "1"}, opts);
    frame = getFrameData(dataset, opts);
    fitDatasetToFrame(dataset, frame);
    setCoordinatePrecision(dataset, opts.precision || 0.0001);

    // error if one or more svg_data fields are not present in any layers
    if (opts.svg_data) validateSvgDataFields(dataset.layers, opts.svg_data);

    layers = dataset.layers;
    if (opts.scalebar) {
      layers.push(getScalebarLayer({})); // default options
    }
    svg = layers.map(function(lyr) {
      var obj;
      if (layerHasFurniture(lyr)) {
        obj = exportFurnitureLayerForSVG(lyr, frame, opts);
      } else {
        obj = exportLayerForSVG(lyr, dataset, opts);
      }
      convertPropertiesToDefinitions(obj, defs);
      return stringify(obj);
    }).join('\n');

    if (defs.length > 0) {
      svg = '<defs>\n' + utils.pluck(defs, 'svg').join('') + '</defs>\n' + svg;
    }

    if (svg.includes('xlink:')) {
      namespace += ' xmlns:xlink="http://www.w3.org/1999/xlink"';
    }

    // default line style properties
    var capStyle = opts.default_linecap || 'round';
    var lineProps = `stroke-linecap="${capStyle}" stroke-linejoin="round"`;
    if (svg.includes('stroke-linejoin="miter"')) {
      // the default limit in Illustrator seems to be 10 -- too large for mapping
      // (Mapbox uses 2 as the default in their styles)
      lineProps += ' stroke-miterlimit="2"';
    }
    var template = `<?xml version="1.0"?>
<svg ${namespace} version="1.2" baseProfile="tiny" width="%d" height="%d" viewBox="%s %s %s %s" ${lineProps}>${style}
${svg}
</svg>`;
    svg = utils.format(template, frame.width, frame.height, 0, 0, frame.width, frame.height);
    return [{
      content: svg,
      filename: opts.file || getOutputFileBase(dataset) + '.svg'
    }];
  }

  function exportFurnitureLayerForSVG(lyr, frame, opts) {
    var layerObj = getEmptyLayerForSVG(lyr, opts);
    layerObj.children = renderFurnitureLayer(lyr, frame);
    return layerObj;
  }

  // Prevent unstyled rectangle layers from displaying with the SVG default
  // solid black fill.
  // lyr: a layer, assumed to contain a single rectangular polygon
  function adjustRectangleStyle(lyr) {
    var data = getLayerDataTable(lyr);
    var d = data.getRecords()[0];
    if (!d.fill && !d.stroke) {
      d.fill = "none";
    }
  }

  function exportLayerForSVG(lyr, dataset, opts) {
    var layerObj = getEmptyLayerForSVG(lyr, opts);
    if (layerIsRectangle(lyr, dataset.arcs)) {
      lyr = copyLayer(lyr);
      adjustRectangleStyle(lyr);
    }
    layerObj.children = exportSymbolsForSVG(lyr, dataset, opts);
    return layerObj;
  }

  function exportSymbolsForSVG(lyr, dataset, opts) {
    // TODO: convert geojson features one at a time
    var d = utils.defaults({layers: [lyr]}, dataset);
    var geojson = exportDatasetAsGeoJSON(d, opts);
    var features = geojson.features || geojson.geometries || (geojson.type ? [geojson] : []);
    var children = importGeoJSONFeatures(features, opts);
    if (opts.svg_data && lyr.data) {
      addDataAttributesToSVG(children, lyr.data, opts.svg_data);
    }
    return children;
  }

  function validateSvgDataFields(layers, fieldsArg) {
    var missingFields = fieldsArg.reduce(function(memo, field) {
      if (!fieldExists(layers, field)) {
        memo.push(field);
      }
      return memo;
    }, []);

    if (missingFields.length && missingFields.indexOf('*') == -1) {
      stop("Missing data field(s):", missingFields.join(', '));
    }

    function fieldExists(layers, field) {
      return utils.some(layers, function(lyr) {
        return lyr.data && lyr.data.fieldExists(field) || false;
      });
    }
  }

  function addDataAttributesToSVG(children, table, fieldsArg) {
    var allFields = table.getFields();
    var dataFields = fieldsArg.indexOf('*') > -1 ? allFields.concat() : fieldsArg;
    var missingFields = utils.difference(dataFields, allFields);
    if (missingFields.length > 0) {
      dataFields = utils.difference(dataFields, missingFields);
      // stop("Missing data field(s):", missingFields.join(', '));
    }
    var records = table.getRecords();
    var data = exportDataAttributesForSVG(records, dataFields);
    if (children.length != data.length) {
      error("Mismatch between number of SVG symbols and data attributes");
    }
    children.forEach(function(child, i) {
      utils.extend(child.properties || {}, data[i]);
    });
  }

  function exportDataAttributesForSVG(records, fields) {
    var validRxp = /^[a-z_][a-z0-9_-]*$/i;
    var invalidRxp = /^xml/;
    var validFields = fields.filter(function(name) {
      return validRxp.test(name) && !invalidRxp.test(name);
    });
    var invalidFields = utils.difference(fields, validFields);
    if (invalidFields.length > 0) {
      message("Unable to add data-* attributes for field(s):", invalidFields.join(', '));
      message("data-* names should match pattern [a-z_][a-z0-9_-]*");
    }
    return records.map(function(rec) {
      var obj = {};
      for (var i=0; i<validFields.length; i++) {
        obj['data-' + validFields[i].toLowerCase()] =
          validDataAttributeValue(rec[validFields[i]]);
      }
      return obj;
    });
  }

  function validDataAttributeValue(val) {
    // TODO: consider converting some falsy values to empty strings
    // (e.g. null, undefined, NaN)
    return String(val);
  }

  // internal.validDataAttributeNames = function(names) {
  //   return utils.uniqifyNames(names.map(internal.validDataAttributeName));
  // };

  // There are restrictions on data-* attribute names
  // This function modifies names so they can be used
  // See: https://developer.mozilla.org/en-US/docs/Web/SVG/Attribute/data-*
  // Mapshaper's rules are a bit more restrictive than the spec -- e.g.
  //   the first character after "data-" is restricted to "_" | [a-z]
  //
  // internal.validDataAttributeName = function(name) {
  //   name = name.toLowerCase();
  //   name = name.replace(/[^a-z0-9_-]/g, ''); // accept only these letters
  //   if (/^([0-9-]|xml)/.test(name) || name === '') {
  //     name = '_' + name; // prepend underscore if needed
  //   }
  //   return name;
  // };

  function getEmptyLayerForSVG(lyr, opts) {
    var id = (opts.id_prefix || '') + (lyr.name || utils.getUniqueName('layer'));
    var layerObj = {
      tag: 'g',
      properties: {id: id},
      children: []
    };

    // override default black fill for layers that might have open paths
    // TODO: set fill="none" in SVG symbols, not on the container
    //   (setting fill=none on the container overrides the default black fill
    //   on paths, which may alter the appearance of SVG icons loaded from external URLs).
    if (lyr.geometry_type == 'polyline' || layerHasSvgSymbols(lyr)) {
      layerObj.properties.fill = 'none';
    }

    // add default display properties to line layers
    // (these are overridden by feature-level styles set via -style)
    if (lyr.geometry_type == 'polyline') {
      layerObj.properties.stroke = 'black';
      layerObj.properties['stroke-width'] = 1;
    }


    // add default text properties to layers with labels
    if (layerHasLabels(lyr) || layerHasSvgSymbols(lyr) || layerHasFurniture(lyr)) {
      layerObj.properties['font-family'] = 'sans-serif';
      layerObj.properties['font-size'] = '12';
      layerObj.properties['text-anchor'] = 'middle';
    }

    return layerObj;
  }

  function featureHasSvgSymbol(d) {
    return !!(d && (d['svg-symbol'] || d.r));
  }

  function featureHasLabel(d) {
    var text = d && d['label-text'];
    return text || text === 0; // accept numerical 0 as label text
  }

  function layerHasSvgSymbols(lyr) {
    return lyr.geometry_type == 'point' && lyr.data && lyr.data.fieldExists('svg-symbol');
  }

  function layerHasLabels(lyr) {
    var hasLabels = lyr.geometry_type == 'point' && lyr.data && lyr.data.fieldExists('label-text');
    //if (hasLabels && internal.findMaxPartCount(lyr.shapes) > 1) {
    //  console.error('Multi-point labels are not fully supported');
    //}
    return hasLabels;
  }

  var Svg = /*#__PURE__*/Object.freeze({
    __proto__: null,
    exportSVG: exportSVG,
    exportFurnitureLayerForSVG: exportFurnitureLayerForSVG,
    exportLayerForSVG: exportLayerForSVG,
    validateSvgDataFields: validateSvgDataFields,
    exportDataAttributesForSVG: exportDataAttributesForSVG,
    getEmptyLayerForSVG: getEmptyLayerForSVG,
    featureHasSvgSymbol: featureHasSvgSymbol,
    featureHasLabel: featureHasLabel,
    layerHasSvgSymbols: layerHasSvgSymbols,
    layerHasLabels: layerHasLabels
  });

  // import { isKmzFile } from '../io/mapshaper-file-types';

  function exportKML(dataset, opts) {
    var toKML = require("@placemarkio/tokml").toKML;
    var geojsonOpts = Object.assign({combine_layers: true, geojson_type: 'FeatureCollection'}, opts);
    var geojson = exportDatasetAsGeoJSON(dataset, geojsonOpts);
    var kml = toKML(geojson);
    // TODO: add KMZ output
    // var useKmz = opts.file && isKmzFile(opts.file);
    var ofile = opts.file || getOutputFileBase(dataset) + '.kml';
    return [{
      content: kml,
      filename: ofile
    }];
  }

  function buffersAreIdentical(a, b) {
    var alen = BinArray.bufferSize(a);
    var blen = BinArray.bufferSize(b);
    if (alen != blen) {
      return false;
    }
    for (var i=0; i<alen; i++) {
      if (a[i] !== b[i]) {
        return false;
      }
    }
    return true;
  }

  // Wrapper for DataView class for more convenient reading and writing of
  //   binary data; Remembers endianness and read/write position.
  // Has convenience methods for copying from buffers, etc.
  //
  function BinArray(buf, le) {
    if (utils.isNumber(buf)) {
      buf = new ArrayBuffer(buf);
    } else if (buf instanceof ArrayBuffer) ; else if (typeof B$3 == 'function' && buf instanceof B$3 || buf instanceof Uint8Array) {
      if (buf.buffer && buf.buffer.byteLength == buf.length) {
        buf = buf.buffer;
      } else {
        buf = BinArray.copyToArrayBuffer(buf);
      }
    } else {
      error("BinArray constructor takes an integer, ArrayBuffer or Buffer argument");
    }
    this._buffer = buf;
    this._bytes = new Uint8Array(buf);
    this._view = new DataView(buf);
    this._idx = 0;
    this._le = le !== false;
  }

  BinArray.bufferToUintArray = function(buf, wordLen) {
    if (wordLen == 4) return new Uint32Array(buf);
    if (wordLen == 2) return new Uint16Array(buf);
    if (wordLen == 1) return new Uint8Array(buf);
    error("BinArray.bufferToUintArray() invalid word length:", wordLen);
  };

  BinArray.uintSize = function(i) {
    return i & 1 || i & 2 || 4;
  };

  BinArray.bufferCopy = function(dest, destId, src, srcId, bytes) {
    srcId = srcId || 0;
    bytes = bytes || src.byteLength - srcId;
    if (dest.byteLength - destId < bytes)
      error("Buffer overflow; tried to write:", bytes);

    // When possible, copy buffer data in multi-byte chunks... Added this for faster copying of
    // shapefile data, which is aligned to 32 bits.
    var wordSize = Math.min(BinArray.uintSize(bytes), BinArray.uintSize(srcId),
        BinArray.uintSize(dest.byteLength), BinArray.uintSize(destId),
        BinArray.uintSize(src.byteLength));

    var srcArr = BinArray.bufferToUintArray(src, wordSize),
        destArr = BinArray.bufferToUintArray(dest, wordSize),
        count = bytes / wordSize,
        i = srcId / wordSize,
        j = destId / wordSize;

    while (count--) {
      destArr[j++] = srcArr[i++];
    }
    return bytes;
  };

  BinArray.copyToArrayBuffer = function(src) {
    var n = src.length,
        dest = new ArrayBuffer(n),
        view = new Uint8Array(dest);
    for (var i=0; i<n; i++) {
        view[i] = src[i];
    }
    return dest;
  };

  // Return length in bytes of an ArrayBuffer or Buffer
  //
  BinArray.bufferSize = function(buf) {
    return (buf instanceof ArrayBuffer ?  buf.byteLength : buf.length | 0);
  };

  BinArray.prototype = {
    size: function() {
      return this._buffer.byteLength;
    },

    littleEndian: function() {
      this._le = true;
      return this;
    },

    bigEndian: function() {
      this._le = false;
      return this;
    },

    buffer: function() {
      return this._buffer;
    },

    bytesLeft: function() {
      return this._buffer.byteLength - this._idx;
    },

    skipBytes: function(bytes) {
      this._idx += (bytes + 0);
      return this;
    },

    readUint8: function() {
      return this._bytes[this._idx++];
    },

    writeUint8: function(val) {
      this._bytes[this._idx++] = val;
      return this;
    },

    readInt8: function() {
      return this._view.getInt8(this._idx++);
    },

    writeInt8: function(val) {
      this._view.setInt8(this._idx++, val);
      return this;
    },

    readUint16: function() {
      var val = this._view.getUint16(this._idx, this._le);
      this._idx += 2;
      return val;
    },

    writeUint16: function(val) {
      this._view.setUint16(this._idx, val, this._le);
      this._idx += 2;
      return this;
    },

    readUint32: function() {
      var val = this._view.getUint32(this._idx, this._le);
      this._idx += 4;
      return val;
    },

    writeUint32: function(val) {
      this._view.setUint32(this._idx, val, this._le);
      this._idx += 4;
      return this;
    },

    readInt32: function() {
      var val = this._view.getInt32(this._idx, this._le);
      this._idx += 4;
      return val;
    },

    writeInt32: function(val) {
      this._view.setInt32(this._idx, val, this._le);
      this._idx += 4;
      return this;
    },

    readFloat64: function() {
      var val = this._view.getFloat64(this._idx, this._le);
      this._idx += 8;
      return val;
    },

    writeFloat64: function(val) {
      this._view.setFloat64(this._idx, val, this._le);
      this._idx += 8;
      return this;
    },

    // Returns a Float64Array containing @len doubles
    //
    readFloat64Array: function(len) {
      var bytes = len * 8,
          i = this._idx,
          buf = this._buffer,
          arr;
      // Inconsistent: first is a view, second a copy...
      if (i % 8 === 0) {
        arr = new Float64Array(buf, i, len);
      } else if (buf.slice) {
        arr = new Float64Array(buf.slice(i, i + bytes));
      } else { // ie10, etc
        var dest = new ArrayBuffer(bytes);
        BinArray.bufferCopy(dest, 0, buf, i, bytes);
        arr = new Float64Array(dest);
      }
      this._idx += bytes;
      return arr;
    },

    readUint32Array: function(len) {
      var arr = [];
      for (var i=0; i<len; i++) {
        arr.push(this.readUint32());
      }
      return arr;
    },

    peek: function(i) {
      return this._view.getUint8(i >= 0 ? i : this._idx);
    },

    position: function(i) {
      if (i != null) {
        this._idx = i;
        return this;
      }
      return this._idx;
    },

    readCString: function(fixedLen, asciiOnly) {
      var str = "",
          count = fixedLen >= 0 ? fixedLen : this.bytesLeft();
      while (count > 0) {
        var byteVal = this.readUint8();
        count--;
        if (byteVal == 0) {
          break;
        } else if (byteVal > 127 && asciiOnly) {
          str = null;
          break;
        }
        str += String.fromCharCode(byteVal);
      }

      if (fixedLen > 0 && count > 0) {
        this.skipBytes(count);
      }
      return str;
    },

    writeString: function(str, maxLen) {
      var bytesWritten = 0,
          charsToWrite = str.length,
          cval;
      if (maxLen) {
        charsToWrite = Math.min(charsToWrite, maxLen);
      }
      for (var i=0; i<charsToWrite; i++) {
        cval = str.charCodeAt(i);
        if (cval > 127) {
          // Unicode value beyond ascii range
          cval = '?'.charCodeAt(0);
        }
        this.writeUint8(cval);
        bytesWritten++;
      }
      return bytesWritten;
    },

    writeCString: function(str, fixedLen) {
      var maxChars = fixedLen ? fixedLen - 1 : null,
          bytesWritten = this.writeString(str, maxChars);

      this.writeUint8(0); // terminator
      bytesWritten++;

      if (fixedLen) {
        while (bytesWritten < fixedLen) {
          this.writeUint8(0);
          bytesWritten++;
        }
      }
      return this;
    },

    writeBuffer: function(buf, bytes, startIdx) {
      this._idx += BinArray.bufferCopy(this._buffer, this._idx, buf, startIdx, bytes);
      return this;
    }
  };

  var BinArray$1 = /*#__PURE__*/Object.freeze({
    __proto__: null,
    buffersAreIdentical: buffersAreIdentical,
    BinArray: BinArray
  });

  var Dbf = {};
  var MAX_STRING_LEN = 254;

  Dbf.MAX_STRING_LEN = MAX_STRING_LEN;
  Dbf.convertValueToString = convertValueToString;
  Dbf.convertFieldNames = convertFieldNames;
  Dbf.discoverFieldType = discoverFieldType;
  Dbf.getDecimalFormatter = getDecimalFormatter;
  Dbf.getNumericFieldInfo = getNumericFieldInfo;
  Dbf.truncateEncodedString = truncateEncodedString;
  Dbf.getFieldInfo = getFieldInfo;
  Dbf.exportRecords = exportRecords;

  function BufferPool() {
    var n = 5000,
        pool, i;
    newPool();

    function newPool() {
      pool = new Uint8Array(n);
      i = 0;
    }

    return {
      reserve: function(bytes) {
        if (i + bytes > n) newPool();
        i += bytes;
        return pool.subarray(i - bytes, i);
      },
      putBack: function(bytes) {
        i -= bytes;
      }
    };
  }

  var bufferPool = new BufferPool();

  function exportRecords(records, encoding, fieldOrder) {
    var rows = records.length;
    var fields = findFieldNames(records, fieldOrder);
    var dataEncoding = encoding || 'utf8';
    var headerEncoding = stringIsAscii(fields.join('')) ? 'ascii' : dataEncoding;
    var fieldNames = convertFieldNames(fields, headerEncoding);
    var fieldBuffers = encodeFieldNames(fieldNames, headerEncoding); // array of 11-byte buffers
    var fieldData = fields.map(function(name, i) {
      var info = getFieldInfo(records, name, dataEncoding);
      if (info.warning) {
        message('[' + name + '] ' + info.warning);
      }
      return info;
    });

    var headerBytes = getHeaderSize(fieldData.length),
        recordBytes = getRecordSize(utils.pluck(fieldData, 'size')),
        fileBytes = headerBytes + rows * recordBytes + 1;

    var buffer = new ArrayBuffer(fileBytes);
    var bin = new BinArray(buffer).littleEndian();
    var now = new Date();

    // write header
    bin.writeUint8(3);
    bin.writeUint8(now.getFullYear() - 1900);
    bin.writeUint8(now.getMonth() + 1);
    bin.writeUint8(now.getDate());
    bin.writeUint32(rows);
    bin.writeUint16(headerBytes);
    bin.writeUint16(recordBytes);
    bin.skipBytes(17);
    bin.writeUint8(0); // language flag; TODO: improve this
    bin.skipBytes(2);


    // field subrecords
    fieldData.reduce(function(recordOffset, obj, i) {
      // bin.writeCString(obj.name, 11);
      bin.writeBuffer(fieldBuffers[i], 11, 0);
      bin.writeUint8(obj.type.charCodeAt(0));
      bin.writeUint32(recordOffset);
      bin.writeUint8(obj.size);
      bin.writeUint8(obj.decimals);
      bin.skipBytes(14);
      return recordOffset + obj.size;
    }, 1);

    bin.writeUint8(0x0d); // "field descriptor terminator"
    if (bin.position() != headerBytes) {
      error("Dbf#exportRecords() header size mismatch; expected:", headerBytes, "written:", bin.position());
    }

    records.forEach(function(rec, i) {
      var start = bin.position();
      bin.writeUint8(0x20); // delete flag; 0x20 valid 0x2a deleted
      for (var j=0, n=fieldData.length; j<n; j++) {
        fieldData[j].write(i, bin);
      }
      if (bin.position() - start != recordBytes) {
        error("#exportRecords() Error exporting record:", rec);
      }
    });

    bin.writeUint8(0x1a); // end-of-file

    if (bin.position() != fileBytes) {
      error("Dbf#exportRecords() file size mismatch; expected:", fileBytes, "written:", bin.position());
    }
    return buffer;
  }

  function getHeaderSize(numFields) {
    return 33 + numFields * 32;
  }

  function getRecordSize(fieldSizes) {
    return utils.sum(fieldSizes) + 1; // delete byte plus data bytes
  }

  function initNumericField(info, arr, name) {
    var MAX_FIELD_SIZE = 18,
        data, size;

    data = getNumericFieldInfo(arr, name);
    info.decimals = data.decimals;
    size = Math.max(data.max.toFixed(info.decimals).length,
        data.min.toFixed(info.decimals).length);
    if (size > MAX_FIELD_SIZE) {
      size = MAX_FIELD_SIZE;
      info.decimals -= size - MAX_FIELD_SIZE;
      if (info.decimals < 0) {
        error ("Dbf#getFieldInfo() Out-of-range error.");
      }
    }
    info.size = size;

    var formatter = getDecimalFormatter(size, info.decimals);
    info.write = function(i, bin) {
      var rec = arr[i],
          str = formatter(rec[name]);
      if (str.length < size) {
        str = utils.lpad(str, size, ' ');
      }
      bin.writeString(str, size);
    };
  }

  function initBooleanField(info, arr, name) {
    info.size = 1;
    info.write = function(i, bin) {
      var val = arr[i][name],
          c;
      if (val === true) c = 'T';
      else if (val === false) c = 'F';
      else c = '?';
      bin.writeString(c);
    };
  }

  function initDateField(info, arr, name) {
    info.size = 8;
    info.write = function(i, bin) {
      var d = arr[i][name],
          str;
      if (d instanceof Date === false) {
        str = '00000000';
      } else {
        str = utils.lpad(d.getUTCFullYear(), 4, '0') +
              utils.lpad(d.getUTCMonth() + 1, 2, '0') +
              utils.lpad(d.getUTCDate(), 2, '0');
      }
      bin.writeString(str);
    };
  }

  function convertValueToString(s) {
    return s === undefined || s === null ? '' : String(s);
  }

  function initStringField(info, arr, name, encoding) {
    var formatter = encoding == 'ascii' ? encodeValueAsAscii : getStringWriterEncoded(encoding);
    // Set minimum field size to 1 byte, for interoperability with PostGIS
    // (see https://github.com/mbloch/mapshaper/issues/541)
    var size = 1;
    var truncated = 0;
    var buffers = arr.map(function(rec) {
      var strval = convertValueToString(rec[name]);
      var buf = formatter(strval);
      if (buf.length > MAX_STRING_LEN) {
        if (encoding == 'ascii') {
          buf = buf.subarray(0, MAX_STRING_LEN);
        } else {
          buf = truncateEncodedString(buf, encoding, MAX_STRING_LEN);
        }
        truncated++;
      }
      size = Math.max(size, buf.length);
      return buf;
    });
    info.size = size;
    info.write = function(i, bin) {
      var buf = buffers[i],
          n = Math.min(size, buf.length),
          dest = bin._bytes,
          pos = bin.position(),
          j;
      for (j=0; j<n; j++) {
        dest[j + pos] = buf[j];
      }
      bin.position(pos + size);
    };
    if (truncated > 0) {
      info.warning = 'Truncated ' + truncated + ' string' + (truncated == 1 ? '' : 's') + ' to fit the 254-byte limit';
    }
  }

  // Convert string names to 11-byte buffers terminated by 0
  function encodeFieldNames(names, encoding) {
    return names.map(function(name) {
      var encoded = encodeString(name, encoding);
      var encLen = encoded.length;
      var buf = utils.createBuffer(11);
      for (var i=0; i < 11; i++) {
        buf[i] = i < 10 && encLen >= i - 1 ? encoded[i] : 0;
      }
      return buf;
    });
  }

  // Truncate and dedup field names
  //
  function convertFieldNames(names, encoding) {
    var names2 = getUniqFieldNames(names.map(cleanFieldName), 10, encoding);
    names2.forEach(function(name2, i) {
      if (names[i] != name2) {
        message('Changed field name from "' + names[i] + '" to "' + name2 + '"');
      }
    });
    return names2;
  }

  // Support non-ascii field names
  function cleanFieldName(name) {
    return name.replace(/[-\s]+/g, '_');
  }

  function getFieldInfo(arr, name, encoding) {
    var type = discoverFieldType(arr, name),
        info = {
          type: type,
          decimals: 0
        };
    if (type == 'N') {
      initNumericField(info, arr, name);
    } else if (type == 'C') {
      initStringField(info, arr, name, encoding);
    } else if (type == 'L') {
      initBooleanField(info, arr, name);
    } else if (type == 'D') {
      initDateField(info, arr, name);
    } else {
      // Treat null fields as empty numeric fields; this way, they will be imported
      // again as nulls.
      info.size = 0;
      info.type = 'N';
      if (type) {
        info.warning = 'Unable to export ' + type + '-type data, writing null values';
      }
      info.write = function() {};
    }
    return info;
  }

  function discoverFieldType(arr, name) {
    var val;
    for (var i=0, n=arr.length; i<n; i++) {
      val = arr[i][name];
      if (utils.isString(val)) return "C";
      if (utils.isNumber(val)) return "N";
      if (utils.isBoolean(val)) return "L";
      if (val instanceof Date) return "D";
      if (val) return (typeof val);
    }
    return null;
  }

  function getDecimalFormatter(size, decimals) {
    // TODO: find better way to handle nulls
    var nullValue = ' '; // ArcGIS may use 0
    return function(val) {
      // TODO: handle invalid values better
      var valid = utils.isFiniteNumber(val),
          strval = valid ? val.toFixed(decimals) : String(nullValue);
      return utils.lpad(strval, size, ' ');
    };
  }

  function getNumericFieldInfo(arr, name) {
    var min = 0,
        max = 0,
        k = 1,
        power = 1,
        decimals = 0,
        eps = 1e-15,
        val;
    for (var i=0, n=arr.length; i<n; i++) {
      val = arr[i][name];
      if (!utils.isFiniteNumber(val)) {
        continue;
      }
      if (val < min || val > max) {
        if (val < min) min = val;
        if (val > max) max = val;
        while (Math.abs(val) >= power) {
          power *= 10;
          eps *= 10;
        }
      }
      while (Math.abs(Math.round(val * k) - val * k) > eps) {
        if (decimals == 15) { // dbf limit
          // TODO: round overflowing values ?
          break;
        }
        decimals++;
        eps *= 10;
        k *= 10;
      }
    }
    return {
      decimals: decimals,
      min: min,
      max: max
    };
  }

  // return an array buffer or null if value contains non-ascii chars
  function encodeValueAsAscii(val, strict) {
    var str = String(val),
        n = str.length,
        view = bufferPool.reserve(n),
        i, c;
    for (i=0; i<n; i++) {
      c = str.charCodeAt(i);
      if (c > 127) {
        if (strict) {
          view = null;
          i = 0; // return all bytes to pool
          break;
        }
        c = '?'.charCodeAt(0);
      }
      view[i] = c;
    }
    bufferPool.putBack(n-i);
    return view ? view.subarray(0, i) : null;
  }

  function getStringWriterEncoded(encoding) {
    return function(val) {
      // optimization -- large majority of strings in real-world datasets are
      // ascii. Try (faster) ascii encoding first, fall back to text encoder.
      var buf = encodeValueAsAscii(val, true);
      if (buf === null) {
        buf = encodeString(String(val), encoding);
      }
      return buf;
    };
  }

  // try to remove partial multi-byte characters from the end of an encoded string.
  function truncateEncodedString(buf, encoding, maxLen) {
    var truncated = buf.slice(0, maxLen);
    var len = maxLen;
    var tmp, str;
    while (len > 0 && len >= maxLen - 3) {
      tmp = len == maxLen ? truncated : buf.slice(0, len);
      str = decodeString(tmp, encoding);
      if (str.charAt(str.length-1) != '\ufffd') {
        truncated = tmp;
        break;
      }
      len--;
    }
    return truncated;
  }

  function exportDbf(dataset, opts) {
    return dataset.layers.reduce(function(files, lyr) {
      if (lyr.data) {
        files = files.concat(exportDbfFile(lyr, dataset, opts));
      }
      return files;
    }, []);
  }

  function exportDbfFile(lyr, dataset, opts) {
    var data = lyr.data,
        buf;
    // create empty data table if missing a table or table is being cut out
    if (!data || opts.cut_table || opts.drop_table) {
      data = new DataTable(lyr.shapes ? lyr.shapes.length : 0);
    }
    // dbfs should have at least one column; add id field if none
    if (data.isEmpty()) {
      data.addIdField();
    }
    if (data.exportAsDbf) {
      buf = data.exportAsDbf(opts);
    } else {
      buf = Dbf.exportRecords(data.getRecords(), opts.encoding, opts.field_order);
    }
    if (utils.isInteger(opts.ldid)) {
      new Uint8Array(buf)[29] = opts.ldid; // set language driver id
    }
    // TODO: also export .cpg page
    return [{
      content: buf,
      filename: lyr.name + '.dbf'
    }];
  }

  function exportRecordsAsFixedWidthString(fields, records, opts) {
    var rows = [], col;
    for (var i=0; i<fields.length; i++) {
      col = formatFixedWidthColumn(fields[i], records, opts);
      if (i === 0) {
        rows = col;
      } else for (var j=0; j<rows.length; j++) {
        rows[j] += ' ' + col[j];
      }
    }
    return rows.join('\n');
  }

  function formatFixedWidthColumn(field, records, opts) {
    var arr = [],
        maxLen = field.length,
        n = records.length,
        i, val;
    arr.push(field);
    for (i=0; i<n; i++) {
      val = formatFixedWidthValue(records[i][field], opts);
      maxLen = Math.max(maxLen, val.length);
      arr.push(val);
    }
    for (i=0; i<arr.length; i++) {
      arr[i] = arr[i].padEnd(maxLen, ' ');
    }
    return arr;
  }

  function formatFixedWidthValue(val, opts) {
    // TODO: remove duplication with mapshaper-delim-export.js
    var s;
    if (val == null) {
      s = '';
    } else if (utils.isString(val)) {
      s = val; // TODO: handle wide characters, newlines etc.
    } else if (utils.isNumber(val)) {
      s = opts.decimal_comma ? utils.formatIntlNumber(val) : utils.formatNumber(val);
    } else if (utils.isObject(val)) {
      s = JSON.stringify(val);
    } else {
      s = val + '';
    }
    return s;
  }


  function readFixedWidthRecords(reader, opts) {
    var str = reader.toString(opts.encoding || 'ascii');
    return readFixedWidthRecordsFromString(str);
  }

  function readFixedWidthRecordsFromString(str) {
    var fields = parseFixedWidthInfo(str.substring(0, 2000));
    if (!fields) return [];
    var lines = utils.splitLines(str);
    if (lines[lines.length - 1] === '') lines.pop(); // handle newline at end of string
    var records = [];
    for (var i=1; i<lines.length; i++) {
      records.push(parseFixedWidthLine(lines[i], fields));
    }
    return records;
  }

  function parseFixedWidthInfo(sample) {
    var lines = utils.splitLines(sample);
    if (lines.length > 2) lines.pop(); // remove possible partial line
    var n = getMaxLineLength(lines);
    var headerLine = lines[0];
    var colInfo = [];
    var colStart = 0;
    var inContent = false;
    var inHeader = false;
    var isContentChar, isHeaderChar, isColStart, colEnd;
    for (var i=0; i<=n; i++) {
      isHeaderChar = testContentChar(headerLine, i);
      isContentChar = !testEmptyCol(lines, i);
      isColStart = isHeaderChar && !inHeader;
      if (isColStart && inContent) {
        // all lines should have a space char in the position right before a header starts
        return null;
      }
      if (i == n || i > 0 && isColStart) {
        colEnd = i == n ? undefined : i-1;
        colInfo.push({
          name: readValue$1(headerLine, colStart, colEnd),
          end: colEnd,
          start: colStart
        });
        colStart = i;
      }
      inContent = isContentChar;
      inHeader = isHeaderChar;
    }
    return colInfo.length > 0 ? colInfo : null;
  }

  function getMaxLineLength(lines) {
    var max = 0;
    for (var i=0; i<lines.length; i++) {
      max = Math.max(max, lines[i].length);
    }
    return max;
  }

  function readValue$1(line, start, end) {
    return line.substring(start, end).trim();
  }

  function parseFixedWidthLine(str, fields) {
    var obj = {}, field;
    for (var i=0; i<fields.length; i++) {
      field = fields[i];
      obj[field.name] = readValue$1(str, field.start, field.end);
    }
    return obj;
  }

  function testContentChar(str, i) {
    return i < str.length && str[i] !== ' ';
  }

  // return true iff all samples are blank at index i
  function testEmptyCol(samples, i) {
    var line;
    for (var j=0; j<samples.length; j++) {
      line = samples[j];
      if (testContentChar(line, i)) return false;
    }
    return true;
  }

  // Generate output content from a dataset object
  function exportDelim(dataset, opts) {
    var delim = getExportDelimiter(dataset.info, opts),
        ext = getDelimFileExtension(delim, opts);
    return dataset.layers.reduce(function(arr, lyr) {
      if (lyr.data){
        arr.push({
          // TODO: consider supporting encoding= option
          content: exportLayerAsDSV(lyr, delim, opts),
          filename: (lyr.name || 'output') + '.' + ext
        });
      }
      return arr;
    }, []);
  }

  function exportLayerAsDSV(lyr, delim, optsArg) {
    var opts = optsArg || {};
    var encoding = opts.encoding || 'utf8';
    var records = lyr.data.getRecords();
    var fields = findFieldNames(records, opts.field_order);
    if (delim == ' ') {
      return exportRecordsAsFixedWidthString(fields, records, opts);
    }
    var formatRow = getDelimRowFormatter(fields, delim, opts);
    // exporting utf8 and ascii text as string by default (for now)
    var exportAsString = encodingIsUtf8(encoding) && !opts.to_buffer &&
        (records.length < 10000 || opts.to_string);
    if (exportAsString) {
      return exportRecordsAsString(fields, records, formatRow);
    } else {
      return exportRecordsAsBuffer(fields, records, formatRow, encoding);
    }
  }

  function exportRecordsAsString(fields, records, formatRow) {
    var header = formatHeader(fields, formatRow);
    if (!records.length) return header;
    return header + '\n' + records.map(formatRow).join('\n');
  }

  function exportRecordsAsBuffer(fields, records, formatRow, encoding) {
    var str = formatHeader(fields, formatRow);
    var buffers = [encodeString(str, encoding)];
    var tmp = [];
    var n = records.length;
    var i = 0;
    while (i < n) {
      tmp.push(formatRow(records[i]));
      i++;
      if (i % 1000 === 0 || i == n) {
        str = '\n' + tmp.join('\n');
        tmp = [];
        buffers.push(encodeString(str, encoding));
      }
    }
    return B$3.concat(buffers);
  }

  function formatHeader(fields, formatRow) {
    var rec = fields.reduce(function(memo, f) {
      memo[f] = f;
      return memo;
    }, {});
    return formatRow(rec);
  }

  function getDelimRowFormatter(fields, delim, opts) {
    var formatValue = getDelimValueFormatter(delim, opts);
    return function(rec) {
      return fields.map(function(f) {
        return formatValue(rec[f]);
      }).join(delim);
    };
  }

  function getDelimValueFormatter(delim, opts) {
    var dquoteRxp = new RegExp('["\n\r' + delim + ']');
    var decimalComma = opts && opts.decimal_comma || false;
    function formatString(s) {
      if (dquoteRxp.test(s)) {
        s = '"' + s.replace(/"/g, '""') + '"';
      }
      return s;
    }
    return function(val) {
      var s;
      if (val == null) {
        s = '';
      } else if (utils.isString(val)) {
        s = formatString(val);
      } else if (utils.isNumber(val)) {
        s = decimalComma ? utils.formatIntlNumber(val) : utils.formatNumber(val);
      } else if (utils.isObject(val)) {
        s = formatString(JSON.stringify(val));
      } else {
        s = val + '';
      }
      return s;
    };
  }

  function getExportDelimiter(info, opts) {
    var delim = ','; // default
    var outputExt = opts.file ? getFileExtension(opts.file) : '';
    if (opts.delimiter) {
      delim = opts.delimiter;
    } else if (outputExt == 'tsv') {
      delim = '\t';
    } else if (outputExt == 'csv') {
      delim = ',';
    } else if (info.input_delimiter) {
      delim = info.input_delimiter;
    }
    return delim;
  }

  // If output filename is not specified, use the delimiter char to pick
  // an extension.
  function getDelimFileExtension(delim, opts) {
    var ext = 'txt'; // default
    if (opts.file) {
      ext = getFileExtension(opts.file);
    } else if (delim == '\t') {
      ext = 'tsv';
    } else if (delim == ',') {
      ext = 'csv';
    }
    return ext;
  }

  var DelimExport = /*#__PURE__*/Object.freeze({
    __proto__: null,
    exportDelim: exportDelim,
    exportLayerAsDSV: exportLayerAsDSV,
    getDelimValueFormatter: getDelimValueFormatter
  });

  var ShpType = {
    NULL: 0,
    POINT: 1,
    POLYLINE: 3,
    POLYGON: 5,
    MULTIPOINT: 8,
    POINTZ: 11,
    POLYLINEZ: 13,
    POLYGONZ: 15,
    MULTIPOINTZ: 18,
    POINTM: 21,
    POLYLINEM: 23,
    POLYGONM: 25,
    MULIPOINTM: 28,
    MULTIPATCH: 31 // not supported
  };

  ShpType.isPolygonType = function(t) {
    return t == 5 || t == 15 || t == 25;
  };

  ShpType.isPolylineType = function(t) {
    return t == 3 || t == 13 || t == 23;
  };

  ShpType.isMultiPartType = function(t) {
    return ShpType.isPolygonType(t) || ShpType.isPolylineType(t);
  };

  ShpType.isMultiPointType = function(t) {
    return t == 8 || t == 18 || t == 28;
  };

  ShpType.isZType = function(t) {
    return [11,13,15,18].includes(t);
  };

  ShpType.isMType = function(t) {
    return ShpType.isZType(t) || [21,23,25,28].includes(t);
  };

  ShpType.hasBounds = function(t) {
    return ShpType.isMultiPartType(t) || ShpType.isMultiPointType(t);
  };

  // Convert a dataset to Shapefile files
  function exportShapefile(dataset, opts) {
    return dataset.layers.reduce(function(files, lyr) {
      var prj = exportPrjFile(lyr, dataset);
      files = files.concat(exportShpAndShxFiles(lyr, dataset));
      files = files.concat(exportDbfFile(lyr, dataset, opts));
      if (prj) files.push(prj);
      return files;
    }, []);
  }

  function exportPrjFile(lyr, dataset) {
    var info = dataset.info || {};
    var prj = info.prj;
    if (!prj) {
      try {
        prj = crsToPrj(getDatasetCRS(dataset));
      } catch(e) {}
    }
    if (!prj) {
      message("Unable to generate .prj file for", lyr.name + '.shp');
    }
    return prj ? {
      content: prj,
      filename: lyr.name + '.prj'
    } : null;
  }

  function getShapefileExportType(lyr) {
    var type = lyr.geometry_type;
    var shpType;
    if (type == 'point') {
      shpType = findMaxPartCount(lyr.shapes || []) <= 1 ? ShpType.POINT : ShpType.MULTIPOINT;
    } else if (type == 'polygon') {
      shpType = ShpType.POLYGON;
    } else if (type == 'polyline') {
      shpType = ShpType.POLYLINE;
    } else {
      shpType = ShpType.NULL;
    }
    return shpType;
  }

  function exportShpAndShxFiles(layer, dataset, opts) {
    var shapes = layer.shapes || utils.initializeArray(new Array(getFeatureCount(layer)), null);
    var bounds = new Bounds();
    var shpType = getShapefileExportType(layer);
    var fileBytes = 100;
    var shxBytes = 100 + shapes.length * 8;
    var shxBin = new BinArray(shxBytes).bigEndian().position(100); // jump to record section
    var shpBin;

    // TODO: consider writing records to an expanding buffer instead of generating
    // individual buffers for each record (for large point datasets,
    // creating millions of buffers impacts performance significantly)
    var shapeBuffers = shapes.map(function(shape, i) {
      var pathData = exportPathData(shape, dataset.arcs, layer.geometry_type);
      var rec = exportShpRecord(pathData, i+1, shpType);
      var recBytes = rec.buffer.byteLength;

      // add shx record
      shxBin.writeInt32(fileBytes / 2); // record offset in 16-bit words
      // alternative to below: shxBin.writeBuffer(rec.buffer, 4, 4)
      shxBin.writeInt32(recBytes / 2 - 4); // record content length in 16-bit words

      fileBytes += recBytes;
      if (rec.bounds) bounds.mergeBounds(rec.bounds);
      return rec.buffer;
    });

    // write .shp header section
    shpBin = new BinArray(fileBytes, false)
      .writeInt32(9994)
      .skipBytes(5 * 4)
      .writeInt32(fileBytes / 2)
      .littleEndian()
      .writeInt32(1000)
      .writeInt32(shpType);

    if (bounds.hasBounds()) {
      shpBin.writeFloat64(bounds.xmin || 0) // using 0s as empty value
        .writeFloat64(bounds.ymin || 0)
        .writeFloat64(bounds.xmax || 0)
        .writeFloat64(bounds.ymax || 0);
    } else {
      // no bounds -- assume no shapes or all null shapes -- using 0s as bbox
      shpBin.skipBytes(4 * 8);
    }
    shpBin.skipBytes(4 * 8); // skip Z & M type bounding boxes;

    // write records section of .shp
    shapeBuffers.forEach(function(buf) {
      shpBin.writeBuffer(buf);
    });

    // write .shx header
    shxBin.position(0)
      .writeBuffer(shpBin.buffer(), 100) // copy .shp header to .shx
      .position(24) // substitute shx file size for shp file size
      .writeInt32(shxBytes / 2);

    return [{
        content: shpBin.buffer(),
        filename: layer.name + ".shp"
      }, {
        content: shxBin.buffer(),
        filename: layer.name + ".shx"
      }];
  }

  // Returns an ArrayBuffer containing a Shapefile record for one shape
  //   and the bounding box of the shape.
  // TODO: remove collapsed rings, convert to null shape if necessary
  //
  function exportShpRecord(data, id, shpType) {
    var multiPartType = ShpType.isMultiPartType(shpType),
        singlePointType = !multiPartType && !ShpType.isMultiPointType(shpType),
        isNull = data.pointCount > 0 === false,
        bounds = isNull ? null : data.bounds,
        bin = null;

    if (isNull) {
      bin = new BinArray(12, false)
        .writeInt32(id)
        .writeInt32(2)
        .littleEndian()
        .writeInt32(0);

    } else if (singlePointType) {
      bin = new BinArray(28, false)
        .writeInt32(id)
        .writeInt32(10)
        .littleEndian()
        .writeInt32(shpType)
        .writeFloat64(data.pathData[0].points[0][0])
        .writeFloat64(data.pathData[0].points[0][1]);

    } else {
      var partIndexIdx = 52,
          pointsIdx = multiPartType ? partIndexIdx + 4 * data.pathCount : 48,
          recordBytes = pointsIdx + 16 * data.pointCount,
          pointCount = 0;

      bin = new BinArray(recordBytes, false)
        .writeInt32(id)
        .writeInt32((recordBytes - 8) / 2)
        .littleEndian()
        .writeInt32(shpType)
        .writeFloat64(bounds.xmin)
        .writeFloat64(bounds.ymin)
        .writeFloat64(bounds.xmax)
        .writeFloat64(bounds.ymax);

      if (multiPartType) {
        bin.writeInt32(data.pathCount);
      }

      bin.writeInt32(data.pointCount);
      data.pathData.forEach(function(path, i) {
        if (multiPartType) {
          bin.position(partIndexIdx + i * 4).writeInt32(pointCount);
        }
        bin.position(pointsIdx + pointCount * 16);
        for (var j=0, len=path.points.length; j<len; j++) {
          bin.writeFloat64(path.points[j][0]);
          bin.writeFloat64(path.points[j][1]);
        }
        pointCount += j;
      });
      if (data.pointCount != pointCount) {
        error("Shp record point count mismatch; pointCount:",
            pointCount, "data.pointCount:", data.pointCount);
      }
    }

    return {bounds: bounds, buffer: bin.buffer()};
  }

  var ShpExport = /*#__PURE__*/Object.freeze({
    __proto__: null,
    exportShapefile: exportShapefile
  });

  var TopoJSON = {};

  // Iterate over all arrays of arc is in a geometry object
  // @cb callback: function(ids)
  // callback returns undefined or an array of replacement ids
  //
  TopoJSON.forEachShapePart = function forEachShapePart(obj, cb) {
    var iterators = {
          GeometryCollection: function(o) {o.geometries.forEach(eachGeom);},
          LineString: function(o) {
            var retn = cb(o.arcs);
            if (retn) o.arcs = retn;
          },
          MultiLineString: function(o) {eachMultiPath(o.arcs);},
          Polygon: function(o) {eachMultiPath(o.arcs);},
          MultiPolygon: function(o) {o.arcs.forEach(eachMultiPath);}
        };

    eachGeom(obj);

    function eachGeom(o) {
      if (o.type in iterators) {
        iterators[o.type](o);
      }
    }

    function eachMultiPath(arr) {
      var retn;
      for (var i=0; i<arr.length; i++) {
        retn = cb(arr[i]);
        if (retn) arr[i] = retn;
      }
    }
  };

  TopoJSON.forEachArc = function forEachArc(obj, cb) {
    TopoJSON.forEachShapePart(obj, function(ids) {
      var retn;
      for (var i=0; i<ids.length; i++) {
        retn = cb(ids[i]);
        if (utils.isInteger(retn)) {
          ids[i] = retn;
        }
      }
    });
  };

  function getPresimplifyFunction(width) {
    var quanta = 10000,  // enough resolution for pixel-level detail at 1000px width and 10x zoom
        k = quanta / width;
    return function(z) {
      // could substitute a rounding function with decimal precision
      return z === Infinity ? 0 : Math.ceil(z * k);
    };
  }

  function importMetadata(dataset, obj) {
    if (obj.proj4) {
      setDatasetCrsInfo(dataset, getCrsInfo(obj.proj4));
    }
  }

  function exportMetadata(dataset) {
    var crs = getDatasetCRS(dataset);
    var proj4 = null;
    if (crs) {
      proj4 = crsToProj4(crs);
    }
    return {
      proj4: proj4
    };
  }

  cmd.explodeFeatures = function(lyr, arcs, opts) {
    var properties = lyr.data ? lyr.data.getRecords() : null,
        explodedProperties = properties ? [] : null,
        explodedShapes = [],
        explodedLyr = utils.extend({}, lyr);

    lyr.shapes.forEach(function(shp, shpId) {
      var exploded;
      if (!shp) {
        explodedShapes.push(null);
      } else {
        if (lyr.geometry_type == 'polygon' && shp.length > 1) {
          if (opts && opts.naive) {
            exploded = explodePolygonNaive(shp, arcs);
          } else {
            exploded = explodePolygon(shp, arcs);
          }
        } else {
          exploded = explodeShape(shp);
        }
        utils.merge(explodedShapes, exploded);
      }
      if (explodedProperties !== null) {
        for (var i=0, n=exploded ? exploded.length : 1; i<n; i++) {
          explodedProperties.push(cloneProperties(properties[shpId]));
        }
      }
    });

    explodedLyr.shapes = explodedShapes;
    if (explodedProperties !== null) {
      explodedLyr.data = new DataTable(explodedProperties);
    }

    printMessage(lyr, explodedLyr);

    return explodedLyr;
  };

  function printMessage(pre, post) {
  var n1 = getFeatureCount(pre),
      n2 = getFeatureCount(post),
      msg = utils.format('Exploded %,d feature%s into %,d feature%s',
        n1, utils.pluralSuffix(n1), n2,
        utils.pluralSuffix(n2));
    message(msg);
  }

  function explodeShape(shp) {
    return shp.map(function(part) {
      return [part.concat()];
    });
  }

  function explodePolygon(shape, arcs, reverseWinding) {
    var paths = getPathMetadata(shape, arcs, "polygon");
    var groups = groupPolygonRings(paths, arcs, reverseWinding);
    return groups.map(function(group) {
      return group.map(function(ring) {
        return ring.ids;
      });
    });
  }

  function explodePolygonNaive(shape, arcs) {
    var paths = getPathMetadata(shape, arcs, "polygon");
    return paths.map(function(path) {
      if (path.area < 0) {
        reversePath(path.ids);
      }
      return [path.ids];
    });
  }

  function cloneProperties(obj) {
    return Object.assign({}, obj);
  }

  var Explode = /*#__PURE__*/Object.freeze({
    __proto__: null,
    explodePolygon: explodePolygon
  });

  TopoJSON.getPresimplifyFunction = getPresimplifyFunction;

  function exportTopoJSON(dataset, opts) {
    var extension = '.' + (opts.extension || 'json'),
        needCopy = !opts.final || datasetHasPaths(dataset) && dataset.arcs.getRetainedInterval() > 0,
        stringify = JSON.stringify;

    if (needCopy) {
      dataset = copyDatasetForExport(dataset);
    }

    if (opts.prettify) {
      stringify = getFormattedStringify('coordinates,arcs,bbox,translate,scale'.split(','));
    }

    if (opts.width > 0 || opts.height > 0) {
      // these options create a TopoJSON with pixel coordinates, including
      // origin (0,0) in the top left corner of the viewport, generally for
      // direct conversion to SVG (many online examples using d3 are like this)
      //
      opts = utils.defaults({invert_y: true}, opts);
      fitDatasetToFrame(dataset, getFrameData(dataset, opts));
    } else if (opts.fit_bbox) {
      fitDatasetToFrame(dataset, getFrameData(dataset, {fit_bbox: opts.fit_bbox}));
    }

    if (opts.precision && opts.no_quantization) {
      setCoordinatePrecision(dataset, opts.precision, !!opts.fix_geometry);
    } else if (opts.precision) {
      message(`Ignoring precision=${opts.precision} -- this option only works with no-quantization.`);
    }

    if (opts.singles) {
      return splitDataset(dataset).map(function(dataset) {
        return {
          content: stringify(TopoJSON.exportTopology(dataset, opts)),
          filename: (dataset.layers[0].name || 'output') + extension
        };
      });
    } else {
      return [{
        filename: opts.file || getOutputFileBase(dataset) + extension,
        content: stringify(TopoJSON.exportTopology(dataset, opts))
      }];
    }
  }

  // Convert a dataset object to a TopoJSON topology object
  // Careful -- arcs must be a copy if further processing will occur.
  TopoJSON.exportTopology = function(dataset, opts) {
    var topology = {type: "Topology", arcs: []},
        hasPaths = datasetHasPaths(dataset),
        bounds = getDatasetBounds(dataset);

    if (opts.bbox && bounds.hasBounds()) {
      topology.bbox = bounds.toArray();
    }

    if (hasPaths && opts.presimplify && !dataset.arcs.getVertexData().zz) {
      // Calculate simplification thresholds if needed
      cmd.simplify(dataset, opts);
    }
    // auto-detect quantization if arcs are present
    if (!opts.no_quantization && (opts.quantization || hasPaths)) {
      topology.transform = transformDataset(dataset, bounds, opts);
    }
    if (hasPaths) {
      dissolveArcs(dataset); // dissolve/prune arcs for more compact output
      topology.arcs = exportArcs(dataset.arcs, bounds, opts);
      if (topology.transform) {
        deltaEncodeArcs(topology.arcs);
      }
    }

    // export layers as TopoJSON named objects
    topology.objects = dataset.layers.reduce(function(objects, lyr, i) {
      var name = lyr.name || 'layer' + (i + 1);
      objects[name] = TopoJSON.exportLayer(lyr, dataset.arcs, opts);
      return objects;
    }, {});

    if (opts.metadata) {
      topology.metadata = exportMetadata(dataset);
    }
    return topology;
  };

  function transformDataset(dataset, bounds, opts) {
    var bounds2 = calcExportBounds(bounds, dataset.arcs, opts),
        fw = bounds.getTransform(bounds2),
        inv = fw.invert(),
        repairArcs;

    function transformWithRounding(x, y) {
      var p = fw.transform(x, y);
      return [Math.round(p[0]), Math.round(p[1])];
    }

    function transformWithoutRounding(x, y) {
      return fw.transform(x, y);
    }

    if (dataset.arcs && opts.fix_geometry) {
      // try to repair intersections caused by quantization
      dataset.arcs.transformPoints(transformWithoutRounding);
      repairArcs = getRepairFunction(dataset.arcs);
      dataset.arcs.transformPoints(function(x, y) {
        return [Math.round(x), Math.round(y)];
      });
      repairArcs(dataset.arcs);

    } else if (dataset.arcs) {
      dataset.arcs.transformPoints(transformWithRounding);
    }

    // support non-standard format with quantized arcs and non-quantized points
    if (!opts.no_point_quantization) {
      dataset.layers.filter(layerHasPoints).forEach(function(lyr) {
        transformPointsInLayer(lyr, transformWithRounding);
      });
    }

    // TODO: think about handling geometrical errors introduced by quantization,
    // e.g. segment intersections and collapsed polygon rings.
    return {
      scale: [inv.mx, inv.my],
      translate: [inv.bx, inv.by]
    };
  }

  // Export arcs as arrays of [x, y] and possibly [z] coordinates
  function exportArcs(arcs, bounds, opts) {
    var fromZ = null,
        output = [];
    if (opts.presimplify) {
      fromZ = getPresimplifyFunction(bounds.width());
    }
    arcs.forEach2(function(i, n, xx, yy, zz) {
      var arc = [], p;
      for (var j=i + n; i<j; i++) {
        p = [xx[i], yy[i]];
        if (fromZ) {
          p.push(fromZ(zz[i]));
        }
        arc.push(p);
      }
      output.push(arc.length > 1 ? arc : null);
    });
    return output;
  }

  // Apply delta encoding in-place to an array of topojson arcs
  function deltaEncodeArcs(arcs) {
    arcs.forEach(function(arr) {
      var ax, ay, bx, by, p;
      for (var i=0, n=arr.length; i<n; i++) {
        p = arr[i];
        bx = p[0];
        by = p[1];
        if (i > 0) {
          p[0] = bx - ax;
          p[1] = by - ay;
        }
        ax = bx;
        ay = by;
      }
    });
  }

  // Calculate the x, y extents that map to an integer unit in topojson output
  // as a fraction of the x- and y- extents of the average segment.
  function calcExportResolution(arcs, k) {
    // TODO: think about the effect of long lines, e.g. from polar cuts.
    var xy = getAvgSegment2(arcs);
    return [xy[0] * k, xy[1] * k];
  }

  // Calculate the bounding box of quantized topojson coordinates using one
  // of several methods.
  function calcExportBounds(bounds, arcs, opts) {
    var unitXY, xmax, ymax;
    if (opts.topojson_precision > 0) {
      unitXY = calcExportResolution(arcs, opts.topojson_precision);
    } else if (opts.quantization > 0) {
      unitXY = [bounds.width() / (opts.quantization-1), bounds.height() / (opts.quantization-1)];
    } else if (opts.precision > 0) {
      unitXY = [opts.precision, opts.precision];
    } else {
      // default -- auto quantization at 0.02 of avg. segment len
      unitXY = calcExportResolution(arcs, 0.02);
    }
    xmax = Math.ceil(bounds.width() / unitXY[0]) || 0;
    ymax = Math.ceil(bounds.height() / unitXY[1]) || 0;
    return new Bounds(0, 0, xmax, ymax);
  }

  TopoJSON.exportProperties = function(geometries, table, opts) {
    var properties = exportProperties(table, opts),
        ids = exportIds(table, opts);
    geometries.forEach(function(geom, i) {
      if (properties) {
        geom.properties = properties[i];
      }
      if (ids) {
        geom.id = ids[i];
      }
    });
  };

  // Export a mapshaper layer as a TopoJSON GeometryCollection
  TopoJSON.exportLayer = function(lyr, arcs, opts) {
    var n = getFeatureCount(lyr),
        geometries = [],
        exporter = TopoJSON.exporters[lyr.geometry_type] || null,
        shp;
    for (var i=0; i<n; i++) {
      shp = exporter && lyr.shapes[i];
      if (shp) {
        geometries[i] = exporter(shp, arcs, opts);
      } else {
        geometries[i] = {type: null};
      }
    }
    if (lyr.data) {
      TopoJSON.exportProperties(geometries, lyr.data, opts);
    }
    return {
      type: "GeometryCollection",
      geometries: geometries
    };
  };

  TopoJSON.exportPolygonGeom = function(shape, coords, opts) {
    var geom = {};
    shape = filterEmptyArcs(shape, coords);
    if (!shape || shape.length === 0) {
      geom.type = null;
    } else if (shape.length > 1) {
      geom.arcs = explodePolygon(shape, coords, opts.invert_y);
      if (geom.arcs.length == 1) {
        geom.arcs = geom.arcs[0];
        geom.type = "Polygon";
      } else {
        geom.type = "MultiPolygon";
      }
    } else {
      geom.arcs = shape;
      geom.type = "Polygon";
    }
    return geom;
  };

  TopoJSON.exportLineGeom = function(shape, coords) {
    var geom = {};
    shape = filterEmptyArcs(shape, coords);
    if (!shape || shape.length === 0) {
      geom.type = null;
    } else if (shape.length == 1) {
      geom.type = "LineString";
      geom.arcs = shape[0];
    } else {
      geom.type = "MultiLineString";
      geom.arcs = shape;
    }
    return geom;
  };

  TopoJSON.exporters = {
    polygon: TopoJSON.exportPolygonGeom,
    polyline: TopoJSON.exportLineGeom,
    point: GeoJSON.exportPointGeom
  };

  var TopojsonExport = /*#__PURE__*/Object.freeze({
    __proto__: null,
    exportTopoJSON: exportTopoJSON,
    calcExportBounds: calcExportBounds
  });

  function importJSONTable(arr) {
    fixInconsistentFields(arr);
    return {
      layers: [{
        data: new DataTable(arr)
      }],
      info: {}
    };
  }

  function exportJSON(dataset, opts) {
    return dataset.layers.reduce(function(arr, lyr) {
      if (lyr.data){
        arr.push({
          content: exportJSONTable(lyr, opts),
          filename: (lyr.name || 'output') + '.json'
        });
      }
      return arr;
    }, []);
  }

  function exportJSONTable(lyr, opts) {
    opts = opts || {};
    var records = lyr.data.getRecords();
    if (opts.ndjson) {
      return records.map(stringifyAsNDJSON).join('\n');
    }
    if (opts.prettify) {
      return getFormattedStringify([])(records);
    }
    return JSON.stringify(records);
  }

  var JsonTable = /*#__PURE__*/Object.freeze({
    __proto__: null,
    importJSONTable: importJSONTable,
    exportJSON: exportJSON,
    exportJSONTable: exportJSONTable
  });

  function getOutputFormat(dataset, opts) {
    var outFile = opts.file || null,
        inFmt = dataset.info && dataset.info.input_formats && dataset.info.input_formats[0],
        outFmt = null;

    // if user has specified a format, use that
    if (opts.format) {
      return opts.format;
    }

    // if an output filename is given, try to infer format from filename etc.
    if (outFile) {
      outFmt = inferOutputFormat(outFile, inFmt);
    } else if (inFmt) {
      outFmt = inFmt;
    }

    if (outFmt == 'json' && datasetHasGeometry(dataset)) {
      // special case: inferred output format is a json table (either because
      // the output file has a .json extension or because the input file was a
      // json table), but the output dataset contains shapes
      outFmt = 'geojson';
    }

    return outFmt || null;
  }

  // Infer output format by considering file name and (optional) input format
  function inferOutputFormat(file, inputFormat) {
    var ext = getFileExtension(file).toLowerCase(),
        format = null;
    if (ext == 'gz') {
      return inferOutputFormat(replaceFileExtension(file, ''), inputFormat);
    } else if (ext == PACKAGE_EXT) {
      format = PACKAGE_EXT;
    } else if (ext == 'shp') {
      format = 'shapefile';
    } else if (ext == 'dbf') {
      format = 'dbf';
    } else if (ext == 'svg') {
      format = 'svg';
    } else if (ext == 'kml' || ext == 'kmz') {
      format = 'kml';
    } else if (/json$/.test(ext)) {
      format = 'geojson';
      if (ext == 'topojson' || inputFormat == 'topojson' && ext != 'geojson') {
        format = 'topojson';
      } else if (ext == 'json' && inputFormat == 'json') {
        // .json -> json table is not always the best inference...
        // additional logic should be applied downstream
        format = 'json'; // JSON table
      }
    } else if (couldBeDsvFile(file)) {
      format = 'dsv';
    } else if (inputFormat) {
      format = inputFormat;
    }
    return format;
  }

  var OutputFormat = /*#__PURE__*/Object.freeze({
    __proto__: null,
    getOutputFormat: getOutputFormat,
    inferOutputFormat: inferOutputFormat
  });

  // @targets - non-empty output from Catalog#findCommandTargets()
  //
  async function exportTargetLayers(catalog, targets, opts) {
    // kludge: get extent of 'fit-extent' layer (if given)
    if (opts.fit_extent) {
      var target = catalog.findSingleLayer(opts.fit_extent);
      var bounds = getLayerBounds(target.layer, target.dataset.arcs);
      opts = Object.assign({svg_bbox: bounds.toArray()}, opts);
    }
    // convert target fmt to dataset fmt
    var datasets = targets.map(function(target) {
      return utils.defaults({layers: target.layers}, target.dataset);
    });
    return exportDatasets(datasets, opts);
  }

  //
  //
  async function exportDatasets(datasets, opts) {
    var format = getOutputFormat(datasets[0], opts);
    var files;
    if (format == PACKAGE_EXT) {
      opts = utils.defaults({compact: true}, opts);
      return exportPackedDatasets(datasets, opts);
    }
    if (format == 'kml' || format == 'svg' || format == 'topojson' || format == 'geojson' && opts.combine_layers) {
      // multi-layer formats: combine multiple datasets into one
      if (datasets.length > 1) {
        datasets = [mergeDatasetsForExport(datasets)];
        if (format == 'topojson') {
          // Build topology, in case user has loaded several
          // files derived from the same source, with matching coordinates
          // (Downsides: useless work if geometry is unrelated;
          // could create many small arcs if layers are partially related)
          buildTopology(datasets[0]);
        }
        // KLUDGE let exporter know that copying is not needed
        // (because shape data was deep-copied during merge)
        opts = utils.defaults({final: true}, opts);
      }
    } else {
      datasets = datasets.map(copyDatasetForRenaming);
      assignUniqueLayerNames2(datasets);
    }
    files = datasets.reduce(function(memo, dataset) {
      if (runningInBrowser()) {
        utils.sortOn(dataset.layers, 'menu_order', true);
      } else {
        // kludge to export layers in order that target= option or previous
        // -target command matched them (useful mainly for SVG output)
        // target_id was assigned to each layer by findCommandTargets()
        utils.sortOn(dataset.layers, 'target_id', true);
      }
      return memo.concat(exportFileContent(dataset, opts));
    }, []);

    if (opts.bbox_index) {
      // If rounding or quantization are applied during export, bounds may
      // change somewhat... consider adding a bounds property to each layer during
      // export when appropriate.
      files.push(createIndexFile(datasets));
    }

    // need unique names for multiple output files
    assignUniqueFileNames(files);

    if (opts.gzip) {
      files.forEach(function(obj) {
        obj.filename += '.gz';
        obj.content = gzipSync(obj.content);
      });
    }
    return files;
  }

  // Return an array of objects with 'filename' and 'content' members.
  //
  function exportFileContent(dataset, opts) {
    var outFmt = opts.format = getOutputFormat(dataset, opts),
        exporter = exporters[outFmt],
        files = [];

    if (!outFmt) {
      error('Missing output format');
    } else if (!exporter) {
      error('Unknown output format:', outFmt);
    }

    // shallow-copy dataset and layers, so layers can be renamed for export
    dataset = utils.defaults({
      layers: dataset.layers.map(function(lyr) {return utils.extend({}, lyr);})
    }, dataset);

    // Adjust layer names, so they can be used as output file names
    // (except for multi-layer formats TopoJSON, SVG, KML)
    if (opts.file && outFmt != 'topojson' && outFmt != 'svg'&& outFmt != 'kml') {
      dataset.layers.forEach(function(lyr) {
        lyr.name = getFileBase(opts.file);
      });
    }
    assignUniqueLayerNames(dataset.layers);

    // apply coordinate precision, except:
    //   svg precision is applied by the SVG exporter, after rescaling
    //   TopoJSON precision is applied to avoid redundant copying
    if (opts.precision && outFmt != 'svg' && outFmt != 'topojson') {
      dataset = copyDatasetForExport(dataset);
      setCoordinatePrecision(dataset, opts.precision, !!opts.fix_geometry);
    }

    if (opts.cut_table) {
      files = exportDataTables(dataset.layers).concat(files);
    }

    if (opts.extension) {
      opts.extension = fixFileExtension(opts.extension);
    }

    validateLayerData(dataset.layers);
    files = exporter(dataset, opts).concat(files);
    validateFileNames(files);
    return files;
  }

  var exporters = {
    // [PACKAGE_EXT]: exportPackedDatasets, // handled as a special case
    geojson: exportGeoJSON,
    topojson: exportTopoJSON,
    shapefile: exportShapefile,
    dsv: exportDelim,
    dbf: exportDbf,
    json: exportJSON,
    svg: exportSVG,
    kml: exportKML
  };


  // Generate json file with bounding boxes and names of each export layer
  // TODO: consider making this a command, or at least make format settable
  //
  function createIndexFile(datasets) {
    var index = [];
    datasets.forEach(function(dataset) {
      dataset.layers.forEach(function(lyr) {
        var bounds = getLayerBounds(lyr, dataset.arcs);
        index.push({
          bbox: bounds.toArray(),
          name: lyr.name
        });
      });
    });

    return {
      content: JSON.stringify(index),
      filename: 'bbox-index.json'
    };
  }

  // Throw errors for various error conditions
  function validateLayerData(layers) {
    layers.forEach(function(lyr) {
      if (!lyr.geometry_type) {
        // allowing data-only layers
        if (lyr.shapes && utils.some(lyr.shapes, function(o) {
          return !!o;
        })) {
          error('A layer contains shape records and a null geometry type');
        }
      } else {
        if (!utils.contains(['polygon', 'polyline', 'point'], lyr.geometry_type)) {
          error ('A layer has an invalid geometry type:', lyr.geometry_type);
        }
        if (!lyr.shapes) {
          error ('A layer is missing shape data');
        }
      }
    });
  }

  function validateFileNames(files) {
    var index = {};
    files.forEach(function(file, i) {
      var filename = file.filename;
      if (!filename) error('Missing a filename for file' + i);
      if (filename in index) error('Duplicate filename', filename);
      index[filename] = true;
    });
  }

  function assignUniqueLayerNames(layers) {
    var names = layers.map(function(lyr) {
      return lyr.name || 'layer';
    });
    var uniqueNames = utils.uniqifyNames(names);
    layers.forEach(function(lyr, i) {
      lyr.name = uniqueNames[i];
    });
  }

  // Assign unique layer names across multiple datasets
  function assignUniqueLayerNames2(datasets) {
    var layers = datasets.reduce(function(memo, dataset) {
      return memo.concat(dataset.layers);
    }, []);
    assignUniqueLayerNames(layers);
  }

  function assignUniqueFileNames(output) {
    var names = output.map(function(o) {return o.filename;});
    var uniqnames = utils.uniqifyNames(names, formatVersionedFileName);
    output.forEach(function(o, i) {o.filename = uniqnames[i];});
  }

  // TODO: remove this -- format=json creates the same output
  //   (but need to make sure there's a way to prevent names of json data files
  //    from colliding with names of GeoJSON or TopoJSON files)
  function exportDataTables(layers, opts) {
    var tables = [];
    layers.forEach(function(lyr) {
      if (lyr.data) {
        tables.push({
          content: JSON.stringify(lyr.data),
          filename: (lyr.name ? lyr.name + '-' : '') + 'table.json'
        });
      }
    });
    return tables;
  }

  function formatVersionedFileName(filename, i) {
    var parts = filename.split('.');
    var ext, base;
    if (parts.length < 2) {
      return utils.formatVersionedName(filename, i);
    }
    ext = parts.pop();
    base = parts.join('.');
    return utils.formatVersionedName(base, i) + '.' + ext;
  }

  function fixFileExtension(ext, fmt) {
    // TODO: use fmt to validate
    return ext.replace(/^\.+/, '');
  }

  var Export = /*#__PURE__*/Object.freeze({
    __proto__: null,
    exportTargetLayers: exportTargetLayers,
    exportFileContent: exportFileContent,
    assignUniqueLayerNames: assignUniqueLayerNames,
    assignUniqueFileNames: assignUniqueFileNames,
    formatVersionedFileName: formatVersionedFileName
  });

  function readFirstChars(reader, n) {
    return bufferToString(reader.readSync(0, Math.min(n || 1000, reader.size())));
  }

  // Wraps a BufferReader or FileReader with an API that keeps track of position in the file
  function Reader2(reader) {
    var offs = 0; // read-head position in bytes

    this.position = function() {return offs;};

    this.remaining = function() {
      return Math.max(reader.size() - offs, 0);
    };

    this.advance = function(i) {
      offs += i;
    };

    this.readSync = function() {
      return reader.readSync(offs);
    };

    this.expandBuffer = function() {
      reader.expandBuffer();
    };
  }

  // Same interface as FileReader, for reading from a Buffer or ArrayBuffer instead of a file.
  function BufferReader(src) {
    var bufSize = src.byteLength || src.length,
        binArr, buf;

    this.readToBinArray = function(start, length) {
      if (bufSize < start + length) {
        error("Out-of-range error");
      }
      if (!binArr) binArr = new BinArray(src);
      binArr.position(start);
      return binArr;
    };

    this.toString = function(enc) {
      return bufferToString(buffer(), enc);
    };

    this.readSync = function(start, length) {
      // TODO: consider using a default length like FileReader
      return buffer().slice(start, length ? start + length : bufSize);
    };

    function buffer() {
      if (!buf) {
        // buf = (src instanceof ArrayBuffer) ? utils.createBuffer(src) : src;
        buf = utils.toBuffer(src);
      }
      return buf;
    }

    this.findString = FileReader.prototype.findString;
    this.expandBuffer = function() {return this;};
    this.size = function() {return bufSize;};
    this.close = function() {};
  }

  function FileReader(path, opts) {
    var fs = require$1('fs'),
        fileLen = fs.statSync(path).size,
        DEFAULT_CACHE_LEN = opts && opts.cacheSize || 0x1000000, // 16MB
        DEFAULT_BUFFER_LEN = opts && opts.bufferSize || 0x40000, // 256K
        fd, cacheOffs, cache, binArr;
    // kludge to let us check if input files are being overwritten
    (getStashedVar('input_files') || []).push(path);

    // Double the default size of the Buffer returned by readSync()
    this.expandBuffer = function() {
      DEFAULT_BUFFER_LEN *= 2;
      if (DEFAULT_BUFFER_LEN * 2 > DEFAULT_CACHE_LEN) {
        // Keep the file cache larger than the default buffer size.
        // This fixes a performance bug caused when the size of the buffer returned by
        // readSync() grows as large as the file cache, causing each subsequent
        // call to readSync() to trigger a call to fs.readFileSync()
        DEFAULT_CACHE_LEN = DEFAULT_BUFFER_LEN * 2;
      }
      return this;
    };

    // Read to BinArray (for compatibility with ShpReader)
    this.readToBinArray = function(start, length) {
      if (updateCache(start, length)) {
        binArr = new BinArray(cache);
      }
      binArr.position(start - cacheOffs);
      return binArr;
    };

    // Returns a Buffer containing a string of bytes read from the file
    // start: file offset of the first byte
    // length: (optional) length of the returned Buffer
    this.readSync = function(start, length) {
      if (length > 0 === false) {
        // use default size if length is not specified
        length = DEFAULT_BUFFER_LEN;
      }

      if (start + length > fileLen) {
        length = fileLen - start; // truncate at eof
      }
      if (length === 0) {
        return utils.createBuffer(0); // kludge to allow reading up to eof
      }
      updateCache(start, length);
      return cache.slice(start - cacheOffs, start - cacheOffs + length);
    };

    this.size = function() {
      return fileLen;
    };

    this.toString = function(enc) {
      // TODO: use fd
      return cli.readFile(path, enc || 'utf8');
    };

    this.close = function() {
      if (fd) {
        fs.closeSync(fd);
        fd = null;
        cache = null;
      }
    };

    // Update the file cache (if necessary) so that a given range of bytes is available.
    // Receive: offset and length of byte string that must be read
    // Returns: true if cache was updated, or false
    function updateCache(fileOffs, bytesNeeded) {
      var headroom = fileLen - fileOffs,
          bytesRead, bytesToRead;
      if (headroom < bytesNeeded || headroom < 0) {
        error("Tried to read past end-of-file");
      }
      if (cache && fileOffs >= cacheOffs && cacheOffs + cache.length >= fileOffs + bytesNeeded) {
        // cache contains enough data to satisfy the request (no need to read from disk)
        return false;
      }
      bytesToRead = Math.max(DEFAULT_CACHE_LEN, bytesNeeded);
      if (headroom < bytesToRead) {
        bytesToRead = headroom;
      }
      if (!cache || bytesToRead != cache.length) {
        cache = utils.createBuffer(bytesToRead);
      }
      if (!fd) {
        fd = fs.openSync(path, 'r');
      }
      bytesRead = fs.readSync(fd, cache, 0, bytesToRead, fileOffs);
      cacheOffs = fileOffs;
      if (bytesRead != bytesToRead) error("Error reading file");
      return true;
    }
  }

  FileReader.prototype.findString = function (str, maxLen) {
    var len = Math.min(this.size(), maxLen || this.size());
    var buf = this.readSync(0, len);
    var strLen = str.length;
    var n = buf.length - strLen;
    var firstByte = str.charCodeAt(0);
    var i;
    for (i=0; i < n; i++) {
      if (buf[i] == firstByte && buf.toString('utf8', i, i + strLen) == str) {
        return {
          offset: i + strLen,
          text: buf.toString('utf8', 0, i)
        };
      }
    }
    return null;
  };

  var FileReader$1 = /*#__PURE__*/Object.freeze({
    __proto__: null,
    readFirstChars: readFirstChars,
    Reader2: Reader2,
    BufferReader: BufferReader,
    FileReader: FileReader
  });

  // Read and parse a DSV file
  // This version performs field filtering before fields are extracted (faster)
  // (tested with a 40GB CSV)
  //
  // TODO: confirm compatibility with all supported encodings
  function readDelimRecords(reader, delim, optsArg) {
    var opts = optsArg || {};
    if (delim == ' ') return readFixedWidthRecords(reader, opts);
    var reader2 = new Reader2(reader),
        headerStr = readLinesAsString(reader2, getDelimHeaderLines(opts), opts.encoding),
        header = parseDelimHeaderSection(headerStr, delim, opts),
        convertRowArr = getRowConverter(header.import_fields),
        batchSize = opts.batch_size || 1000,
        records = [],
        str, batch;
    if (header.import_fields.length === 0) return []; // e.g. empty file
    // read in batches (faster than line-by-line)
    while ((str = readLinesAsString(reader2, batchSize, opts.encoding))) {
      batch = parseDelimText(str, delim, convertRowArr, header.column_filter || false, header.row_filter || false);
      records.push.apply(records, batch);
      if (opts.csv_lines && records.length >= opts.csv_lines) {
        return records.slice(0, opts.csv_lines);
      }
    }
    return records;
  }

  // Fallback for readDelimRecords(), for encodings that do not use ascii values
  // for delimiter characters and newlines. Input size is limited by the maximum
  // string size.
  function readDelimRecordsFromString(str, delim, opts) {
    if (delim == ' ') return readFixedWidthRecordsFromString(str);
    var header = parseDelimHeaderSection(str, delim, opts);
    if (header.import_fields.length === 0 || !header.remainder) return [];
    var convert = getRowConverter(header.import_fields);
    var records = parseDelimText(header.remainder, delim, convert, header.column_filter, header.row_filter);
    if (opts.csv_lines > 0) {
      // TODO: don't parse unneeded rows
      records = records.slice(0, opts.csv_lines);
    }
    return records;
  }

  // Get index in string of the nth line
  // line numbers are 1-based (first line is 1)
  function indexOfLine(str, nth) {
    var rxp = /\r\n|[\r\n]|.$/g; // dot prevents matching end of string twice
    var i = 1;
    if (nth === 1) return 0;
    if (nth > 1 === false) return -1;
    while (rxp.exec(str)) {
      i++;
      if (i < nth === false) return rxp.lastIndex;
    }
    return -1;
  }

  function getDelimHeaderLines(opts) {
    var skip = opts.csv_skip_lines || 0;
    if (!opts.csv_field_names) skip++;
    return skip;
  }

  // Adapted from https://github.com/d3/d3-dsv
  function getRowConverter(fields) {
    return new Function('arr', 'return {' + fields.map(function(name, i) {
      return JSON.stringify(name) + ': arr[' + i + '] || ""';
    }).join(',') + '}');
  }

  function parseDelimHeaderSection(str, delim, opts) {
    var nodata = {headers: [], import_fields: []},
        retn = {},
        i;
    str = str || '';
    if (opts.csv_skip_lines > 0) {
      i = indexOfLine(str, opts.csv_skip_lines + 1);
      if (i === -1) return nodata;
      str = str.substr(i);
    }
    if (opts.csv_field_names) {
      retn.headers = opts.csv_field_names;
    } else {
      i = indexOfLine(str, 2);
      if (i === -1) return nodata;
      retn.headers = parseDelimText(str.slice(0, i), delim)[0];
      str = str.substr(i);
    }
    if (opts.csv_dedup_fields) {
      retn.headers = utils.uniqifyNames(retn.headers);
    }
    if (opts.csv_filter) {
      retn.row_filter = getDelimRecordFilterFunction(opts.csv_filter);
    }
    if (opts.csv_fields) {
      retn.column_filter = getDelimFieldFilter(retn.headers, opts.csv_fields);
      retn.import_fields = retn.headers.filter(function(name, i) {return retn.column_filter(i);});
    } else {
      retn.import_fields = retn.headers;
    }
    retn.remainder = str;
    return retn;
  }

  // Returns a function for filtering records
  // TODO: look into using more code from standard expressions.
  function getDelimRecordFilterFunction(expression) {
    var rowFilter = getExpressionFunction(expression);
    return function(rec) {
      var val = rowFilter(rec);
      requireBooleanResult(val);
      return val;
    };
  }

  // Returns a function for filtering fields by column index
  // The function returns true for retained fields and false for excluded fields
  function getDelimFieldFilter(header, fieldsToKeep) {
    var index = utils.arrayToIndex(fieldsToKeep);
    var map = header.map(function(name) {
      return name in index;
    });
    var missing = utils.difference(fieldsToKeep, header);
    if (missing.length > 0) {
      var foundStr = [''].concat(header).join('\n  ');
      var missingStr = [''].concat(missing).join('\n  ');
      stop('csv-fields option has', missing.length == 1 ? 'a name' : missing.length + ' names',  'not found in the file\nFields:', foundStr, '\nMissing:', missingStr);
    }
    return function(colIdx) {
      return map[colIdx];
    };
  }

  function readLinesAsString(reader, lines, encoding) {
    var buf = reader.readSync();
    var retn = readLinesFromBuffer(buf, lines);
    var str;
    if (retn.bytesRead == buf.length && retn.bytesRead < reader.remaining()) {
      // buffer overflow -- enlarge buffer and read lines again
      reader.expandBuffer();
      return readLinesAsString(reader, lines, encoding);
    }
    // str = retn.bytesRead > 0 ? retn.buffer.toString('ascii', 0, retn.bytesRead) : '';
    str = retn.bytesRead > 0 ? decodeString(retn.buffer, encoding) : '';
    if (reader.position() === 0) {
     str = trimBOM(str);
    }
    reader.advance(retn.bytesRead);
    return str;
  }

  function readLinesFromBuffer(buf, linesToRead) {
    var CR = 13, LF = 10, DQUOTE = 34,
        inQuotedText = false,
        lineCount = 0,
        bufLen = buf.length,
        i, c;

    lineCount++;
    for (i=0; i < bufLen && lineCount <= linesToRead; i++) {
      c = buf[i];
      if (c == DQUOTE) {
        inQuotedText = !inQuotedText;
      } else if ((c == CR || c == LF) && !inQuotedText) {
        if (c == CR && i + 1 < bufLen && buf[i + 1] == LF) {
          // first half of CRLF pair: advance one byte
          i++;
        }
        lineCount++;
      }
    }
    return {
      bytesRead: i,
      buffer: buf.slice(0, i)
    };
  }

  // Convert a string of CSV data into an array of data records
  // convert: optional function for converting an array record to an object record (values indexed by field names)
  // colFilter: optional function for filtering columns by numerical column id (0-based); accepts an array record and an id
  // rowFilter: optional function for filtering rows; accepts a record in object format
  function parseDelimText(text, delim, convert, colFilter, rowFilter) {
    var CR = 13, LF = 10, DQUOTE = 34,
        DELIM = delim.charCodeAt(0),
        inQuotedText = false,
        capturing = false,
        srcCol = -1,
        records = [],
        fieldStart, i, c, len, record;

    if (!convert) convert = function(d) {return d;};

    function endLine() {
      var rec = convert ? convert(record) : record;
      if (!rowFilter || rowFilter(rec)) records.push(rec);
      srcCol = -1;
    }

    function startFieldAt(j) {
      fieldStart = j;
      srcCol++;
      if (srcCol === 0) record = [];
      if (!colFilter || colFilter(srcCol)) {
        capturing = true;
      }
    }

    function captureField(start, end) {
      var s;
      if (!capturing) return;
      capturing = false;
      if (start === end) {
        s = '';
      } else if (text.charCodeAt(start) == DQUOTE) {
        s = text.slice(start+1, end-1).replace(/""/g, '"');
      } else {
        s = text.slice(start, end);
      }
      record.push(s);
    }

    startFieldAt(0);
    for (i=0, len=text.length; i < len; i++) {
      c = text.charCodeAt(i);
      if (c == DQUOTE) {
        inQuotedText = !inQuotedText;
      } else if (inQuotedText) ; else if (c == DELIM) {
        captureField(fieldStart, i);
        startFieldAt(i + 1);
      } else if (c == CR || c == LF) {
        captureField(fieldStart, i);
        endLine();
        if (c == CR && text.charCodeAt(i+1) == LF) {
          i++; // first half of CRLF pair; skip a char
        }
        if (i + 1 < len) startFieldAt(i+1);
      }
    }

    if (srcCol > -1) { // finish last line (if file ends without newline)
      if (capturing) captureField(fieldStart, i);
      endLine();
    }

    return records;
  }

  var DelimReader = /*#__PURE__*/Object.freeze({
    __proto__: null,
    readDelimRecords: readDelimRecords,
    readDelimRecordsFromString: readDelimRecordsFromString,
    indexOfLine: indexOfLine,
    getRowConverter: getRowConverter,
    parseDelimHeaderSection: parseDelimHeaderSection,
    getDelimFieldFilter: getDelimFieldFilter,
    readLinesAsString: readLinesAsString,
    parseDelimText: parseDelimText
  });

  function detectEncodingFromBOM(bytes) {
    // utf8 EF BB BF
    // utf16be FE FF
    // utf16le FF FE
    var n = bytes.length;
    if (n >= 2 && bytes[0] == 0xFE && bytes[1] == 0xFF) return 'utf16be';
    if (n >= 2 && bytes[0] == 0xFF && bytes[1] == 0xFE) return 'utf16le';
    if (n >= 3 && bytes[0] == 0xEF && bytes[1] == 0xBB && bytes[2] == 0xBF) return 'utf8';
    return '';
  }

  // Try to detect the encoding of some sample text.
  // Returns an encoding name or null.
  // @samples Array of buffers containing sample text fields
  // TODO: Improve reliability and number of detectable encodings.
  function detectEncoding(samples) {
    // score each encoding as 2 (high confidence) 1 (low confidence) or 0 (fail)
    var candidates = [{
      // latin1 is the original Shapefile encoding, using as an imperfect fallback
      // (sorts to the top only if all other encodings score 0)
      encoding: 'latin1',
      confidence: 0
    },{
      encoding: 'win1252',
      confidence: looksLikeWin1252(samples)
    }, {
      encoding: 'utf8',
      confidence: looksLikeUtf8(samples)
    }, {
      encoding: 'gb18030',
      confidence: looksLikeGB18030(samples)
    }];
    utils.sortOn(candidates, 'confidence', 'descending');
    return candidates[0];
  }

  function decodeSamples(enc, samples) {
    return samples.map(function(buf) {
      return decodeString(buf, enc).trim();
    });
  }

  // Win1252 is the same as Latin1, except it replaces a block of control
  // characters with n-dash, Euro and other glyphs. Encountered in-the-wild
  // in Natural Earth (airports.dbf uses n-dash).
  //
  // Quick-and-dirty win1251 detection: decoded string contains mostly common ascii
  // chars and almost no chars other than word chars + punctuation.
  // This excludes encodings like Greek, Cyrillic or Thai, but
  // is susceptible to false positives with encodings like codepage 1250 ("Eastern
  // European").
  //
  function looksLikeWin1252(samples) {
        //common l.c. ascii chars
    var commonAscii = 'abcdefghijklmnopqrstuvwxyz0123456789.()\'"?+-\n,:;/|_$% ',
        // more common extended chars + NBS (found in the wild)
        moreChars = '' + '\xA0',
        str = decodeSamples('win1252', samples).join(''),
        commonAsciiPct = calcCharPct(str, commonAscii),
        expandedPct = calcCharPct(str, moreChars) + commonAsciiPct;
    var high = expandedPct > 0.98 && commonAsciiPct >= 0.8;
    var low = expandedPct > 0.97 && commonAsciiPct >= 0.6;
    return getScore(high, low);
  }

  function looksLikeUtf8(samples) {
    // Reject string if it contains the "replacement character" after decoding
    // as utf-8
    var str = decodeSamples('utf8', samples).join('');
    var invalidPct = getInvalidPct(str);
    var high = invalidPct == 0;
    var low = invalidPct < 0.03;
    return getScore(high, low);
  }

  function looksLikeGB18030(samples) {
    // from Jun Da's frequency table
    var commonHanZi = '';
    var str = decodeSamples('gb18030', samples).join('');
    // Almost all the common Unicode Hanzi are in this range (along with many more uncommon ones)
    var chineseStr = str.replace(/[^\u4e00-\u9fa5]/g, '');
    var chinesePct = chineseStr.length / str.length;
    var commonAsciiStr = extractCommonAsciiChars(str);
    var commonAsciiPct = commonAsciiStr.length / str.length;
    // Some encodings get converted almost completely into valid (but mostly
    // uncommon) Chinese characters by the gb18030 converter.
    // To guard against this, we're requiring that a certain percentage of
    // characters be on a list of the most common characters.
    var commonHanZiPct = calcCharPct(chineseStr, commonHanZi);
    // check for non-convertible characters
    var invalidPct = getInvalidPct(str);
    var high = chinesePct > 0.5 && (chinesePct + commonAsciiPct) > 0.9 &&
        invalidPct === 0 && commonHanZiPct > 0.25;
    var low = chinesePct > 0.3 && (chinesePct + commonAsciiPct) > 0.8 &&
        commonHanZiPct > 0.15;
    return getScore(high, low);
  }

  function getScore(high, low) {
    return high && 2 || low && 1 || 0;
  }

  function getInvalidPct(str) {
    // count occurences of the "replacement" character
    var invalidCount = (str.match(/\ufffd/g) || []).length;
    return invalidCount / str.length;
  }

  function extractCommonAsciiChars(str) {
    return str.replace(/[^a-zA-Z0-9.()'"?+\n,:;/|_$% -]/g, '');
  }

  // Calc percentage of chars in a string that are present in a second string
  // @chars String of chars to look for in @str
  function calcCharPct(str, chars) {
    var index = {},
        count = 0;
    str = str.toLowerCase();
    for (var i=0, n=chars.length; i<n; i++) {
      index[chars[i]] = 1;
    }
    for (i=0, n=str.length; i<n; i++) {
      count += index[str[i]] || 0;
    }
    return count / str.length || 0;
  }

  var EncodingDetection = /*#__PURE__*/Object.freeze({
    __proto__: null,
    detectEncodingFromBOM: detectEncodingFromBOM,
    detectEncoding: detectEncoding,
    decodeSamples: decodeSamples
  });

  // Convert a string containing delimited text data into a dataset object
  function importDelim(str, opts) {
    return importDelim2({content: str}, opts);
  }

  // Convert a string, buffer or file containing delimited text into a dataset obj.
  function importDelim2(data, opts) {
    // TODO: remove duplication with importJSON()
    var readFromFile = !data.content && data.content !== '',
        content = data.content,
        reader, records, delimiter, table, encoding;
    opts = opts || {};

    // // read content of all but very large files into a buffer
    // if (readFromFile && cli.fileSize(data.filename) < 2e9) {
    //   content = cli.readFile(data.filename);
    //   readFromFile = false;
    // }

    if (readFromFile) {
      reader = new FileReader(data.filename);
    } else if (content instanceof ArrayBuffer || content instanceof B$3 || content instanceof Uint8Array) {
      // Web API may import as ArrayBuffer, to support larger files
      reader = new BufferReader(content);
      content = null;
    } else if (utils.isString(content)) ; else {
      error("Unexpected object type");
    }

    if (reader) {
      encoding = detectEncodingFromBOM(reader.readSync(0, Math.min(reader.size(), 3)));
      // Files in some encodings have to be converted to strings before parsing
      // Other encodings are similar enough to ascii that CSV can be parsed
      // byte-by-byte.
      if (encoding == 'utf16be' || encoding == 'utf16le') {
        content = trimBOM(reader.toString(encoding));
        reader = null;
      } else if (opts.encoding && !encodingIsAsciiCompat(opts.encoding)) {
        content = reader.toString(opts.encoding);
        reader = null;
      }
    }

    if (reader) {
      delimiter = guessDelimiter(readFirstChars(reader, 2000));
      records = readDelimRecords(reader, delimiter, opts);
    } else {
      delimiter = guessDelimiter(content);
      records = readDelimRecordsFromString(content, delimiter, opts);
    }
    if (records.length === 0) {
      message("Unable to read any data records");
    }
    adjustRecordTypes(records, opts);
    table = new DataTable(records);
    deleteFields(table, isInvalidFieldName);
    return {
      layers: [{data: table}],
      info: {input_delimiter: delimiter}
    };
  }

  var supportedDelimiters = ['|', '\t', ',', ';', ' '];

  function isSupportedDelimiter(d) {
    return utils.contains(supportedDelimiters, d);
  }

  function guessDelimiter(content) {
    return utils.find(supportedDelimiters, function(delim) {
      var rxp = getDelimiterRxp(delim);
      return rxp.test(content);
    }) || ',';
  }

  // Get RegExp to test for a delimiter before first line break of a string
  // Assumes that the first line does not contain alternate delim chars (this will
  // be true if the first line has field headers composed of word characters).
  function getDelimiterRxp(delim) {
    var rxp = "^[^\\n\\r]+" + utils.regexEscape(delim);
    return new RegExp(rxp);
  }

  function getFieldTypeHints(opts) {
    var hints = {};
    opts = opts || {};
    if (opts.string_fields) {
      opts.string_fields.forEach(function(f) {
        hints[f] = 'string';
      });
    }
    if (opts.field_types) {
      opts.field_types.forEach(function(raw) {
        var parts, name, type;
        if (raw.indexOf(':') != -1) {
          parts = raw.split(':');
          name = parts[0];
          type = validateFieldType(parts[1]);
        } else if (raw[0] === '+') { // d3-style type hint: unary plus
          name = raw.substr(1);
          type = 'number';
        }
        if (type) {
          hints[name] = type;
        } else {
          message("Invalid type hint (expected :str or :num) [" + raw + "]");
        }
      });
    }
    return hints;
  }


  // Detect and convert data types of data from csv files.
  // TODO: decide how to handle records with inconstent properties. Mapshaper
  //    currently assumes tabular data
  function adjustRecordTypes(records, optsArg) {
    var opts = optsArg || {},
        typeIndex = getFieldTypeHints(opts),
        singleType = typeIndex['*'], // support for setting all fields to a single type
        fields = Object.keys(records[0] || []),
        detectedNumFields = [],
        parseNumber = opts.decimal_comma ? utils.parseIntlNumber : utils.parseNumber,
        replacements = {};
    fields.forEach(function(key) {
      var typeHint = typeIndex[key];
      var values = null;
      if (typeHint == 'number' || singleType == 'number') {
        values = convertDataField(key, records, parseNumber);
      } else if (typeHint == 'string' || singleType == 'string') {
        // We should be able to assume that imported CSV fields are strings,
        //   so parsing + replacement is not required
        // values = internal.convertDataField(key, records, utils.parseString);
        values = null;
      } else {
        values = tryNumericField(key, records, parseNumber);
        if (values) detectedNumFields.push(key);
      }
      if (values) replacements[key] = values;
    });
    if (Object.keys(replacements).length > 0) {
      updateFieldsInRecords(fields, records, replacements);
    }
    if (detectedNumFields.length > 0) {
      message(utils.format("Auto-detected number field%s: %s",
          detectedNumFields.length == 1 ? '' : 's', detectedNumFields.join(', ')));
    }
  }

  // Copy original data properties and replacements to a new set of records
  // (Better performance in v8 than making in-place replacements)
  function updateFieldsInRecords(fields, records, replacements) {
    // Use object-literal syntax (faster than alternative)
    var convertBody = 'return {' + fields.map(function(name) {
        var key = JSON.stringify(name);
        return key + ': ' + (replacements[name] ? 'replacements[' + key + '][i]' : 'rec[' + key + ']');
      }).join(', ') + '}';
    var convert = new Function('rec', 'replacements', 'i', convertBody);
    records.forEach(function(rec, i) {
      records[i] = convert(rec, replacements, i);
    });
  }

  function tryNumericField(key, records, parseNumber) {
    var arr = [],
        count = 0,
        raw, str, num;
    for (var i=0, n=records.length; i<n; i++) {
      raw = records[i][key];
      num = parseNumber(raw);
      if (num === null) {
        str = raw ? raw.trim() : '';
        if (str.length > 0 && str != 'NA' && str != 'NaN') { // ignore NA values ("NA" seen in R output)
          return null; // unparseable value -- fail
        }
      } else {
        count++;
      }
      arr.push(num);
    }
    return count > 0 ? arr : null;
  }

  function convertDataField(name, records, f) {
    var values = [];
    for (var i=0, n=records.length; i<n; i++) {
      values.push(f(records[i][name]));
    }
    return values;
  }

  // Accept a type hint from a header like "FIPS:str"
  // Return standard type name (number|string) or null if hint is not recognized
  function validateFieldType(hint) {
    var str = hint.toLowerCase(),
        type = null;
    if (str[0] == 'n') {
      type = 'number';
    } else if (str[0] == 's') {
      type = 'string';
    }
    return type;
  }

  var DelimImport = /*#__PURE__*/Object.freeze({
    __proto__: null,
    importDelim: importDelim,
    importDelim2: importDelim2,
    isSupportedDelimiter: isSupportedDelimiter,
    guessDelimiter: guessDelimiter,
    getFieldTypeHints: getFieldTypeHints,
    adjustRecordTypes: adjustRecordTypes
  });

  function validateInputOpts(cmd) {
    var o = cmd.options;
        cmd._;

    if (o.files) {
      o.files = cli.expandInputFiles(o.files);
      if (o.files[0] == '-' || o.files[0] == '/dev/stdin') {
        delete o.files;
        o.stdin = true;
      }
    }

    if ('precision' in o && o.precision > 0 === false) {
      error('precision= option should be a positive number');
    }

    if (o.encoding) {
      o.encoding = validateEncoding(o.encoding);
    }
  }

  function validateSimplifyOpts(cmd) {
    var o = cmd.options;
    if (!o.interval && !o.percentage && !o.resolution) {
      error('Command requires an interval, percentage or resolution parameter');
    }
  }

  function validateProjOpts(cmd) {
    if (!(cmd.options.crs || cmd.options.match || cmd.options.init)) {
      stop('Missing projection data');
    }
  }

  function validateGridOpts(cmd) {
    var o = cmd.options;
    if (cmd._.length == 1) {
      var tmp = cmd._[0].split(',');
      o.cols = parseInt(tmp[0], 10);
      o.rows = parseInt(tmp[1], 10) || o.cols;
    }
  }

  function validateExpressionOpt(cmd) {
    if (!cmd.options.expression) {
      error('Command requires a JavaScript expression');
    }
  }

  function validateOutputOpts(cmd) {
    var o = cmd.options,
        arg = o._ || '',
        pathInfo = parseLocalPath(arg);

    // if (!arg) {
    //   error('Command requires an output file or directory.');
    // }

    if (arg == '-' || arg == '/dev/stdout') {
      o.stdout = true;
    } else if (arg && !pathInfo.extension) {
      if (!cli.isDirectory(arg)) {
        error('Unknown output option:', arg);
      }
      o.directory = arg;
    } else if (arg) {
      if (pathInfo.directory) {
        o.directory = pathInfo.directory;
        // no longer checking for missing directory
        // (cli.writeFileSync() now creates directories that don't exist)
      }
      if (/gz/i.test(pathInfo.extension)) {
        // handle arguments like -o out.json.gz (the preferred format)
        if (parseLocalPath(pathInfo.basename).extension) {
          o.file = pathInfo.basename;
        } else {
          // handle arguments like -o out.gz
          o.file = pathInfo.filename;
        }
        o.gzip = true;
      } else if (/zip/i.test(pathInfo.extension)) {
        o.file = null;
        o.zipfile = pathInfo.filename;
        o.zip = true;
      } else {
        o.file = pathInfo.filename;
      }

      if (filenameIsUnsupportedOutputType(o.file)) {
        error('Output file looks like an unsupported file type:', o.file);
      }
    }

    if (o.format) {
      o.format = o.format.toLowerCase();
      if (o.format == 'csv') {
        o.format = 'dsv';
        o.delimiter = o.delimiter || ',';
      } else if (o.format == 'tsv') {
        o.format = 'dsv';
        o.delimiter = o.delimiter || '\t';
      }
      if (!isSupportedOutputFormat(o.format)) {
        error('Unsupported output format:', o.format);
      }
    }

    if (o.delimiter) {
      // convert '\t' '\t' \t to tab
      o.delimiter = o.delimiter.replace(/^["']?\\t["']?$/, '\t');
      if (!isSupportedDelimiter(o.delimiter)) {
        error('Unsupported delimiter:', o.delimiter);
      }
    }

    if (o.encoding) {
      o.encoding = validateEncoding(o.encoding);
    }

    if (o.field_order && o.field_order != 'ascending') {
      error('Unsupported field order:', o.field_order);
    }

    // topojson-specific
    if ('quantization' in o && o.quantization > 0 === false) {
      error('quantization= option should be a nonnegative integer');
    }

    if ('topojson_precision' in o && o.topojson_precision > 0 === false) {
      error('topojson-precision= option should be a positive number');
    }
  }

  var assignmentRxp = /^([a-z0-9_+-]+)=(?!=)(.*)$/i; // exclude ==

  function splitShellTokens(str) {
    var BAREWORD = `([^'"\\s])+`;
    var DOUBLE_QUOTE = `"((\\\\"|[^"])*?)"`;
    var SINGLE_QUOTE = `'((\\\\'|[^'])*?)'`;
    var rxp = new RegExp('(' + BAREWORD + '|' + SINGLE_QUOTE + '|' + DOUBLE_QUOTE + ')*', 'g');
    var matches = str.match(rxp) || [];
    var chunks = matches.filter(function(chunk) {
      // single backslashes may be present in multiline commands pasted from a makefile, e.g.
      return !!chunk && chunk != '\\';
    }).map(utils.trimQuotes);
    return chunks;
  }

  function parseNumberList(token) {
    return token.split(',').map(parseFloat);
  }

  // Split comma-delimited list, trim quotes from entire list and
  // individual members
  function parseStringList(token) {
    var delim = ',';
    var list = splitOptionList(token, delim);
    if (list.length == 1) {
      list = splitOptionList(list[0], delim);
    }
    return list;
  }

  // Accept spaces and/or commas as delimiters
  function parseColorList(token) {
    var delim = ', ';
    // accept rgb(0 0 0) rgb(0,0,0) rgb(0, 0, 0)
    var token2 = token.replace(/[ ,] *(?=[^(]*\))/g, '~~~'); // kludge: protect rgba() functions from being split apart
    var list = splitOptionList(token2, delim);
    if (list.length == 1) {
      list = splitOptionList(list[0], delim);
    }
    list = list.map(function(str) {
      return str.replace(/~~~/g, ',');
    });
    return list;
  }

  function cleanArgv(argv) {
    // Note: original trim caused some quoted spaces to be removed
    // (e.g. bash shell seems to convert [delimiter=" "] to [delimiter= ],
    //  which then got trimmed to [delimiter=] below)
    //// argv = argv.map(function(s) {return s.trim();}); // trim whitespace

    // Updated: don't trim space from tokens like [delimeter= ]
    argv = argv.map(function(s) {
      if (!/= $/.test(s)) {
        s = utils.rtrim(s);
      }
      s = utils.ltrim(s);
      return s;
    });
    argv = argv.filter(function(s) {return s !== '';}); // remove empty tokens
    // Note: removing trimQuotes() call... now, strings like 'name="Meg"' will no longer
    // be parsed the same way as name=Meg and name="Meg"
    //// argv = argv.map(utils.trimQuotes); // remove one level of single or dbl quotes
    return argv;
  }

  function splitOptionList(str, delimChars) {
    var BAREWORD = '([^' + delimChars + '\'"][^' + delimChars + ']*)'; // TODO: make safer
    var DOUBLE_QUOTE = '"((\\\\"|[^"])*?)"';
    var SINGLE_QUOTE = '\'((\\\\\'|[^\'])*?)\'';
    var rxp = new RegExp('^(' + BAREWORD + '|' + SINGLE_QUOTE + '|' + DOUBLE_QUOTE + ')([' + delimChars + ']+|$)');
    var chunks = [];
    var match;
    while ((match = rxp.exec(str)) !== null) {
      chunks.push(match[1]);
      str = str.substr(match[0].length);
    }
    return chunks.filter(function(chunk) {
      return !!chunk && chunk != '\\';
    }).map(utils.trimQuotes);
  }

  // Prepare a value to be used as an option value.
  // Places quotes around strings containing spaces.
  // e.g. converts   Layer 1 -> "Layer 1"
  //   for use in contexts like: name="Layer 1"
  function formatOptionValue(val) {
    val = String(val);
    if (val.indexOf(' ') > -1) {
      val = JSON.stringify(val); // quote ids with spaces
    }
    return val;
  }

  function isAssignment(token) {
    return assignmentRxp.test(token);
  }

  function splitAssignment(token) {
    var match = assignmentRxp.exec(token),
        name = match[1],
        val = utils.trimQuotes(match[2]);
    return [name, val];
  }

  var OptionParsingUtils = /*#__PURE__*/Object.freeze({
    __proto__: null,
    splitShellTokens: splitShellTokens,
    parseNumberList: parseNumberList,
    parseStringList: parseStringList,
    parseColorList: parseColorList,
    cleanArgv: cleanArgv,
    formatOptionValue: formatOptionValue,
    isAssignment: isAssignment,
    splitAssignment: splitAssignment
  });

  function CommandParser() {
    var commandRxp = /^--?([a-z][\w-]*)$/i,
        invalidCommandRxp = /^--?[a-z][\w-]*[=]/i, // e.g. -target=A // could be more general
        _usage = "",
        _examples = [],
        _commands = [],
        _default = null,
        _note;

    if (this instanceof CommandParser === false) return new CommandParser();

    this.usage = function(str) {
      _usage = str;
      return this;
    };

    this.note = function(str) {
      _note = str;
      return this;
    };

    // set a default command; applies to command line args preceding the first
    // explicit command
    this.default = function(str) {
      _default = str;
    };

    this.example = function(str) {
      _examples.push(str);
    };

    this.command = function(name) {
      var opts = new CommandOptions(name);
      // support 'verbose' and 'debug' flags for each command, without help entries
      opts.option('verbose', {type: 'flag'});
      opts.option('debug', {type: 'flag'});
      _commands.push(opts);
      return opts;
    };

    this.section = function(name) {
      return this.command("").title(name);
    };

    this.isCommandName = tokenIsCommandName;

    this.parseArgv = function(raw) {
      var commandDefs = getCommands(),
          commands = [], cmd,
          argv = cleanArgv(raw),
          cmdName, cmdDef;

      if (argv.length == 1 && tokenIsCommandName(argv[0])) {
        // show help if only a command name is given
        argv.unshift('-help'); // kludge (assumes -help <command> syntax)
      } else if (argv.length > 0 && !tokenLooksLikeCommand(argv[0]) && _default) {
        // if there are arguments before the first explicit command, use the default command
        argv.unshift('-' + _default);
      }

      while (argv.length > 0) {
        cmdName = readCommandName(argv);
        if (!cmdName) {
          stop("Invalid command:", argv[0]);
        }
        cmdDef = findCommandDefn(cmdName, commandDefs) || null;
        if (!cmdDef) {
          cmd = parseUnknownCommandOptions(argv, cmdName);
        } else {
          cmd = parseCommandOptions(argv, cmdDef);
        }
        commands.push(cmd);
      }
      return commands;

      function parseCommandOptions(argv, cmdDef) {
        var cmd = {
          name: cmdDef.name,
          options: {},
          _: []
        };

        while (argv.length > 0 && !tokenLooksLikeCommand(argv[0])) {
          readOption(cmd, argv, cmdDef);
        }

        try {
          if (cmd._.length > 0) {
            readDefaultOptionValue(cmd, cmdDef);
          }
          if (cmdDef.validate) {
            cmdDef.validate(cmd);
          }
          delete cmd.options._; // kludge to remove -o placeholder option
        } catch(e) {
          stop("[" + cmdName + "] " + e.message);
        }
        return cmd;
      }

      function parseUnknownCommandOptions(argv, cmdName) {
        // In order to support adding commands at runtime, unknown commands
        // are parsed without options (tokens get stored for later parsing)
        var cmd = {
          name: cmdName,
          options: {},
          _: []
        };
        while (argv.length > 0 && !tokenLooksLikeCommand(argv[0])) {
          cmd._.push(argv.shift());
        }
        return cmd;
      }

      function tokenLooksLikeCommand(s) {
        if (invalidCommandRxp.test(s)) {
          stop('Invalid command syntax:', s);
        }
        return commandRxp.test(s);
      }

      // Try to read an option for command @cmdDef from @argv
      function readOption(cmd, argv, cmdDef) {
        var token = argv.shift(),
            optName, optDef, parts;

        if (isAssignment(token)) {
          // token looks like name=value style option
          parts = splitAssignment(token);
          optDef = findOptionDefn(parts[0], cmdDef);
          if (!optDef) ; else if (optDef.type == 'flag' || optDef.assign_to) {
            stop("-" + cmdDef.name + " " + parts[0] + " option doesn't take a value");
          } else {
            argv.unshift(parts[1]);
          }
        } else {
          // try to parse as a flag option,
          // or as a space-delimited assignment option (for backwards compatibility)
          optDef = findOptionDefn(token, cmdDef);
        }

        if (!optDef) {
          // token is not a known option -- add to array of unnamed options
          cmd._.push(token);
          return;
        }

        if (optDef.alias_to) {
          optDef = findOptionDefn(optDef.alias_to, cmdDef);
        }

        optName = optDef.name;
        optName = optName.replace(/-/g, '_');

        if (optDef.assign_to) {
          cmd.options[optDef.assign_to] = optDef.name;
        } else if (optDef.type == 'flag') {
          cmd.options[optName] = true;
        } else {
          cmd.options[optName] = readOptionValue(argv, optDef);
        }
      }

      // Read an option value for @optDef from @argv
      function readOptionValue(argv, optDef) {
        if (argv.length === 0 || tokenLooksLikeCommand(argv[0])) {
          stop("Missing value for " + optDef.name + " option");
        }
        return parseOptionValue(argv.shift(), optDef); // remove token from argv
      }

      // convert strings in cmd._ array to command parameers in cmd.options object
      //
      function readDefaultOptionValue(cmd, cmdDef) {
        var optDef = findDefaultOptionDefn(cmdDef);
        var argv = cmd._;
        var value;
        if (cmdDef)
        if (!optDef) {
          // no option has been specified as the default option
          error('Received one or more unexpected parameters:', argv.join(' '));
        }
        // DEFAULT may be true (simple case of one argument) or an object
        var argDef = optDef.DEFAULT === true ? {} : optDef.DEFAULT;
        argDef.type = argDef.type || optDef.type || 'string';
        argDef.name = optDef.name; // used in parse error message

        if (argv.length > 1 && !argDef.multi_arg) {
          error((argDef.multi_error_msg || 'Command expects a single value.'),
            'Received:', argv.join(' '));
        }

        argv = argv.map(arg => parseOptionValue(arg, argDef));
        if (!argDef.multi_arg) {
          value = argv[0];
        } else if (utils.isString(argDef.join)) {
          value = argv.join(argDef.join);
        } else {
          value = argv;
        }
        cmd.options[optDef.name] = value;
      }

      function parseOptionValue(token, optDef) {
        var type = optDef.type;
        var val, err;
        if (type == 'number') {
          val = Number(token);
        } else if (type == 'integer') {
          val = Math.round(Number(token));
        } else if (type == 'colors') {
          val = parseColorList(token);
        } else if (type == 'strings') {
          val = parseStringList(token);
        } else if (type == 'bbox' || type == 'numbers') {
          val = parseNumberList(token);
        } else if (type == 'percent') {
          // val = utils.parsePercent(token);
          val = token; // string value is parsed by command function
        } else if (type == 'distance' || type == 'area') {
          val = token; // string value is parsed by command function
        } else {
          val = token; // assume string type
        }

        if (val !== val) {
          err = "Invalid numeric value";
        }

        if (err) {
          stop(err + " for " + optDef.name + " option");
        }
        return val;
      }

      // Check first element of an array of tokens; remove and return if it looks
      // like a command name, else return null;
      function readCommandName(args) {
        var match = commandRxp.exec(args[0]);
        if (match) {
          args.shift();
          return match[1];
        }
        return null;
      }

    };

    this.getHelpMessage = function(cmdName) {
      var helpCommands, singleCommand, lines;
      if (cmdName) {
        singleCommand = findCommandDefn(cmdName, getCommands());
        if (!singleCommand) {
          stop(cmdName, "is not a known command");
        }
        lines = getSingleCommandLines(singleCommand);
      } else {
        helpCommands = getCommands().filter(function(cmd) {return cmd.name && cmd.describe || cmd.title;});
        lines = getMultiCommandLines(helpCommands);
      }

      return formatLines(lines);

      function formatLines(lines) {
        var colWidth = calcColWidth(lines);
        var gutter = '  ';
        var indent = runningInBrowser() ? '' : '  ';
        var helpStr = lines.map(function(line) {
          if (Array.isArray(line)) {
            line = indent + utils.rpad(line[0], colWidth, ' ') + gutter + line[1];
          }
          return line;
        }).join('\n');
        return helpStr;
      }

      function getSingleCommandLines(cmd) {
        var lines = [];
        var options = [];
        cmd.options.forEach(function(opt) {
          options = options.concat(getOptionLines(opt));
        });

        lines.push('COMMAND', getCommandLine(cmd));
        if (options.length > 0) {
          lines.push('', 'OPTIONS');
          lines = lines.concat(options);
        }

        // examples
        if (cmd.examples) {
          lines.push('', 'EXAMPLE' + (cmd.examples.length > 1 ? 'S' : ''));
          cmd.examples.forEach(function(ex, i) {
            if (i > 0) lines.push('');
            ex.split('\n').forEach(function(line, i) {
              lines.push('  ' + line);
            });
          });
        }
        return lines;
      }

      function getOptionLines(opt, cmd) {
        var lines = [];
        var description = opt.describe;
        var label;
        if (!description) ; else if (opt.label) {
          lines.push([opt.label, description]);
        } else if (opt.DEFAULT) {
          label = opt.name + '=';
          lines.push(['<' + opt.name + '>', 'shortcut for ' + label]);
          lines.push([label, description]);
        } else {
          label = opt.name;
          if (opt.alias) label += ', ' + opt.alias;
          if (opt.type != 'flag' && !opt.assign_to) label += '=';
          lines.push([label, description]);
        }
        return lines;
      }

      function getCommandLine(cmd) {
        var name = cmd.name ? "-" + cmd.name : '';
        if (cmd.alias) name += ', -' + cmd.alias;
        return [name, cmd.describe || '(undocumented command)'];
      }

      function getMultiCommandLines(commands) {
        var lines = [];
        // usage
        if (_usage) lines.push(_usage);

        // list of commands
        commands.forEach(function(cmd) {
          if (cmd.title) {
            lines.push('', cmd.title);
          } else {
            lines.push(getCommandLine(cmd));
          }
        });

        // examples
        if (_examples.length > 0) {
          lines.push('', 'Examples');
          _examples.forEach(function(str) {
            lines.push('', str);
          });
        }

        // note
        if (_note) {
          lines.push('', _note);
        }
        return lines;
      }


      function calcColWidth(lines) {
        var w = 0;
        lines.forEach(function(line) {
          if (Array.isArray(line)) {
            w = Math.max(w, line[0].length);
          }
        });
        return w;
      }
    };

    function getCommands() {
      return _commands.map(function(cmd) {
        return cmd.done();
      });
    }

    function tokenIsCommandName(s) {
      var cmd = findCommandDefn(s, getCommands());
      return !!cmd;
    }

    function findCommandDefn(name, arr) {
      return utils.find(arr, function(cmd) {
        return cmd.name === name || cmd.alias === name || cmd.old_alias === name;
      });
    }

    function findOptionDefn(name, cmdDef) {
      return utils.find(cmdDef.options, function(o) {
        return o.name === name || o.alias === name || o.old_alias === name;
      });
    }

    function findDefaultOptionDefn(cmdDef) {
      return utils.find(cmdDef.options, function(o) {
        return !!o.DEFAULT;
      });
    }
  }

  function CommandOptions(name) {
    var _command = {
      name: name,
      options: []
    };

    this.validate = function(f) {
      _command.validate = f;
      return this;
    };

    this.describe = function(str) {
      _command.describe = str;
      return this;
    };

    this.example = function(str) {
      if (!_command.examples) {
        _command.examples = [];
      }
      _command.examples.push(str);
      return this;
    };

    this.alias = function(name) {
      _command.alias = name;
      return this;
    };

    // define an alias command name that doesn't appear in command line help
    // (to support old versions of renamed commands)
    this.oldAlias = function(name) {
      _command.old_alias = name;
      return this;
    };

    this.title = function(str) {
      _command.title = str;
      return this;
    };

    this.option = function(name, opts) {
      opts = utils.extend({}, opts); // accept just a name -- some options don't need properties
      if (!utils.isString(name) || !name) error("Missing option name");
      if (!utils.isObject(opts)) error("Invalid option definition:", opts);
      opts.name = name;
      _command.options.push(opts);
      return this;
    };

    this.options = function(o) {
      Object.keys(o).forEach(function(key) {
        this.option(key, o[key]);
      }, this);
      return this;
    };

    this.done = function() {
      return _command;
    };
  }

  function getOptionParser() {
    // definitions of options shared by more than one command
    var targetOpt = {
          describe: 'layer(s) to target (comma-sep. list)'
        },
        nameOpt = {
          describe: 'rename the edited layer(s)'
        },
        noReplaceOpt = {
          alias: '+',
          type: 'flag',
          label: '+, no-replace', // show alias as primary option
          describe: 'retain both input and output layer(s)'
        },
        nameOpt2 = { // for -calc and -info
          describe: 'name the output layer'
        },
        noReplaceOpt2 = { // for -calc and -info
          alias: '+',
          type: 'flag',
          label: '+',
          describe: 'save output to a new layer'
        },
        noSnapOpt = {
          // describe: 'don't snap points before applying command'
          type: 'flag'
        },
        encodingOpt = {
          describe: 'text encoding (applies to .dbf and delimited text files)'
        },
        snapIntervalOpt = {
          describe: 'snapping distance in source units (default is tiny)',
          type: 'distance'
        },
        minGapAreaOpt = {
          old_alias: 'min-gap-area',
          describe: 'threshold for filling gaps, e.g. 1.5km2 (default is small)',
          type: 'area'
        },
        sliverControlOpt = {
          describe: 'boost gap-fill-area of slivers (0-1, default is 1)',
          type: 'number'
        },
        calcOpt = {
          describe: 'use a JS expression to aggregate data values'
        },
        sumFieldsOpt = {
          describe: 'fields to sum when dissolving  (comma-sep. list)',
          type: 'strings'
        },
        copyFieldsOpt = {
          describe: 'fields to copy when dissolving (comma-sep. list)',
          type: 'strings'
        },
        dissolveFieldsOpt = {
          DEFAULT: true,
          type: 'strings',
          describe: '(optional) field(s) to dissolve on (comma-sep. list)'
        },
        fieldTypesOpt = {
          describe: 'type hints for csv source files, e.g. FIPS:str,ZIPCODE:str',
          type: 'strings'
        },
        stringFieldsOpt = {
          describe: 'csv field(s) to import as strings, e.g. FIPS,ZIPCODE',
          type: 'strings'
        },
        bboxOpt = {
          type: 'bbox',
          describe: 'comma-sep. bounding box: xmin,ymin,xmax,ymax'
        },
        invertOpt = {
          type: 'flag',
          describe: 'retain only features that would have been deleted'
        },
        whereOpt = {
          describe: 'use a JS expression to select a subset of features'
        },
        whereOpt2 = {
          describe: 'filter polygon boundaries using a JS expression (with A and B)'
        },
        eachOpt2 = {
          describe: 'apply a JS expression to each polygon boundary (with A and B)'
        },
        aspectRatioOpt = {
          describe: 'aspect ratio as a number or range (e.g. 2 0.8,1.6 ,2)'
        },
        offsetOpt = {
          describe: 'offset distance or pct of h/w (single value or l,b,r,t list)',
          type: 'distance'
        };

    var parser = new CommandParser();
    parser.usage('Usage:  mapshaper -<command> [options] ...');

    /*
    parser.example('Fix minor topology errors, simplify to 10%, convert to GeoJSON\n' +
        '$ mapshaper states.shp snap -simplify 10% -o format=geojson');

    parser.example('Aggregate census tracts to counties\n' +
        '$ mapshaper tracts.shp -each \'CTY_FIPS=FIPS.substr(0, 5)\' -dissolve CTY_FIPS');
    */

    parser.note('Enter mapshaper -help <command> to view options for a single command');

    parser.section('I/O commands');

    parser.default('i');

    parser.command('i')
      .describe('input one or more files')
      .validate(validateInputOpts)
      .option('files', {
        DEFAULT: {
          multi_arg: true,
          type: 'string'
        },
        type: 'strings',
        describe: 'one or more files to import, or - to use stdin'
      })
      .option('combine-files', {
        describe: 'import files to separate layers with shared topology',
        type: 'flag'
      })
      .option('merge-files', {
        // describe: 'merge features from compatible files into the same layer',
        type: 'flag'
      })
      .option('no-topology', {
        describe: 'treat each shape as topologically independent',
        type: 'flag'
      })
      .option('precision', {
        describe: 'coordinate precision in source units, e.g. 0.001',
        type: 'number'
      })
      .option('snap', {
        type: 'flag',
        describe: 'snap nearly identical points to fix minor topology errors'
      })
      .option('auto-snap', {alias_to: 'snap'})
      .option('snap-interval', snapIntervalOpt)
      .option('encoding', encodingOpt)
      /*
      .option('fields', {
        describe: 'attribute fields to import (comma-sep.) (default is all fields)',
        type: 'strings'
      }) */
      .option('id-field', {
        describe: 'import Topo/GeoJSON id property to this field'
      })
      .option('string-fields', stringFieldsOpt)
      .option('field-types', fieldTypesOpt)
      .option('name', {
        describe: 'rename the imported layer(s)'
      })
      .option('geometry-type', {
        // undocumented; GeoJSON import rejects all but one kind of geometry
        // describe: '[GeoJSON] Import one kind of geometry (point|polygon|polyline)'
      })
      .option('json-path', {
        // describe: path to an array of data values
      })
      .option('csv-skip-lines', {
        type: 'integer',
        describe: '[CSV] number of lines to skip at the beginning of the file'
      })
      .option('csv-lines', {
        type: 'integer',
        describe: '[CSV] number of data records to read'
      })
      .option('csv-field-names', {
        type: 'strings',
        describe: '[CSV] comma-sep. list of field names to assign each column'
      })
      .option('csv-dedup-fields', {
        type: 'flag',
        describe: '[CSV] rename fields with duplicate names'
      })
      .option('csv-filter', {
        describe: '[CSV] JS expression for filtering records'
      })
      .option('csv-fields', {
        type: 'strings',
        describe: '[CSV] comma-sep. list of fields to import'
      })
      // .option('csv-comment', {
      //   describe: '[CSV] comment line character(s)'
      // })
      .option('decimal-comma', {
        type: 'flag',
        describe: '[CSV] import numbers formatted like 1.000,01 or 1 000,01'
      })
      .option('json-path', {
        old_alias: 'json-subtree',
        describe: '[JSON] path to JSON input data; separator is /'
      })
      .option('single-part', {
        type: 'flag',
        // describe: '[GeoJSON] split multi-part features into single-part features'
      });

    parser.command('o')
      .describe('output edited content')
      .validate(validateOutputOpts)
      .option('_', {
        label: '<file|directory>',
        describe: '(optional) name of output file or directory, - for stdout',
        DEFAULT: {
          multi_error_msg: 'Command takes one file or directory argument.'
        }
      })
      .option('format', {
        describe: 'options: shapefile,geojson,topojson,json,dbf,csv,tsv,svg'
      })
      .option('target', targetOpt)
      .option('force', {
        describe: 'allow overwriting input files',
        type: 'flag'
      })
      .option('gzip', {
        describe: 'apply gzip compression to output files',
        type: 'flag'
      })
     .option('zip', {
        describe: 'save all output files in a single .zip file',
        type: 'flag'
      })
      .option('dry-run', {
        // describe: 'do not output any files'
        type: 'flag'
      })
      .option('ldid', {
        // describe: 'language driver id of dbf file',
        type: 'number'
      })
      .option('precision', {
        describe: 'coordinate precision in source units, e.g. 0.001',
        type: 'number'
      })
      .option('fix-geometry', {
        describe: 'remove intersections introduced by rounding or quantization',
        type: 'flag'
      })
      .option('bbox-index', {
        describe: 'export a .json file with bbox of each layer',
        type: 'flag'
      })
      .option('cut-table', {
        describe: 'detach data attributes from shapes and save as a JSON file',
        type: 'flag'
      })
      .option('drop-table', {
        describe: 'remove data attributes from output',
        type: 'flag'
      })
      .option('encoding', {
        describe: '[Shapefile/CSV] text encoding (default is utf8)'
      })
      .option('field-order', {
        describe: '[Shapefile/CSV] field-order=ascending sorts columns A-Z'
      })
      .option('id-field', {
        describe: '[Topo/GeoJSON/SVG] field to use for id property',
        type: 'strings'
      })
      .option('bbox', {
        type: 'flag',
        describe: '[Topo/GeoJSON] add bbox property'
      })
      .option('extension', {
        describe: '[Topo/GeoJSON] set file extension (default is ".json")'
      })
      .option('prettify', {
        type: 'flag',
        describe: '[Topo/GeoJSON/JSON] format output for readability'
      })
      .option('singles', {
        describe: '[TopoJSON] save each target layer as a separate file',
        type: 'flag'
      })
      .option('quantization', {
        describe: '[TopoJSON] specify quantization (auto-set by default)',
        type: 'integer'
      })
      .option('no-quantization', {
        describe: '[TopoJSON] export coordinates without quantization',
        type: 'flag'
      })
      .option('metadata', {
        // describe: '[TopoJSON] Add a metadata object containing CRS information',
        type: 'flag'
      })
      .option('no-point-quantization', {
        // describe: '[TopoJSON] export point coordinates without quantization',
        type: 'flag'
      })
      .option('presimplify', {
        describe: '[TopoJSON] add per-vertex data for dynamic simplification',
        type: 'flag'
      })
      .option('topojson-precision', {
        // describe: 'pct of avg segment length for rounding (0.02 is default)',
        type: 'number'
      })
      // .option('winding', {
      //   describe: '[GeoJSON] set polygon winding order (use CW with d3-geo)'
      // })
      .option('gj2008', {
        describe: '[GeoJSON] use original GeoJSON spec (not RFC 7946)',
        type: 'flag'
      })
      .option('rfc7946', {
        // dummy option so old commands do not break
        type: 'flag'
      })
      .option('combine-layers', {
        describe: '[GeoJSON] output layers as a single file',
        type: 'flag'
      })
      .option('geojson-type', {
        describe: '[GeoJSON] FeatureCollection, GeometryCollection or Feature'
      })
      .option('no-null-props', {
        describe: '[GeoJSON] use "properties":{} when a Feature has no data',
        type: 'flag'
      })
      .option('hoist', {
        describe: '[GeoJSON] move properties to the root level of each Feature',
        type: 'strings'
      })
      .option('ndjson', {
        describe: '[GeoJSON/JSON] output newline-delimited features or records',
        type: 'flag'
      })
      .option('width', {
        describe: '[SVG/TopoJSON] pixel width of output (SVG default is 800)',
        type: 'number'
      })
      .option('height', {
        describe: '[SVG/TopoJSON] pixel height of output (optional)',
        type: 'number'
      })
      .option('max-height', {
        describe: '[SVG/TopoJSON] max pixel height of output (optional)',
        type: 'number'
      })
      .option('margin', {
        describe: '[SVG/TopoJSON] space betw. data and viewport (default is 1)'
      })
      .option('pixels', {
        describe: '[SVG/TopoJSON] output area in pix. (alternative to width=)',
        type: 'number'
      })
      .option('fit-bbox', {
        type: 'bbox',
        describe: '[TopoJSON] scale and shift coordinates to fit a bbox'
      })
      .option('svg-scale', {
        describe: '[SVG] source units per pixel (alternative to width= option)',
        type: 'number'
      })
      .option('svg-bbox', {
        describe: '[SVG] bounding box of SVG map in projected map units',
        type: 'bbox'
      })
      .option('fit-extent', {
        describe: '[SVG] layer to use for the map extent'
      })
      .option('point-symbol', {
        describe: '[SVG] circle or square (default is circle)'
      })
      .option('svg-data', {
        type: 'strings',
        describe: '[SVG] fields to export as data-* attributes'
      })
      .option('id-prefix', {
        describe: '[SVG] prefix for namespacing layer and feature ids'
      })
      .option('scalebar', {
        type: 'flag',
        // describe: '[SVG] add a scalebar showing scale at the center of the map'
      })
      .option('delimiter', {
        describe: '[CSV] field delimiter'
      })
      .option('decimal-comma', {
        type: 'flag',
        describe: '[CSV] export numbers with decimal commas not points'
      })
      .option('final', {
        type: 'flag' // for testing
      })
      .option('metadata', {
        // describe: '[TopoJSON] add a metadata object',
        type: 'flag'
      });

    parser.section('Editing commands');

    parser.command('affine')
      .describe('transform coordinates by shifting, scaling and rotating')
      .option('shift', {
        type: 'strings',
        describe: 'x,y offsets in source units (e.g. 5000,-5000)'
      })
      .option('scale', {
        type: 'number',
        describe: 'scale (default is 1)'
      })
      .option('rotate', {
        type: 'number',
        describe: 'angle of rotation in degrees (default is 0)'
      })
      .option('anchor', {
        type: 'numbers',
        describe: 'center of rotation/scaling (default is center of selected shapes)'
      })
      .option('fit-bbox', {
        type: 'bbox',
        describe: 'scale and shift coordinates to fit a bbox'
      })
      .option('where', whereOpt)
      .option('target', targetOpt);

    parser.command('buffer')
      // .describe('')
      .option('radius', {
        describe: 'radius of buffer, as an expression or a constant',
        DEFAULT: true
      })
      .option('tolerance', {
        // describe: 'acceptable deviation for approximating curves'
      })
      .option('vertices', {
        // describe: 'number of vertices to use when buffering points',
        type: 'integer'
      })
      .option('backtrack', {
        type: 'integer'
      })
      .option('type', {
        // left, right, outer, inner (default is full buffer)
      })
      .option('planar', {
        type: 'flag'
      })
      .option('v2', { // use v2 method
        type: 'flag'
      })
      .option('debug-division', {
        type: 'flag'
      })
      .option('debug-mosaic', {
        type: 'flag'
      })
      .option('no-cleanup', {
        type: 'flag'
      })
      .option('units', {
        describe: 'distance units (meters|miles|km|feet) (default is meters)'
      })
      .option('name', nameOpt)
      .option('target', targetOpt)
      .option('no-replace', noReplaceOpt);

    parser.command('classify')
      // .describe('apply sequential or categorical classification')
      .describe('assign colors or values using one of several methods')
      .option('field', {
        describe: 'name of field to classify',
        DEFAULT: true
      })
      .option('save-as', {
          describe: 'name of output field (default is fill|stroke|class)'
      })
      .option('colors', {
        describe: 'list of CSS colors or color scheme name (see -colors)',
        type: 'colors'
      })
      .option('values', {
        describe: 'values to assign to classes (alternative to colors=)',
        type: 'strings'
      })
      .option('color-scheme', {
        // deprecated in favor of colors=
        // describe: 'name of a predefined color scheme (see -colors command)'
      })
      .option('non-adjacent', {
        describe: 'assign non-adjacent colors to a polygon layer',
        assign_to: 'method'
      })
      .option('stops', {
        describe: 'a pair of values (0-100) for limiting a color ramp',
        type: 'numbers'
      })
      .option('null-value', {
        describe: 'value (or color) to use for invalid or missing data'
      })
      .option('method', {
        describe: 'quantile, nice, equal-interval, categorical, etc.'
      })
      .option('quantile', {
        //describe: 'shortcut for method=quantile (the default)',
        assign_to: 'method'
      })
      .option('equal-interval', {
        //describe: 'short for method=equal-interval',
        assign_to: 'method'
      })
      .option('hybrid', {
        // describe: 'short for method=hybrid (equal-interval inner breaks + quantile outliers)',
        assign_to: 'method'
      })
      .option('nice', {
        //describe: 'short for method=nice (rounded, equal inner breaks)',
        assign_to: 'method'
      })
      .option('breaks', {
        describe: 'user-defined sequential class breaks',
        type: 'numbers'
      })
      .option('outer-breaks', {
        describe: 'min,max breakpoints, to limit the effect of outliers',
        old_alias: 'range',
        type: 'numbers'
      })
      .option('classes', {
        describe: 'number of classes (can be inferred from other options)',
        type: 'integer'
      })
      .option('invert', {
        describe: 'reverse the order of colors/values',
        type: 'flag'
      })
      .option('continuous', {
        describe: 'output interpolated values, for unclassed colors',
        type: 'flag'
      })
      .option('index-field', {
        describe: 'apply pre-calculated classes (0 ... n-1, -1)'
      })
      .option('precision', {
        describe: 'round data values before classification (e.g. 0.1)',
        type: 'number'
      })
      .option('categories', {
        describe: 'list of data values for categorical color scheme',
        type: 'strings'
      })
      .option('other', {
        describe: 'default value for categorical scheme'
      })
      .option('key', {type: 'flag'})
      .option('key-style', {
        describe: 'one of: simple, gradient, dataviz'
      })
      .option('key-name', {
        describe: 'name of output SVG file'
      })
      .option('key-width', {
        describe: 'width of key in pixels',
        type: 'number'
      })
      .option('key-font-size', {
        describe: 'label size in pixels',
        type: 'number'
      })
      .option('key-tile-height', {
        describe: 'height of color tiles in pixels',
        type: 'number'
      })
      .option('key-tic-length', {
        describe: 'length of tic mark in pixels'
      })
      .option('key-label-suffix', {
        describe: 'string to append to each label'
      })
      .option('key-last-suffix', {
        describe: 'string to append to last label'
      })
      .option('target', targetOpt);

    parser.command('clean')
      .describe('fixes geometry issues, such as polygon overlaps and gaps')
      .option('gap-fill-area', minGapAreaOpt)
      .option('sliver-control', sliverControlOpt)
      .option('snap-interval', snapIntervalOpt)
      .option('no-snap', noSnapOpt)
      .option('allow-overlaps', {
        describe: 'allow polygons to overlap (disables gap fill)',
        type: 'flag'
      })
      .option('overlap-rule', {
        describe: 'how to resolve overlaps: min-id|max-id|min-area|[max-area]'
      })
      .option('allow-empty', {
        describe: 'keep null geometries (removed by default)',
        type: 'flag'
      })
      .option('rewind', {
        describe: 'fix errors in the CW/CCW winding order of polygon rings',
        type: 'flag'
      })
      // TODO: consider making this the standard way of removing null geometry
      // (currently there's -filter remove-empty)
      // .option('empty', {
      //   describe: 'remove features with null geometry',
      //   type: 'flag'
      // })
      .option('arcs', { // old name for arcs-only
        alias_to: 'only-arcs'
      })
      .option('only-arcs', {
        describe: 'delete unused arcs but don\'t remove gaps and overlaps',
        type: 'flag'
      })
      .option('no-arc-dissolve', {
        type: 'flag' // no description
      })
      .option('target', targetOpt);

    parser.command('clip')
      .describe('use a polygon layer to clip another layer')
      .example('$ mapshaper states.shp -clip land_area.shp -o clipped.shp')
      .option('source', {
        DEFAULT: true,
        describe: 'file or layer containing clip polygons'
      })
      .option('remove-slivers', {
        describe: 'remove sliver polygons created by clipping',
        type: 'flag'
      })
      .option('bbox', bboxOpt)
      .option('bbox2', {
          type: 'bbox',
          describe: 'experimental fast bbox clipping'
        })
      .option('name', nameOpt)
      .option('no-snap', noSnapOpt)
      .option('target', targetOpt)
      .option('no-replace', noReplaceOpt);

    parser.command('colorizer')
      .describe('define a function to convert data values to color classes')
      .option('colors', {
        describe: 'comma-separated list of CSS colors',
        type: 'colors'
      })
      .option('breaks', {
        describe: 'ascending-order list of breaks for sequential color scheme',
        type: 'numbers'
      })
      .option('categories', {
        describe: 'comma-sep. list of keys for categorical color scheme',
        type: 'strings'
      })
      .option('random', {
        describe: 'randomly assign colors',
        type: 'flag'
      })
      .option('other', {
        describe: 'default color for categorical scheme (default is nodata color)'
      })
      .option('nodata', {
        describe: 'color to use for invalid or missing data (default is white)'
      })
      .option('name', {
        describe: 'function name to use in -each and -svg-style commands'
      })
      .option('precision', {
        describe: 'rounding precision to apply before classification (e.g. 0.1)',
        type: 'number'
      })
      .example('Define a sequential color scheme and use it to create a new field\n' +
          '$ mapshaper data.json -colorizer name=getColor nodata=#eee breaks=20,40 \\\n' +
          '  colors=#e0f3db,#a8ddb5,#43a2ca -each \'fill = getColor(RATING)\' -o output.json');

    parser.command('dashlines')
      .describe('split lines into sections, with or without a gap')
      .oldAlias('split-lines')
      .option('dash-length', {
        type: 'distance',
        describe: 'length of split-apart lines (e.g. 200km)'
      })
      .option('gap-length', {
        type: 'distance',
        describe: 'length of gaps between dashes (default is 0)'
      })
      .option('scaled', {
        type: 'flag',
        describe: 'scale dashes and gaps to prevent partial dashes'
      })
      .option('planar', {
        type: 'flag',
        describe: 'use planar geometry'
      })
      .option('where', whereOpt)
      .option('target', targetOpt);

    parser.command('define')
      // .describe('define expression variables')
      .option('expression', {
        DEFAULT: true,
        describe: 'one or more assignment expressions (comma-sep.)'
      });

    parser.command('dissolve')
      .describe('merge features within a layer')
      .example('Dissolve all polygons in a feature layer into a single polygon\n' +
        '$ mapshaper states.shp -dissolve -o country.shp')
      .example('Generate state-level polygons by dissolving a layer of counties\n' +
        '(STATE_FIPS, POPULATION and STATE_NAME are attribute field names)\n' +
        '$ mapshaper counties.shp -dissolve STATE_FIPS copy-fields=STATE_NAME sum-fields=POPULATION -o states.shp')
      .option('field', {}) // old arg handled by dissolve function
      .option('fields', dissolveFieldsOpt)
      .option('calc', calcOpt)
      .option('sum-fields', sumFieldsOpt)
      .option('copy-fields', copyFieldsOpt)
      .option('multipart', {
        type: 'flag',
        describe: 'make multipart features instead of dissolving'
      })
      .option('where', whereOpt)
      .option('group-points', {
        type: 'flag',
        describe: '[points] group points instead of converting to centroids'
      })
      .option('weight', {
        describe: '[points] field or expression to use for weighting centroid'
      })
      .option('planar', {
        type: 'flag',
        describe: '[points] use 2D math to find centroids of latlong points'
      })
      .option('name', nameOpt)
      .option('target', targetOpt)
      .option('no-replace', noReplaceOpt);


    parser.command('dissolve2')
      .describe('merge adjacent polygons (repairs overlaps and gaps)')
      .option('field', {}) // old arg handled by dissolve function
      .option('fields', dissolveFieldsOpt)
      // UPDATE: Use -mosaic command for debugging
      //.option('mosaic', {type: 'flag'}) // debugging option
      //.option('arcs', {type: 'flag'}) // debugging option
      //.option('tiles', {type: 'flag'}) // debugging option
      .option('calc', calcOpt)
      .option('sum-fields', sumFieldsOpt)
      .option('copy-fields', copyFieldsOpt)
      .option('gap-fill-area', {
        describe: 'threshold for filling gaps, e.g. 1.5km2',
        type: 'area'
      })
      .option('sliver-control', sliverControlOpt)
      .option('allow-overlaps', {
        describe: 'allow dissolved polygons to overlap (disables gap fill)',
        type: 'flag'
      })
      .option('name', nameOpt)
      .option('no-snap', noSnapOpt)
      .option('target', targetOpt)
      .option('no-replace', noReplaceOpt);

    parser.command('divide')
      .describe('divide lines by polygons, copy polygon data to lines')
      .option('fields', {
        describe: 'fields to copy (comma-sep.) (default is all but key field)',
        type: 'strings'
      })
      .option('calc', {
        describe: 'use a JS expression to assign values (for many-to-one joins)'
      })
      .option('force', {
        describe: 'replace values from same-named fields',
        type: 'flag'
      })
      .option('source', {
        DEFAULT: true,
        describe: 'file or layer containing polygons'
      })
      .option('target', targetOpt);
      // .option('no-replace', noReplaceOpt);

    parser.command('dots')
      .describe('fill polygons with dots of one or more colors')
      .option('fields', {
        DEFAULT: true,
        describe: 'one or more fields containing numbers of dots',
        type: 'strings'
      })
      .option('colors', {
        describe: 'one or more colors',
        type: 'strings'
      })
      .option('values', {
        describe: 'values to assign to dot classes (alternative to colors=)',
        type: 'strings'
      })
      .option('save-as', {
        describe: 'name of color/value output field (default is fill)'
      })
      .option('progressive', {
        // describe: 'fill in points progressively',
        type: 'flag'
      })
      .option('r', {
        describe: 'radius of each dot in pixels',
        type: 'number'
      })
      .option('evenness', {
        describe: '(0-1) dot spacing, from random to even (default is 1)',
        type: 'number'
      })
      .option('per-dot', {
        describe: 'number for scaling data values (e.g. 10 per dot)',
        type: 'number'
      })
      .option('copy-fields', {
        describe: 'list of fields to copy from polygons to dots',
        type: 'strings'
      })
      .option('multipart', {
        describe: 'combine groups of same-color dots into multi-part features',
        type: 'flag'
      })
      .option('target', targetOpt)
      .option('name', nameOpt)
      .option('no-replace', noReplaceOpt);

    parser.command('drop')
      .describe('delete layer(s) or elements within the target layer(s)')
      .option('geometry', {
        describe: 'delete all geometry from the target layer(s)',
        type: 'flag'
      })
      .option('holes', {
        describe: 'delete holes from polygons',
        type: 'flag'
      })
      .option('fields', {
        type: 'strings',
        describe: 'delete a list of attribute data fields, e.g. \'id,name\' \'*\''
      })
      .option('target', targetOpt);

    parser.command('each')
      .describe('create/update/delete data fields using a JS expression')
      .example('Add two calculated data fields to a layer of U.S. counties\n' +
          '$ mapshaper counties.shp -each \'STATE_FIPS=CNTY_FIPS.substr(0, 2), AREA=$.area\'')
      .option('expression', {
        DEFAULT: true,
        describe: 'JS expression to apply to each target feature'
      })
      .option('ids', { // undocumented, used by GUI
        type: 'numbers'
      })
      .option('where', whereOpt)
      .option('target', targetOpt);

    parser.command('erase')
      .describe('use a polygon layer to erase another layer')
      .example('$ mapshaper land_areas.shp -erase water_bodies.shp -o erased.shp')
      .option('source', {
        DEFAULT: true,
        describe: 'file or layer containing erase polygons'
      })
      .option('remove-slivers', {
        describe: 'remove sliver polygons created by erasing',
        type: 'flag'
      })
      .option('bbox', bboxOpt)
      .option('name', nameOpt)
      .option('no-snap', noSnapOpt)
      .option('target', targetOpt)
      .option('no-replace', noReplaceOpt);

    parser.command('explode')
      .describe('divide multi-part features into single-part features')
      .option('naive', {type: 'flag'}) // testing
      .option('target', targetOpt);

    parser.command('filter')
      .describe('delete features using a JS expression')
      .option('expression', {
        DEFAULT: true,
        describe: 'delete features that evaluate to false'
      })
      .option('bbox', {
        describe: 'delete features outside bbox (xmin,ymin,xmax,ymax)',
        type: 'bbox'
      })
      .option('invert', invertOpt)
      .option('remove-empty', {
        type: 'flag',
        describe: 'delete features with null geometry'
      })
      .option('keep-shapes', {
        type: 'flag'
      })
      .option('ids', {
        // describe: 'filter on a list of feature ids',
        type: 'numbers'
      })
      .option('cleanup', {type: 'flag'}) // TODO: document
      .option('name', nameOpt)
      .option('target', targetOpt)
      .option('no-replace', noReplaceOpt);

    parser.command('filter-fields')
      .describe('retain a subset of data fields')
      .option('fields', {
        DEFAULT: true,
        type: 'strings',
        describe: 'fields to retain (comma-sep.), e.g. \'fips,name\''
      })
      .option('invert', {
        type: 'flag',
        describe: 'retain only fields that would have been deleted'
      })
      .option('target', targetOpt);

    parser.command('filter-geom')
      .describe('')
      .option('bbox', {
        type: 'bbox',
        describe: 'remove non-intersecting geometry (xmin,ymin,xmax,ymax)'
      })
      .option('target', targetOpt);

    parser.command('filter-islands2')
      // .describe('remove small detached polygon rings (islands)')
      .option('min-area', {
        type: 'area',
        describe: 'remove small-area islands (e.g. 10km2)'
      })
      .option('min-vertices', {
        type: 'integer',
        describe: 'remove low-vertex-count islands'
      })
      .option('keep-shapes', {
        type: 'flag',
        describe: 'only filter smaller parts of multipart polygons',
      })
      .option('remove-empty', {
        type: 'flag',
        describe: 'delete features with null geometry'
      })
      .option('target', targetOpt);

    parser.command('filter-islands')
      .describe('remove small detached polygon rings (islands)')
      .option('min-area', {
        type: 'area',
        describe: 'remove small-area islands (e.g. 10km2)'
      })
      .option('min-vertices', {
        type: 'integer',
        describe: 'remove low-vertex-count islands'
      })
      .option('remove-empty', {
        type: 'flag',
        describe: 'delete features with null geometry'
      })
      .option('target', targetOpt);

    parser.command('filter-slivers')
      .describe('remove small polygon rings')
      .option('min-area', {
        type: 'area',
        describe: 'area threshold (e.g. 2sqkm)'
      })
      .option('sliver-control', {
        describe: 'boost area threshold of slivers (0-1, default is 1)',
        type: 'number'
      })
      .option('weighted', {
        // describe: 'multiply min-area by Polsby-Popper compactness (0-1)'
        type: 'flag',
      })
      .option('remove-empty', {
        type: 'flag',
        describe: 'delete features with null geometry'
      })
      .option('target', targetOpt);

    parser.command('graticule')
      .describe('create a graticule layer')
      .option('interval', {
        describe: 'size of grid cells in degrees (default is 10)',
        type: 'number'
      })
      .option('polygon', {
        describe: 'create a polygon to match the outline of the graticule',
        type: 'flag'
      })
      .option('name', nameOpt);


    // for testing grid update
    parser.command('grid2')
      .option('type', {
        describe: 'square, hex or hex2 (default is square)'
      })
      .option('interval', {
        describe: 'side length (e.g. 500m, 12km)',
        type: 'distance'
      })
      .option('name', nameOpt)
      .option('target', targetOpt)
      .option('no-replace', noReplaceOpt);

    parser.command('grid')
      .describe('create a grid of square or hexagonal polygons')
      .option('type', {
        describe: 'square, hex or hex2 (default is square)'
      })
      .option('interval', {
        describe: 'side length (e.g. 500m, 12km)',
        type: 'distance'
      })
      .option('cols', {
        type: 'integer'
      })
      .option('rows', {
        type: 'integer'
      })
      // .option('bbox', {
      //   type: 'bbox',
      //   describe: 'xmin,ymin,xmax,ymax (default is bbox of data)'
      // })
      .option('name', nameOpt)
      .option('target', targetOpt)
      .option('no-replace', noReplaceOpt);

    parser.command('include')
      .describe('import JS data and functions for use in JS expressions')
      .option('file', {
        DEFAULT: true,
        describe: 'file containing a JS object with key:value pairs to import'
      });

    parser.command('inlay')
      .describe('inscribe a polygon layer inside another polygon layer')
      .option('source', {
        DEFAULT: true,
        describe: 'file or layer containing polygons to inlay'
      })
      .option('target', targetOpt);

    parser.command('innerlines')
      .describe('convert polygons to polylines along shared edges')
      .option('where', whereOpt2)
      // .option('each', eachOpt2)
      .option('name', nameOpt)
      .option('target', targetOpt)
      .option('no-replace', noReplaceOpt);

    parser.command('join')
      .describe('join data records from a file or layer to a layer')
      .example('Join a csv table to a Shapefile (don\'t auto-convert FIPS column to numbers)\n' +
        '$ mapshaper states.shp -join data.csv keys=STATE_FIPS,FIPS string-fields=FIPS -o joined.shp')
      .validate(function(cmd) {
        if (!cmd.options.source) {
          error('Command requires the name of a layer or file to join');
        }
      })
      .option('source', {
        DEFAULT: true,
        describe: 'file or layer containing data records'
      })
      .option('keys', {
        describe: 'join by matching target,source key fields, e.g. keys=FID,id',
        type: 'strings'
      })
      .option('calc', {
        describe: 'use a JS expression to assign values (for many-to-one joins)'
      })
      .option('where', {
        describe: 'use a JS expression to filter source records'
      })
      .option('fields', {
        describe: 'fields to copy (comma-sep.) (default is all but key field)',
        type: 'strings'
      })
      .option('prefix', {
        describe: 'prefix for renaming fields joined from the source table'
      })
      .option('interpolate', {
        describe: '(polygon-polygon join) list of area-interpolated fields',
        type: 'strings'
      })
      .option('point-method', {
        describe: '(polygon-polygon join) join polygons via inner points',
        type: 'flag'
      })
      .option('largest-overlap', {
        describe: '(polygon-polygon join) use max overlap to join one polygon',
        type: 'flag'
      })
      // .option('nearest-point', {
      //   describe: '(point-point join)',
      //   type: 'flag'
      // })
      .option('max-distance', {
        describe: '(point-point join) join source points within this radius',
        type: 'distance'
      })
      .option('planar', {
        // describe: 'use planar geometry when interpolating by area' // useful for testing
        type: 'flag'
      })
      .option('duplication', {
        describe: 'duplicate target features on many-to-one joins',
        type: 'flag'
      })
      .option('string-fields', stringFieldsOpt)
      .option('field-types', fieldTypesOpt)
      .option('sum-fields', {
        describe: 'fields to sum in a many-to-one join (or use calc= for this)',
        type: 'strings'
      })
      .option('force', {
        describe: 'replace values from same-named fields',
        type: 'flag'
      })
      .option('unjoined', {
        describe: 'copy unjoined records from source table to "unjoined" layer',
        type: 'flag'
      })
      .option('unmatched', {
        describe: 'copy unmatched records in target table to "unmatched" layer',
        type: 'flag'
      })
      .option('encoding', encodingOpt)
      .option('target', targetOpt);

    parser.command('lines')
      .describe('convert a polygon or point layer to a polyline layer')
      .option('fields', {
        DEFAULT: true,
        describe: 'field(s) to create a hierarchy of boundary lines',
        type: 'strings'
      })
      .option('where', whereOpt2)
      .option('each', eachOpt2)
      .option('segments', {
        describe: 'convert paths to segments, for debugging',
        type: 'flag'
      })
      .option('callouts', {
        // describe: 'convert points to lines for editing in the GUI',
        type: 'flag'
      })
      .option('arcs', {
        describe: 'convert paths to arcs, for debugging',
        type: 'flag'
      })
      .option('groupby', {
        describe: 'field for grouping point input into multiple lines'
      })
      .option('name', nameOpt)
      .option('target', targetOpt)
      .option('no-replace', noReplaceOpt);

    parser.command('merge-layers')
      .describe('merge multiple layers into as few layers as possible')
      .option('force', {
        type: 'flag',
        describe: 'merge layers with inconsistent data fields'
      })
      .option('flatten', {
        describe: 'remove polygon overlaps; higher-id polygons take priority',
        type: 'flag'
      })
      .option('name', nameOpt)
      .option('target', targetOpt);

    parser.command('mosaic')
      .describe('convert a polygon layer with overlaps into a flat mosaic')
      .option('calc', calcOpt)
      .option('name', nameOpt)
      .option('target', targetOpt)
      .option('no-replace', noReplaceOpt);

    parser.command('point-grid')
      .describe('create a rectangular grid of points')
      .validate(validateGridOpts)
      .option('_', {
        label: '<cols,rows>',
        describe: 'size of the grid, e.g. -point-grid 100,100',
        DEFAULT: true
      })
      .option('interval', {
        describe: 'distance between adjacent points, in source units',
        type: 'distance'
      })
      .option('cols', {
        type: 'integer'
      })
      .option('rows', {
        type: 'integer'
      })
      .option('bbox', {
        type: 'bbox',
        describe: 'xmin,ymin,xmax,ymax (default is bbox of data)'
      })
      .option('name', nameOpt)
      .option('target', targetOpt)
      .option('no-replace', noReplaceOpt);

    parser.command('points')
      .describe('create a point layer from a different layer type')
      .option('x', {
        describe: 'field containing x coordinate'
      })
      .option('y', {
        describe: 'field containing y coordinate'
      })
      .option('inner', {
        describe: 'create an interior point for each polygon\'s largest ring',
        type: 'flag'
      })
      .option('centroid', {
        describe: 'create a centroid point for each polygon\'s largest ring',
        type: 'flag'
      })
      .option('vertices', {
        describe: 'capture unique vertices of polygons and polylines',
        type: 'flag'
      })
      .option('vertices2', {
        describe: 'like vertices, but without removal of duplicate coordinates',
        type: 'flag'
      })
      .option('endpoints', {
        describe: 'capture unique endpoints of polygons and polylines',
        type: 'flag'
      })
      .option('midpoints', {
        describe: 'find the (planar) midpoint of each polyline',
        type: 'flag'
      })
      // WORK IN PROGRESS todo: create a point layer containing segment intersections
      .option('intersections', {
       // describe: 'capture line segment intersections of polygons and polylines',
       type: 'flag'
      })
      .option('interpolated', {
        describe: 'interpolate points along polylines; requires interval=',
        type: 'flag'
      })
      .option('interval', {
        describe: 'distance between interpolated points (meters or projected units)',
        type: 'distance'
      })
      .option('name', nameOpt)
      .option('target', targetOpt)
      .option('no-replace', noReplaceOpt);

    parser.command('polygons')
      .describe('convert polylines to polygons')
      .option('gap-tolerance', {
        describe: 'specify gap tolerance in source units',
        type: 'distance'
      })
      .option('from-rings', {
        describe: 'do simple conversion from a layer of closed paths',
        type: 'flag'
      })
      .option('target', targetOpt);

    parser.command('proj')
      .describe('project your data (using Proj.4)')
      .option('crs', {
        DEFAULT: {
          multi_arg: true,
          join: ' '
        },
        describe: 'set destination CRS using a Proj.4 definition or alias'
      })
      .option('projection', {
        alias_to: 'crs'
      })
      .option('match', {
        describe: 'set destination CRS using a .prj file or layer id'
      })
      .option('source', {
        // describe: '(deprecated) alias for match',
        alias_to: 'match'
      })
      .option('from', {
        alias_to: 'init',
        describe: '(deprecated) alias for init='
      })
      .option('init', {
        describe: 'set source CRS (if unset) using a string, .prj or layer id'
      })
      .option('densify', {
        type: 'flag',
        describe: 'add points along straight segments to approximate curves'
      })
      .option('clip-angle', {
        describe: 'use a custom clipping radius (for azimuthal projections)',
        type: 'number'
      })
      .option('clip-bbox', {
        describe: 'clip to a lat-long bounding box before projecting',
        type: 'bbox'
      })
      .option('target', targetOpt)
      .validate(validateProjOpts);

    parser.command('rectangle')
      .describe('create a rectangle from a bbox or target layer')
      .option('bbox', {
        describe: 'rectangle coordinates (xmin,ymin,xmax,ymax)',
        type: 'bbox'
      })
      .option('offset', offsetOpt)
      .option('width', {
        describe: 'set width of map in pixels, use rectangle as frame'
        // type: 'number' // use string, to allow units (e.g. in, px, pt)
      })
      .option('aspect-ratio', aspectRatioOpt)
      .option('source', {
        describe: 'name of layer to enclose'
      })
      .option('name', nameOpt)
      .option('target', targetOpt)
      .option('no-replace', noReplaceOpt);

    parser.command('rectangles')
      .describe('create a rectangle for each feature in a layer')
      .option('offset', offsetOpt)
      .option('bbox', {
        describe: 'Use an expression to generate a rectangle for each feature'
      })
      .option('aspect-ratio', aspectRatioOpt)
      .option('name', nameOpt)
      .option('target', targetOpt)
      .option('no-replace', noReplaceOpt);

    parser.command('rename-fields')
      .describe('rename data fields')
      .option('fields', {
        DEFAULT: true,
        type: 'strings',
        describe: 'list of replacements (comma-sep.), e.g. \'fips=STATE_FIPS,st=state\''
      })
      .option('target', targetOpt);

    parser.command('rename-layers')
      .describe('assign new names to layers')
      .option('names', {
        DEFAULT: true,
        type: 'strings',
        describe: 'list of replacements (comma-sep.)'
      })
      .option('target', targetOpt);

    parser.command('simplify')
      .validate(validateSimplifyOpts)
      .example('Retain 10% of removable vertices\n$ mapshaper input.shp -simplify 10%')
      .describe('simplify the geometry of polygon and polyline features')
      .option('percentage', {
        DEFAULT: true,
        alias: 'p',
        type: 'percent',
        describe: 'percentage of removable points to retain, e.g. 10%'
      })
      .option('dp', {
        alias: 'rdp',
        describe: 'use Ramer-Douglas-Peucker simplification',
        assign_to: 'method'
      })
      .option('visvalingam', {
        describe: 'use Visvalingam simplification with "effective area" metric',
        assign_to: 'method'
      })
      .option('weighted', {
        describe: 'use weighted Visvalingam simplification (default)',
        assign_to: 'method'
      })
      .option('method', {
        // hidden option
      })
      .option('weighting', {
        type: 'number',
        describe: 'weighted Visvalingam coefficient (default is 0.7)'
      })
      .option('resolution', {
        describe: 'output resolution as a grid (e.g. 1000x500)'
      })
      .option('interval', {
        // alias: 'i',
        describe: 'output resolution as a distance (e.g. 100)',
        type: 'distance'
      })
      /*
      .option('value', {
        // for testing
        // describe: 'raw value of simplification threshold',
        type: 'number'
      })
      */
      .option('variable', {
        // describe: 'expect an expression with interval=, percentage= or resolution=',
        describe: 'JS expr. assigning to one of: interval= percentage= resolution=',
        type: 'flag'
      })
      .option('planar', {
        describe: 'simplify decimal degree coords in 2D space (default is 3D)',
        type: 'flag'
      })
      .option('cartesian', {
        // describe: '(deprecated) alias for planar',
        alias_to: 'planar'
      })
      .option('keep-shapes', {
        describe: 'prevent small polygon features from disappearing',
        type: 'flag'
      })
      .option('lock-box', {
        // describe: 'don't remove vertices along bbox edges'
        type: 'flag'
      })
      .option('no-repair', {
        describe: 'don\'t remove intersections introduced by simplification',
        type: 'flag'
      })
      .option('stats', {
        describe: 'display simplification statistics',
        type: 'flag'
      })
      .option('target', targetOpt);

    parser.command('slice')
      // .describe('slice a layer using polygons in another layer')
      .option('source', {
        DEFAULT: true,
        describe: 'file or layer containing clip polygons'
      })
      /*
      .option('remove-slivers', {
        describe: 'remove sliver polygons created by clipping',
        type: 'flag'
      }) */
      .option('id-field', {
        describe: 'slice id field (from source layer)'
      })
      .option('name', nameOpt)
      .option('no-snap', noSnapOpt)
      .option('target', targetOpt)
      .option('no-replace', noReplaceOpt);

    parser.command('snap')
      .describe('snap together nearby vertices')
      .option('interval', {
        describe: 'snap together vertices within a tolerance (default is small)',
        DEFAULT: true,
        type: 'distance'
      })
      .option('endpoints', {
        describe: 'only snap together the endpoints of lines',
        type: 'flag'
      })
      .option('precision', {
        describe: 'round all coordinates to a given decimal precision (e.g. 0.000001)',
        type: 'number'
      })
      .option('fix-geometry', {
        describe: 'remove intersections introduced by rounding and snapping',
        type: 'flag'
      })
      .option('target', targetOpt);

    parser.command('sort')
      .describe('sort features using a JS expression')
      .option('expression', {
        DEFAULT: true,
        describe: 'JS expression to generate a sort key for each feature'
      })
      .option('ascending', {
        describe: 'sort in ascending order (default)',
        type: 'flag'
      })
      .option('descending', {
        describe: 'sort in descending order',
        type: 'flag'
      })
      .option('target', targetOpt);

    parser.command('split')
      .describe('split a layer into single-feature or multi-feature layers')
      .option('field', {
        // former name
        alias_to: 'expression'
      })
      .option('expression', {
        DEFAULT: true,
        describe: 'expression or field for grouping features and naming split layers'
      })
      .option('ids', {
        // used by gui history to split on selected features
        // describe: 'split on a list of feature ids',
        type: 'numbers'
      })
      .option('apart', {
        describe: 'save output layers to independent datasets',
        type: 'flag'
      })
      .option('target', targetOpt)
      .option('no-replace', noReplaceOpt);

    parser.command('split-on-grid')
      .describe('split features into separate layers using a grid')
      .validate(validateGridOpts)
      .option('_', {
        DEFAULT: true,
        label: '<cols,rows>',
        describe: 'size of the grid, e.g. -split-on-grid 12,10'
      })
      .option('cols', {
        type: 'integer'
      })
      .option('rows', {
        type: 'integer'
      })
      .option('id-field', {
        describe: 'assign each feature a cell id instead of splitting layer'
      })
      // .option('no-replace', noReplaceOpt)
      .option('target', targetOpt);

    parser.command('style')
      .oldAlias('svg-style')
      .describe('set SVG style properties using JS or literal values')
      .option('where', whereOpt)
      .option('class', {
        describe: 'name of CSS class or classes (space-separated)'
      })
      .option('css', {
        describe: 'inline css style'
      })
      .option('fill', {
        describe: 'fill color; examples: #eee pink rgba(0, 0, 0, 0.2)'
      })
      .option('fill-pattern', {
        describe: 'pattern fill, ex: "hatches 2px grey 2px blue"'
      })
      .option('fill-effect', {
        describe: 'use "sphere" on a circle for a 3d globe effect'
      })
      .option('fill-opacity', {
        describe: 'fill opacity'
      })
      .option('fill-hatch', {
        alias_to: 'fill-pattern'
      })
      .option('stroke', {
        describe: 'stroke color'
      })
      .option('stroke-width', {
        describe: 'stroke width'
      })
      .option('stroke-dasharray', {
        describe: 'stroke dashes. Examples: "4" "2 4"'
      })
      .option('stroke-opacity', {
        describe: 'stroke opacity'
      })
      .option('opacity', {
        describe: 'opacity; example: 0.5'
      })
      .option('r', {
        describe: 'symbol radius (set this to export points as circles)',
      })
      .option('label-text', {
        describe: 'label text (set this to export points as labels)'
      })
      .option('text-anchor', {
        describe: 'label alignment; one of: start, end, middle (default)'
      })
      .option('dx', {
        describe: 'x offset of labels (default is 0)'
      })
      .option('dy', {
        describe: 'y offset of labels (default is 0/baseline-aligned)'
      })
      .option('font-size', {
        describe: 'size of label text (default is 12)'
      })
      .option('font-family', {
        describe: 'CSS font family of labels (default is sans-serif)'
      })
      .option('font-weight', {
        describe: 'CSS font weight property of labels (e.g. bold, 700)'
      })
      .option('font-style', {
        describe: 'CSS font style property of labels (e.g. italic)'
      })
      .option('font-stretch', {
        describe: 'CSS font stretch property of labels (e.g. condensed)'
      })
      .option('letter-spacing', {
        describe: 'CSS letter-spacing property of labels'
      })
       .option('line-height', {
        describe: 'line spacing of multi-line labels (default is 1.1em)'
      })
     .option('target', targetOpt);

    parser.command('symbols')
      .describe('symbolize points as arrows, circles, stars, polygons, etc.')
      .option('type', {
        describe: 'types: arrow, circle, square, star, polygon, ring'
      })
      .option('stroke', {})
      .option('stroke-width', {})
      .option('fill', {
        describe: 'symbol fill color (filled symbols only)'
      })
      .option('stroke', {
        describe: 'symbol line color (linear symbols only)'
      })
      .option('stroke-width', {
        describe: 'symbol line width (linear symbols only)'
      })
      .option('opacity', {
        describe: 'symbol opacity'
      })
      .option('geographic', {
        old_alias: 'polygons',
         describe: 'make geographic shapes instead of SVG objects',
        type: 'flag'
      })
      .option('pixel-scale', {
        describe: 'set symbol scale in meters per pixel (geographic option)',
        type: 'number',
      })
      // .option('flipped', {
      //   type: 'flag',
      //   describe: 'symbol is vertically flipped'
      // })
      .option('rotated', {
        type: 'flag',
        describe: 'symbol is rotated to an alternate orientation'
      })
      .option('rotation', {
        describe: 'rotation of symbol in degrees'
      })
      .option('scale', {
        describe: 'scale symbols by a multiplier',
        type: 'number'
      })
      .option('radius', {
        describe: 'distance from center to farthest point on the symbol',
        type: 'distance'
      })
      .option('sides', {
        describe: '(polygon) number of sides of a (regular) polygon symbol',
        type: 'number'
      })
      .option('points', {
        describe: '(star) number of points'
      })
      .option('point-ratio', {
        old_alias: 'star-ratio',
        describe: '(star) ratio of minor to major radius of star',
        type: 'number'
      })
      .option('radii', {
        describe: '(ring) comma-sep. list of concentric radii, ascending order'
      })
      .option('arrow-style', {
        describe: '(arrow) options: stick, standard (default is standard)'
      })
      .option('length', {
        old_alias: 'arrow-length',
        describe: '(arrow) length of arrow in pixels'
      })
      .option('direction', {
        old_alias: 'arrow-direction',
        describe: '(arrow) angle off of vertical (-90 = left-pointing)'
      })
      .option('head-angle', {
        old_alias: 'arrow-head-angle',
        describe: '(arrow) angle of tip of arrow (default is 40 degrees)'
      })
      .option('head-width', {
        old_alias: 'arrow-head-width',
        describe: '(arrow) width of arrow head from side to side'
      })
      .option('head-length', {
        old_alias: 'arrow-head-width',
        describe: '(arrow) length of head (alternative to head-angle)'
      })
      .option('head-shape', {
        // describe: 'options: a b c'
      })
      .option('stem-width', {
        old_alias: 'arrow-stem-width',
        describe: '(arrow) width of stem at its widest point'
      })
      .option('stem-length', {
        old_alias: 'arrow-stem-length',
        describe: '(arrow) alternative to length'
      })
      .option('stem-taper', {
        old_alias: 'arrow-stem-taper',
        describe: '(arrow) factor for tapering the width of the stem (0-1)'
      })
      .option('stem-curve', {
        old_alias: 'arrow-stem-curve',
        describe: '(arrow) curvature in degrees (default is 0)'
      })
      .option('min-stem-ratio', {
        old_alias: 'arrow-min-stem',
        describe: '(arrow) minimum ratio of stem to total length',
        type: 'number'
      })
      .option('anchor', {
        describe: '(arrow) takes one of: start, middle, end (default is start)'
      })
      .option('effect', {})
      // .option('where', whereOpt)
      .option('name', nameOpt)
      .option('target', targetOpt)
      .option('no-replace', noReplaceOpt);
      // .option('name', nameOpt);

    parser.command('target')
      .describe('set active layer (or layers)')
      .option('target', {
        DEFAULT: true,
        describe: 'name or index of layer to target'
      })
      .option('type', {
        describe: 'type of layer to target (polygon|polyline|point)'
      })
      // .option('combine', {
      //   type: 'flag',
      //   describe: 'place all targeted layers in one dataset together with any  associated layers'
      // })
      // .option('isolate', {
      //   type: 'flag',
      //   describe: 'place all targeted layers in one dataset exclusive of associated layers'
      // })
      .option('name', {
        describe: 'rename the target layer'
      });

    parser.command('union')
      .describe('create a flat mosaic from two or more polygon layers')
      // .option('add-fid', {
      //   describe: 'add FID_A, FID_B, ... fields to output layer',
      //   type: 'flag'
      // })
      .option('fields', {
        type: 'strings',
        describe: 'fields to retain (comma-sep.) (default is all fields)',
      })
      .option('name', nameOpt)
      .option('target', {
        describe: 'specify layers to target (comma-sep. list)'
      })
      .option('no-replace', noReplaceOpt);

    parser.command('uniq')
      .describe('delete features with the same id as a previous feature')
      .option('expression', {
        DEFAULT: true,
        describe: 'JS expression to obtain the id of a feature'
      })
      .option('max-count', {
        type: 'number',
        describe: 'max features with the same id (default is 1)'
      })
      .option('index', {
        // describe: 'add an index instead of filtering'
        type: 'flag'
      })
      .option('invert', invertOpt)
      .option('verbose', {
        describe: 'print each removed feature',
        type: 'flag'
      })
      .option('target', targetOpt);

    // Experimental commands
    parser.section('Experimental commands (may give unexpected results)');

    parser.command('add-shape')
      .describe('')
      .option('geojson', {

      })
      .option('coordinates', {

      })
      .option('properties', {

      })
      .option('name', nameOpt)
      .option('target', targetOpt)
      .option('no-replace', noReplaceOpt);

    parser.command('alpha-shapes')
      // .describe('convert points to alpha shapes (aka concave hulls)')
      .option('interval', {
        describe: 'alpha parameter',
        type: 'number'
      })
      .option('keep-points', {
        // describe: 'replace single points with tiny triangles',
        type: 'flag'
      })
      .option('name', nameOpt)
      .option('target', targetOpt)
      .option('no-replace', noReplaceOpt);

    parser.command('check-geometry')
      // .describe()
      .option('strict', {
        describe: 'stops the program if any errors are found',
        type: 'flag'
      });

    parser.command('cluster')
      .describe('group polygons into compact clusters')
      .option('id-field', {
        describe: 'field name of cluster id (default is "cluster")'
      })
      .option('pct', {
        alias: 'p',
        type: 'percent',
        describe: 'percentage of shapes to retain, e.g. 50%'
      })
      .option('max-width', {
        describe: 'max width of cluster bounding box',
        type: 'number'
      })
      .option('max-height', {
        describe: 'max height of cluster bounding box',
        type: 'number'
      })
      .option('max-area', {
        describe: 'max area of a cluster',
        type: 'number'
      })
      .option('group-by', {
        describe: 'field name; only same-value shapes will be grouped'
      })
      .option('target', targetOpt);

    parser.command('data-fill')
      .describe('fill in missing values in a polygon layer')
      .option('field', {
        describe: 'name of field to fill in'
      })
      .option('postprocess', {alias_to: 'contiguous'})
      .option('contiguous', {
        describe: 'remove non-contiguous data islands',
        type: 'flag'
      })
      // .option('min-weight-pct', {
      //   describe: 'retain data islands weighted more than this pct'
      // })
      .option('weight-field', {
        describe: 'use field values to calculate data island weights'
      });

    // replaced by -require
    // parser.command('external')
    //   .option('module', {
    //     DEFAULT: true,
    //     describe: 'name of Node module containing the command'
    //   });

    parser.command('filter-points')
      // .describe('remove points that are not part of a group')
      // .option('min-group-size', {
      //   // describe: 'drop points with fewer points in the vicinity',
      //   type: 'number'
      // })
      .option('group-interval', {
        // describe: max interval separating a point from other points
        type: 'number'
      });

    parser.command('frame')
      .describe('create a rectangular map frame layer at a given display width')
      .option('width', {
        describe: 'width of frame (e.g. 5in, 10cm, 600px; default is 800px)'
      })
      .option('height', {
        describe: '(optional) height of frame; similar to width= option'
      })
      .option('aspect-ratio', {
        describe: '(optional) aspect ratio of frame, if height= or width= is omitted',
        type: 'number'
      })
      .option('bbox', {
        describe: 'frame coordinates (xmin,ymin,xmax,ymax)',
        type: 'bbox'
      })
      .option('offset', {
        describe: 'padding in display units or pct of width, e.g. 5cm 20px 5%',
        type: 'strings'
      })
      .option('offsets', {
        describe: 'separate offsets for each side, in l,b,r,t order',
        type: 'strings'
      })
      .option('name', nameOpt)
      .option('target', targetOpt);

      // .option('height', {
      //   describe: 'pixel height of output (may be a range)'
      // })
      // .option('pixels', {
      //   describe: 'area of output in pixels (alternative to width and height)',
      //   type: 'number'
      // })
      // .option('source', {
      //   describe: 'name of layer to enclose'
      // })

    parser.command('fuzzy-join')
      .describe('join points to polygons, with data fill and fuzzy match')
      .option('source', {
        DEFAULT: true,
        describe: 'file or layer containing data records'
      })
      .option('field', {
        describe: 'field to join'
      })
      .option('dedup-points', {
        describe: 'uniqify points with the same location and field value',
        type: 'flag'
      })
      .option('no-dropouts', {
        describe: 'try to retain all values from the point layer',
        type: 'flag'
      })
      .option('postprocess', {alias_to: 'contiguous'})
      .option('contiguous', {
        describe: 'remove non-contiguous data islands',
        type: 'flag'
      })
      .option('target', targetOpt);

    parser.command('point-to-grid')
      .option('interval', {
        // describe: size of grid in projected units
        type: 'number'
      })
      .option('radius', {
        // describe: radius to assign each point
        type: 'number'
      })
      .option('circles', {
        // describe: create a grid of circles instead of squares
        type: 'flag'
      })
      .option('cell-margin', {
        // describe: (0-1) inset grid shapes by a percentage
        type: 'number'
      })
      .option('aligned', {
        // describe: all grids of a given cell size will be aligned
        type: 'flag'
      })
      .option('calc', calcOpt)
      .option('target', targetOpt)
      .option('name', nameOpt)
      .option('no-replace', noReplaceOpt);

    parser.command('require')
      .describe('require a Node module or ES module to use in JS expressions')
      .option('module', {
        DEFAULT: true,
        describe: 'name of installed module or path to module file'
      })
      .option('alias', {
        describe: 'Set the module name to an alias'
      });
      // .option('init', {
      //   describe: 'JS expression to run after the module loads'
      // });

    parser.command('rotate')
      // .describe('apply d3-style 3-axis rotation to a lat-long dataset')
      .option('rotation', {
        // describe: 'two or three angles of rotation',
        DEFAULT: true,
        type: 'numbers'
      })
      .option('invert', {
        type: 'flag'
      });

    parser.command('run')
      .describe('create commands on-the-fly and run them')
      .option('expression', {
        DEFAULT: true,
        describe: 'JS expression or template to generate command(s)'
      })
      // deprecated
      .option('commands', {alias_to: 'expression'})
      .option('target', targetOpt);

    parser.command('scalebar')
      .describe('add a simple scale bar to SVG output')
      .option('label', {
        DEFAULT: true,
        describe: 'distance label, e.g. "35 miles"'
      })
      .option('style', {
        describe: 'two options: a or b'
      })
      .option('font-size', {
        type: 'number'
      })
      .option('tic-length', {
        describe: 'length of tic marks (style b)',
        type: 'number'
      })
      .option('bar-width', {
        describe: 'line width of bar',
        type: 'number'
      })
      .option('label-offset', {
        type: 'number'
      })
      .option('position', {
        describe: 'e.g. bottom-right (default is top-left)'
      })
      .option('label-position', {
        describe: 'top, bottom, top-center (style a), etc'
      })
      .option('dual-units', {
        // describe: 'display both metric and imperial units',
        type: 'flag'
      })
      .option('margin', {
        describe: 'offset in pixels from edge of map',
        type: 'number'
      });

    parser.command('shape')
      .describe('create a polyline or polygon from coordinates')
      .option('coordinates', {
        describe: 'list of vertices as x,y,x,y...',
        type: 'numbers'
      })
      .option('offsets', {
        describe: 'list of vertices as offsets from coordinates list',
        type: 'numbers'
      })
      .option('closed', {
        describe: 'close an open path to create a polygon',
        type: 'flag'
      })
      .option('type', {
        // describe: 'circle or ???'
        DEFAULT: true,
      })
      .option('center', {
        //describe: 'center of the circle (default is 0,0)',
        type: 'numbers'
      })
      .option('radius', {
        //describe: 'radius of the circle in meters',
        type: 'number'
      })
      .option('radius-angle', {
        //describe: 'radius of the circle in degrees',
        type: 'number'
      })
      .option('bbox', {
        // describe: 'rectangle bounding box',
        type: 'numbers'
      })
      .option('geometry', {
        //describe: 'polygon or polyline'
      })
      .option('rotation', {
        // describe: 'two or three angles of rotation',
        type: 'numbers'
      })
      .option('name', nameOpt);

    parser.command('subdivide')
      .describe('recursively split a layer using a JS expression')
      .validate(validateExpressionOpt)
      .option('expression', {
        DEFAULT: true,
        describe: 'boolean JS expression'
      })
      .option('target', targetOpt);

    parser.section('Control flow commands');

    var ifOpts = {
      expression: {
        DEFAULT: true,
        describe: 'JS expression'
      },
      // empty: {
      //   describe: 'run if layer is empty',
      //   type: 'flag'
      // },
      // 'not-empty': {
      //   describe: 'run if layer is not empty',
      //   type: 'flag'
      // },
      layer: {
        describe: 'name or id of layer to test (default is current target)'
      },
      target: targetOpt
    };

    parser.command('if')
      .describe('run the following commands if a condition is met')
      .options(ifOpts);

    parser.command('elif')
      .describe('test an alternate condition; used after -if')
      .options(ifOpts);

    parser.command('else')
      .describe('run commands if all preceding -if/-elif conditions are false');

    parser.command('endif')
      .describe('mark the end of an -if sequence');

    parser.command('ignore')
      // .describe('stop processing if a condition is met')
      .option('empty', {
        describe: 'ignore empty files',
        type: 'flag'
      })
      .option('target', targetOpt);

    parser.command('stop')
      .describe('stop processing (skip remaining commands)');

    parser.section('Informational commands');

    parser.command('calc')
      .describe('calculate statistics about the features in a layer')
      .example('Calculate the total area of a polygon layer\n' +
        '$ mapshaper polygons.shp -calc \'sum($.area)\'')
      .example('Count census blocks in NY with zero population\n' +
        '$ mapshaper ny-census-blocks.shp -calc \'count()\' where=\'POPULATION == 0\'')
      .validate(validateExpressionOpt)
      .option('expression', {
        DEFAULT: true,
        describe: 'functions: sum() average() median() max() min() count()'
      })
      .option('where', whereOpt)
      .option('target', targetOpt)
      .option('to-layer', noReplaceOpt2)
      .option('name', nameOpt2);

    parser.command('colors')
      .describe('print list of color scheme names');

    parser.command('comment')
      .describe('add a comment to the sequence of commands')
      .option('message', {
        DEFAULT: {
          multi_arg: true,
          join: ' '
        }
      });

    parser.command('encodings')
      .describe('print list of supported text encodings (for .dbf import)');

    parser.command('help')
      .alias('h')
      .describe('print help; takes optional command name')
      .option('command', {
        DEFAULT: true,
        describe: 'view detailed information about a command'
      });

    parser.command('info')
      .describe('print information about data layers')
      .option('save-to', {
        describe: 'name of file to save info in JSON format'
      })
      .option('target', targetOpt)
      .option('to-layer', noReplaceOpt2)
      .option('name', nameOpt2);

    parser.command('inspect')
      .describe('print information about a feature')
      .option('expression', {
        DEFAULT: true,
        describe: 'boolean JS expression for selecting a feature'
      })
      .option('target', targetOpt)
      .validate(validateExpressionOpt);

    parser.command('print')
      .describe('print a message to stdout')
      .option('message', {
        DEFAULT: {
          multi_arg: true,
          join: ' '
        }
      });

    parser.command('projections')
      .describe('print list of supported projections');

    parser.command('quiet')
      .describe('inhibit console messages');

    parser.command('verbose')
      .describe('print verbose processing messages');

    parser.command('version')
      .alias('v')
      .describe('print mapshaper version');

    parser.command('debug');

    return parser;
  }

  // DBF format references:
  // http://www.dbf2002.com/dbf-file-format.html
  // http://www.digitalpreservation.gov/formats/fdd/fdd000325.shtml
  // http://www.clicketyclick.dk/databases/xbase/format/index.html
  // http://www.clicketyclick.dk/databases/xbase/format/data_types.html
  // esri docs:
  // https://support.esri.com/en/technical-article/000007920
  // https://desktop.arcgis.com/en/arcmap/latest/manage-data/shapefiles/geoprocessing-considerations-for-shapefile-output.htm

  // source: http://webhelp.esri.com/arcpad/8.0/referenceguide/index.htm#locales/task_code.htm
  var languageIds = [0x01,'437',0x02,'850',0x03,'1252',0x08,'865',0x09,'437',0x0A,'850',0x0B,'437',0x0D,'437',0x0E,'850',0x0F,'437',0x10,'850',0x11,'437',0x12,'850',0x13,'932',0x14,'850',0x15,'437',0x16,'850',0x17,'865',0x18,'437',0x19,'437',0x1A,'850',0x1B,'437',0x1C,'863',0x1D,'850',0x1F,'852',0x22,'852',0x23,'852',0x24,'860',0x25,'850',0x26,'866',0x37,'850',0x40,'852',0x4D,'936',0x4E,'949',0x4F,'950',0x50,'874',0x57,'1252',0x58,'1252',0x59,'1252',0x64,'852',0x65,'866',0x66,'865',0x67,'861',0x6A,'737',0x6B,'857',0x6C,'863',0x78,'950',0x79,'949',0x7A,'936',0x7B,'932',0x7C,'874',0x86,'737',0x87,'852',0x88,'857',0xC8,'1250',0xC9,'1251',0xCA,'1254',0xCB,'1253',0xCC,'1257'];

  // Language & Language family names for some code pages
  var encodingNames = {
    '932': "Japanese",
    '936': "Simplified Chinese",
    '950': "Traditional Chinese",
    '1252': "Western European",
    '949': "Korean",
    '874': "Thai",
    '1250': "Eastern European",
    '1251': "Russian",
    '1254': "Turkish",
    '1253': "Greek",
    '1257': "Baltic"
  };

  var ENCODING_PROMPT =
    "To set the text encoding, re-import using the \"encoding=\" option.\n" +
    "To list the supported encodings, run the \"encodings\" command.";

  function lookupCodePage(lid) {
    var i = languageIds.indexOf(lid);
    return i == -1 ? null : languageIds[i+1];
  }

  // function readAsciiString(bin, size) {
  //   var require7bit = true;
  //   var str = bin.readCString(size, require7bit);
  //   if (str === null) {
  //     stop("DBF file contains non-ascii text.\n" + ENCODING_PROMPT);
  //   }
  //   return utils.trim(str);
  // }

  function readStringBytes(bin, size, buf) {
    var start = bin.position();
    var count = 0, c;
    for (var i=0; i<size; i++) {
      c = bin.readUint8();
      // treating 0 as C-style string terminator (observed in-the-wild)
      // TODO: in some encodings (e.g. utf-16) the 0-byte occurs in other
      //   characters than the NULL character (ascii 0). The following code
      //   should be changed to support non-ascii-compatible encodings
      if (c === 0) break;
      if (count > 0 || c != 32) { // ignore leading spaces (e.g. DBF numbers)
        buf[count++] = c;
      }
    }
    // ignore trailing spaces (DBF string fields are typically r-padded w/ spaces)
    while (count > 0 && buf[count-1] == 32) {
      count--;
    }
    bin.position(start + size);
    return count;
  }


  function getStringReader(arg) {
    var encoding = arg || 'ascii';
    var slug = standardizeEncodingName(encoding);
    var buf = utils.createBuffer(256);
    var inNode = typeof module == 'object';

    // optimization -- use (fast) native Node conversion if available
    if (inNode && (slug == 'utf8' || slug == 'ascii')) {
      return function(bin, size) {
        var n = readStringBytes(bin, size, buf);
        return buf.toString(slug, 0, n);
      };
    }

    return function readEncodedString(bin, size) {
      var n = readStringBytes(bin, size, buf),
          str = '', i, c;
      // optimization: fall back to text decoder only if string contains non-ascii bytes
      // (data files of any encoding typically contain mostly ascii fields)
      // TODO: verify this assumption - some supported encodings may not be ascii-compatible
      for (i=0; i<n; i++) {
        c = buf[i];
        if (c > 127) {
          return bufferToString(buf, encoding, 0, n);
        }
        str += String.fromCharCode(c);
      }
      return str;
    };
  }

  function bufferContainsHighBit(buf, n) {
    for (var i=0; i<n; i++) {
      if (buf[i] >= 128) return true;
    }
    return false;
  }

  function getNumberReader() {
    var read = getStringReader('ascii');
    return function readNumber(bin, size) {
      var str = read(bin, size);
      var val;
      if (str.indexOf(',') >= 0) {
        str = str.replace(',', '.'); // handle comma decimal separator
      }
      val = parseFloat(str);
      return isNaN(val) ? null : val;
    };
  }

  function readInt(bin, size) {
    return bin.readInt32();
  }

  function readBool(bin, size) {
    var c = bin.readCString(size),
        val = null;
    if (/[ty]/i.test(c)) val = true;
    else if (/[fn]/i.test(c)) val = false;
    return val;
  }

  function readDate(bin, size) {
    var str = bin.readCString(size),
        yr = str.substr(0, 4),
        mo = str.substr(4, 2),
        day = str.substr(6, 2);
    return new Date(Date.UTC(+yr, +mo - 1, +day));
  }

  // cf. http://code.google.com/p/stringencoding/
  //
  // @src is a Buffer or ArrayBuffer or filename
  //
  function DbfReader(src, encodingArg) {
    var opts = {
      cacheSize: 0x2000000, // 32MB
      bufferSize: 0x400000 // 4MB
    };
    var dbfFile = utils.isString(src) ? new FileReader(src, opts) : new BufferReader(src);
    var header = readHeader(dbfFile);

    // encoding and fields are set on first access
    var fields;
    var encoding;

    this.size = function() {return header.recordCount;};

    this.readRow = function(i) {
      // create record reader on-the-fly
      // (delays encoding detection until we need to read data)
      return getRecordReader()(i);
    };

    this.getFields = getFieldNames;

    // TODO: switch to streaming output under Node.js
    this.getBuffer = function() {
      return dbfFile.readSync(0, dbfFile.size());
    };

    this.deleteField = function(f) {
      prepareToRead();
      fields = fields.filter(function(field) {
        return field.name != f;
      });
    };

    this.readRows = function() {
      var reader = getRecordReader();
      var data = [];
      for (var r=0, n=this.size(); r<n; r++) {
        data.push(reader(r));
      }
      return data;
    };

    // Prepare to read from table:
    // * determine encoding
    // * convert encoded field names to strings
    //   (DBF standard is ascii names, but ArcGIS etc. support encoded names)
    //
    function prepareToRead() {
      if (fields) return; // already initialized
      var headerEncoding = 'ascii';
      initEncoding();
      if (getNonAsciiHeaders().length > 0) {
        headerEncoding = getEncoding();
      }
      fields = header.fields.map(function(f) {
        var copy = utils.extend({}, f);
        copy.name = decodeString(f.namebuf, headerEncoding);
        return copy;
      });
      // Uniqify header names
      getUniqFieldNames(utils.pluck(fields, 'name')).forEach(function(name2, i) {
        fields[i].name = name2;
      });
    }

    function readHeader(reader) {
      // fetch enough bytes to accomodate any header
      var maxHeaderLen = 32 * 256 + 1; // 255 fields * fieldRecSize + headerRecSize + terminator
      var bin = reader.readToBinArray(0, Math.min(maxHeaderLen, reader.size()));
      bin.position(0).littleEndian();
      var header = {
        version: bin.readInt8(),
        updateYear: bin.readUint8(),
        updateMonth: bin.readUint8(),
        updateDay: bin.readUint8(),
        recordCount: bin.readUint32(),
        dataOffset: bin.readUint16(),
        recordSize: bin.readUint16(),
        incompleteTransaction: bin.skipBytes(2).readUint8(),
        encrypted: bin.readUint8(),
        mdx: bin.skipBytes(12).readUint8(),
        ldid: bin.readUint8()
      };
      var colOffs = 1; // first column starts on second byte of record
      var field;
      bin.skipBytes(2);
      header.fields = [];

      // Detect header terminator (LF is standard, CR has been seen in the wild)
      while (bin.peek() != 0x0D && bin.peek() != 0x0A && bin.position() < header.dataOffset - 1) {
        field = readFieldHeader(bin);
        field.columnOffset = colOffs;
        header.fields.push(field);
        colOffs += field.size;
      }
      if (colOffs != header.recordSize) {
        error("Record length mismatch; header:", header.recordSize, "detected:", colOffs);
      }
      if (bin.peek() != 0x0D) {
        message('Found a non-standard DBF header terminator (' + bin.peek() + '). DBF file may be corrupted.');
      }

      return header;
    }

    function readFieldHeader(bin) {
      var buf = utils.createBuffer(11);
      var chars = readStringBytes(bin, 11, buf);
      return {
        // name: bin.readCString(11),
        namebuf: utils.createBuffer(buf.slice(0, chars)),
        type: String.fromCharCode(bin.readUint8()),
        address: bin.readUint32(),
        size: bin.readUint8(),
        decimals: bin.readUint8(),
        id: bin.skipBytes(2).readUint8(),
        position: bin.skipBytes(2).readUint8(),
        indexFlag: bin.skipBytes(7).readUint8()
      };
    }

    function getFieldNames() {
      prepareToRead();
      return utils.pluck(fields, 'name');
    }

    function getRowOffset(r) {
      return header.dataOffset + header.recordSize * r;
    }

    function initEncoding() {
      if (encoding) return;
      encoding = encodingArg || findStringEncoding();
    }

    function getEncoding() {
      initEncoding();
      return encoding;
    }

    // Create new record objects using object literal syntax
    // (Much faster in v8 and other engines than assigning a series of properties
    //  to an object)
    function getRecordConstructor() {
      var args = getFieldNames().map(function(name, i) {
            return JSON.stringify(name) + ': arguments[' + i + ']';
          });
      return new Function('return {' + args.join(',') + '};');
    }

    // function findEofPos(bin) {
    //   var pos = bin.size() - 1;
    //   if (bin.peek(pos) != 0x1A) { // last byte may or may not be EOF
    //     pos++;
    //   }
    //   return pos;
    // }

    function getRecordReader() {
      prepareToRead();
      var readers = fields.map(getFieldReader),
          create = getRecordConstructor(),
          values = [];

      return function readRow(r) {
        var bin = dbfFile.readToBinArray(getRowOffset(r), header.recordSize),
            rowOffs = bin.position(),
            fieldOffs, field;
        if (bin.bytesLeft() < header.recordSize ||
            bin.bytesLeft() == header.recordSize && bin.peek(bin.size() - 1) == 0x1A) {
          // check for observed data error: last data byte contains EOF
          stop('Invalid DBF file: encountered end-of-file while reading data');
        }
        for (var c=0, cols=fields.length; c<cols; c++) {
          field = fields[c];
          fieldOffs = rowOffs + field.columnOffset;
          bin.position(fieldOffs);
          values[c] = readers[c](bin, field.size);
        }
        return create.apply(null, values);
      };
    }

    // @f Field metadata from dbf header
    function getFieldReader(f) {
      var type = f.type,
          r = null;
      if (type == 'I') {
        r = readInt;
      } else if (type == 'F' || type == 'N') {
        r = getNumberReader();
      } else if (type == 'L') {
        r = readBool;
      } else if (type == 'D') {
        r = readDate;
      } else if (type == 'C') {
        r = getStringReader(getEncoding());
      } else {
        message("Field \"" + f.name + "\" has an unsupported type (" + f.type + ") -- converting to null values");
        r = function() {return null;};
      }
      return r;
    }

    function findStringEncoding() {
      var ldid = header.ldid,
          codepage = lookupCodePage(ldid),
          samples = getNonAsciiSamples(),
          only7bit = samples.length === 0,
          encoding;

      // First, check the ldid (language driver id) (an obsolete way to specify which
      // codepage to use for text encoding.)
      // ArcGIS up to v.10.1 sets ldid and encoding based on the 'locale' of the
      // user's Windows system :P
      //
      if (codepage && ldid != 87) {
        // if 8-bit data is found and codepage is detected, use the codepage,
        // except ldid 87, which some GIS software uses regardless of encoding.
        encoding = codepage;
      } else if (only7bit) {
        // Text with no 8-bit chars should be compatible with 7-bit ascii
        // (Most encodings are supersets of ascii)
        encoding = 'ascii';
      }

      // As a last resort, try to guess the encoding:
      if (!encoding) {
        var info = detectEncoding(samples);
        var msg;
        encoding = info.encoding;
        if (info.confidence < 2) {
          msg = 'Warning: Unable to auto-detect the DBF file text encoding' +
            (info.confidence == 1 ? ' with high confidence' : '') + '.';
          msg += ' Defaulting to ' + encoding + (encoding in encodingNames ? ' (' + encodingNames[encoding] + ').' : '.');
          msg += '\n\nSample of how non-ascii text was imported:\n';
          if (runningInBrowser()) {
            msg += '<pre>' + formatStringsAsGrid(decodeSamples(encoding, samples), 50) + '</pre>';
          } else {
            msg += formatStringsAsGrid(decodeSamples(encoding, samples));
          }
          msg += '\n\n' + ENCODING_PROMPT + '\n';
          message(msg);
        }
      }

      return encoding;
    }

    function getNonAsciiHeaders() {
      var arr = [];
      header.fields.forEach(function(f) {
        if (bufferContainsHighBit(f.namebuf, f.namebuf.length)) {
          arr.push(f.namebuf);
        }
      });
      return arr;
    }

    // Return an array of buffers containing text samples
    // with at least one byte outside the 7-bit ascii range.
    function getNonAsciiSamples() {
      var samples = [];
      var stringFields = header.fields.filter(function(f) {
        return f.type == 'C';
      });
      var cols = stringFields.length;
      // don't scan all the rows in large files (slow)
      var rows = Math.min(header.recordCount, 10000);
      var maxSamples = 50;
      var buf = utils.createBuffer(256);
      var index = {};
      var f, chars, sample, hash, bin, rowOffs;
      // include non-ascii field names, if any
      samples = getNonAsciiHeaders();
      for (var r=0; r<rows; r++) {
        bin = dbfFile.readToBinArray(getRowOffset(r), header.recordSize);
        rowOffs = bin.position();
        for (var c=0; c<cols; c++) {
          if (samples.length >= maxSamples) break;
          f = stringFields[c];
          // bin.position(getRowOffset(r) + f.columnOffset);
          bin.position(rowOffs + f.columnOffset);
          chars = readStringBytes(bin, f.size, buf);
          if (chars > 0 && bufferContainsHighBit(buf, chars)) {
            sample = utils.createBuffer(buf.slice(0, chars)); //
            hash = sample.toString('hex');
            if (hash in index === false) { // avoid duplicate samples
              index[hash] = true;
              samples.push(sample);
            }
          }
        }
      }
      return samples;
    }
  }

  function importDbfTable(src, o) {
    var opts = o || {};
    return new ShapefileTable(src, opts.encoding);
  }

  // Implements the DataTable api for DBF file data.
  // We avoid touching the raw DBF field data if possible. This way, we don't need
  // to parse the DBF at all in common cases, like importing a Shapefile, editing
  // just the shapes and exporting in Shapefile format.
  // TODO: consider accepting just the filename, so buffer doesn't consume memory needlessly.
  //
  function ShapefileTable(src, encoding) {
    var reader = new DbfReader(src, encoding),
        altered = false,
        table;

    function getTable() {
      if (!table) {
        // export DBF records on first table access
        table = new DataTable(reader.readRows());
        reader = null;
        src = null; // null out references to DBF data for g.c.
      }
      return table;
    }

    this.exportAsDbf = function(opts) {
      // export original dbf bytes if possible
      // (e.g. if the data attributes haven't changed)
      var useOriginal = !!reader && !altered && !opts.field_order && !opts.encoding;
      if (useOriginal) {
        try {
          // Maximum Buffer in current Node.js is 2GB
          // We fall back to import-export if getBuffer() fails.
          // This may produce a buffer that does not exceed the maximum size.
          return reader.getBuffer();
        } catch(e) {}
      }
      return Dbf.exportRecords(getTable().getRecords(), opts.encoding, opts.field_order);
    };

    this.getReadOnlyRecordAt = function(i) {
      return reader ? reader.readRow(i) : table.getReadOnlyRecordAt(i);
    };

    this.deleteField = function(f) {
      if (table) {
        table.deleteField(f);
      } else {
        altered = true;
        reader.deleteField(f);
      }
    };

    this.getRecords = function() {
      return getTable().getRecords();
    };

    this.getFields = function() {
      return reader ? reader.getFields() : table.getFields();
    };

    this.isEmpty = function() {
      return reader ? this.size() === 0 : table.isEmpty();
    };

    this.size = function() {
      return reader ? reader.size() : table.size();
    };
  }

  Object.assign(ShapefileTable.prototype, DataTable.prototype);

  var DbfImport = /*#__PURE__*/Object.freeze({
    __proto__: null,
    importDbfTable: importDbfTable,
    ShapefileTable: ShapefileTable
  });

  function translateShapefileType(shpType) {
    if ([ShpType.POLYGON, ShpType.POLYGONM, ShpType.POLYGONZ].includes(shpType)) {
      return 'polygon';
    } else if ([ShpType.POLYLINE, ShpType.POLYLINEM, ShpType.POLYLINEZ].includes(shpType)) {
      return 'polyline';
    } else if ([ShpType.POINT, ShpType.POINTM, ShpType.POINTZ,
        ShpType.MULTIPOINT, ShpType.MULTIPOINTM, ShpType.MULTIPOINTZ].includes(shpType)) {
      return 'point';
    }
    return null;
  }

  function isSupportedShapefileType(t) {
    return [0,1,3,5,8,11,13,15,18,21,23,25,28].includes(t);
  }

  var ShpCommon = /*#__PURE__*/Object.freeze({
    __proto__: null,
    translateShapefileType: translateShapefileType,
    isSupportedShapefileType: isSupportedShapefileType
  });

  function getNullRecord(id) {
    return {
      id: id,
      isNull: true,
      pointCount: 0,
      partCount: 0,
      byteLength: 12
    };
  }

  // Returns a constructor function for a shape record class with
  //   properties and methods for reading coordinate data.
  //
  // Record properties
  //   type, isNull, byteLength, pointCount, partCount (all types)
  //
  // Record methods
  //   read(), readPoints() (all types)
  //   readBounds(), readCoords()  (all but single point types)
  //   readPartSizes() (polygon and polyline types)
  //   readZBounds(), readZ() (Z types except POINTZ)
  //   readMBounds(), readM(), hasM() (M and Z types, except POINT[MZ])
  //
  function ShpRecordClass(type) {
    var hasBounds = ShpType.hasBounds(type),
        hasParts = ShpType.isMultiPartType(type),
        hasZ = ShpType.isZType(type),
        hasM = ShpType.isMType(type),
        singlePoint = !hasBounds,
        mzRangeBytes = singlePoint ? 0 : 16,
        constructor, proto;

    // @bin is a BinArray set to the first data byte of a shape record
    constructor = function ShapeRecord(bin, bytes) {
      var pos = bin.position();
      this.id = bin.bigEndian().readUint32();
      this.type = bin.littleEndian().skipBytes(4).readUint32();
      if (this.type === 0 || type === 0) {
        return getNullRecord(this.id);
      }
      if (bytes > 0 !== true || (this.type != type && this.type !== 0)) {
        error("Unable to read a shape -- .shp file may be corrupted");
      }
      this.byteLength = bytes; // bin.readUint32() * 2 + 8; // bytes in content section + 8 header bytes
      if (singlePoint) {
        this.pointCount = 1;
        this.partCount = 1;
      } else {
        bin.skipBytes(32); // skip bbox
        this.partCount = hasParts ? bin.readUint32() : 1;
        this.pointCount = bin.readUint32();
      }
      this._data = function() {
        return bin.position(pos);
      };
    };

    // base prototype has methods shared by all Shapefile types except NULL type
    // (Type-specific methods are mixed in below)
    var baseProto = {
      // return offset of [x, y] point data in the record
      _xypos: function() {
        var offs = 12; // skip header & record type
        if (!singlePoint) offs += 4; // skip point count
        if (hasBounds) offs += 32;
        if (hasParts) offs += 4 * this.partCount + 4; // skip part count & index
        return offs;
      },

      readCoords: function() {
        if (this.pointCount === 0) return null;
        var partSizes = this.readPartSizes(),
            xy = this._data().skipBytes(this._xypos());

        return partSizes.map(function(pointCount) {
          return xy.readFloat64Array(pointCount * 2);
        });
      },

      readXY: function() {
        if (this.pointCount === 0) return new Float64Array(0);
        return this._data().skipBytes(this._xypos()).readFloat64Array(this.pointCount * 2);
      },

      readPoints: function() {
        var xy = this.readXY(),
            zz = hasZ ? this.readZ() : null,
            mm = hasM && this.hasM() ? this.readM() : null,
            points = [], p;

        for (var i=0, n=xy.length / 2; i<n; i++) {
          p = [xy[i*2], xy[i*2+1]];
          if (zz) p.push(zz[i]);
          if (mm) p.push(mm[i]);
          points.push(p);
        }
        return points;
      },

      // Return an array of point counts in each part
      // Parts containing zero points are skipped (Shapefiles with zero-point
      // parts are out-of-spec but exist in the wild).
      readPartSizes: function() {
        var sizes = [];
        var partLen, startId, bin;
        if (this.pointCount === 0) ; else if (this.partCount == 1) {
          // single-part type or multi-part type with one part
          sizes.push(this.pointCount);
        } else {
          // more than one part
          startId = 0;
          bin = this._data().skipBytes(56); // skip to second entry in part index
          for (var i=0, n=this.partCount; i<n; i++) {
            partLen = (i < n - 1 ? bin.readUint32() : this.pointCount) - startId;
            if (partLen > 0) {
              sizes.push(partLen);
              startId += partLen;
            }
          }
        }
        return sizes;
      }
    };

    var singlePointProto = {
      read: function() {
        var n = 2;
        if (hasZ) n++;
        if (this.hasM()) n++;
        return this._data().skipBytes(12).readFloat64Array(n);
      },

      stream: function(sink) {
        var src = this._data().skipBytes(12);
        sink.addPoint(src.readFloat64(), src.readFloat64());
        sink.endPath();
      }
    };

    var multiCoordProto = {
      readBounds: function() {
        return this._data().skipBytes(12).readFloat64Array(4);
      },

      stream: function(sink) {
        var sizes = this.readPartSizes(),
            xy = this.readXY(),
            i = 0, j = 0, n;
        while (i < sizes.length) {
          n = sizes[i];
          while (n-- > 0) {
            sink.addPoint(xy[j++], xy[j++]);
          }
          sink.endPath();
          i++;
        }
        if (xy.length != j) error('Counting error');
      },

      // TODO: consider switching to this simpler functino
      stream2: function(sink) {
        var sizes = this.readPartSizes(),
            bin = this._data().skipBytes(this._xypos()),
            i = 0, n;
        while (i < sizes.length) {
          n = sizes[i];
          while (n-- > 0) {
            sink.addPoint(bin.readFloat64(), bin.readFloat64());
          }
          sink.endPath();
          i++;
        }
      },

      read: function() {
        var parts = [],
            sizes = this.readPartSizes(),
            points = this.readPoints();
        for (var i=0, n = sizes.length - 1; i<n; i++) {
          parts.push(points.splice(0, sizes[i]));
        }
        parts.push(points);
        return parts;
      }
    };

    var mProto = {
      _mpos: function() {
        var pos = this._xypos() + this.pointCount * 16;
        if (hasZ) {
          pos += this.pointCount * 8 + mzRangeBytes;
        }
        return pos;
      },

      readMBounds: function() {
        return this.hasM() ? this._data().skipBytes(this._mpos()).readFloat64Array(2) : null;
      },

      // TODO: group into parts, like readCoords()
      readM: function() {
        return this.hasM() ? this._data().skipBytes(this._mpos() + mzRangeBytes).readFloat64Array(this.pointCount) : null;
      },

      // Test if this record contains M data
      // (according to the Shapefile spec, M data is optional in a record)
      //
      hasM: function() {
        var bytesWithoutM = this._mpos(),
            bytesWithM = bytesWithoutM + this.pointCount * 8 + mzRangeBytes;
        if (this.byteLength == bytesWithoutM) {
          return false;
        } else if (this.byteLength == bytesWithM) {
          return true;
        } else {
          error("#hasM() Counting error");
        }
      }
    };

    var zProto = {
      _zpos: function() {
        return this._xypos() + this.pointCount * 16;
      },

      readZBounds: function() {
        return this._data().skipBytes(this._zpos()).readFloat64Array(2);
      },

      // TODO: group into parts, like readCoords()
      readZ: function() {
        return this._data().skipBytes(this._zpos() + mzRangeBytes).readFloat64Array(this.pointCount);
      }
    };

    if (type === 0) {
      proto = {};
    } else if (singlePoint) {
      proto = Object.assign(baseProto, singlePointProto);
    } else {
      proto = Object.assign(baseProto, multiCoordProto);
    }
    if (hasZ) Object.assign(proto, zProto);
    if (hasM) Object.assign(proto, mProto);

    constructor.prototype = proto;
    proto.constructor = constructor;
    return constructor;
  }

  // Read data from a .shp file
  // @src is an ArrayBuffer, Node.js Buffer or filename
  //
  //    // Example: iterating using #nextShape()
  //    var reader = new ShpReader(buf), s;
  //    while (s = reader.nextShape()) {
  //      // process the raw coordinate data yourself...
  //      var coords = s.readCoords(); // [[x,y,x,y,...], ...] Array of parts
  //      var zdata = s.readZ();  // [z,z,...]
  //      var mdata = s.readM();  // [m,m,...] or null
  //      // .. or read the shape into nested arrays
  //      var data = s.read();
  //    }
  //
  //    // Example: reading records using a callback
  //    var reader = new ShpReader(buf);
  //    reader.forEachShape(function(s) {
  //      var data = s.read();
  //    });
  //
  function ShpReader(shpSrc, shxSrc) {
    if (this instanceof ShpReader === false) {
      return new ShpReader(shpSrc, shxSrc);
    }
    var shpFile = utils.isString(shpSrc) ? new FileReader(shpSrc) : new BufferReader(shpSrc);
    var header = parseHeader(shpFile.readToBinArray(0, 100));
    var shpType = header.type;
    var shpOffset = 100; // used when reading .shp without .shx
    var recordCount = 0;
    var badRecordNumberCount = 0;
    var RecordClass = new ShpRecordClass(shpType);
    var shxBin, shxFile;

    if (shxSrc) {
      shxFile = utils.isString(shxSrc) ? new FileReader(shxSrc) : new BufferReader(shxSrc);
      shxBin = shxFile.readToBinArray(0, shxFile.size()).bigEndian();
    }

    this.header = function() {
      return header;
    };

    // Callback interface: for each record in a .shp file, pass a
    //   record object to a callback function
    //
    this.forEachShape = function(callback) {
      var shape = this.nextShape();
      while (shape) {
        callback(shape);
        shape = this.nextShape();
      }
    };

    // Iterator interface for reading shape records
    this.nextShape = function() {
      var shape;
      if (!shpFile) {
        error('Tried to read from a used ShpReader');
        // return null; // this reader was already used
      }
      shape = readNextShape(recordCount);
      if (!shape) {
        done();
        return null;
      }
      recordCount++;
      return shape;
    };

    // Returns a shape record or null if no more shapes can be read
    // i: Expected 0-based index of the next record
    //
    function readNextShape(i) {
      return shxBin ?
        readIndexedShape(shpFile, shxBin, i) :
        readNonIndexedShape(shpFile, shpOffset, i);
    }

    function done() {
      shpFile.close();
      shpFile = shxFile = shxBin = null;
      if (badRecordNumberCount > 0) {
        message(`Warning: ${badRecordNumberCount}/${recordCount} features have non-standard record numbers in the .shp file.`);
      }
    }

    function parseHeader(bin) {
      var header = {
        signature: bin.bigEndian().readUint32(),
        byteLength: bin.skipBytes(20).readUint32() * 2,
        version: bin.littleEndian().readUint32(),
        type: bin.readUint32(),
        bounds: bin.readFloat64Array(4), // xmin, ymin, xmax, ymax
        zbounds: bin.readFloat64Array(2),
        mbounds: bin.readFloat64Array(2)
      };

      if (header.signature != 9994) {
        error("Not a valid .shp file");
      }

      if (!isSupportedShapefileType(header.type)) {
        error("Unsupported .shp type:", header.type);
      }

      if (header.byteLength != shpFile.size()) {
        error("File size of .shp doesn't match size in header");
      }

      return header;
    }


    function readShapeAtOffset(shpFile, offset) {
      var fileSize = shpFile.size();
      if (offset + 12 > fileSize) return null; // reached end-of-file
      var bin = shpFile.readToBinArray(offset, 12);
      bin.bigEndian().readUint32();
      // record size is bytes in content section + 8 header bytes
      var recordSize = bin.readUint32() * 2 + 8;
      var recordType = bin.littleEndian().readUint32();
      var goodSize = offset + recordSize <= fileSize && recordSize >= 12;
      var goodType = recordType === 0 || recordType == shpType;
      if (!goodSize || !goodType) {
        return null;
      }
      bin = shpFile.readToBinArray(offset, recordSize);
      return new RecordClass(bin, recordSize);
    }

    function readIndexedShape(shpFile, shxBin, i) {
      if (shxBin.size() <= 100 + i * 8) return null; // done
      shxBin.position(100 + i * 8);
      var expectedId = i + 1;
      var offset = shxBin.readUint32() * 2;
      shxBin.readUint32() * 2; // TODO: match this to recLen in .shp
      var shape = readShapeAtOffset(shpFile, offset);
      if (!shape) {
        stop('Index of Shapefile record', expectedId, 'in the .shx file is invalid.');
      }
      if (shape.id != expectedId) {
        badRecordNumberCount++;
        verbose(`Warning: A feature has a different record number in .shx (${expectedId}) and .shp (${shape.id}).`);
      }
      // TODO: consider printing verbose message if a .shp file contains garbage bytes
      // example files:
      // ne_10m_admin_0_boundary_lines_land.shp
      // ne_110m_admin_0_scale_rank.shp
      return shape;
    }

    // The Shapefile specification does not require records to be densely packed or
    // in consecutive sequence in the .shp file. This is a problem when the .shx
    // index file is not present.
    //
    // Here, we try to scan past any invalid content to find the next record.
    // Records are required to be in sequential order.
    //
    function readNonIndexedShape(shpFile, start, i) {
      var expectedId = i + 1, // Shapefile ids are 1-based
          offset = start,
          fileSize = shpFile.size(),
          shape = null,
          bin, recordId, recordType, isValidType;
      while (offset + 12 <= fileSize) {
        bin = shpFile.readToBinArray(offset, 12);
        recordId = bin.bigEndian().readUint32();
        recordType = bin.littleEndian().skipBytes(4).readUint32();
        isValidType = recordType == shpType || recordType === 0;
        if (!isValidType || recordId != expectedId && recordType === 0) {
          offset += 4; // keep scanning -- try next integer position
          continue;
        }
        shape = readShapeAtOffset(shpFile, offset);
        if (!shape) break; // probably ran into end of file
        shpOffset = offset + shape.byteLength; // update
        if (recordId == expectedId) break; // found an apparently valid shape
        if (recordId < expectedId) {
          message("Found a Shapefile record with the same id as a previous record (" + shape.id + ") -- skipping.");
          offset += shape.byteLength;
        } else {
          stop("Shapefile contains an out-of-sequence record. Possible data corruption -- bailing.");
        }
      }
      if (shape && offset > start) {
        verbose("Skipped over " + (offset - start) + " non-data bytes in the .shp file.");
      }
      return shape;
    }
  }

  ShpReader.prototype.type = function() {
    return this.header().type;
  };

  // Apply snapping, remove duplicate coords and clean up defective paths in a dataset
  // Assumes that any CRS info has been added to the dataset
  // @opts: import options
  function cleanPathsAfterImport(dataset, opts) {
    var arcs = dataset.arcs;
    var snapDist;
    if (opts.snap || opts.auto_snap || opts.snap_interval) { // auto_snap is older name
      if (opts.snap_interval) {
        snapDist = convertIntervalParam(opts.snap_interval, getDatasetCRS(dataset));
      }
      if (arcs) {
        snapCoords(arcs, snapDist);
      }
    }
    dataset.layers.forEach(function(lyr) {
      if (layerHasPaths(lyr)) {
        cleanShapes(lyr.shapes, arcs, lyr.geometry_type);
      }
    });
  }

  function pointHasValidCoords(p) {
    // The Shapefile spec states that "measures" less then -1e38 indicate null values
    // This should not apply to coordinate data, but in-the-wild Shapefiles have been
    // seen with large negative values indicating null coordinates.
    // This test catches these and also NaNs, but does not detect other kinds of
    // invalid coords
    return p[0] > -1e38 && p[1] > -1e38;
  }

  // Accumulates points in buffers until #endPath() is called
  // @drain callback: function(xarr, yarr, size) {}
  //
  function PathImportStream(drain) {
    var buflen = 10000,
        xx = new Float64Array(buflen),
        yy = new Float64Array(buflen),
        i = 0;

    this.endPath = function() {
      drain(xx, yy, i);
      i = 0;
    };

    this.addPoint = function(x, y) {
      if (i >= buflen) {
        buflen = Math.ceil(buflen * 1.3);
        xx = utils.extendBuffer(xx, buflen);
        yy = utils.extendBuffer(yy, buflen);
      }
      xx[i] = x;
      yy[i] = y;
      i++;
    };
  }

  // Import path data from a non-topological source (Shapefile, GeoJSON, etc)
  // in preparation for identifying topology.
  // @opts.reserved_points -- estimate of points in dataset, for pre-allocating buffers
  //
  function PathImporter(opts) {
    var bufSize = opts.reserved_points > 0 ? opts.reserved_points : 20000,
        xx = new Float64Array(bufSize),
        yy = new Float64Array(bufSize),
        shapes = [],
        properties = [],
        nn = [],
        types = [],
        collectionType = opts.type || null, // possible values: polygon, polyline, point
        round = null,
        pathId = -1,
        shapeId = -1,
        pointId = 0,
        dupeCount = 0,
        openRingCount = 0;

    if (opts.precision) {
      round = getRoundingFunction(opts.precision);
    }

    // mix in #addPoint() and #endPath() methods
    utils.extend(this, new PathImportStream(importPathCoords));

    this.startShape = function(d) {
      shapes[++shapeId] = null;
      if (d) properties[shapeId] = d;
    };

    this.importLine = function(points) {
      if (points.length < 2) {
        verbose("Skipping a defective line");
        return;
      }
      setShapeType('polyline');
      this.importPath(points);
    };

    this.importPoints = function(points) {
      setShapeType('point');
      points = points.filter(pointHasValidCoords);
      if (round) {
        points.forEach(function(p) {
          p[0] = round(p[0]);
          p[1] = round(p[1]);
        });
      }
      points.forEach(appendToShape);
    };

    this.importRing = function(points, isHole) {
      var area = geom.getPlanarPathArea2(points);
      if (!area || points.length < 4) {
        verbose("Skipping a defective ring");
        return;
      }
      setShapeType('polygon');
      if (isHole === true && area > 0 || isHole === false && area < 0) {
        // GeoJSON rings may be either direction -- no point in logging reversal
        // verbose("Reversing", isHole ? "a CW hole" : "a CCW ring");
        points.reverse();
      }
      this.importPath(points);
    };

    // Import an array of [x, y] Points
    this.importPath = function importPath(points) {
      var p;
      for (var i=0, n=points.length; i<n; i++) {
        p = points[i];
        this.addPoint(p[0], p[1]);
      }
      this.endPath();
    };

    // Return imported dataset
    // Apply any requested snapping and rounding
    // Remove duplicate points, check for ring inversions
    //
    this.done = function() {
      var arcs;
      var layers;
      var lyr = {name: ''};

      if (dupeCount > 0) {
        verbose(utils.format("Removed %,d duplicate point%s", dupeCount, utils.pluralSuffix(dupeCount)));
      }
      if (openRingCount > 0) {
        message(utils.format("Closed %,d open polygon ring%s", openRingCount, utils.pluralSuffix(openRingCount)));
      }
      if (pointId > 0) {
         if (pointId < xx.length) {
          xx = xx.subarray(0, pointId);
          yy = yy.subarray(0, pointId);
        }
        arcs = new ArcCollection(nn, xx, yy);

        //if (opts.snap || opts.auto_snap || opts.snap_interval) { // auto_snap is older name
        //  internal.snapCoords(arcs, opts.snap_interval);
        //}
      }

      if (collectionType == 'mixed') {
        layers = divideFeaturesByType(shapes, properties, types);

      } else {
        lyr = {geometry_type: collectionType};
        if (collectionType) {
          lyr.shapes = shapes;
        }
        if (properties.length > 0) {
          lyr.data = new DataTable(properties);
        }
        layers = [lyr];
      }

      layers.forEach(function(lyr) {
        //if (internal.layerHasPaths(lyr)) {
          //internal.cleanShapes(lyr.shapes, arcs, lyr.geometry_type);
        //}
        if (lyr.data) {
          fixInconsistentFields(lyr.data.getRecords());
        }
      });

      return {
        arcs: arcs || null,
        info: {},
        layers: layers
      };
    };

    function setShapeType(t) {
      var currType = shapeId < types.length ? types[shapeId] : null;
      if (!currType) {
        types[shapeId] = t;
        if (!collectionType) {
          collectionType = t;
        } else if (t != collectionType) {
          collectionType = 'mixed';
        }
      } else if (currType != t) {
        stop("Unable to import mixed-geometry features");
      }
    }

    function checkBuffers(needed) {
      if (needed > xx.length) {
        var newLen = Math.max(needed, Math.ceil(xx.length * 1.5));
        xx = utils.extendBuffer(xx, newLen, pointId);
        yy = utils.extendBuffer(yy, newLen, pointId);
      }
    }

    function appendToShape(part) {
      var currShape = shapes[shapeId] || (shapes[shapeId] = []);
      currShape.push(part);
    }

    function appendPath(n) {
      pathId++;
      nn[pathId] = n;
      appendToShape([pathId]);
    }

    function importPathCoords(xsrc, ysrc, n) {
      var count = 0;
      var x, y, prevX, prevY;
      checkBuffers(pointId + n);
      for (var i=0; i<n; i++) {
        x = xsrc[i];
        y = ysrc[i];
        if (round) {
          x = round(x);
          y = round(y);
        }
        if (i > 0 && x == prevX && y == prevY) {
          dupeCount++;
        } else {
          xx[pointId] = x;
          yy[pointId] = y;
          pointId++;
          count++;
        }
        prevY = y;
        prevX = x;
      }

      // check for open rings
      if (collectionType == 'polygon' && count > 0) {
        if (xsrc[0] != xsrc[n-1] || ysrc[0] != ysrc[n-1]) {
          checkBuffers(pointId + 1);
          xx[pointId] = xsrc[0];
          yy[pointId] = ysrc[0];
          openRingCount++;
          pointId++;
          count++;
        }
      }

      appendPath(count);
    }
  }

  var PathImport = /*#__PURE__*/Object.freeze({
    __proto__: null,
    cleanPathsAfterImport: cleanPathsAfterImport,
    pointHasValidCoords: pointHasValidCoords,
    PathImporter: PathImporter
  });

  // Read Shapefile data from a file, ArrayBuffer or Buffer
  // @shp, @shx: filename or buffer
  function importShp(shp, shx, opts) {
    var reader = new ShpReader(shp, shx),
        shpType = reader.type(),
        type = translateShapefileType(shpType),
        importOpts = utils.defaults({
          type: type,
          reserved_points: Math.round(reader.header().byteLength / 16)
        }, opts),
        importer = new PathImporter(importOpts);

    if (!isSupportedShapefileType(shpType)) {
      stop("Unsupported Shapefile type:", shpType);
    }
    if (ShpType.isZType(shpType)) {
      verbose("Warning: Shapefile Z data will be lost.");
    } else if (ShpType.isMType(shpType)) {
      verbose("Warning: Shapefile M data will be lost.");
    }

    // TODO: test cases: null shape; non-null shape with no valid parts
    reader.forEachShape(function(shp) {
      importer.startShape();
      if (shp.isNull) ; else if (type == 'point') {
        importer.importPoints(shp.readPoints());
      } else {
        shp.stream(importer);
        // shp.stream2(importer);
      }
    });

    return importer.done();
  }

  var ShpImport = /*#__PURE__*/Object.freeze({
    __proto__: null,
    importShp: importShp
  });

  function importGeoJSON(src, optsArg) {
    var opts = optsArg || {};
    var supportedGeometries = Object.keys(GeoJSON.pathImporters),
        srcObj = utils.isString(src) ? JSON.parse(src) : src,
        importer = new GeoJSONParser(opts),
        srcCollection, dataset;

    // Convert single feature or geometry into a collection with one member
    if (srcObj.type == 'Feature') {
      srcCollection = {
        type: 'FeatureCollection',
        features: [srcObj]
      };
    } else if (supportedGeometries.includes(srcObj.type)) {
      srcCollection = {
        type: 'GeometryCollection',
        geometries: [srcObj]
      };
    } else {
      srcCollection = srcObj;
    }
    (srcCollection.features || srcCollection.geometries || []).forEach(importer.parseObject);
    dataset = importer.done();
    importCRS(dataset, srcObj); // TODO: remove this
    return dataset;
  }

  function GeoJSONParser(opts) {
    var idField = opts.id_field || GeoJSON.ID_FIELD,
        importer = new PathImporter(opts);

    this.parseObject = function(o) {
      var geom, rec;
      if (!o || !o.type) {
        // not standard GeoJSON -- importing as null record
        // (useful when parsing GeoJSON generated internally)
        geom = null;
      } else if (o.type == 'Feature') {
        geom = o.geometry;
        rec = o.properties || {};
        if ('id' in o) {
          rec[idField] = o.id;
        }
      } else {
        geom = o;
      }
      // TODO: improve so geometry_type option skips features instead of creating null geometries
      if (geom && geom.type == 'GeometryCollection') {
        GeoJSON.importComplexFeature(importer, geom, rec, opts);
      } else if (opts.single_part && isMultiPartGeometry(geom)) {
        GeoJSON.importMultiAsSingles(importer, geom, rec, opts);
      } else {
        GeoJSON.importSimpleFeature(importer, geom, rec, opts);
      }
    };

    this.done = function() {
      return importer.done();
    };
  }

  GeoJSON.importComplexFeature = function(importer, geom, rec, opts) {
    var types = divideGeometriesByType(geom.geometries || []);
    if (types.length === 0) {
      importer.startShape(rec); // import a feature with null geometry
      return;
    }
    types.forEach(function(geometries, i) {
      importer.startShape(copyRecord(rec));
      geometries.forEach(function(geom) {
        GeoJSON.importSimpleGeometry(importer, geom, opts);
      });
    });
  };

  function divideGeometriesByType(geometries, index) {
    index = index || {};
    geometries.forEach(function(geom) {
      if (!geom) return;
      var mtype = GeoJSON.translateGeoJSONType(geom.type);
      if (mtype) {
        if (mtype in index === false) {
          index[mtype] = [];
        }
        index[mtype].push(geom);
      } else if (geom.type == 'GeometryCollection') {
        divideGeometriesByType(geom.geometries || [], index);
      }
    });
    return Object.values(index);
  }

  function isMultiPartGeometry(geom) {
    return geom && geom.type && geom.type.indexOf('Multi') === 0;
  }

  GeoJSON.importSimpleFeature = function(importer, geom, rec, opts) {
    importer.startShape(rec);
    GeoJSON.importSimpleGeometry(importer, geom, opts);
  };

  // Split a multi-part feature into several single features
  GeoJSON.importMultiAsSingles = function(importer, geom, rec, opts) {
    geom.coordinates.forEach(function(coords, i) {
      var geom2 = {
        type: geom.type.substr(5),
        coordinates: coords
      };
      var rec2 = i === 0 ? rec : copyRecord(rec);
      GeoJSON.importSimpleFeature(importer, geom2, rec2, opts);
    });
  };

  GeoJSON.importSimpleGeometry = function(importer, geom, opts) {
    var type = geom ? geom.type : null;
    if (type === null) ; else if (type in GeoJSON.pathImporters) {
      if (opts.geometry_type && opts.geometry_type != GeoJSON.translateGeoJSONType(type)) {
        // kludge to filter out all but one type of geometry
        return;
      }
      GeoJSON.pathImporters[type](geom.coordinates, importer);
    } else {
      verbose("Unsupported geometry type:", geom.type);
    }
  };


  // Functions for importing geometry coordinates using a PathImporter
  //
  GeoJSON.pathImporters = {
    LineString: function(coords, importer) {
      importer.importLine(coords);
    },
    MultiLineString: function(coords, importer) {
      for (var i=0; i<coords.length; i++) {
        GeoJSON.pathImporters.LineString(coords[i], importer);
      }
    },
    Polygon: function(coords, importer) {
      for (var i=0; i<coords.length; i++) {
        importer.importRing(coords[i], i > 0);
      }
    },
    MultiPolygon: function(coords, importer) {
      for (var i=0; i<coords.length; i++) {
        GeoJSON.pathImporters.Polygon(coords[i], importer);
      }
    },
    Point: function(coord, importer) {
      importer.importPoints([coord]);
    },
    MultiPoint: function(coords, importer) {
      importer.importPoints(coords);
    }
  };


  function importCRS(dataset, jsonObj) {
    if ('crs' in jsonObj) {
      dataset.info.input_geojson_crs = jsonObj.crs;
    }
  }

  var GeojsonImport = /*#__PURE__*/Object.freeze({
    __proto__: null,
    importGeoJSON: importGeoJSON,
    GeoJSONParser: GeoJSONParser,
    importCRS: importCRS
  });

  // Convert a TopoJSON topology into mapshaper's internal format
  // Side-effect: data in topology is modified
  //
  function importTopoJSON(topology, opts) {
    var dataset, arcs, layers;

    if (utils.isString(topology)) {
      topology = JSON.parse(topology);
    }

    if (topology.arcs && topology.arcs.length > 0) {
      // TODO: apply transform to ArcCollection, not input arcs
      if (topology.transform) {
        decodeArcs(topology.arcs, topology.transform);
      }

      if (opts && opts.precision) {
        roundCoords(topology.arcs, opts.precision);
      }

      arcs = new ArcCollection(topology.arcs);
    }

    layers = Object.keys(topology.objects).reduce(function(memo, name) {
      var layers = TopoJSON.importObject(topology.objects[name], arcs, opts),
          lyr;
      for (var i=0, n=layers.length; i<n; i++) {
        lyr = layers[i];
        lyr.name = name; // TODO: consider type-suffixes if different-typed layers
        memo.push(lyr);
      }
      return memo;
    }, []);

    layers.forEach(function(lyr) {
      if (layerHasPaths(lyr)) {
        // Cleaning here may be unnecessary
        // (cleanPathsAfterImport() is called in mapshaper-import.js)
        cleanShapes(lyr.shapes, arcs, lyr.geometry_type);
      }
      if (lyr.geometry_type == 'point' && topology.transform) {
        decodePoints(lyr.shapes, topology.transform);
      }
      if (lyr.data) {
        fixInconsistentFields(lyr.data.getRecords());
      }
    });

    dataset = {
      layers: layers,
      arcs: arcs,
      info: {}
    };
    importCRS(dataset, topology);
    if (topology.metadata) {
      importMetadata(dataset, topology.metadata);
    }
    return dataset;
  }

  function decodePoints(shapes, transform) {
    forEachPoint(shapes, function(p) {
      p[0] = p[0] * transform.scale[0] + transform.translate[0];
      p[1] = p[1] * transform.scale[1] + transform.translate[1];
    });
  }

  function decodeArcs(arcs, transform) {
    var mx = transform.scale[0],
        my = transform.scale[1],
        bx = transform.translate[0],
        by = transform.translate[1];

    arcs.forEach(function(arc) {
      var prevX = 0,
          prevY = 0,
          xy, x, y;
      for (var i=0, len=arc.length; i<len; i++) {
        xy = arc[i];
        x = xy[0] + prevX;
        y = xy[1] + prevY;
        xy[0] = x * mx + bx;
        xy[1] = y * my + by;
        prevX = x;
        prevY = y;
      }
    });
  }


  // TODO: consider removing dupes...
  function roundCoords(arcs, precision) {
    var round = getRoundingFunction(precision),
        p;
    arcs.forEach(function(arc) {
      for (var i=0, len=arc.length; i<len; i++) {
        p = arc[i];
        p[0] = round(p[0]);
        p[1] = round(p[1]);
      }
    });
  }

  TopoJSON.importObject = function(obj, arcs, opts) {
    var importer = new TopoJSON.GeometryImporter(arcs, opts);
    var geometries = obj.type == 'GeometryCollection' ? obj.geometries : [obj];
    geometries.forEach(importer.addGeometryObject, importer);
    return importer.done();
  };

  //
  //
  TopoJSON.GeometryImporter = function(arcs, opts) {
    var idField = opts && opts.id_field || GeoJSON.ID_FIELD,
        properties = [],
        shapes = [], // topological ids
        types = [],
        dataNulls = 0,
        collectionType = null,
        shapeId;

    this.addGeometryObject = function(geom) {
      var rec = geom.properties || null;
      shapeId = shapes.length;
      shapes[shapeId] = null;
      if ('id' in geom) {
        rec = rec || {};
        rec[idField] = geom.id;
      }
      properties[shapeId] = rec;
      if (!rec) dataNulls++;
      if (geom.type) {
        this.addShape(geom);
      }
    };

    this.addShape = function(geom) {
      var curr = shapes[shapeId];
      var type = GeoJSON.translateGeoJSONType(geom.type);
      var shape;
      if (geom.type == "GeometryCollection") {
        geom.geometries.forEach(this.addShape, this);
      } else if (type) {
        this.setGeometryType(type);
        shape = TopoJSON.shapeImporters[geom.type](geom, arcs);
        // TODO: better shape validation
        if (!shape || !shape.length) ; else if (!Array.isArray(shape[0])) {
          stop("Invalid TopoJSON", geom.type, "geometry");
        } else {
          shapes[shapeId] = curr ? curr.concat(shape) : shape;
        }
      } else if (geom.type) {
        stop("Invalid TopoJSON geometry type:", geom.type);
      }
    };

    this.setGeometryType = function(type) {
      var currType = shapeId < types.length ? types[shapeId] : null;
      if (!currType) {
        types[shapeId] = type;
        this.updateCollectionType(type);
      } else if (currType != type) {
        stop("Unable to import mixed-type TopoJSON geometries");
      }
    };

    this.updateCollectionType = function(type) {
      if (!collectionType) {
        collectionType = type;
      } else if (type && collectionType != type) {
        collectionType = 'mixed';
      }
    };

    this.done = function() {
      var layers;
      if (collectionType == 'mixed') {
        layers = divideFeaturesByType(shapes, properties, types);
      } else {
        layers = [{
          geometry_type: collectionType,
          shapes : collectionType ? shapes : null,
          data: dataNulls < shapes.length ? new DataTable(properties) : null
        }];
      }
      return layers;
    };
  };

  // TODO: check that interior ring bboxes are contained in external ring
  // TODO: check that rings are closed
  TopoJSON.importPolygonArcs = function(rings, arcs) {
    var ring = rings[0],
        imported = null, area;
    if (!arcs) stop("Invalid TopoJSON file: missing arc data.");
    area = ring ? geom.getPlanarPathArea(ring, arcs) : null;
    if (!area) {
      return null;
    }
    if (area < 0) reversePath(ring);
    imported = [ring];
    for (var i=1; i<rings.length; i++) {
      ring = rings[i];
      area = geom.getPlanarPathArea(ring, arcs);
      if (!area) continue;
      if (area > 0) reversePath(ring);
      imported.push(ring);
    }
    return imported;
  };

  TopoJSON.shapeImporters = {
    Point: function(geom) {
      return [geom.coordinates];
    },
    MultiPoint: function(geom) {
      return geom.coordinates;
    },
    LineString: function(geom) {
      return [geom.arcs];
    },
    MultiLineString: function(geom) {
      return geom.arcs;
    },
    Polygon: function(geom, arcColl) {
      return TopoJSON.importPolygonArcs(geom.arcs, arcColl);
    },
    MultiPolygon: function(geom, arcColl) {
      return geom.arcs.reduce(function(memo, arr) {
        var rings = TopoJSON.importPolygonArcs(arr, arcColl);
        if (rings) {
          memo = memo ? memo.concat(rings) : rings;
        }
        return memo;
      }, null);
    }
  };

  var TopojsonImport = /*#__PURE__*/Object.freeze({
    __proto__: null,
    importTopoJSON: importTopoJSON
  });

  // This is a JSON parser optimized for GeoJSON files.
  //
  // The native JSON parser, JSON.parse(), is limited by the maximum string
  // size, about ~536.8M chars in Node.
  // (See https://github.com/v8/v8/blob/ea56bf5513d0cbd2a35a9035c5c2996272b8b728/src/objects/string.h#L365).
  // This parser can parse much larger files -- it is limited by available memory.
  //
  // Performance:
  // In Node, this parser is about twice as fast as JSON.parse() when parsing
  // GeoJSON files containing mostly coordinate data and when coordinate precision
  // is less than the float64 maximum. Similar files with full-precision
  // coordinates see a smaller improvement. Files that contain mostly attribute
  // data (e.g. a typical Point feature file) may be parsed a bit slower than
  // JSON.parse().
  //
  // JSON parsing reference: https://www.json.org/json-en.html
  //
  var
    LBRACE = 123,
    RBRACE = 125,
    LBRACK = 91,
    RBRACK = 93,
    DQUOTE = 34,
    COMMA = 44;

  var EOF; // undefined is used as an EOF marker

  var RESERVE = 4096; // RESERVE is the number of bytes to keep in read buffer
  var BUFLEN = 1e7; // buffer chunk size
  var MAX_STRLEN = 5e6; // max byte len of a value string (object keys are shorter)

  // Parse from a Buffer or FileReader
  function parseJSON(arg) {
    var reader = isArrayLike(arg) ? new BufferReader(arg) : arg;
    var src = ByteReader(reader, 0);
    skipWS(src);
    var val = readValue(src);
    skipWS(src);
    if (src.peek() != EOF) {
      unexpectedCharAt(src.peek(), src.index());
    }
    return val;
  }

  // Parse data from:
  //  * FeatureCollection
  //  * GeometryCollection
  //  * Single Feature or Geometry
  //  * WS-delimited sequence of Features or geometries
  //
  // reader: FileReader or compatible reader
  // cb: callback function, called once for each parsed Feature or bare geometry
  //
  // Returns:
  //  * collections - top-level object with features/geometries array set to null
  //  * others - null
  //
  function parseGeoJSON(reader, cb) {
    var src = ByteReader(reader, 0);
    var isObject = seekObjectStart(src);
    if (!isObject) {
      stop('File is not GeoJSON');
    }
    var obj = readObject(src, cb);
    if (obj.type == 'FeatureCollection' || obj.type == 'GeometryCollection') {
      return obj;
    }
    if (!obj.type) { // TODO: validate type
      stop('Invalid GeoJSON');
    }
    cb(obj);
    // try to read newline-delimited GeoJSON
    skipWS(src);
    while (src.peek() == LBRACE) {
      cb(readObject(src, cb));
      skipWS(src);
    }
    return null;
  }


  function parseError(msg, i) {
    if (i >= 0) {
      msg += ' at position ' + i;
    }
    stop(msg);
  }

  function unexpectedCharAt(tok, i) {
    var msg;
    if (tok == EOF) {
      return parseError('Unexpected end of JSON input');
    }
    if (tok == DQUOTE) {
      msg = 'Unexpected string in JSON';
    } else if (tok < 33 || tok > 126) { // not ascii glyph
      msg = 'Unexpected token in JSON';
    } else {
      msg = 'Unexpected token ' + String.fromCharCode(tok) + ' in JSON';
    }
    parseError(msg, i);
  }

  function stringOverflow(i, c) {
    if (c == EOF) {
      parseError('Unterminated string in JSON', i);
    }
    parseError('Too-long string in JSON', i);
  }

  function seekObjectStart(src) {
    var c = src.getChar();
    var i = 0;
    while (c != EOF && i < RESERVE) {
      i++;
      if (c == LBRACE) {
        src.back();
        return true;
      }
      c = src.getChar();
    }
    return false;
  }

  function isWS(c) {
    return c == 32 || c == 10 || c == 13 || c == 9;
  }

  function skipWS(src) {
    while (isWS(src.peek())) src.advance();
  }

  function readArray(src) {
    var arr = [], c;
    eatChar(src, LBRACK);
    c = scanForSyntaxChar(src, RBRACK);
    while (c != RBRACK) {
      src.refresh();
      arr.push(readArrayElement(src));
      c = scanForAorB(src, COMMA, RBRACK);
    }
    return arr;
  }

  function readCollectionArray(src, cb) {
    var c;
    eatChar(src, LBRACK);
    c = scanForSyntaxChar(src, RBRACK);
    while (c != RBRACK) {
      src.refresh();
      cb(readArrayElement(src));
      c = scanForAorB(src, COMMA, RBRACK);
    }
  }

  // Using this function instead of readValue() to read array elements
  // gives up to a 25% reduction in overall processing time when parsing
  // coordinate-heavy GeoJSON files.
  function readArrayElement(src) {
    var i = src.index();
    var x, y, a, b;
    if (src.getChar() == LBRACK && isFirstNumChar(src.peek())) {
      x = readNumber(src);
      a = src.getChar();
      skipWS(src);
      if (a == COMMA && isFirstNumChar(src.peek())) {
        y = readNumber(src);
        b = src.getChar();
        if (b == RBRACK) {
          return [x, y];
        } else if (b == COMMA) {
          return extendArray(src, [x, y]);
        }
      }
    }
    // Fall back to general-purpose value reader
    src.index(i);
    return readValue(src);
  }

  function extendArray(src, arr) {
    skipWS(src);
    do {
      src.refresh(); // make make sure long arrays of numbers don't overflow
      arr.push(readValue(src));
    } while(scanForAorB(src, COMMA, RBRACK) == COMMA);
    return arr;
  }

  function eatChars(src, str) {
    for (var i = 0; i < str.length; i++) {
      eatChar(src, str.charCodeAt(i));
    }
    return true;
  }

  function eatChar(src, char) {
    var c = src.getChar();
    if (c != char) {
      unexpectedCharAt(c, src.index() - 1);
    }
  }

  // Reads and returns tok if tok is the next non-whitespace byte,
  // else returns null.
  // Scans past WS chars, both before and after tok
  function scanForSyntaxChar(src, tok) {
    skipWS(src);
    var c = src.peek();
    if (c === tok) {
      src.advance();
      skipWS(src);
      return tok;
    }
    return null;
  }

  // Assumes next char is the first char of a data object (not WS "," ":" "}" "]" etc)
  function readValue(src) {
    var c = src.peek();
    var val;
    if (isFirstNumChar(c)) val = readNumber(src);
    else if (c == LBRACK) val = readArray(src);
    else if (c == DQUOTE) val = readString(src);
    else if (c == LBRACE) val = readObject(src);
    else if (c == 110) val = readNull(src); // "n" -> null
    else if (c == 116) val = readTrue(src); // "t" -> true
    else if (c == 102) val = readFalse(src); // "f" -> false
    else unexpectedCharAt(c, src.index());
    return val;
  }

  function readTrue(src) {
    eatChars(src, 'true');
    return true;
  }

  function readFalse(src) {
    eatChars(src, 'false');
    return false;
  }

  function readNull(src) {
    eatChars(src, 'null');
    return null;
  }

  function scanForAorB(src, a, b) {
    skipWS(src);
    var c = src.getChar();
    if (c != a && c != b) unexpectedCharAt(c, src.index() - 1);
    skipWS(src);
    return c;
  }


  // cb: optional callback for returning GeoJSON features or geometries
  //
  function readObject(src, cb) {
    var o = {};
    var key, c;
    eatChar(src, LBRACE);
    c = scanForSyntaxChar(src, RBRACE);
    while (c != RBRACE) {
      src.refresh();
      key = readKeywordString(src); // optimization: use caching with object keys
      skipWS(src);
      eatChar(src, 58); // ":"
      skipWS(src);
      if ((key == 'features' || key == 'geometries') &&
          src.peek() == LBRACK && cb) {
        readCollectionArray(src, cb);
        o[key] = null;
      } else if (key == 'type' && src.peek() == DQUOTE) {
        o[key] = readKeywordString(src); // use caching with GeoJSON "type" params
      } else {
        o[key] = readValue(src);
      }
      c = scanForAorB(src, COMMA, RBRACE);
    }
    return o;
  }

  function growReserve() {
    RESERVE *= 2;
    return RESERVE <= MAX_STRLEN;
  }

  // Uses caching to speed up parsing of repeated strings.
  // The caching scheme used here can give a 20% overall speed improvement
  // when parsing files consisting mostly of attribute data (e.g. typical Point features)
  function readKeywordString(src) {
    var MAXLEN = 2000; // must be less than RESERVE
    var i = src.index();
    var cache = src.cache;
    var escapeNext = false;
    var n = 0;
    eatChar(src, DQUOTE);
    var c = src.getChar();
    while (c != DQUOTE || escapeNext === true) {
      n++;
      if (n > MAXLEN) {
        stringOverflow(i, c);
      }
      if (escapeNext) {
        escapeNext = false;
      } else if (c == 92) {
        escapeNext = true;
      }
      if (!cache[c]) {
        cache[c] = [];
      }
      cache = cache[c];
      c = src.getChar();
    }
    if (cache[0]) {
      return cache[0];
    }
    src.index(i);
    cache[0] = readString(src);
    return cache[0];
  }

  // Fast path for reading strings.
  // A slower fallback is used to read strings that are longer, non-ascii or
  // contain escaped chars
  function readString(src) {
    var i = src.index();
    eatChar(src, DQUOTE);
    var LIMIT = 256;
    var n = 0;
    var str = '';
    var c = src.getChar();
    while (c != DQUOTE) {
      n++;
      if (n > LIMIT || c == 92 || c < 32 || c > 126) {
        src.index(i);
        return readString_slow(src);
      }
      // String concatenation is faster than Buffer#toString()
      // (as tested with typical strings found in GeoJSON)
      str += String.fromCharCode(c);
      c = src.getChar();
    }
    return str;
  }

  // Fallback for reading long strings, escaped strings, non-ascii strings, etc.
  function readString_slow(src) {
    src.refresh();
    var LIMIT = RESERVE - 2;
    var i = src.index();
    var n = 0;
    var escapeNext = false;
    eatChar(src, DQUOTE);
    var c = src.getChar();
    var str;
    while (c != DQUOTE || escapeNext === true) {
      n++;
      if (n > LIMIT) {
        // we've exceeded the number of reserved bytes
        // expand the limit and try reading this string again
        if (c == EOF || !growReserve()) {
          stringOverflow(i, c);
        }
        src.index(i);
        return readString_slow(src);
      }
      if (escapeNext) {
        escapeNext = false;
      } else if (c == 92) {
        escapeNext = true;
      }
      c = src.getChar();
    }
    // skipping JSON.parse() is faster, but doesn't work when strings contain
    // escapes or a handful of ascii control characters.
    // str = src.toString(i + 1, n);
    str = JSON.parse(src.toString(i, n + 2));
    src.refresh();
    return str;
  }

  function isDigit(c) {
    return c >= 48 && c <= 57;
  }

  function isFirstNumChar(c) {
    return c >= 48 && c <= 57 || c == 45;
  }

  function isNumChar(c) {
    return c >= 48 && c <= 57 || c == 45 || c == 46 || c == 43 || c == 69 || c == 101;
  }


  // Correctly parses any valid JSON number
  // This function gives the correctly rounded result for numbers that are
  // incorrectly rounded using the fast method (a subset of numbers with >15 digits).
  function readNumber_slow(src) {
    var i = src.index();
    var n = 0;
    while (isNumChar(src.getChar())) {
      n++;
    }
    src.back();
    var str = src.toString(i, n);
    var num = Number(str);
    if (isNaN(num)) parseError('Invalid number in JSON', i);
    return num;
  }

  // Parses numbers quickly, falls back to a slower method when
  // correct fp rounding is not assured.
  function readNumber(src) {
    var i = src.index();
    var num = 0;
    var den = 1;
    var sign = 1;
    var oflo = false;
    var invalid = false;
    var c = src.getChar();
    var d0, d;
    if (c === 45) {
      sign = -1;
      c = src.getChar();
    }
    d0 = c;
    while (isDigit(c)) {
      d = c - 48;
      num = num * 10 + d;
      c = src.getChar();
    }
    if (num > 0 && d0 === 48) {
      // catch "01" "-01" etc.
      invalid = true;
    }
    if (c == 46) { // "."
      while (isDigit(c = src.getChar())) {
        d = c - 48;
        den *= 10;
        num = num * 10 + d;
      }
      if (den == 1 || d0 == 46) {
        // catch "1." "1.e" "-.1"
        invalid = true;
      }
    }
    if (num === 0 && d0 != 48) {
      invalid = true; // catch "-";
    }
    if (invalid) parseError('Invalid number in JSON', i);
    if (den > 1e22) oflo = true; // denominator gets rounded above this limit
    if (num >= 0x20000000000000) { // 2^53
      // Some numerators get rounded with > 52 bits of mantissa
      // (When numerator or denominator are rounded, dividing them may
      // not have the same result as JSON.parse() and the IEEE standard)
      // See: https://www.exploringbinary.com/fast-path-decimal-to-floating-point-conversion/
      if (num >= 0x40000000000000 || (d & 1) === 1) {
        // We don't need to fall back to the slow routine
        // for even integers with 53 bits
        // This optimization can reduce overall processing time by 15% for
        // GeoJSON files with full-precision coordinates.
        oflo = true;
      }
    }
    if (oflo || c == 69 || c == 101) { // e|E
      // Exponents are uncommon in GeoJSON... simpler to use slow function
      // than to parse manually and check for overflow and rounding errors
      src.index(i);
      return readNumber_slow(src);
    }
    src.back();
    return sign * num / den;
  }

  // Wrap a FileReader to support reading files one byte at a time.
  function ByteReader(reader, start) {
    var fileLen = reader.size();
    var bufOffs = start;
    var buf = reader.readSync(bufOffs, BUFLEN);
    var i = 0;
    var obj = { peek, getChar, advance, back, toString, index, refresh };
    obj.cache = []; // kludgy place to put the key cache
    refresh();
    return obj;

    // This function should be called to make sure that the buffer has enough
    // bytes remaining to read any reasonable JSON content.
    function refresh() {
      // if RESERVE bytes are still available in the buffer, no update is required
      if (buf.length - i >= RESERVE) return;

      // CHANGE: now using undefined as an EOF marker, so a bounds check is unneeded
      // // if we're close to the end of the file, start checking for overflow
      // // (we don't do this all the time because the bounds check on every read
      // // causes a significant slowdown, as much as 20%)
      // if (fileLen - (bufOffs + i) < RESERVE) {
      //   obj.peek = safePeek;
      //   obj.getChar = safeGetChar;
      // }

      // if buffer reaches the end of the file, no update is required
      if (bufOffs + buf.length >= fileLen) return;

      // fewer than RESERVE bytes are unread in buffer -- update the buffer
      bufOffs += i;
      i = 0;
      buf = reader.readSync(bufOffs, BUFLEN);
    }
    function peek() {
      return buf[i];
    }
    function getChar() {
      return buf[i++];
    }
    function advance() {
      i++;
    }
    function back() {
      i--;
    }
    function index(idx) {
      if (idx >= 0 === false) return i + bufOffs;
      i = idx - bufOffs;
    }
    function toString(idx, n) {
      var i = idx - bufOffs;
      return buf.toString("utf8", i, i + n);
    }
  }

  // Identify JSON type from the initial subset of a JSON string
  function identifyJSONString(str, opts) {
    var maxChars = 1000;
    var fmt = null;
    if (str.length > maxChars) str = str.substr(0, maxChars);
    str = str.replace(/\s/g, '');
    if (opts && opts.json_path) {
      fmt = 'json'; // TODO: make json_path compatible with other types
    } else if (/^\[[{\]]/.test(str)) {
      // empty array or array of objects
      fmt = 'json';
    } else if (/"arcs":\[|"objects":\{|"transform":\{/.test(str)) {
      fmt =  'topojson';
    } else if (/^\{"/.test(str)) {
      fmt = 'geojson';
    }
    return fmt;
  }

  function identifyJSONObject(o) {
    var fmt = null;
    if (!o) ; else if (o.type == 'Topology') {
      fmt = 'topojson';
    } else if (o.type) {
      fmt = 'geojson';
    } else if (utils.isArray(o)) {
      fmt = 'json';
    }
    return fmt;
  }

  function importGeoJSONFile(fileReader, opts) {
    var importer = new GeoJSONParser(opts);
    parseGeoJSON(fileReader, importer.parseObject);
    // TODO: examine top-level objects, like crs
    return importer.done();
  }

  // Parse GeoJSON directly from a binary data source (supports parsing larger files
  // than the maximum JS string length) or return a string with the entire
  // contents of the file.
  // reader: a binary file reader
  //
  function readJSONFile(reader, opts) {
    var str = readFirstChars(reader, 1000);
    var type = identifyJSONString(str, opts);
    var dataset, retn;
    if (type == 'geojson') { // consider only for larger files
      dataset = importGeoJSONFile(reader, opts);
      retn = {
        dataset: dataset,
        format: 'geojson'
      };
    } else {
      retn = {
        // content: cli.readFile(path, 'utf8')}
        content: reader.toString('utf8')
      };
    }
    reader.close();
    return retn;
  }

  function importJSON(data, opts) {
    var content = data.content,
        filename = data.filename,
        retn = {filename: filename},
        reader, fmt;

    if (!content) {
      reader = new FileReader(filename);
    } else if (content instanceof ArrayBuffer || content instanceof B$3 || content instanceof Uint8Array) {
      // Web API imports JSON as ArrayBuffer, to support larger files
      if ((content.byteLength || content.length) < 1e7) {
        // content = utils.createBuffer(content).toString();
        content = bufferToString(utils.createBuffer(content));
      } else {
        reader = new BufferReader(content);
        content = null;
      }
    }

    if (reader) {
      data = readJSONFile(reader, opts);
      if (data.dataset) {
        retn.dataset = data.dataset;
        retn.format = data.format;
      } else {
        content = data.content;
      }
    }

    if (content) {
      if (utils.isString(content)) {
        try {
          content = JSON.parse(content); // ~3sec for 100MB string
        } catch(e) {
          // stop("Unable to parse JSON");
          stop('JSON parsing error:', e.message);
        }
      }
      if (opts.json_path) {
        content = selectFromObject(content, opts.json_path);
        fmt = identifyJSONObject(content);
        if (!fmt) {
          stop('Unexpected object type at JSON path:', opts.json_path);
        }
      } else {
        fmt = identifyJSONObject(content);
      }
      if (fmt == 'topojson') {
        retn.dataset = importTopoJSON(content, opts);
      } else if (fmt == 'geojson') {
        retn.dataset = importGeoJSON(content, opts);
      } else if (fmt == 'json') {
        retn.dataset = importJSONTable(content);
      } else {
        stop("Unknown JSON format");
      }
      retn.format = fmt;
    }

    return retn;
  }

  // path: path from top-level to the target object
  function selectFromObject(o, path) {
    var arrayRxp = /(.*)\[([0-9]+)\]$/; // array bracket notation w/ index
    var separator = path.indexOf('/') > 0 ? '/' : '.';
    var parts = path.split(separator);
    var subpath, array, match;

    while (parts.length > 0) {
      subpath = parts.shift();
      match = arrayRxp.exec(subpath);
      if (match) {
        array = o[match[1]];
        o = array && array[+match[2]] || null;
      } else {
        o = o[subpath];
      }
      if (!o) return null;
    }
    return o;
  }

  var JsonImport = /*#__PURE__*/Object.freeze({
    __proto__: null,
    identifyJSONString: identifyJSONString,
    identifyJSONObject: identifyJSONObject,
    importGeoJSONFile: importGeoJSONFile,
    importJSON: importJSON
  });

  function importKML(str, opts) {
    var togeojson = require$1("@tmcw/togeojson");
    var Parser = typeof DOMParser == 'undefined' ? require$1("@xmldom/xmldom").DOMParser : DOMParser;
    var geojson = togeojson.kml(new Parser().parseFromString(str, "text/xml"));
    return importGeoJSON(geojson, opts || {});
  }

  // Parse content of one or more input files and return a dataset
  // @obj: file data, indexed by file type
  // File data objects have two properties:
  //    content: Uint8Array, Buffer, ArrayBuffer, String or Object
  //    filename: String or null
  //
  function importContent(obj, opts) {
    var dataset, fileFmt, data;
    opts = opts || {};
    if (obj.json) {
      data = importJSON(obj.json, opts);
      fileFmt = data.format;
      dataset = data.dataset;
      cleanPathsAfterImport(dataset, opts);

    } else if (obj.text) {
      fileFmt = 'dsv';
      data = obj.text;
      dataset = importDelim2(data, opts);

    } else if (obj.shp) {
      fileFmt = 'shapefile';
      data = obj.shp;
      dataset = importShapefile(obj, opts);
      cleanPathsAfterImport(dataset, opts);

    } else if (obj.dbf) {
      fileFmt = 'dbf';
      data = obj.dbf;
      dataset = importDbf(obj, opts);

    } else if (obj.prj) {
      // added for -proj command source
      fileFmt = 'prj';
      data = obj.prj;
      dataset = {layers: [], info: {prj: data.content}};

    } else if (obj.kml) {
      fileFmt = 'kml';
      data = obj.kml;
      dataset = importKML(data.content, opts);
    }

    if (!dataset) {
      stop("Missing an expected input type");
    }

    // Convert to topological format, if needed
    if (dataset.arcs && !opts.no_topology && fileFmt != 'topojson') {
      buildTopology(dataset);
    }

    // Use file basename for layer name, except TopoJSON, which uses object names
    if (fileFmt != 'topojson') {
      dataset.layers.forEach(function(lyr) {
        if (!lyr.name) {
          lyr.name = filenameToLayerName(data.filename || '');
        }
      });
    }

    // Add input filename and format to the dataset's 'info' object
    // (this is useful when exporting if format or name has not been specified.)
    if (data.filename) {
      dataset.info.input_files = [data.filename];
    }
    dataset.info.input_formats = [fileFmt];
    return dataset;
  }

  // Deprecated (included for compatibility with older tests)
  function importFileContent(content, filename, opts) {
    var type = guessInputType(filename, content),
        input = {};
    input[type] = {filename: filename, content: content};
    return importContent(input, opts);
  }


  function importShapefile(obj, opts) {
    var shpSrc = obj.shp.content || obj.shp.filename, // read from a file if (binary) content is missing
        shxSrc = obj.shx ? obj.shx.content || obj.shx.filename : null,
        dataset = importShp(shpSrc, shxSrc, opts),
        lyr = dataset.layers[0],
        dbf;
    if (obj.dbf) {
      dbf = importDbf(obj, opts);
      utils.extend(dataset.info, dbf.info);
      lyr.data = dbf.layers[0].data;
      if (lyr.shapes && lyr.data.size() != lyr.shapes.length) {
        message("Mismatched .dbf and .shp record count -- possible data loss.");
      }
    }
    if (obj.prj) {
      dataset.info.prj = obj.prj.content;
    }
    if (obj.cpg) {
      // TODO: consider using the input encoding as the default output encoding
      dataset.info.cpg = obj.cpg.content;
      if (typeof dataset.info.cpg != 'string') {
        error('Invalid encoding argument, expected a string');
      }
    }
    return dataset;
  }

  function importDbf(input, opts) {
    var table;
    opts = utils.extend({}, opts);
    if (input.cpg && !opts.encoding) {
      opts.encoding = input.cpg.content;
    }
    table = importDbfTable(input.dbf.content || input.dbf.filename, opts);
    return {
      info: {},
      layers: [{data: table}]
    };
  }

  function filenameToLayerName(path) {
    var name = 'layer1';
    var obj = parseLocalPath(path);
    if (obj.basename && obj.extension) { // exclude paths like '/dev/stdin'
      name = obj.basename;
    }
    return name;
  }

  var Import = /*#__PURE__*/Object.freeze({
    __proto__: null,
    importContent: importContent,
    importFileContent: importFileContent
  });

  // Import datasets contained in a BSON blob
  // Return command target as a dataset
  //
  async function unpackSessionData(buf) {
    return restoreSessionData(unpack(buf, {}));
  }

  async function restoreSessionData(obj) {
    if (!isValidSession(obj)) {
      stop('Invalid mapshaper session data object');
    }
    var datasets = await Promise.all(obj.datasets.map(importDataset));
    datasets = datasets.filter(Boolean); // skip corrupted datasets
    return Object.assign(obj, {datasets: datasets});
  }

  function isValidSession(obj) {
    if (!Array.isArray(obj.datasets)) {
      return false;
    }
    return true;
  }

  async function importDataset(obj) {
    var arcs = null;
    var layers = (obj.layers || []).map(importLayer);
    try {
      if (obj.arcs) {
        arcs = await importArcs(obj.arcs);
      }
    } catch(e) {
      warn(`Some coordinates are corrupted, skipping ${layers.length == 1 ? 'a layer' : layers.length + ' layers'}.`);
      return null;
    }

    return {
      info: await importInfo(obj.info || {}),
      layers: layers,
      arcs: arcs
    };
  }

  function bufferToDataView(buf, constructor) {
    return new constructor(BinArray.copyToArrayBuffer(buf));
    // this doesn't work: "RangeError: start offset of Float64Array should be a multiple of 8"
    // return new constructor(buf.buffer, buf.byteOffset, buf.byteLength);
  }

  async function importArcs(obj) {
    if (isGzipped(obj.xx)) {
      var promises = [];
      promises.push(gunzipAsync(obj.nn));
      promises.push(gunzipAsync(obj.xx));
      promises.push(gunzipAsync(obj.yy));
      if (obj.zz) {
        promises.push(gunzipAsync(obj.zz));
      }
      var data = await Promise.all(promises);
      obj.nn = data.shift();
      obj.xx = data.shift();
      obj.yy = data.shift();
      if (obj.zz) {
        obj.zz = data.shift();
      }
    }
    var nn = bufferToDataView(obj.nn, Uint32Array);
    var xx = bufferToDataView(obj.xx, Float64Array);
    var yy = bufferToDataView(obj.yy, Float64Array);
    var arcs = new ArcCollection(nn, xx, yy);
    if (obj.zz) {
      arcs.setThresholds(bufferToDataView(obj.zz, Float64Array));
      arcs.setRetainedInterval(obj.zlimit);
    }
    return arcs;
  }

  async function importInfo(o) {
    if (o.crs_string) {
      // load external files (e.g. epsg definitions) if needed in GUI
      await initProjLibrary({crs: o.crs_string});
      o.crs = parseCrsString(o.crs_string);
    } else if (o.prj) {
      o.crs = parsePrj(o.prj);
    }
    return o;
  }

  function importLayer(lyr) {
    var data = lyr.data;
    if (data) {
      data = importTable(data);
    }
    return Object.assign(lyr, {
      data: lyr.data ? new DataTable(data) : null
    });
  }

  var Unpack = /*#__PURE__*/Object.freeze({
    __proto__: null,
    unpackSessionData: unpackSessionData,
    restoreSessionData: restoreSessionData
  });

  cmd.importFiles = async function(catalog, opts) {
    var files = opts.files || [];
    var dataset;

    if (opts.stdin) {
      dataset = importFile('/dev/stdin', opts);
      catalog.addDataset(dataset);
      return dataset;
    }

    if (files.length > 0 === false) {
      stop('Missing input file(s)');
    }

    verbose("Importing: " + files.join(' '));

    // copy opts, so parameters can be modified within this command
    opts = Object.assign({}, opts);
    opts.input = Object.assign({}, opts.input); // make sure we have a cache

    convertDataObjects(files, opts.input);

    files = expandFiles(files, opts.input);

    if (files.length === 0) {
      stop('Missing importable files');
    }

    // special case: package file
    if (files.some(isPackageFile)) {
      if (files.length > 1) {
        stop('Expected a single package file');
      }
      dataset = await importMshpFile(files[0], catalog, opts);
      return dataset;
    }

    if (files.length == 1) {
      dataset = importFile(files[0], opts);
    } else {
      dataset = importFilesTogether(files, opts);
    }

    if (opts.merge_files && files.length > 1) {
      // TODO: deprecate and remove this option (use -merge-layers cmd instead)
      dataset.layers = cmd.mergeLayers(dataset.layers);
    }

    catalog.addDataset(dataset);
    return dataset;
  };

  // replace any JSON data objects with filenames and cache the data
  function convertDataObjects(files, cache) {
    var names = files.map(str => stringLooksLikeJSON(str) ? 'layer.json' : null).filter(Boolean);
    if (names.length === 0) return;
    if (names.length > 1) {
      // make unique names if importing multiple objects
      names = utils.uniqifyNames(names, formatVersionedFileName);
    }
    files.forEach((str, i) => {
      if (!stringLooksLikeJSON(str)) return;
      var name = names.shift();
      cache[name] = str;
      files[i] = name;
    });
  }

  async function importMshpFile(file, catalog, opts) {
    var buf = cli.readFile(file, null, opts.input);
    var obj = await unpackSessionData(buf);
    obj.datasets.forEach(catalog.addDataset, catalog);
    return obj.target;
  }

  function expandFiles(files, cache) {
    var files2 = [];
    files.forEach(function(file) {
      var expanded;
      if (isZipFile(file)) {
        expanded = expandZipFile(file, cache);
      } else if (isKmzFile(file)) {
        expanded = expandKmzFile(file, cache);
      } else {
        expanded = [file]; // ordinary file, no change
      }
      files2 = files2.concat(expanded);
    });
    return files2;
  }

  function expandKmzFile(file, cache) {
    var files = expandZipFile(file, cache);
    var name = replaceFileExtension(parseLocalPath(file).filename, 'kml');
    if (files[0] == 'doc.kml') {
      files[0] = name;
      cache[name] = cache['doc.kml'];
    }
    return files;
  }

  function expandZipFile(file, cache) {
    var input;
    if (file in cache) {
      input = cache[file];
    } else {
      input = file;
      cli.checkFileExists(file);
    }
    var index = unzipSync(input);
    Object.assign(cache, index);
    return findPrimaryFiles(index);
  }

  // Return the names of primary files in a file cache
  // (exclude auxiliary files, which can't be converted into datasets)
  function findPrimaryFiles(cache) {
    return Object.keys(cache).filter(function(filename) {
      var type = guessInputFileType(filename);
      if (type == 'dbf') {
        // don't import .dbf separately if .shp is present
        if (replaceFileExtension(filename, 'shp') in cache) return false;
      }
      return type && !isAuxiliaryInputFileType(type);
    });
  }

  // Let the web UI replace importFile() with a browser-friendly version
  function replaceImportFile(func) {
    _importFile = func;
  }

  function importFile(path, opts) {
    return _importFile(path, opts);
  }

  var _importFile = function(path, opts) {
    var fileType = guessInputFileType(path),
        input = {},
        encoding = opts && opts.encoding || null,
        cache = opts && opts.input || null,
        cached = cache && (path in cache),
        content;

    cli.checkFileExists(path, cache);

    if ((fileType == 'shp' || fileType == 'json' || fileType == 'text' || fileType == 'dbf') && !cached) {
      // these file types are read incrementally
      content = null;

    } else if (fileType && isSupportedBinaryInputType(path)) {
      content = cli.readFile(path, null, cache);
      if (utils.isString(content)) {
        // Fix for issue #264 (applyCommands() input is file path instead of binary content)
        stop('Expected binary content, received a string');
      }

    } else if (fileType) { // string type, e.g. kml, geojson
      content = cli.readFile(path, encoding || 'utf-8', cache);

    } else if (getFileExtension(path) == 'gz') {
      var pathgz = path;
      path = pathgz.replace(/\.gz$/, '');
      fileType = guessInputFileType(path);
      if (!fileType) {
        stop('Unrecognized file type:', path);
      }
      content = gunzipSync(cli.readFile(pathgz, null, cache), path);

    } else { // type can't be inferred from filename -- try reading as text
      content = cli.readFile(path, encoding || 'utf-8', cache);
      fileType = guessInputContentType(content);
      if (fileType == 'text' && content.indexOf('\ufffd') > -1) {
        // invalidate string data that contains the 'replacement character'
        fileType = null;
      }
    }

    if (!fileType) {
      stop(getUnsupportedFileMessage(path));
    }
    input[fileType] = {filename: path, content: content};
    content = null; // for g.c.
    if (fileType == 'shp' || fileType == 'dbf') {
      readShapefileAuxFiles(path, input, cache);
    }
    if (fileType == 'shp' && !input.dbf) {
      message(utils.format("[%s] .dbf file is missing - shapes imported without attribute data.", path));
    }
    return importContent(input, opts);
  };

  // Import multiple files to a single dataset
  function importFilesTogether(files, opts) {
    var unbuiltTopology = false;
    var datasets = files.map(function(fname) {
      // import without topology or snapping
      var importOpts = utils.defaults({no_topology: true, snap: false, snap_interval: null, files: [fname]}, opts);
      var dataset = importFile(fname, importOpts);
      // check if dataset contains non-topological paths
      // TODO: may also need to rebuild topology if multiple topojson files are merged
      if (dataset.arcs && dataset.arcs.size() > 0 && dataset.info.input_formats[0] != 'topojson') {
        unbuiltTopology = true;
      }
      return dataset;
    });
    var combined = mergeDatasets(datasets);
    // Build topology, if needed
    // TODO: consider updating topology of TopoJSON files instead of concatenating arcs
    // (but problem of mismatched coordinates due to quantization in input files.)
    if (unbuiltTopology && !opts.no_topology) {
      cleanPathsAfterImport(combined, opts);
      buildTopology(combined);
    }
    return combined;
  }

  function getUnsupportedFileMessage(path) {
    var ext = getFileExtension(path);
    var msg = 'Unable to import ' + path;
    if (ext.toLowerCase() == 'zip') {
      msg += ' (ZIP files must be unpacked before running mapshaper)';
    } else {
      msg += ' (unknown file type)';
    }
    return msg;
  }

  function readShapefileAuxFiles(path, obj, cache) {
    var dbfPath = replaceFileExtension(path, 'dbf');
    var shxPath = replaceFileExtension(path, 'shx');
    var cpgPath = replaceFileExtension(path, 'cpg');
    var prjPath = replaceFileExtension(path, 'prj');
    if (cli.isFile(prjPath, cache)) {
      obj.prj = {filename: prjPath, content: cli.readFile(prjPath, 'utf-8', cache)};
    }
    if (cli.isFile(shxPath, cache)) {
      obj.shx = {filename: shxPath, content: cli.readFile(shxPath, null, cache)};
    }
    if (!obj.dbf && cli.isFile(dbfPath, cache)) {
      // obj.dbf = {filename: dbfPath, content: cli.readFile(dbfPath, null, cache)};
      obj.dbf = {
        filename: dbfPath,
        content: (cache && (dbfPath in cache)) ? cli.readFile(dbfPath, null, cache) : null
      };
    }
    if (obj.dbf && cli.isFile(cpgPath, cache)) {
      obj.cpg = {filename: cpgPath, content: cli.readFile(cpgPath, 'utf-8', cache).trim()};
    }
  }

  var FileImport = /*#__PURE__*/Object.freeze({
    __proto__: null,
    replaceImportFile: replaceImportFile,
    importFile: importFile,
    importFilesTogether: importFilesTogether
  });

  function convertSourceName(name, targets) {
    if (!nameIsInterpolated(name)) return name;
    if (targets.length > 1 || targets[0].layers.length != 1) {
      stop("Interpolated names are not compatible with multiple targets.");
    }
    return convertInterpolatedName(name, targets[0].layers[0]);
  }

  function convertInterpolatedName(name, lyr) {
    var ctx = {target: lyr.name || ''};
    var body = 'with($$ctx) { return `' + name + '`; }';
    var func;
    try {
      func = new Function("$$ctx", body);
      name = func(ctx);
    } catch(e) {
      stop("Unable to interpolate [" + name + "]");
    }
    return name;
  }

  function nameIsInterpolated(name) {
    return /[$][{]/.test(name);
  }

  function findCommandSource(sourceName, catalog, opts) {
    var source = catalog.findSingleLayer(sourceName);
    var sourceDataset;
    if (!source) {
      // assuming opts.source is a filename
      // don't need to build topology, because:
      //    join -- don't need topology
      //    clip/erase -- topology is built later, when datasets are combined
      sourceDataset = importFile(sourceName, utils.defaults({no_topology: true}, opts));
      if (!sourceDataset) {
        stop(utils.format('Unable to find source [%s]', sourceName));
      } else if (sourceDataset.layers.length > 1) {
        stop('Multiple-layer sources are not supported');
      }
      // mark as disposable to indicate that data can be mutated
      source = {dataset: sourceDataset, layer: sourceDataset.layers[0], disposable: true};
    }
    return source;
  }

  var SourceUtils = /*#__PURE__*/Object.freeze({
    __proto__: null,
    convertSourceName: convertSourceName,
    convertInterpolatedName: convertInterpolatedName,
    findCommandSource: findCommandSource
  });

  // Catalog contains zero or more multi-layer datasets
  // One layer is always "active", corresponding to the currently selected
  //   layer in the GUI or the current target in the CLI
  function Catalog() {
    var datasets = [],
        defaultTargets = [];// saved default command targets [{layers:[], dataset}, ...]

    this.forEachLayer = function(cb) {
      var i = 0;
      datasets.forEach(function(dataset) {
        dataset.layers.forEach(function(lyr) {
          cb(lyr, dataset, i++);
        });
      });
    };

    // remove a layer from a dataset
    this.deleteLayer = function(lyr, dataset) {
      // if deleting first target layer (selected in gui) -- switch to some other layer
      if (this.getActiveLayer().layer == lyr) {
        defaultTargets = [];
      }

      // remove layer from its dataset
      dataset.layers.splice(dataset.layers.indexOf(lyr), 1);
      if (dataset.layers.length === 0) {
        this.removeDataset(dataset);
      }

      // remove layer from defaultTargets
      defaultTargets = defaultTargets.filter(function(targ) {
        var i = targ.layers.indexOf(lyr);
        if (i == -1) return true;
        targ.layers.splice(i, 1);
        return targ.layers.length > 0;
      });
    };

    // @arg: a layer object or a test function
    this.findLayer = function(arg) {
      var test = typeof arg == 'function' ? arg : null;
      var found = null;
      this.forEachLayer(function(lyr, dataset) {
        if (test ? test(lyr, dataset) : lyr == arg) {
          found = layerObject(lyr, dataset);
        }
      });
      return found;
    };

    this.findCommandTargets = function(pattern, type) {
      if (!pattern) return this.getDefaultTargets() || [];
      return findCommandTargets(this.getLayers(), pattern, type);
    };

    this.findSingleLayer = function(pattern) {
      var matches = findMatchingLayers(this.getLayers(), pattern);
      if (matches.length > 1) {
        stop('Ambiguous pattern (multiple layers were matched):', pattern);
      }
      return matches[0] || null;
    };

    this.clear = function() {
      datasets = [];
      defaultTargets = [];
    };

    this.removeDataset = function(dataset) {
      defaultTargets = defaultTargets.filter(function(targ) {
        return targ.dataset != dataset;
      });
      datasets = datasets.filter(function(d) {
        return d != dataset;
      });
    };

    this.getDatasets = function() {
      return datasets;
    };

    this.getLayers = function() {
      var layers = [];
      this.forEachLayer(function(lyr, dataset) {
        layers.push(layerObject(lyr, dataset));
      });
      return layers;
    };

    this.addDataset = function(dataset) {
      this.setDefaultTarget(dataset.layers, dataset);
      return this;
    };

    this.addDatasets = function(datasets) {
      datasets.forEach(function(dataset) {
        this.addDataset(dataset);
      }, this);
    };

    this.findNextLayer = function(lyr) {
      var layers = this.getLayers(),
          idx = indexOfLayer(lyr, layers);
      return idx > -1 ? layers[(idx + 1) % layers.length] : null;
    };

    this.findPrevLayer = function(lyr) {
      var layers = this.getLayers(),
          idx = indexOfLayer(lyr, layers);
      return idx > -1 ? layers[(idx - 1 + layers.length) % layers.length] : null;
    };

    this.isEmpty = function() {
      return datasets.length === 0;
    };

    this.getDefaultTargets = function() {
      if (defaultTargets.length === 0 && !this.isEmpty()) {
        defaultTargets = [{dataset: datasets[0], layers: datasets[0].layers.slice(0, 1)}];
      }
      return defaultTargets;
    };

    this.setDefaultTarget = function(layers, dataset) {
      this.setDefaultTargets([{
        // Copy layers array, in case layers is a reference to dataset.layers.
        // This prevents layers that are added to the dataset inside a command from
        //  being added to the next command's target, e.g. debugging layers added
        //  by '-join unmatched unjoined'.
        layers: layers.concat(),
        dataset: dataset
      }]);
    };

    // arr: array of target objects {layers:[], dataset:{}}
    this.setDefaultTargets = function(arr) {
      arr.forEach(function(target) {
        if (datasets.indexOf(target.dataset) == -1) {
          datasets.push(target.dataset);
        }
      });
      defaultTargets = arr;
    };

    // should be in gui-model.js, moved here for testing
    this.getActiveLayer = function() {
      var targ = (this.getDefaultTargets() || [])[0];
      // var lyr = targ.layers[0];
      // Reasons to select the last layer of a multi-layer target:
      // * This layer was imported last
      // * This layer is displayed on top of other layers
      // * This layer is at the top of the layers list
      // * In TopoJSON input, it makes sense to think of the last object/layer
      //   as the topmost one -- it corresponds to the painter's algorithm and
      //   the way that objects are ordered in SVG.
      var lyr = targ?.layers[targ.layers.length - 1];
      return targ ? {layer: lyr, dataset: targ.dataset} : null;
    };

    function layerObject(lyr, dataset) {
      return {
        layer: lyr,
        dataset: dataset
      };
    }

    function indexOfLayer(lyr, layers) {
      var idx = -1;
      layers.forEach(function(o, i) {
        if (o.layer == lyr) idx = i;
      });
      return idx;
    }
  }

  function getFormattedLayerList(catalog) {
    var lines = [];
    catalog.forEachLayer(function(lyr, dataset, i) {
      lines.push('  [' + (i+1) + ']  ' + (lyr.name || '[unnamed]'));
    });
    return lines.length > 0 ? lines.join('\n') : '[none]';
  }

  var Catalog$1 = /*#__PURE__*/Object.freeze({
    __proto__: null,
    Catalog: Catalog,
    getFormattedLayerList: getFormattedLayerList
  });

  function Job(catalog) {
    var currentCmd;

    var job = {
      catalog: catalog || new Catalog(),
      defs: {},
      settings: {},
      input_files: []
    };

    job.initSettings = function(o) {
      job.settings = o;
      stashVars(job, {});
    };

    job.startCommand = function(cmd) {
      currentCmd = cmd;
      stashVars(job, cmd);
    };

    // Rejected the idea of passing a command reference to compare with the initial command
    // (for error checking) ... the "-run" command inserts other commands before this call
    job.endCommand = function() {
      currentCmd = null;
      clearStash();
    };

    job.resumeCommand = function() {
      stashVars(job, currentCmd);
    };

    return job;
  }

  function stashVars(job, cmd) {
    clearStash();  // prevent errors from overwriting stash
    stashVar('current_command', cmd.name);
    stashVar('DEBUG', job.settings.DEBUG || cmd.debug);
    stashVar('VERBOSE', job.settings.VERBOSE || cmd.verbose);
    stashVar('QUIET', job.settings.QUIET || cmd.quiet);
    stashVar('defs', job.defs);
    stashVar('input_files', job.input_files);
  }

  // Apply a command to an array of target layers
  function applyCommandToEachLayer(func, targetLayers) {
    var args = utils.toArray(arguments).slice(2);
    var output = targetLayers.reduce(function(memo, lyr) {
      var result = func.apply(null, [lyr].concat(args));
      if (utils.isArray(result)) { // some commands return an array of layers
        memo = memo.concat(result);
      } else if (result) { // assuming result is a layer
        memo.push(result);
      }
      return memo;
    }, []);
    return output.length > 0 ? output : null;
  }

  function applyCommandToEachTarget(func, targets) {
    var args = utils.toArray(arguments).slice(2);
    targets.forEach(function(target) {
      var result = func.apply(null, [target].concat(args));
      if (result) {
        error('Unexpected output from command');
      }
    });
  }

  cmd.addShape = addShape;

  function addShape(targetLayers, targetDataset, opts) {
    if (targetLayers.length > 1) {
      stop('Command expects a single target layer');
    }
    var targetLyr = targetLayers[0]; // may be undefined
    var targetType = !opts.no_replace && targetLyr && targetLyr.geometry_type || null;
    var dataset = importGeoJSON(toFeature(opts, targetType));
    var outputLyr = mergeDatasetsIntoDataset(targetDataset, [dataset])[0];
    if (opts.no_replace || !targetLyr) {
      // create new layer
      setOutputLayerName(outputLyr, targetLyr && targetLyr.name, null, opts);
      return [outputLyr];
    }
    // merge into target layer
    return cmd.mergeLayers([targetLyr, outputLyr], {force: true});
  }

  function toFeature(opts, geomType) {
    if (opts.geojson) {
      return parseArg(opts.geojson);
    }

    var geom = opts.coordinates && parseCoordsAsGeometry(opts.coordinates) || null;

    if (!geom) {
      stop('Missing required shape coordinates');
    }

    if (geomType == 'point' && geom.type != 'Point') {
      stop('Expected point coordinates, received', geom.type);
    }

    if (geomType == 'polygon' && geom.type != 'Polygon') {
      stop('Expected polygon coordinates, received', geom.type);
    }

    if (geomType == 'polyline') {
      if (geom.type == 'Polygon') {
        geom.coordinates = geom.coordinates[0];
        geom.type = 'LineString';
      } else {
        stop('Expected polyline coordinates, received', geom.type);
      }
    }

    return {
      type: 'Feature',
      properties: parseProperties(opts.properties),
      geometry: geom
    };
  }

  function parseArg(obj) {
    return typeof obj == 'string' ? JSON.parse(obj) : obj;
  }

  function parseProperties(arg) {
    if (!arg) return null;
    return parseArg(arg);
  }

  function isArrayOfNumbers(arr) {
    return arr.length >= 2 && arr.every(utils.isNumber);
  }

  function isClosedPath$1(arr) {
    return isArrayOfPoints(arr) && arr.length > 3 && samePoint$1(arr[0], arr[arr.length - 1]);
  }

  function samePoint$1(a, b) {
    return a[0] == b[0] && a[1] == b[1];
  }

  function isArrayOfPoints(arr) {
    return arr.every(isPoint);
  }

  function isPoint(arr) {
    return arr && arr.length == 2 && isArrayOfNumbers(arr);
  }

  function transposeCoords(arr) {
    var coords = [];
    for (var i=0; i<arr.length; i+=2) {
      coords.push([arr[i], arr[i+1]]);
    }
    if (!isArrayOfPoints(coords)) {
      stop('Unable to parse x,y,x,y... coordinates');
    }
    return coords;
  }

  function parseCoordsAsGeometry(arg) {
    if (typeof arg == 'string') {
      arg = arg.trim();
      if (!arg.startsWith('[') && !arg.endsWith(']')) {
        arg = '[' + arg + ']';
      }
    }
    var arr = parseArg(arg);
    if (isPoint(arr)) {
      return {
        type: 'Point',
        coordinates: arr
      };
    }

    if (isArrayOfNumbers(arr)) {
      arr = transposeCoords(arr);
    }

    if (isClosedPath$1(arr)) {
      return {
        type: 'Polygon',
        coordinates: [arr]
      };
    }

    if (isArrayOfPoints(arr)) {
      return {
        type: 'LineString',
        coordinates: arr
      };
    }

    stop('Unable to import coordinates');
  }

  const epsilon = 1.1102230246251565e-16;
  const splitter = 134217729;
  const resulterrbound = (3 + 8 * epsilon) * epsilon;

  // fast_expansion_sum_zeroelim routine from oritinal code
  function sum(elen, e, flen, f, h) {
      let Q, Qnew, hh, bvirt;
      let enow = e[0];
      let fnow = f[0];
      let eindex = 0;
      let findex = 0;
      if ((fnow > enow) === (fnow > -enow)) {
          Q = enow;
          enow = e[++eindex];
      } else {
          Q = fnow;
          fnow = f[++findex];
      }
      let hindex = 0;
      if (eindex < elen && findex < flen) {
          if ((fnow > enow) === (fnow > -enow)) {
              Qnew = enow + Q;
              hh = Q - (Qnew - enow);
              enow = e[++eindex];
          } else {
              Qnew = fnow + Q;
              hh = Q - (Qnew - fnow);
              fnow = f[++findex];
          }
          Q = Qnew;
          if (hh !== 0) {
              h[hindex++] = hh;
          }
          while (eindex < elen && findex < flen) {
              if ((fnow > enow) === (fnow > -enow)) {
                  Qnew = Q + enow;
                  bvirt = Qnew - Q;
                  hh = Q - (Qnew - bvirt) + (enow - bvirt);
                  enow = e[++eindex];
              } else {
                  Qnew = Q + fnow;
                  bvirt = Qnew - Q;
                  hh = Q - (Qnew - bvirt) + (fnow - bvirt);
                  fnow = f[++findex];
              }
              Q = Qnew;
              if (hh !== 0) {
                  h[hindex++] = hh;
              }
          }
      }
      while (eindex < elen) {
          Qnew = Q + enow;
          bvirt = Qnew - Q;
          hh = Q - (Qnew - bvirt) + (enow - bvirt);
          enow = e[++eindex];
          Q = Qnew;
          if (hh !== 0) {
              h[hindex++] = hh;
          }
      }
      while (findex < flen) {
          Qnew = Q + fnow;
          bvirt = Qnew - Q;
          hh = Q - (Qnew - bvirt) + (fnow - bvirt);
          fnow = f[++findex];
          Q = Qnew;
          if (hh !== 0) {
              h[hindex++] = hh;
          }
      }
      if (Q !== 0 || hindex === 0) {
          h[hindex++] = Q;
      }
      return hindex;
  }

  function estimate(elen, e) {
      let Q = e[0];
      for (let i = 1; i < elen; i++) Q += e[i];
      return Q;
  }

  function vec(n) {
      return new Float64Array(n);
  }

  const ccwerrboundA = (3 + 16 * epsilon) * epsilon;
  const ccwerrboundB = (2 + 12 * epsilon) * epsilon;
  const ccwerrboundC = (9 + 64 * epsilon) * epsilon * epsilon;

  const B$2 = vec(4);
  const C1 = vec(8);
  const C2 = vec(12);
  const D$1 = vec(16);
  const u = vec(4);

  function orient2dadapt(ax, ay, bx, by, cx, cy, detsum) {
      let acxtail, acytail, bcxtail, bcytail;
      let bvirt, c, ahi, alo, bhi, blo, _i, _j, _0, s1, s0, t1, t0, u3;

      const acx = ax - cx;
      const bcx = bx - cx;
      const acy = ay - cy;
      const bcy = by - cy;

      s1 = acx * bcy;
      c = splitter * acx;
      ahi = c - (c - acx);
      alo = acx - ahi;
      c = splitter * bcy;
      bhi = c - (c - bcy);
      blo = bcy - bhi;
      s0 = alo * blo - (s1 - ahi * bhi - alo * bhi - ahi * blo);
      t1 = acy * bcx;
      c = splitter * acy;
      ahi = c - (c - acy);
      alo = acy - ahi;
      c = splitter * bcx;
      bhi = c - (c - bcx);
      blo = bcx - bhi;
      t0 = alo * blo - (t1 - ahi * bhi - alo * bhi - ahi * blo);
      _i = s0 - t0;
      bvirt = s0 - _i;
      B$2[0] = s0 - (_i + bvirt) + (bvirt - t0);
      _j = s1 + _i;
      bvirt = _j - s1;
      _0 = s1 - (_j - bvirt) + (_i - bvirt);
      _i = _0 - t1;
      bvirt = _0 - _i;
      B$2[1] = _0 - (_i + bvirt) + (bvirt - t1);
      u3 = _j + _i;
      bvirt = u3 - _j;
      B$2[2] = _j - (u3 - bvirt) + (_i - bvirt);
      B$2[3] = u3;

      let det = estimate(4, B$2);
      let errbound = ccwerrboundB * detsum;
      if (det >= errbound || -det >= errbound) {
          return det;
      }

      bvirt = ax - acx;
      acxtail = ax - (acx + bvirt) + (bvirt - cx);
      bvirt = bx - bcx;
      bcxtail = bx - (bcx + bvirt) + (bvirt - cx);
      bvirt = ay - acy;
      acytail = ay - (acy + bvirt) + (bvirt - cy);
      bvirt = by - bcy;
      bcytail = by - (bcy + bvirt) + (bvirt - cy);

      if (acxtail === 0 && acytail === 0 && bcxtail === 0 && bcytail === 0) {
          return det;
      }

      errbound = ccwerrboundC * detsum + resulterrbound * Math.abs(det);
      det += (acx * bcytail + bcy * acxtail) - (acy * bcxtail + bcx * acytail);
      if (det >= errbound || -det >= errbound) return det;

      s1 = acxtail * bcy;
      c = splitter * acxtail;
      ahi = c - (c - acxtail);
      alo = acxtail - ahi;
      c = splitter * bcy;
      bhi = c - (c - bcy);
      blo = bcy - bhi;
      s0 = alo * blo - (s1 - ahi * bhi - alo * bhi - ahi * blo);
      t1 = acytail * bcx;
      c = splitter * acytail;
      ahi = c - (c - acytail);
      alo = acytail - ahi;
      c = splitter * bcx;
      bhi = c - (c - bcx);
      blo = bcx - bhi;
      t0 = alo * blo - (t1 - ahi * bhi - alo * bhi - ahi * blo);
      _i = s0 - t0;
      bvirt = s0 - _i;
      u[0] = s0 - (_i + bvirt) + (bvirt - t0);
      _j = s1 + _i;
      bvirt = _j - s1;
      _0 = s1 - (_j - bvirt) + (_i - bvirt);
      _i = _0 - t1;
      bvirt = _0 - _i;
      u[1] = _0 - (_i + bvirt) + (bvirt - t1);
      u3 = _j + _i;
      bvirt = u3 - _j;
      u[2] = _j - (u3 - bvirt) + (_i - bvirt);
      u[3] = u3;
      const C1len = sum(4, B$2, 4, u, C1);

      s1 = acx * bcytail;
      c = splitter * acx;
      ahi = c - (c - acx);
      alo = acx - ahi;
      c = splitter * bcytail;
      bhi = c - (c - bcytail);
      blo = bcytail - bhi;
      s0 = alo * blo - (s1 - ahi * bhi - alo * bhi - ahi * blo);
      t1 = acy * bcxtail;
      c = splitter * acy;
      ahi = c - (c - acy);
      alo = acy - ahi;
      c = splitter * bcxtail;
      bhi = c - (c - bcxtail);
      blo = bcxtail - bhi;
      t0 = alo * blo - (t1 - ahi * bhi - alo * bhi - ahi * blo);
      _i = s0 - t0;
      bvirt = s0 - _i;
      u[0] = s0 - (_i + bvirt) + (bvirt - t0);
      _j = s1 + _i;
      bvirt = _j - s1;
      _0 = s1 - (_j - bvirt) + (_i - bvirt);
      _i = _0 - t1;
      bvirt = _0 - _i;
      u[1] = _0 - (_i + bvirt) + (bvirt - t1);
      u3 = _j + _i;
      bvirt = u3 - _j;
      u[2] = _j - (u3 - bvirt) + (_i - bvirt);
      u[3] = u3;
      const C2len = sum(C1len, C1, 4, u, C2);

      s1 = acxtail * bcytail;
      c = splitter * acxtail;
      ahi = c - (c - acxtail);
      alo = acxtail - ahi;
      c = splitter * bcytail;
      bhi = c - (c - bcytail);
      blo = bcytail - bhi;
      s0 = alo * blo - (s1 - ahi * bhi - alo * bhi - ahi * blo);
      t1 = acytail * bcxtail;
      c = splitter * acytail;
      ahi = c - (c - acytail);
      alo = acytail - ahi;
      c = splitter * bcxtail;
      bhi = c - (c - bcxtail);
      blo = bcxtail - bhi;
      t0 = alo * blo - (t1 - ahi * bhi - alo * bhi - ahi * blo);
      _i = s0 - t0;
      bvirt = s0 - _i;
      u[0] = s0 - (_i + bvirt) + (bvirt - t0);
      _j = s1 + _i;
      bvirt = _j - s1;
      _0 = s1 - (_j - bvirt) + (_i - bvirt);
      _i = _0 - t1;
      bvirt = _0 - _i;
      u[1] = _0 - (_i + bvirt) + (bvirt - t1);
      u3 = _j + _i;
      bvirt = u3 - _j;
      u[2] = _j - (u3 - bvirt) + (_i - bvirt);
      u[3] = u3;
      const Dlen = sum(C2len, C2, 4, u, D$1);

      return D$1[Dlen - 1];
  }

  function orient2d(ax, ay, bx, by, cx, cy) {
      const detleft = (ay - cy) * (bx - cx);
      const detright = (ax - cx) * (by - cy);
      const det = detleft - detright;

      if (detleft === 0 || detright === 0 || (detleft > 0) !== (detright > 0)) return det;

      const detsum = Math.abs(detleft + detright);
      if (Math.abs(det) >= ccwerrboundA * detsum) return det;

      return -orient2dadapt(ax, ay, bx, by, cx, cy, detsum);
  }

  const EPSILON = Math.pow(2, -52);
  const EDGE_STACK = new Uint32Array(512);

  class Delaunator {

      static from(points, getX = defaultGetX, getY = defaultGetY) {
          const n = points.length;
          const coords = new Float64Array(n * 2);

          for (let i = 0; i < n; i++) {
              const p = points[i];
              coords[2 * i] = getX(p);
              coords[2 * i + 1] = getY(p);
          }

          return new Delaunator(coords);
      }

      constructor(coords) {
          const n = coords.length >> 1;
          if (n > 0 && typeof coords[0] !== 'number') throw new Error('Expected coords to contain numbers.');

          this.coords = coords;

          // arrays that will store the triangulation graph
          const maxTriangles = Math.max(2 * n - 5, 0);
          this._triangles = new Uint32Array(maxTriangles * 3);
          this._halfedges = new Int32Array(maxTriangles * 3);

          // temporary arrays for tracking the edges of the advancing convex hull
          this._hashSize = Math.ceil(Math.sqrt(n));
          this._hullPrev = new Uint32Array(n); // edge to prev edge
          this._hullNext = new Uint32Array(n); // edge to next edge
          this._hullTri = new Uint32Array(n); // edge to adjacent triangle
          this._hullHash = new Int32Array(this._hashSize).fill(-1); // angular edge hash

          // temporary arrays for sorting points
          this._ids = new Uint32Array(n);
          this._dists = new Float64Array(n);

          this.update();
      }

      update() {
          const {coords, _hullPrev: hullPrev, _hullNext: hullNext, _hullTri: hullTri, _hullHash: hullHash} =  this;
          const n = coords.length >> 1;

          // populate an array of point indices; calculate input data bbox
          let minX = Infinity;
          let minY = Infinity;
          let maxX = -Infinity;
          let maxY = -Infinity;

          for (let i = 0; i < n; i++) {
              const x = coords[2 * i];
              const y = coords[2 * i + 1];
              if (x < minX) minX = x;
              if (y < minY) minY = y;
              if (x > maxX) maxX = x;
              if (y > maxY) maxY = y;
              this._ids[i] = i;
          }
          const cx = (minX + maxX) / 2;
          const cy = (minY + maxY) / 2;

          let minDist = Infinity;
          let i0, i1, i2;

          // pick a seed point close to the center
          for (let i = 0; i < n; i++) {
              const d = dist(cx, cy, coords[2 * i], coords[2 * i + 1]);
              if (d < minDist) {
                  i0 = i;
                  minDist = d;
              }
          }
          const i0x = coords[2 * i0];
          const i0y = coords[2 * i0 + 1];

          minDist = Infinity;

          // find the point closest to the seed
          for (let i = 0; i < n; i++) {
              if (i === i0) continue;
              const d = dist(i0x, i0y, coords[2 * i], coords[2 * i + 1]);
              if (d < minDist && d > 0) {
                  i1 = i;
                  minDist = d;
              }
          }
          let i1x = coords[2 * i1];
          let i1y = coords[2 * i1 + 1];

          let minRadius = Infinity;

          // find the third point which forms the smallest circumcircle with the first two
          for (let i = 0; i < n; i++) {
              if (i === i0 || i === i1) continue;
              const r = circumradius(i0x, i0y, i1x, i1y, coords[2 * i], coords[2 * i + 1]);
              if (r < minRadius) {
                  i2 = i;
                  minRadius = r;
              }
          }
          let i2x = coords[2 * i2];
          let i2y = coords[2 * i2 + 1];

          if (minRadius === Infinity) {
              // order collinear points by dx (or dy if all x are identical)
              // and return the list as a hull
              for (let i = 0; i < n; i++) {
                  this._dists[i] = (coords[2 * i] - coords[0]) || (coords[2 * i + 1] - coords[1]);
              }
              quicksort(this._ids, this._dists, 0, n - 1);
              const hull = new Uint32Array(n);
              let j = 0;
              for (let i = 0, d0 = -Infinity; i < n; i++) {
                  const id = this._ids[i];
                  if (this._dists[id] > d0) {
                      hull[j++] = id;
                      d0 = this._dists[id];
                  }
              }
              this.hull = hull.subarray(0, j);
              this.triangles = new Uint32Array(0);
              this.halfedges = new Uint32Array(0);
              return;
          }

          // swap the order of the seed points for counter-clockwise orientation
          if (orient2d(i0x, i0y, i1x, i1y, i2x, i2y) < 0) {
              const i = i1;
              const x = i1x;
              const y = i1y;
              i1 = i2;
              i1x = i2x;
              i1y = i2y;
              i2 = i;
              i2x = x;
              i2y = y;
          }

          const center = circumcenter(i0x, i0y, i1x, i1y, i2x, i2y);
          this._cx = center.x;
          this._cy = center.y;

          for (let i = 0; i < n; i++) {
              this._dists[i] = dist(coords[2 * i], coords[2 * i + 1], center.x, center.y);
          }

          // sort the points by distance from the seed triangle circumcenter
          quicksort(this._ids, this._dists, 0, n - 1);

          // set up the seed triangle as the starting hull
          this._hullStart = i0;
          let hullSize = 3;

          hullNext[i0] = hullPrev[i2] = i1;
          hullNext[i1] = hullPrev[i0] = i2;
          hullNext[i2] = hullPrev[i1] = i0;

          hullTri[i0] = 0;
          hullTri[i1] = 1;
          hullTri[i2] = 2;

          hullHash.fill(-1);
          hullHash[this._hashKey(i0x, i0y)] = i0;
          hullHash[this._hashKey(i1x, i1y)] = i1;
          hullHash[this._hashKey(i2x, i2y)] = i2;

          this.trianglesLen = 0;
          this._addTriangle(i0, i1, i2, -1, -1, -1);

          for (let k = 0, xp, yp; k < this._ids.length; k++) {
              const i = this._ids[k];
              const x = coords[2 * i];
              const y = coords[2 * i + 1];

              // skip near-duplicate points
              if (k > 0 && Math.abs(x - xp) <= EPSILON && Math.abs(y - yp) <= EPSILON) continue;
              xp = x;
              yp = y;

              // skip seed triangle points
              if (i === i0 || i === i1 || i === i2) continue;

              // find a visible edge on the convex hull using edge hash
              let start = 0;
              for (let j = 0, key = this._hashKey(x, y); j < this._hashSize; j++) {
                  start = hullHash[(key + j) % this._hashSize];
                  if (start !== -1 && start !== hullNext[start]) break;
              }

              start = hullPrev[start];
              let e = start, q;
              while (q = hullNext[e], orient2d(x, y, coords[2 * e], coords[2 * e + 1], coords[2 * q], coords[2 * q + 1]) >= 0) {
                  e = q;
                  if (e === start) {
                      e = -1;
                      break;
                  }
              }
              if (e === -1) continue; // likely a near-duplicate point; skip it

              // add the first triangle from the point
              let t = this._addTriangle(e, i, hullNext[e], -1, -1, hullTri[e]);

              // recursively flip triangles from the point until they satisfy the Delaunay condition
              hullTri[i] = this._legalize(t + 2);
              hullTri[e] = t; // keep track of boundary triangles on the hull
              hullSize++;

              // walk forward through the hull, adding more triangles and flipping recursively
              let n = hullNext[e];
              while (q = hullNext[n], orient2d(x, y, coords[2 * n], coords[2 * n + 1], coords[2 * q], coords[2 * q + 1]) < 0) {
                  t = this._addTriangle(n, i, q, hullTri[i], -1, hullTri[n]);
                  hullTri[i] = this._legalize(t + 2);
                  hullNext[n] = n; // mark as removed
                  hullSize--;
                  n = q;
              }

              // walk backward from the other side, adding more triangles and flipping
              if (e === start) {
                  while (q = hullPrev[e], orient2d(x, y, coords[2 * q], coords[2 * q + 1], coords[2 * e], coords[2 * e + 1]) < 0) {
                      t = this._addTriangle(q, i, e, -1, hullTri[e], hullTri[q]);
                      this._legalize(t + 2);
                      hullTri[q] = t;
                      hullNext[e] = e; // mark as removed
                      hullSize--;
                      e = q;
                  }
              }

              // update the hull indices
              this._hullStart = hullPrev[i] = e;
              hullNext[e] = hullPrev[n] = i;
              hullNext[i] = n;

              // save the two new edges in the hash table
              hullHash[this._hashKey(x, y)] = i;
              hullHash[this._hashKey(coords[2 * e], coords[2 * e + 1])] = e;
          }

          this.hull = new Uint32Array(hullSize);
          for (let i = 0, e = this._hullStart; i < hullSize; i++) {
              this.hull[i] = e;
              e = hullNext[e];
          }

          // trim typed triangle mesh arrays
          this.triangles = this._triangles.subarray(0, this.trianglesLen);
          this.halfedges = this._halfedges.subarray(0, this.trianglesLen);
      }

      _hashKey(x, y) {
          return Math.floor(pseudoAngle(x - this._cx, y - this._cy) * this._hashSize) % this._hashSize;
      }

      _legalize(a) {
          const {_triangles: triangles, _halfedges: halfedges, coords} = this;

          let i = 0;
          let ar = 0;

          // recursion eliminated with a fixed-size stack
          while (true) {
              const b = halfedges[a];

              /* if the pair of triangles doesn't satisfy the Delaunay condition
               * (p1 is inside the circumcircle of [p0, pl, pr]), flip them,
               * then do the same check/flip recursively for the new pair of triangles
               *
               *           pl                    pl
               *          /||\                  /  \
               *       al/ || \bl            al/    \a
               *        /  ||  \              /      \
               *       /  a||b  \    flip    /___ar___\
               *     p0\   ||   /p1   =>   p0\---bl---/p1
               *        \  ||  /              \      /
               *       ar\ || /br             b\    /br
               *          \||/                  \  /
               *           pr                    pr
               */
              const a0 = a - a % 3;
              ar = a0 + (a + 2) % 3;

              if (b === -1) { // convex hull edge
                  if (i === 0) break;
                  a = EDGE_STACK[--i];
                  continue;
              }

              const b0 = b - b % 3;
              const al = a0 + (a + 1) % 3;
              const bl = b0 + (b + 2) % 3;

              const p0 = triangles[ar];
              const pr = triangles[a];
              const pl = triangles[al];
              const p1 = triangles[bl];

              const illegal = inCircle(
                  coords[2 * p0], coords[2 * p0 + 1],
                  coords[2 * pr], coords[2 * pr + 1],
                  coords[2 * pl], coords[2 * pl + 1],
                  coords[2 * p1], coords[2 * p1 + 1]);

              if (illegal) {
                  triangles[a] = p1;
                  triangles[b] = p0;

                  const hbl = halfedges[bl];

                  // edge swapped on the other side of the hull (rare); fix the halfedge reference
                  if (hbl === -1) {
                      let e = this._hullStart;
                      do {
                          if (this._hullTri[e] === bl) {
                              this._hullTri[e] = a;
                              break;
                          }
                          e = this._hullPrev[e];
                      } while (e !== this._hullStart);
                  }
                  this._link(a, hbl);
                  this._link(b, halfedges[ar]);
                  this._link(ar, bl);

                  const br = b0 + (b + 1) % 3;

                  // don't worry about hitting the cap: it can only happen on extremely degenerate input
                  if (i < EDGE_STACK.length) {
                      EDGE_STACK[i++] = br;
                  }
              } else {
                  if (i === 0) break;
                  a = EDGE_STACK[--i];
              }
          }

          return ar;
      }

      _link(a, b) {
          this._halfedges[a] = b;
          if (b !== -1) this._halfedges[b] = a;
      }

      // add a new triangle given vertex indices and adjacent half-edge ids
      _addTriangle(i0, i1, i2, a, b, c) {
          const t = this.trianglesLen;

          this._triangles[t] = i0;
          this._triangles[t + 1] = i1;
          this._triangles[t + 2] = i2;

          this._link(t, a);
          this._link(t + 1, b);
          this._link(t + 2, c);

          this.trianglesLen += 3;

          return t;
      }
  }

  // monotonically increases with real angle, but doesn't need expensive trigonometry
  function pseudoAngle(dx, dy) {
      const p = dx / (Math.abs(dx) + Math.abs(dy));
      return (dy > 0 ? 3 - p : 1 + p) / 4; // [0..1]
  }

  function dist(ax, ay, bx, by) {
      const dx = ax - bx;
      const dy = ay - by;
      return dx * dx + dy * dy;
  }

  function inCircle(ax, ay, bx, by, cx, cy, px, py) {
      const dx = ax - px;
      const dy = ay - py;
      const ex = bx - px;
      const ey = by - py;
      const fx = cx - px;
      const fy = cy - py;

      const ap = dx * dx + dy * dy;
      const bp = ex * ex + ey * ey;
      const cp = fx * fx + fy * fy;

      return dx * (ey * cp - bp * fy) -
             dy * (ex * cp - bp * fx) +
             ap * (ex * fy - ey * fx) < 0;
  }

  function circumradius(ax, ay, bx, by, cx, cy) {
      const dx = bx - ax;
      const dy = by - ay;
      const ex = cx - ax;
      const ey = cy - ay;

      const bl = dx * dx + dy * dy;
      const cl = ex * ex + ey * ey;
      const d = 0.5 / (dx * ey - dy * ex);

      const x = (ey * bl - dy * cl) * d;
      const y = (dx * cl - ex * bl) * d;

      return x * x + y * y;
  }

  function circumcenter(ax, ay, bx, by, cx, cy) {
      const dx = bx - ax;
      const dy = by - ay;
      const ex = cx - ax;
      const ey = cy - ay;

      const bl = dx * dx + dy * dy;
      const cl = ex * ex + ey * ey;
      const d = 0.5 / (dx * ey - dy * ex);

      const x = ax + (ey * bl - dy * cl) * d;
      const y = ay + (dx * cl - ex * bl) * d;

      return {x, y};
  }

  function quicksort(ids, dists, left, right) {
      if (right - left <= 20) {
          for (let i = left + 1; i <= right; i++) {
              const temp = ids[i];
              const tempDist = dists[temp];
              let j = i - 1;
              while (j >= left && dists[ids[j]] > tempDist) ids[j + 1] = ids[j--];
              ids[j + 1] = temp;
          }
      } else {
          const median = (left + right) >> 1;
          let i = left + 1;
          let j = right;
          swap(ids, median, i);
          if (dists[ids[left]] > dists[ids[right]]) swap(ids, left, right);
          if (dists[ids[i]] > dists[ids[right]]) swap(ids, i, right);
          if (dists[ids[left]] > dists[ids[i]]) swap(ids, left, i);

          const temp = ids[i];
          const tempDist = dists[temp];
          while (true) {
              do i++; while (dists[ids[i]] < tempDist);
              do j--; while (dists[ids[j]] > tempDist);
              if (j < i) break;
              swap(ids, i, j);
          }
          ids[left + 1] = ids[j];
          ids[j] = temp;

          if (right - i + 1 >= j - left) {
              quicksort(ids, dists, i, right);
              quicksort(ids, dists, left, j - 1);
          } else {
              quicksort(ids, dists, left, j - 1);
              quicksort(ids, dists, i, right);
          }
      }
  }

  function swap(arr, i, j) {
      const tmp = arr[i];
      arr[i] = arr[j];
      arr[j] = tmp;
  }

  function defaultGetX(p) {
      return p[0];
  }
  function defaultGetY(p) {
      return p[1];
  }

  cmd.alphaShapes = function(pointLyr, targetDataset, opts) {
    requirePointLayer(pointLyr);
    if (opts.interval > 0 === false) {
      stop('Expected a non-negative interval parameter');
    }
    var filter = getAlphaDistanceFilter(targetDataset, opts.interval);
    var dataset = getPolygonDataset$2(pointLyr, filter, opts);
    var merged = mergeDatasets([targetDataset, dataset]);
    var lyr = merged.layers.pop();
    targetDataset.arcs = merged.arcs;
    setOutputLayerName(lyr, pointLyr, null, opts);
    return lyr;
  };

  function getAlphaDistanceFilter(dataset, interval) {
    return isLatLngDataset(dataset) ? getSphericalFilter(interval) : getPlanarFilter(interval);
  }

  function getPlanarFilter(interval) {
    return function(a, b) {
      return distance2D(a[0], a[1], b[0], b[1]) <= interval;
    };
  }

  // TODO: switch to real distance metric (don't assume meters, use CRS data)
  function getSphericalFilter(interval) {
    return function(a, b) {
      return greatCircleDistance(a[0], a[1], b[0], b[1]) <= interval;
    };
  }


  function getTriangleDataset(lyr, filter, opts) {
    var points = getPointsInLayer(lyr);
    var del = Delaunator.from(points);
    var index = opts.keep_points ? new Uint8Array(points.length) : null;
    var triangles = del.triangles;
    var geojson = {
      type: 'MultiPolygon',
      coordinates: []
    };
    var a, b, c, ai, bi, ci;
    for (var i=0, n=triangles.length; i<n; i+=3) {
      // a, b, c: triangle verticies in CCW order
      ai = triangles[i];
      bi = triangles[i+1];
      ci = triangles[i+2];
      a = points[ai];
      b = points[bi];
      c = points[ci];
      if (!(filter(a, b) && filter(b, c) && filter(a, c))) continue;
      geojson.coordinates.push([[c, b, a, c]]);
      if (index) {
        index[ai] = 1;
        index[bi] = 1;
        index[ci] = 1;
      }
    }
    if (index) {
      addPointSymbols(geojson, points, index);
    }
    return importGeoJSON(geojson);
  }

  function addPointSymbols(geom, points, index) {
    for (var i=0, n=index.length; i<n; i++) {
      if (index[i] === 0) {
        geom.coordinates.push(getPointSymbolCoords(points[i]));
      }
    }
  }

  function getPointSymbolCoords(p) {
    var d = 0.0001,
        x = p[0],
        y = p[1];
    return [[[x, y], [x, y+d], [x+d, y+d], [x+d, y], [x, y]]];
  }

  function getPolygonDataset$2(lyr, filter, opts) {
    var dataset = getTriangleDataset(lyr, filter, opts);
    buildTopology(dataset);
    if (!opts.debug) {
      cleanLayers(dataset.layers, dataset, {quiet: true});
    }
    return dataset;
  }

  function dissolveBufferDataset(dataset, optsArg) {
    var opts = optsArg || {};
    var lyr = dataset.layers[0];
    var tmp;
    var nodes = addIntersectionCuts(dataset, {});
    if (opts.debug_division) {
      return debugBufferDivision(lyr, nodes);
    }
    var mosaicIndex = new MosaicIndex(lyr, nodes, {flat: false, no_holes: false});
    if (opts.debug_mosaic) {
      tmp = composeMosaicLayer(lyr, mosaicIndex.mosaic);
      lyr.shapes = tmp.shapes;
      lyr.data = tmp.data;
      return;
    }
    var pathfind = getRingIntersector(mosaicIndex.nodes);
    var shapes2 = lyr.shapes.map(function(shp, shapeId) {
      var tiles = mosaicIndex.getTilesByShapeIds([shapeId]);
      var rings = [];
      for (var i=0; i<tiles.length; i++) {
        rings.push(tiles[i][0]);
      }
      return pathfind(rings, 'dissolve');
    });
    lyr.shapes = shapes2;
    if (!opts.no_dissolve) {
      dissolveArcs(dataset);
    }
  }

  function debugBufferDivision(lyr, nodes) {
    var divide = getHoleDivider(nodes);
    var shapes2 = [];
    var records = [];
    lyr.shapes.forEach(divideShape);
    lyr.shapes = shapes2;
    lyr.data = new DataTable(records);
    return lyr;

    function divideShape(shp) {
      var cw = [], ccw = [];
      divide(shp, cw, ccw);
      cw.forEach(function(ring) {
        shapes2.push([ring]);
        records.push({type: 'ring'});
      });
      ccw.forEach(function(hole) {
        shapes2.push([reversePath(hole)]);
        records.push({type: 'hole'});
      });
    }
  }

  // n = number of segments used to approximate a circle
  // Returns tolerance as a percent of circle radius
  function getBufferToleranceFromCircleSegments(n) {
    return 1 - Math.cos(Math.PI / n);
  }

  function getArcDegreesFromTolerancePct(pct) {
    return 360 * Math.acos(1 - pct) / Math.PI;
  }

  // n = number of segments used to approximate a circle
  // Returns tolerance as a percent of circle radius
  function getBufferToleranceFromCircleSegments2(n) {
    return 1 / Math.cos(Math.PI / n) - 1;
  }

  function getArcDegreesFromTolerancePct2(pct) {
    return 360 * Math.acos(1 / (pct + 1)) / Math.PI;
  }

  // return constant distance in meters, or return null if unparsable
  function parseConstantBufferDistance(str, crs) {
    var parsed = parseMeasure2(str);
    if (!parsed.value) return null;
    return convertDistanceParam(str, crs) || null;
  }

  function getBufferToleranceFunction(dataset, opts) {
    var crs = getDatasetCRS(dataset);
    var constTol = opts.tolerance ? parseConstantBufferDistance(opts.tolerance, crs) : 0;
    var pctOfRadius = 1/100;
    return function(meterDist) {
      if (constTol) return constTol;
      return constTol ? constTol : meterDist * pctOfRadius;
    };
  }

  function getBufferDistanceFunction(lyr, dataset, opts) {
    if (!opts.radius) {
      stop('Missing expected radius parameter');
    }
    var unitStr = opts.units || '';
    var crs = getDatasetCRS(dataset);
    var constDist = parseConstantBufferDistance(opts.radius + unitStr, crs);
    if (constDist) return function() {return constDist;};
    var expr = compileFeatureExpression(opts.radius, lyr, null); // no arcs
    return function(shpId) {
      var val = expr(shpId);
      if (!val) return 0;
      // TODO: optimize common case that expression returns a number
      var dist = parseConstantBufferDistance(val + unitStr, crs);
      return dist || 0;
    };
  }

  var BufferCommon = /*#__PURE__*/Object.freeze({
    __proto__: null,
    dissolveBufferDataset: dissolveBufferDataset,
    getBufferToleranceFromCircleSegments: getBufferToleranceFromCircleSegments,
    getArcDegreesFromTolerancePct: getArcDegreesFromTolerancePct,
    getBufferToleranceFromCircleSegments2: getBufferToleranceFromCircleSegments2,
    getArcDegreesFromTolerancePct2: getArcDegreesFromTolerancePct2,
    parseConstantBufferDistance: parseConstantBufferDistance,
    getBufferToleranceFunction: getBufferToleranceFunction,
    getBufferDistanceFunction: getBufferDistanceFunction
  });

  // Returns a function for generating GeoJSON geometries (MultiLineString or MultiPolygon)
  function getPolylineBufferMaker(arcs, geod, getBearing, opts) {
    var maker = getPathBufferMaker(arcs, geod, getBearing, opts);
    var geomType = opts.geometry_type;
    // polyline output could be used for debugging
    var outputGeom = opts.output_geometry == 'polyline' ? 'polyline' : 'polygon';

    function pathBufferCoords(pathArcs, dist) {
      var pathCoords = maker(pathArcs, dist);
      var revPathArcs;
      if (geomType == 'polyline') {
        revPathArcs = reversePath(pathArcs.concat());
        pathCoords = pathCoords.concat(maker(revPathArcs, dist));
      }
      pathCoords.push(pathCoords[0]); // close path
      return outputGeom == 'polyline' ? pathCoords : [pathCoords];
    }

    return function(shape, dist) {
      var geom = {
        type: outputGeom == 'polyline' ? 'MultiLineString' : 'MultiPolygon',
        coordinates: []
      };
      for (var i=0; i<shape.length; i++) {
        geom.coordinates.push(pathBufferCoords(shape[i], dist));
      }
      return geom.coordinates.length == 0 ? null : geom;
    };
  }


  function getPathBufferMaker(arcs, geod, getBearing, opts) {

    var backtrackSteps = opts.backtrack >= 0 ? opts.backtrack : 50;
    var pathIter = new ShapeIter(arcs);
    var capStyle = opts.cap_style || 'round'; // expect 'round' or 'flat'
    // var tolerance;
    // TODO: implement other join styles than round

    function addRoundJoin(arr, x, y, startDir, angle, dist) {
      var increment = 10;
      var endDir = startDir + angle;
      var dir = startDir + increment;
      while (dir < endDir) {
        addBufferVertex(arr, geod(x, y, dir, dist), backtrackSteps);
        dir += increment;
      }
    }

    // function addRoundJoin2(arr, x, y, startDir, angle, dist) {
    //   var increment = 10;
    //   var endDir = startDir + angle;
    //   var dir = startDir + increment;
    //   while (dir < endDir) {
    //     addBufferVertex(arr, geod(x, y, dir, dist), backtrackSteps);
    //     dir += increment;
    //   }
    // }

    // Test if two points are within a snapping tolerance
    // TODO: calculate the tolerance more sensibly
    function veryClose(x1, y1, x2, y2, tol) {
      var dist = geom.distance2D(x1, y1, x2, y2);
      return dist < tol;
    }

    function veryCloseToPrevPoint(arr, x, y) {
      var prev = arr[arr.length - 1];
      return veryClose(prev[0], prev[1], x, y, 0.000001);
    }

    function appendPoint(arr, p) {
      var prev = arr[arr.length - 1];
      if (!veryClose(prev[0], prev[1], p[0], p[1], 1e-10)) {
        arr.push(p);
      }
    }

    function makeCap(x, y, direction, dist) {
      if (capStyle == 'flat') {
        return [[x, y]];
      }
      return makeRoundCap(x, y, direction, dist);
    }

    function makeRoundCap(x, y, segmentDir, dist) {
      var points = [];
      var increment = 10;
      var startDir = segmentDir - 90;
      var angle = increment;
      while (angle < 180) {
        points.push(geod(x, y, startDir + angle, dist));
        angle += increment;
      }
      return points;
    }

    // get angle between two extruded segments in degrees
    // positive angle means join in convex (range: 0-180 degrees)
    // negative angle means join is concave (range: -180-0 degrees)
    function getJoinAngle(direction1, direction2) {
      var delta = direction2 - direction1;
      if (delta > 180) {
        delta -= 360;
      }
      if (delta < -180) {
        delta += 360;
      }
      return delta;
    }

    function addBufferVertex(arr, d, maxBacktrack) {
      var a, b, c, hit;
      for (var i=0, idx = arr.length - 3; i<maxBacktrack && idx >= 0; i++, idx--) {
        c = arr[arr.length - 1];
        a = arr[idx];
        b = arr[idx + 1];
        // TODO: consider using a geodetic intersection function for lat-long datasets
        hit = bufferIntersection(a[0], a[1], b[0], b[1], c[0], c[1], d[0], d[1]);
        if (hit) {
          // TODO: handle collinear segments
          // if (hit.length != 2) console.log('COLLINEAR', hit)
          // segments intersect -- replace two internal segment endpoints with xx point
          while (arr.length > idx + 1) arr.pop();
          appendPoint(arr, hit);
        }
      }

      appendPoint(arr, d);
    }

    return function(path, dist) {
      var left = [];
      var x0, y0, x1, y1, x2, y2;
      var p1, p2;
      var bearing, prevBearing, firstBearing, joinAngle;
      var i = 0;
      pathIter.init(path);

      while (pathIter.hasNext()) {
        // TODO: use a tolerance
        if (pathIter.x === x2 && pathIter.y === y2) continue; // skip duplicate points
        x1 = x2;
        y1 = y2;
        x2 = pathIter.x;
        y2 = pathIter.y;
        if (i >= 1) {
          prevBearing = bearing;
          bearing = getBearing(x1, y1, x2, y2);
          p1 = geod(x1, y1, bearing - 90, dist);
          p2 = geod(x2, y2, bearing - 90, dist);
          // left.push([x1, y1], p1) // debug extrusion lines
          // left.push([x2, y2], p2) // debug extrusion lines
        }
        if (i == 1) {
          firstBearing = bearing;
          x0 = x1;
          y0 = y1;
          left.push(p1, p2);
        }
        if (i > 1) {
          joinAngle = getJoinAngle(prevBearing, bearing);
          if (veryCloseToPrevPoint(left, p1[0], p1[1])) {
            // skip first point
            addBufferVertex(left, p2, backtrackSteps);
          } else if (joinAngle > 0) {
            addRoundJoin(left, x1, y1, prevBearing - 90, joinAngle, dist);
            addBufferVertex(left, p1, backtrackSteps);
            addBufferVertex(left, p2, backtrackSteps);
          } else {
            addBufferVertex(left, p1, backtrackSteps);
            addBufferVertex(left, p2, backtrackSteps);
          }
        }
        i++;
      }
      // TODO: handle defective polylines

      if (x2 == x0 && y2 == y0) {
        // add join to finish closed path
        joinAngle = getJoinAngle(bearing, firstBearing);
        if (joinAngle > 0) {
          addRoundJoin(left, x2, y2, bearing - 90, joinAngle, dist);
        }
      } else {
        // add a cap to finish open path
        left.push.apply(left, makeCap(x2, y2, bearing, dist));
      }
      return left;
    };
  }

  function addBufferVertex(arr, d, maxBacktrack) {
    var a, b, c, hit;
    for (var i=0, idx = arr.length - 3; i<maxBacktrack && idx >= 0; i++, idx--) {
      c = arr[arr.length - 1];
      a = arr[idx];
      b = arr[idx + 1];
      // TODO: consider using a geodetic intersection function for lat-long datasets
      hit = bufferIntersection(a[0], a[1], b[0], b[1], c[0], c[1], d[0], d[1]);
      if (hit) {
        // TODO: handle collinear segments
        if (hit.length != 2) ;
        // segments intersect -- replace two internal segment endpoints with xx point
        while (arr.length > idx + 1) arr.pop();
        // TODO: check proximity of hit to several points
        arr.push(hit);
      }
    }

    // TODO: check proximity to previous point
    arr.push(d); // add new point
  }

  // Exclude segments with non-intersecting bounding boxes before
  // calling intersection function
  // Possibly slightly faster than direct call... not worth it?
  function bufferIntersection(ax, ay, bx, by, cx, cy, dx, dy) {
    if (ax < cx && ax < dx && bx < cx && bx < dx ||
        ax > cx && ax > dx && bx > cx && bx > dx ||
        ay < cy && ay < dy && by < cy && by < dy ||
        ay > cy && ay > dy && by > cy && by > dy) return null;
    return geom.segmentIntersection(ax, ay, bx, by, cx, cy, dx, dy);
  }

  var PathBuffer = /*#__PURE__*/Object.freeze({
    __proto__: null,
    getPolylineBufferMaker: getPolylineBufferMaker,
    addBufferVertex: addBufferVertex,
    bufferIntersection: bufferIntersection
  });

  function getPolylineBufferMaker2(arcs, geod, getBearing, opts) {
    var makeLeftBuffer = getPathBufferMaker2(arcs, geod, getBearing, opts);
    var geomType = opts.geometry_type;

    function polygonCoords(ring) {
      return [ring];
    }

    function needLeftBuffer(path, arcs) {
      if (geomType == 'polyline') {
        return opts.type != 'right';
      }
      // assume polygon type
      if (opts.type == 'outer') {
        return geom.getPathWinding(path, arcs) == 1;
      }
      if (opts.type == 'inner') {
        return geom.getPathWinding(path, arcs) == -1;
      }
      return true;
    }

    function needRightBuffer() {
      return geomType == 'polyline' && opts.type != 'left';
    }

    function makeBufferParts(pathArcs, dist) {
      var leftPartials, rightPartials, parts, revPathArcs;

      if (needLeftBuffer(pathArcs, arcs)) {
        leftPartials = makeLeftBuffer(pathArcs, dist);
      }
      if (needRightBuffer()) {
        revPathArcs = reversePath(pathArcs.concat());
        rightPartials = makeLeftBuffer(revPathArcs, dist);
      }
      parts = (leftPartials || []).concat(rightPartials || []);
      return parts.map(polygonCoords);
    }

    // Returns a GeoJSON Geometry (MultiLineString or MultiPolygon) or null
    return function(shape, dist) {
      var geom = {
        type: 'MultiPolygon',
        coordinates: []
      };
      for (var i=0; i<shape.length; i++) {
        geom.coordinates = geom.coordinates.concat(makeBufferParts(shape[i], dist));
      }
      return geom.coordinates.length == 0 ? null : geom;
    };
  }

  function getPathBufferMaker2(arcs, geod, getBearing, opts) {
    var backtrackSteps = opts.backtrack >= 0 ? opts.backtrack : 50;
    var pathIter = new ShapeIter(arcs);
    // var capStyle = opts.cap_style || 'round'; // expect 'round' or 'flat'
    var partials, left, center;
    var bounds;
    // TODO: implement other join styles than round

    // function updateTolerance(dist) {

    // }

    function addRoundJoin(x, y, startDir, angle, dist) {
      var increment = 10;
      var endDir = startDir + angle;
      var dir = startDir + increment;
      while (dir < endDir) {
        addBufferVertex(geod(x, y, dir, dist));
        dir += increment;
      }
    }

    // function addRoundJoin2(arr, x, y, startDir, angle, dist) {
    //   var increment = 10;
    //   var endDir = startDir + angle;
    //   var dir = startDir + increment;
    //   while (dir < endDir) {
    //     addBufferVertex(arr, geod(x, y, dir, dist));
    //     dir += increment;
    //   }
    // }

    // Test if two points are within a snapping tolerance
    // TODO: calculate the tolerance more sensibly
    function veryClose(x1, y1, x2, y2, tol) {
      var dist = geom.distance2D(x1, y1, x2, y2);
      return dist < tol;
    }

    function veryCloseToPrevPoint(arr, x, y) {
      var prev = arr[arr.length - 1];
      return veryClose(prev[0], prev[1], x, y, 0.000001);
    }

    function appendPoint(arr, p) {
      var prev = arr[arr.length - 1];
      if (!veryClose(prev[0], prev[1], p[0], p[1], 1e-10)) {
        arr.push(p);
      }
    }

    // function makeCap(x, y, direction, dist) {
    //   if (capStyle == 'flat') {
    //     return [[x, y]];
    //   }
    //   return makeRoundCap(x, y, direction, dist);
    // }

    // function makeRoundCap(x, y, segmentDir, dist) {
    //   var points = [];
    //   var increment = 10;
    //   var startDir = segmentDir - 90;
    //   var angle = increment;
    //   while (angle < 180) {
    //     points.push(geod(x, y, startDir + angle, dist));
    //     angle += increment;
    //   }
    //   return points;
    // }

    // get angle between two extruded segments in degrees
    // positive angle means join in convex (range: 0-180 degrees)
    // negative angle means join is concave (range: -180-0 degrees)
    function getJoinAngle(direction1, direction2) {
      var delta = direction2 - direction1;
      if (delta > 180) {
        delta -= 360;
      }
      if (delta < -180) {
        delta += 360;
      }
      return delta;
    }


    // TODO: handle polygon holes
    function addBufferVertex(d) {
      var arr = left;
      var a, b, c, c0, hit;
      // c is the start point of the segment formed by appending point d to the polyline.
      c0 = c = arr[arr.length - 1];
      for (var i=0, idx = arr.length - 3; idx >= 0; i++, idx--) {
        a = arr[idx];
        b = arr[idx + 1];
        // TODO: consider using a geodetic intersection function for lat-long datasets
        hit = bufferIntersection(a[0], a[1], b[0], b[1], c[0], c[1], d[0], d[1]);
        if (hit) {
          if (segmentTurn(a, b, c, d) == 1) {
            // interpretation: segment cd crosses segment ab from outside to inside
            // the buffer -- we need to start a new partial; otherwise,
            // the following code would likely remove a loop representing
            // an oxbow-type hole in the buffer.
            //
            finishPartial();
            break;
          }
          // TODO: handle collinear segments (consider creating new partial)
          // if (hit.length != 2) console.log('COLLINEAR', hit)

          // segments intersect, indicating a spurious loop: remove the loop and
          // replace the endpoints of the intersecting segments with the intersection point.
          while (arr.length > idx + 1) arr.pop();
          appendPoint(arr, hit);
          c = hit; // update starting point of the newly added segment
        }

        // Maintain a bounding box around vertices before the backtrack limit.
        // If the latest segment intersects this bounding box, there could be a self-
        // intersection -- start a new partial to prevent self-intersection.
        //
        if (i >= backtrackSteps) {
          if (!bounds) {
            bounds = new Bounds();
            bounds.mergePoint(a[0], a[1]);
          }
          bounds.mergePoint(b[0], b[1]);
          if (testSegmentBoundsIntersection(c0, d, bounds)) {
            finishPartial();
          }
          break;
        }
      }

      appendPoint(arr, d);
    }

    function finishPartial() {
      // Get endpoints of the two polylines, for starting the next partial
      var leftEP = left[left.length - 1];
      var centerEP = center[center.length - 1];

      // Make a polygon ring
      var ring = [];
      extendArray(ring, left);
      center.reverse();
      extendArray(ring, center);
      ring.push(ring[0]); // close ring
      partials.push(ring);

      // Start next partial
      left.push(leftEP);
      center.push(centerEP);

      // clear bbox
      // bbox = null;
    }

    function extendArray(arr, arr2) {
      arr2.reverse();
      while(arr2.length > 0) arr.push(arr2.pop());
    }

    return function(path, dist) {
      // var x0, y0;
      var x1, y1, x2, y2;
      var p1, p2;
      // var firstBearing;
      var bearing, prevBearing, joinAngle;
      partials = [];
      left = [];
      center = [];
      pathIter.init(path);

      // if (pathIter.hasNext()) {
      //   x0 = x2 = pathIter.x;
      //   y0 = y2 = pathIter.y;
      // }
      while (pathIter.hasNext()) {
        // TODO: use a tolerance
        if (pathIter.x === x2 && pathIter.y === y2) continue; // skip duplicate points
        x1 = x2;
        y1 = y2;
        x2 = pathIter.x;
        y2 = pathIter.y;

        prevBearing = bearing;
        bearing = getBearing(x1, y1, x2, y2);
        // shift original polyline segment to the left by buffer distance
        p1 = geod(x1, y1, bearing - 90, dist);
        p2 = geod(x2, y2, bearing - 90, dist);

        if (center.length === 0) {
          // first loop, second point in this partial
          // if (partials.length === 0) {
          //   firstBearing = bearing;
          // }
          left.push(p1, p2);
          center.push([x1, y1], [x2, y2]);
        } else {
          //
          joinAngle = getJoinAngle(prevBearing, bearing);
          if (veryCloseToPrevPoint(left, p1[0], p1[1])) {
            // skip first point
            addBufferVertex(p2);
          } else if (joinAngle > 0) {
            addRoundJoin(x1, y1, prevBearing - 90, joinAngle, dist);
            addBufferVertex(p1);
            addBufferVertex(p2);
          } else {
            addBufferVertex(p1);
            addBufferVertex(p2);
          }
          center.push([x2, y2]);
        }
      }

      if (center.length > 1) {
        finishPartial();
      }
      // TODO: handle defective polylines

      // if (x2 == x0 && y2 == y0) {
      //   // add join to finish closed path
      //   joinAngle = getJoinAngle(bearing, firstBearing);
      //   if (joinAngle > 0) {
      //     addRoundJoin(leftpart, x2, y2, bearing - 90, joinAngle, dist);
      //   }
      // } else {
      //   // add a cap to finish open path
      //   leftpart.push.apply(leftpart, makeCap(x2, y2, bearing, dist));
      // }

      return partials;
    };
  }

  // GeographicLib docs: https://geographiclib.sourceforge.io/html/js/
  //   https://geographiclib.sourceforge.io/html/js/module-GeographicLib_Geodesic.Geodesic.html
  //   https://geographiclib.sourceforge.io/html/js/tutorial-2-interface.html
  function getGeodesic(P) {
    if (!isLatLngCRS(P)) error('Expected an unprojected CRS');
    var f = P.es / (1 + Math.sqrt(P.one_es));
    var GeographicLib = require$1('mproj').internal.GeographicLib;
    return new GeographicLib.Geodesic.Geodesic(P.a, f);
  }

  function interpolatePoint2D(ax, ay, bx, by, k) {
    var j = 1 - k;
    return [ax * j + bx * k, ay * j + by * k];
  }

  function getInterpolationFunction(P) {
    var spherical = P && isLatLngCRS(P);
    if (!spherical) return interpolatePoint2D;
    var geod = getGeodesic(P);
    return function(lng, lat, lng2, lat2, k) {
      var r = geod.Inverse(lat, lng, lat2, lng2);
      var dist = r.s12 * k;
      var r2 = geod.Direct(lat, lng, r.azi1, dist);
      return [r2.lon2, r2.lat2];
    };
  }

  function getPlanarSegmentEndpoint(x, y, bearing, meterDist) {
    var rad = bearing / 180 * Math.PI;
    var dx = Math.sin(rad) * meterDist;
    var dy = Math.cos(rad) * meterDist;
    return [x + dx, y + dy];
  }

  // source: https://github.com/mapbox/cheap-ruler/blob/master/index.js
  function fastGeodeticSegmentFunction(lng, lat, bearing, meterDist) {
    var D2R = Math.PI / 180;
    var cos = Math.cos(lat * D2R);
    var cos2 = 2 * cos * cos - 1;
    var cos3 = 2 * cos * cos2 - cos;
    var cos4 = 2 * cos * cos3 - cos2;
    var cos5 = 2 * cos * cos4 - cos3;
    var kx = (111.41513 * cos - 0.09455 * cos3 + 0.00012 * cos5) * 1000;
    var ky = (111.13209 - 0.56605 * cos2 + 0.0012 * cos4) * 1000;
    var bearingRad = bearing * D2R;
    var lat2 = lat + Math.cos(bearingRad) * meterDist / ky;
    var lng2 = lng + Math.sin(bearingRad) * meterDist / kx;
    return [lng2, lat2];
  }

  function getGeodeticSegmentFunction(P) {
    if (!isLatLngCRS(P)) {
      return getPlanarSegmentEndpoint;
    }
    var g = getGeodesic(P);
    return function(lng, lat, bearing, meterDist) {
      var o = g.Direct(lat, lng, bearing, meterDist);
      var p = [o.lon2, o.lat2];
      return p;
    };
  }

  function getFastGeodeticSegmentFunction(P) {
    // CAREFUL: this function has higher error at very large distances and at the poles
    // also, it wouldn't work for other planets than Earth
    return isLatLngCRS(P) ? fastGeodeticSegmentFunction : getPlanarSegmentEndpoint;
  }


  function bearingDegrees(a, b, c, d) {
    return geom.bearing(a, b, c, d) * 180 / Math.PI;
  }

  function bearingDegrees2D(a, b, c, d) {
    return geom.bearing2D(a, b, c, d) * 180 / Math.PI;
  }

  // return function to calculate bearing of a segment in degrees
  function getBearingFunction(dataset) {
    var P = getDatasetCRS(dataset);
    return isLatLngCRS(P) ? bearingDegrees : bearingDegrees2D;
  }

  var Geodesic = /*#__PURE__*/Object.freeze({
    __proto__: null,
    interpolatePoint2D: interpolatePoint2D,
    getInterpolationFunction: getInterpolationFunction,
    getPlanarSegmentEndpoint: getPlanarSegmentEndpoint,
    getGeodeticSegmentFunction: getGeodeticSegmentFunction,
    getFastGeodeticSegmentFunction: getFastGeodeticSegmentFunction,
    bearingDegrees: bearingDegrees,
    bearingDegrees2D: bearingDegrees2D,
    getBearingFunction: getBearingFunction
  });

  function makePolylineBuffer(lyr, dataset, opts) {
    var geojson = makeShapeBufferGeoJSON(lyr, dataset, opts);
    var dataset2 = importGeoJSON(geojson, {});
    dissolveBufferDataset(dataset2, opts);
    return dataset2;
  }

  function makeShapeBufferGeoJSON(lyr, dataset, opts) {
    var distanceFn = getBufferDistanceFunction(lyr, dataset, opts);
    getBufferToleranceFunction(dataset, opts);
    var geod = getFastGeodeticSegmentFunction(getDatasetCRS(dataset));
    var getBearing = getBearingFunction(dataset);
    var makerOpts = Object.assign({geometry_type: lyr.geometry_type}, opts);
    var factory = opts.v2 ? getPolylineBufferMaker2 : getPolylineBufferMaker;
    var makeShapeBuffer = factory(dataset.arcs, geod, getBearing, makerOpts);
    lyr.data ? lyr.data.getRecords() : null;
    var geometries = lyr.shapes.map(function(shape, i) {
      var dist = distanceFn(i);
      if (!dist || !shape) return null;
      return makeShapeBuffer(shape, dist, lyr.geometry_type);
    });
    // TODO: make sure that importer supports null geometries (not standard GeoJSON);
    return {
      type: 'GeometryCollection',
      geometries: geometries
    };
  }

  function makePolygonBuffer(lyr, dataset, opts) {
    var geojson = makeShapeBufferGeoJSON(lyr, dataset, opts);
    var dataset2 = importGeoJSON(geojson, {});
    dissolveBufferDataset(dataset2);
    return dataset2;
  }

  // Utility functions for GeoJSON-style lat-long [x,y] coordinates and arrays of coords

  var e = 1e-10;
  var T = 90 - e;
  var L = -180 + e;
  var B$1 = -90 + e;
  var R = 180 - e;

  function lastEl(arr) {
    return arr[arr.length - 1];
  }

  function samePoint(a, b) {
    return a && b && a[0] === b[0] && a[1] === b[1];
  }

  function isClosedPath(arr) {
    return samePoint(arr[0], lastEl(arr));
  }

  // remove likely rounding errors
  function snapToEdge(p) {
    if (p[0] <= L) p[0] = -180;
    if (p[0] >= R) p[0] = 180;
    if (p[1] <= B$1) p[1] = -90;
    if (p[1] >= T) p[1] = 90;
  }

  function onPole(p) {
    return p[1] >= T || p[1] <= B$1;
  }

  function isWholeWorld(coords) {
    // TODO: check that l,r,t,b are all reached
    for (var i=0, n=coords.length; i<n; i++) {
      if (!isEdgePoint(coords[i])) return false;
    }
    return true;
  }

  function touchesEdge(coords) {
    for (var i=0, n=coords.length; i<n; i++) {
      if (isEdgePoint(coords[i])) return true;
    }
    return false;
  }

  function isEdgeSegment(a, b) {
    // TODO: handle segments between pole and non-edge point
    // (these shoudn't exist in a properly clipped path)
    return (onPole(a) || onPole(b)) ||
      a[0] <= L && b[0] <= L || a[0] >= R && b[0] >= R;
  }

  function isEdgePoint(p) {
    return p[1] <= B$1 || p[1] >= T || p[0] <= L || p[0] >= R;
  }

  // Remove segments that belong solely to cut points
  // TODO: verify that antimeridian crosses have matching y coords
  // TODO: stitch together split-apart polygons ?
  //
  function removeCutSegments(coords) {
    if (!touchesEdge(coords)) return coords;
    var coords2 = [];
    var a, b, c;
    var skipped = false;
    coords.pop(); // remove duplicate point
    a = coords[coords.length-1];
    b = coords[0];
    for (var ci=1, n=coords.length; ci <= n; ci++) {
      c = ci == n ? coords2[0] : coords[ci];
      if (!c) continue; // undefined c could occur in a defective path
      if ((skipped || isEdgeSegment(a, b)) && isEdgeSegment(b, c)) {
        // skip b
        // console.log("skipping b:", ci, a, b, c)
        skipped = true;
      } else {
        if (skipped === true) {
          skipped = false;
        }
        coords2.push(b);
        a = b;
      }
      b = c;
    }
    if (coords2.length > 0) {
      coords2.push(coords2[0].concat()); // close the path
    }
    // TODO: handle runs that are split at the array boundary
    return coords2;
  }


  function removePolylineCrosses(path) {
    return splitPathAtAntimeridian(path);
  }

  function isAntimeridianPoint(p) {
    // return p[0] <= L || p[0] >= R;
    return p[0] == -180 || p[0] == 180;
  }

  // Removes antimeridian crossings from an array of polygon rings
  // TODO: handle edge case: segment is collinear with antimeridian
  // TODO: handle edge case: path coordinates exceed the standard lat-long range
  //
  // rings: array of rings of [x,y] points.
  // Returns array of split-apart rings
  function removePolygonCrosses(rings) {
    var rings2 = [];
    var splitRings = [];
    var ring;
    for (var i=0; i<rings.length; i++) {
      ring = rings[i];
      if (!isClosedPath(ring)) {
        error('Received an open path');
      }
      if (countCrosses(ring) === 0) {
        rings2.push(ring);
      } else {
        splitRings = splitRings.concat(splitPathAtAntimeridian(ring));
      }
    }
    if (splitRings.length > 0) {
      rings2 = rings2.concat(reconnectSplitParts(splitRings));
    }
    return rings2;
  }

  // Stitch an array of split-apart paths into coordinate rings
  // Assumes that the first and last point of each split-apart path is 180 or -180
  // parts: array of paths that have been split at the antimeridian
  function reconnectSplitParts(parts) {
    var yy = getSortedIntersections(parts);
    var rings = [];
    var usedParts = [];
    parts.forEach(function(part, i) {
      if (usedParts[i]) return;
      if (!isValidSplitPart(part)) {
        error('Geometry error');
      }
      var ring = addPartToRing(part, []);
      if (ring) {
        if (!isClosedPath(ring)) {
          error('Generated an open ring');
        }
        rings.push(ring);
      }
    });

    return rings;

    function addPartToRing(part, ring) {
      var lastPoint = lastEl(part);
      var i = parts.indexOf(part);
      if (usedParts[i]) {
        debug('Tried to use a previously used path');
        return null;
      }
      usedParts[i] = true;
      ring = ring.concat(part);
      var nextPoint = findNextPoint(parts, lastPoint, yy);
      if (!nextPoint) {
        return null;
      }
      if (lastPoint[0] != nextPoint[0]) {
        // add polar line to switch from east to west or west to east
        // coming from east -> turn south
        // coming from west -> turn north
        var poleY = lastPoint[0] == 180 ? -90 : 90;
        // need a center point (lines longer than 90 degrees cause confusion when rotating)
        ring.push([lastPoint[0], poleY], [0, poleY], [nextPoint[0], poleY]);
      }
      var nextPart = findPartStartingAt(parts, nextPoint);
      if (!nextPart) {
        return null;
      }
      if (samePoint(ring[0], nextPart[0])) {
        // done!
        ring.push(ring[0]); // close the ring
        return ring;
      }
      return addPartToRing(nextPart, ring);
    }
  }

  function addSubPath(paths, path) {
    if (path.length > 1) paths.push(path);
  }

  function isValidSplitPart(part) {
    var lastX = lastEl(part)[0];
    var firstX = part[0][0];
    return (lastX == 180 || lastX == -180) && (firstX == 180 || firstX == -180);
  }

  // p: last point of previous part
  function findNextPoint(parts, p, yy) {
    var x = p[0];
    var y = p[1];
    var i = yy.indexOf(y);
    var xOpp = x == -180 ? 180 : -180;
    var turnSouth = x == 180; // intersecting from the east -> turn south
    var iNext = turnSouth ? i - 1 : i + 1;
    var nextPoint;
    if (x != 180 && x != -180) {
      debug('Unexpected error');
      return null;
    }
    if (i == -1) {
      debug('Point missing from intersection table:', p);
      return null;
    }
    if (iNext < 0 || iNext >= yy.length) {
      // no path to traverse to along the antimeridian --
      // assume the path surrounds one of the poles
      // enclose south pole
      nextPoint = [xOpp, y];
    } else {
      nextPoint = [x, yy[iNext]];
    }
    return nextPoint;
  }

  function findPartStartingAt(parts, firstPoint) {
    for (var i=0; i<parts.length; i++) {
      if (samePoint(parts[i][0], firstPoint)) {
        return parts[i];
      }
    }
    return null;
  }

  function countCrosses(path) {
    var c = 0, pp, p;
    for (var i=0, n=path.length; i<n; i++) {
      p = path[i];
      if (i>0 && Math.abs(pp[0] - p[0]) > 180) {
        c++;
      }
      pp = p;
    }
    return c;
  }

  function splitPathAtAntimeridian(path) {
    var parts = [];
    var part = [];
    var firstPoint = path[0];
    var lastPoint = lastEl(path);
    var closed = samePoint(firstPoint, lastPoint);
    var p, pp, y;
    for (var i=0, n=path.length; i<n; i++) {
      p = path[i];
      if (i>0 && segmentCrossesAntimeridian(pp, p)) {
        // y = sphericalIntercept(pp, p);
        y = planarIntercept(pp, p);
        addIntersectionPoint(part, pp, y);
        addSubPath(parts, part);
        part = [];
        addIntersectionPoint(part, p, y);
        // console.log(y, y2)
      }
      part.push(p);
      pp = p;
    }
    addSubPath(parts, part);

    // join first and last parts of a split-apart ring, so that the first part
    // originates at the antimeridian
    if (closed && parts.length > 1 && !isAntimeridianPoint(firstPoint)) {
      part = parts.pop();
      part.pop(); // remove duplicate point
      parts[0] = part.concat(parts[0]);
    }
    return parts;
  }

  function segmentCrossesAntimeridian(a, b) {
    return Math.abs(a[0] - b[0]) > 180;
  }

  function getSortedIntersections(parts) {
    var values = parts.map(function(p) {
      return p[0][1];
    });
    return utils.genericSort(values, true);
  }


  function addIntersectionPoint(part, p, yint) {
    var xint = p[0] < 0 ? -180 : 180;
    if (!isAntimeridianPoint(p)) { // don't a point if p is already on the antimeridian
      part.push([xint, yint]);
    }
  }


  // p1, p2: two vertices on different sides of the antimeridian
  // Returns y-intercept of the segment connecting p1, p2
  // TODO: consider using the great-circle intersection, instead of
  // the planar intersection.
  // (Planar should be fine if p1 and p2 are close to lon. 180)
  function planarIntercept(p1, p2) {
    var dx = p2[0] - p1[0]; // pos: crosses antimeridian w->e, neg: e->w
    var dx1, dx2;
    if (dx > 0) {
      dx1 = p1[0] + 180;
      dx2 = 180 - p2[0];
    } else {
      dx1 = 180 - p1[0];
      dx2 = p2[0] + 180;
    }
    // avoid fp rounding error if a point is on antimeridian
    if (dx1 === 0) return p1[1];
    if (dx2 === 0) return p2[1];
    return (dx2 * p1[1] + dx1 * p2[1]) / (dx1 + dx2);
  }

  function ringArea(ring) {
    var iter = new PointIter(ring);
    return getSphericalPathArea2(iter);
  }

  function makePointBuffer(lyr, dataset, opts) {
    var geojson = makePointBufferGeoJSON(lyr, dataset, opts);
    return importGeoJSON(geojson, {});
  }

  // Make a single geodetic circle
  function getCircleGeoJSON(center, radius, vertices, opts) {
    var n = vertices || 360;
    var geod = getGeodeticSegmentFunction(parseCrsString('wgs84')); // ?
    if (opts.inset) {
      radius -= opts.inset;
    }
    return opts.geometry_type == 'polyline' ?
      getPointBufferLineString([center], radius, n, geod) :
      getPointBufferPolygon([center], radius, n, geod, true);
  }

  // Convert a point layer to circles
  function makePointBufferGeoJSON(lyr, dataset, opts) {
    var vertices = opts.vertices || 72;
    var distanceFn = getBufferDistanceFunction(lyr, dataset, opts);
    var crs = getDatasetCRS(dataset);
    var spherical = isLatLngCRS(crs);
    var geod = getGeodeticSegmentFunction(crs);
    var geometries = lyr.shapes.map(function(shape, i) {
      var dist = distanceFn(i);
      if (!dist || !shape) return null;
      return getPointBufferPolygon(shape, dist, vertices, geod, spherical);
    });
    // TODO: make sure that importer supports null geometries (nonstandard GeoJSON);
    return {
      type: 'GeometryCollection',
      geometries: geometries
    };
  }

  function getPointBufferPolygon(points, distance, vertices, geod, spherical) {
    var rings = [], coords, coords2;
    if (!points || !points.length) return null;
    for (var i=0; i<points.length; i++) {
      coords = getPointBufferCoordinates(points[i], distance, vertices, geod);
      if (!spherical) {
        rings.push([coords]);
      } else if (countCrosses(coords) > 0) {
        coords2 = removePolygonCrosses([coords]);
        while (coords2.length > 0) rings.push([coords2.pop()]); // geojson polygon coords, no hole
      } else if (ringArea(coords) < 0) {
        // negative spherical area: CCW ring, indicating a circle of >180 degrees
        // that fully encloses both poles and the antimeridian.
        // need to add an enclosure around the entire sphere
        // TODO: compare to distance param as a sanity check
        rings.push([
          [[180, 90], [180, -90], [0, -90], [-180, -90], [-180, 90], [0, 90], [180, 90]],
          coords
        ]);
      } else {
        rings.push([coords]);
      }
    }
    return {
      type: 'MultiPolygon',
      coordinates: rings
    };
  }

  function getPointBufferLineString(points, distance, vertices, geod) {
    var rings = [], coords;
    if (!points || !points.length) return null;
    for (var i=0; i<points.length; i++) {
      coords = getPointBufferCoordinates(points[i], distance, vertices, geod);
      coords = removePolylineCrosses(coords);
      while (coords.length > 0) rings.push(coords.pop());
    }
    return rings.length == 1 ? {
      type: 'LineString',
      coordinates: rings[0]
    } : {
      type: 'MultiLineString',
      coordinates: rings
    };
  }

  // Returns array of [x, y] coordinates in a closed ring
  function getPointBufferCoordinates(center, meterDist, vertices, geod) {
    var coords = [],
        angle = 360 / vertices,
        theta;
    for (var i=0; i<vertices; i++) {
      // offsetting by half a step so 4 sides are flat, not pointy
      // (looks better on low-vertex circles)
      theta = (i + 0.5) * angle % 360;
      coords.push(geod(center[0], center[1], theta, meterDist));
    }
    coords.push(coords[0].concat());
    return coords;
  }

  // TODO: consider if layers should be buffered together
  // cmd.buffer = function(layers, dataset, opts) {
  //   return makeBufferLayer(layers[0], dataset, opts);
  // };

  cmd.buffer = makeBufferLayer;

  function makeBufferLayer(lyr, dataset, opts) {
    var dataset2;
    if (lyr.geometry_type == 'point') {
      dataset2 = makePointBuffer(lyr, dataset, opts);
    } else if (lyr.geometry_type == 'polyline') {
      dataset2 = makePolylineBuffer(lyr, dataset, opts);
    } else if (lyr.geometry_type == 'polygon') {
      dataset2 = makePolygonBuffer(lyr, dataset, opts);
    } else {
      stop("Unsupported geometry type");
    }

    var lyr2 = mergeOutputLayerIntoDataset(lyr, dataset, dataset2, opts);
    return [lyr2];
  }

  // currently undocumented, used in tests
  cmd.checkGeometry = function(targetLayer, dataset, opts) {
    if (!dataset.arcs) return;

    // TODO: only check the target layer for intersections
    var intersections = findSegmentIntersections(dataset.arcs);
    if (intersections.length > 0) {
      handleError(`Found ${intersections.length} intersection${intersections.length > 1 ? 's' : ''}.`, opts);
    }

    // TODO: look for other geometry errors
  };

  function handleError(msg, opts) {
    var report = opts.strict ? stop : message;
    report(msg);
  }

  var scaledIntervals =
    [10,12,15,18,20,22,25,30,35,40,45,50,60,70,80,90,100];
  var precisions =
    [10, 2, 5, 2,10, 2, 5,10, 5,10, 5,50,10,10,10,10,10];


  function getNormalPrecision(scaledInterval) {
    var i = scaledIntervals.indexOf(scaledInterval);
    return precisions[i] || error('Unknown error');
  }

  // return a weighting (0-1) to add strength to classifications that use
  // rounder numbers
  function getRoundnessScore(interval, precision) {
    return precision >= 50 && 1 || precision >= 10 && 0.9 || precision >= 5 && 0.8 || 0.7;
  }

  function getNiceBreaks(values, numBreaks) {
    var quantileBreaks = getQuantileBreaks(values, numBreaks);
    var lowerBreak = quantileBreaks[0];
    var upperBreak = quantileBreaks[quantileBreaks.length-1];
    var data = getCandidateBreaks(lowerBreak, upperBreak, numBreaks);
    // add distribution data and quality metric to each candidate
    data.forEach(function(o) {
      getDistributionData(o.breaks, values);
      o.distribution = getDistributionData(o.breaks, values);
      o.quality = o.roundness * evaluateDistribution(o.distribution);
    });
    utils.sortOn(data, 'quality', false);
    return data[0].breaks;
  }


  function evaluateDistribution(distribution) {
    var ideal = utils.sum(distribution) / distribution.length;
    var first = distribution[0];
    var last = distribution[distribution.length - 1];
    var q = (bucketScore(ideal, first) + bucketScore(ideal, last)) / 2;
    return q;
  }

  // downweight buckets the more they deviate from an ideal size
  function bucketScore(ideal, actual) {
    if (actual > ideal) {
      return ideal / actual;
    } else {
      return ideal / (2 * ideal - actual);
    }
  }

  // kludge to avoid rounding errors in break values
  function applyScale(normalVal, scale) {
    if (scale < 1) {
      return normalVal * Math.round(1 / scale);
    }
    return normalVal / scale;
  }

  function getCandidateBreaks(lowerBreak, upperBreak, numBreaks) {
    var cands = [];
    // calculate rounding using equal interval, when possible
    var maxBreak = Math.max(Math.abs(lowerBreak), Math.abs(upperBreak));
    var subRange = numBreaks >= 2 ?
        (upperBreak - lowerBreak) / (numBreaks - 1) : maxBreak;
    var scale = getRangeScale(subRange);
    var scaledRange = scale * subRange;
    var scaledIntervals = getNiceIntervals(scaledRange);
    scaledIntervals.forEach(function(scaledInterval) {
      var scaledPrecision = getNormalPrecision(scaledInterval);
      var interval = applyScale(scaledInterval, scale);
      var precision = applyScale(scaledPrecision, scale);
      var fenceposts = getBreakFenceposts(lowerBreak, precision);
      fenceposts.forEach(function(lowBound) {
        cands.push({
          interval: interval,
          precision: precision,
          roundness: getRoundnessScore(scaledInterval, scaledPrecision),
          breaks: getRoundBreaks(lowBound, interval, numBreaks)
        });
      });
    });
    return cands;
  }


  function getRoundBreaks(lowerBreak, interval, numBreaks) {
    var breaks = [lowerBreak];
    for (var i=1; i<numBreaks; i++) {
      breaks.push(lowerBreak + interval * i);
    }
    return breaks;
  }

  function getBreakFenceposts(val, precision) {
    var boundVal = getRoundingFunction(precision)(val);
    var boundVal2 = boundVal + (val > boundVal ? precision : -precision);
    var fenceposts = boundVal < boundVal2 ? [boundVal, boundVal2] : [boundVal2, boundVal];
    return fenceposts;
  }

  function getNiceIntervals(scaledRange) {
    var intervals = scaledIntervals;
    var lower, upper;
    for (var i=1; i<intervals.length; i++) {
      lower = intervals[i-1];
      upper = intervals[i];
      if (scaledRange >= lower && scaledRange <= upper) {
        return [lower, upper];
      }
    }
    error('Range error');
  }

  function getRangeScale(range) {
    var s = 1;
    if (range > 0.0001 === false || range < 1e9 === false) {
      stop('Data range error');
    }
    while (range > 100) {
      range /= 10;
      s /= 10;
    }
    while (range < 10) {
      range *= 10;
      s *= 10;
    }
    return s;
  }

  function define(constructor, factory, prototype) {
    constructor.prototype = factory.prototype = prototype;
    prototype.constructor = constructor;
  }

  function extend(parent, definition) {
    var prototype = Object.create(parent.prototype);
    for (var key in definition) prototype[key] = definition[key];
    return prototype;
  }

  function Color() {}

  var darker = 0.7;
  var brighter = 1 / darker;

  var reI = "\\s*([+-]?\\d+)\\s*",
      reN = "\\s*([+-]?(?:\\d*\\.)?\\d+(?:[eE][+-]?\\d+)?)\\s*",
      reP = "\\s*([+-]?(?:\\d*\\.)?\\d+(?:[eE][+-]?\\d+)?)%\\s*",
      reHex = /^#([0-9a-f]{3,8})$/,
      reRgbInteger = new RegExp(`^rgb\\(${reI},${reI},${reI}\\)$`),
      reRgbPercent = new RegExp(`^rgb\\(${reP},${reP},${reP}\\)$`),
      reRgbaInteger = new RegExp(`^rgba\\(${reI},${reI},${reI},${reN}\\)$`),
      reRgbaPercent = new RegExp(`^rgba\\(${reP},${reP},${reP},${reN}\\)$`),
      reHslPercent = new RegExp(`^hsl\\(${reN},${reP},${reP}\\)$`),
      reHslaPercent = new RegExp(`^hsla\\(${reN},${reP},${reP},${reN}\\)$`);

  var named = {
    aliceblue: 0xf0f8ff,
    antiquewhite: 0xfaebd7,
    aqua: 0x00ffff,
    aquamarine: 0x7fffd4,
    azure: 0xf0ffff,
    beige: 0xf5f5dc,
    bisque: 0xffe4c4,
    black: 0x000000,
    blanchedalmond: 0xffebcd,
    blue: 0x0000ff,
    blueviolet: 0x8a2be2,
    brown: 0xa52a2a,
    burlywood: 0xdeb887,
    cadetblue: 0x5f9ea0,
    chartreuse: 0x7fff00,
    chocolate: 0xd2691e,
    coral: 0xff7f50,
    cornflowerblue: 0x6495ed,
    cornsilk: 0xfff8dc,
    crimson: 0xdc143c,
    cyan: 0x00ffff,
    darkblue: 0x00008b,
    darkcyan: 0x008b8b,
    darkgoldenrod: 0xb8860b,
    darkgray: 0xa9a9a9,
    darkgreen: 0x006400,
    darkgrey: 0xa9a9a9,
    darkkhaki: 0xbdb76b,
    darkmagenta: 0x8b008b,
    darkolivegreen: 0x556b2f,
    darkorange: 0xff8c00,
    darkorchid: 0x9932cc,
    darkred: 0x8b0000,
    darksalmon: 0xe9967a,
    darkseagreen: 0x8fbc8f,
    darkslateblue: 0x483d8b,
    darkslategray: 0x2f4f4f,
    darkslategrey: 0x2f4f4f,
    darkturquoise: 0x00ced1,
    darkviolet: 0x9400d3,
    deeppink: 0xff1493,
    deepskyblue: 0x00bfff,
    dimgray: 0x696969,
    dimgrey: 0x696969,
    dodgerblue: 0x1e90ff,
    firebrick: 0xb22222,
    floralwhite: 0xfffaf0,
    forestgreen: 0x228b22,
    fuchsia: 0xff00ff,
    gainsboro: 0xdcdcdc,
    ghostwhite: 0xf8f8ff,
    gold: 0xffd700,
    goldenrod: 0xdaa520,
    gray: 0x808080,
    green: 0x008000,
    greenyellow: 0xadff2f,
    grey: 0x808080,
    honeydew: 0xf0fff0,
    hotpink: 0xff69b4,
    indianred: 0xcd5c5c,
    indigo: 0x4b0082,
    ivory: 0xfffff0,
    khaki: 0xf0e68c,
    lavender: 0xe6e6fa,
    lavenderblush: 0xfff0f5,
    lawngreen: 0x7cfc00,
    lemonchiffon: 0xfffacd,
    lightblue: 0xadd8e6,
    lightcoral: 0xf08080,
    lightcyan: 0xe0ffff,
    lightgoldenrodyellow: 0xfafad2,
    lightgray: 0xd3d3d3,
    lightgreen: 0x90ee90,
    lightgrey: 0xd3d3d3,
    lightpink: 0xffb6c1,
    lightsalmon: 0xffa07a,
    lightseagreen: 0x20b2aa,
    lightskyblue: 0x87cefa,
    lightslategray: 0x778899,
    lightslategrey: 0x778899,
    lightsteelblue: 0xb0c4de,
    lightyellow: 0xffffe0,
    lime: 0x00ff00,
    limegreen: 0x32cd32,
    linen: 0xfaf0e6,
    magenta: 0xff00ff,
    maroon: 0x800000,
    mediumaquamarine: 0x66cdaa,
    mediumblue: 0x0000cd,
    mediumorchid: 0xba55d3,
    mediumpurple: 0x9370db,
    mediumseagreen: 0x3cb371,
    mediumslateblue: 0x7b68ee,
    mediumspringgreen: 0x00fa9a,
    mediumturquoise: 0x48d1cc,
    mediumvioletred: 0xc71585,
    midnightblue: 0x191970,
    mintcream: 0xf5fffa,
    mistyrose: 0xffe4e1,
    moccasin: 0xffe4b5,
    navajowhite: 0xffdead,
    navy: 0x000080,
    oldlace: 0xfdf5e6,
    olive: 0x808000,
    olivedrab: 0x6b8e23,
    orange: 0xffa500,
    orangered: 0xff4500,
    orchid: 0xda70d6,
    palegoldenrod: 0xeee8aa,
    palegreen: 0x98fb98,
    paleturquoise: 0xafeeee,
    palevioletred: 0xdb7093,
    papayawhip: 0xffefd5,
    peachpuff: 0xffdab9,
    peru: 0xcd853f,
    pink: 0xffc0cb,
    plum: 0xdda0dd,
    powderblue: 0xb0e0e6,
    purple: 0x800080,
    rebeccapurple: 0x663399,
    red: 0xff0000,
    rosybrown: 0xbc8f8f,
    royalblue: 0x4169e1,
    saddlebrown: 0x8b4513,
    salmon: 0xfa8072,
    sandybrown: 0xf4a460,
    seagreen: 0x2e8b57,
    seashell: 0xfff5ee,
    sienna: 0xa0522d,
    silver: 0xc0c0c0,
    skyblue: 0x87ceeb,
    slateblue: 0x6a5acd,
    slategray: 0x708090,
    slategrey: 0x708090,
    snow: 0xfffafa,
    springgreen: 0x00ff7f,
    steelblue: 0x4682b4,
    tan: 0xd2b48c,
    teal: 0x008080,
    thistle: 0xd8bfd8,
    tomato: 0xff6347,
    turquoise: 0x40e0d0,
    violet: 0xee82ee,
    wheat: 0xf5deb3,
    white: 0xffffff,
    whitesmoke: 0xf5f5f5,
    yellow: 0xffff00,
    yellowgreen: 0x9acd32
  };

  define(Color, color, {
    copy(channels) {
      return Object.assign(new this.constructor, this, channels);
    },
    displayable() {
      return this.rgb().displayable();
    },
    hex: color_formatHex, // Deprecated! Use color.formatHex.
    formatHex: color_formatHex,
    formatHex8: color_formatHex8,
    formatHsl: color_formatHsl,
    formatRgb: color_formatRgb,
    toString: color_formatRgb
  });

  function color_formatHex() {
    return this.rgb().formatHex();
  }

  function color_formatHex8() {
    return this.rgb().formatHex8();
  }

  function color_formatHsl() {
    return hslConvert(this).formatHsl();
  }

  function color_formatRgb() {
    return this.rgb().formatRgb();
  }

  function color(format) {
    var m, l;
    format = (format + "").trim().toLowerCase();
    return (m = reHex.exec(format)) ? (l = m[1].length, m = parseInt(m[1], 16), l === 6 ? rgbn(m) // #ff0000
        : l === 3 ? new Rgb((m >> 8 & 0xf) | (m >> 4 & 0xf0), (m >> 4 & 0xf) | (m & 0xf0), ((m & 0xf) << 4) | (m & 0xf), 1) // #f00
        : l === 8 ? rgba(m >> 24 & 0xff, m >> 16 & 0xff, m >> 8 & 0xff, (m & 0xff) / 0xff) // #ff000000
        : l === 4 ? rgba((m >> 12 & 0xf) | (m >> 8 & 0xf0), (m >> 8 & 0xf) | (m >> 4 & 0xf0), (m >> 4 & 0xf) | (m & 0xf0), (((m & 0xf) << 4) | (m & 0xf)) / 0xff) // #f000
        : null) // invalid hex
        : (m = reRgbInteger.exec(format)) ? new Rgb(m[1], m[2], m[3], 1) // rgb(255, 0, 0)
        : (m = reRgbPercent.exec(format)) ? new Rgb(m[1] * 255 / 100, m[2] * 255 / 100, m[3] * 255 / 100, 1) // rgb(100%, 0%, 0%)
        : (m = reRgbaInteger.exec(format)) ? rgba(m[1], m[2], m[3], m[4]) // rgba(255, 0, 0, 1)
        : (m = reRgbaPercent.exec(format)) ? rgba(m[1] * 255 / 100, m[2] * 255 / 100, m[3] * 255 / 100, m[4]) // rgb(100%, 0%, 0%, 1)
        : (m = reHslPercent.exec(format)) ? hsla(m[1], m[2] / 100, m[3] / 100, 1) // hsl(120, 50%, 50%)
        : (m = reHslaPercent.exec(format)) ? hsla(m[1], m[2] / 100, m[3] / 100, m[4]) // hsla(120, 50%, 50%, 1)
        : named.hasOwnProperty(format) ? rgbn(named[format]) // eslint-disable-line no-prototype-builtins
        : format === "transparent" ? new Rgb(NaN, NaN, NaN, 0)
        : null;
  }

  function rgbn(n) {
    return new Rgb(n >> 16 & 0xff, n >> 8 & 0xff, n & 0xff, 1);
  }

  function rgba(r, g, b, a) {
    if (a <= 0) r = g = b = NaN;
    return new Rgb(r, g, b, a);
  }

  function rgbConvert(o) {
    if (!(o instanceof Color)) o = color(o);
    if (!o) return new Rgb;
    o = o.rgb();
    return new Rgb(o.r, o.g, o.b, o.opacity);
  }

  function rgb$1(r, g, b, opacity) {
    return arguments.length === 1 ? rgbConvert(r) : new Rgb(r, g, b, opacity == null ? 1 : opacity);
  }

  function Rgb(r, g, b, opacity) {
    this.r = +r;
    this.g = +g;
    this.b = +b;
    this.opacity = +opacity;
  }

  define(Rgb, rgb$1, extend(Color, {
    brighter(k) {
      k = k == null ? brighter : Math.pow(brighter, k);
      return new Rgb(this.r * k, this.g * k, this.b * k, this.opacity);
    },
    darker(k) {
      k = k == null ? darker : Math.pow(darker, k);
      return new Rgb(this.r * k, this.g * k, this.b * k, this.opacity);
    },
    rgb() {
      return this;
    },
    clamp() {
      return new Rgb(clampi(this.r), clampi(this.g), clampi(this.b), clampa(this.opacity));
    },
    displayable() {
      return (-0.5 <= this.r && this.r < 255.5)
          && (-0.5 <= this.g && this.g < 255.5)
          && (-0.5 <= this.b && this.b < 255.5)
          && (0 <= this.opacity && this.opacity <= 1);
    },
    hex: rgb_formatHex, // Deprecated! Use color.formatHex.
    formatHex: rgb_formatHex,
    formatHex8: rgb_formatHex8,
    formatRgb: rgb_formatRgb,
    toString: rgb_formatRgb
  }));

  function rgb_formatHex() {
    return `#${hex(this.r)}${hex(this.g)}${hex(this.b)}`;
  }

  function rgb_formatHex8() {
    return `#${hex(this.r)}${hex(this.g)}${hex(this.b)}${hex((isNaN(this.opacity) ? 1 : this.opacity) * 255)}`;
  }

  function rgb_formatRgb() {
    const a = clampa(this.opacity);
    return `${a === 1 ? "rgb(" : "rgba("}${clampi(this.r)}, ${clampi(this.g)}, ${clampi(this.b)}${a === 1 ? ")" : `, ${a})`}`;
  }

  function clampa(opacity) {
    return isNaN(opacity) ? 1 : Math.max(0, Math.min(1, opacity));
  }

  function clampi(value) {
    return Math.max(0, Math.min(255, Math.round(value) || 0));
  }

  function hex(value) {
    value = clampi(value);
    return (value < 16 ? "0" : "") + value.toString(16);
  }

  function hsla(h, s, l, a) {
    if (a <= 0) h = s = l = NaN;
    else if (l <= 0 || l >= 1) h = s = NaN;
    else if (s <= 0) h = NaN;
    return new Hsl(h, s, l, a);
  }

  function hslConvert(o) {
    if (o instanceof Hsl) return new Hsl(o.h, o.s, o.l, o.opacity);
    if (!(o instanceof Color)) o = color(o);
    if (!o) return new Hsl;
    if (o instanceof Hsl) return o;
    o = o.rgb();
    var r = o.r / 255,
        g = o.g / 255,
        b = o.b / 255,
        min = Math.min(r, g, b),
        max = Math.max(r, g, b),
        h = NaN,
        s = max - min,
        l = (max + min) / 2;
    if (s) {
      if (r === max) h = (g - b) / s + (g < b) * 6;
      else if (g === max) h = (b - r) / s + 2;
      else h = (r - g) / s + 4;
      s /= l < 0.5 ? max + min : 2 - max - min;
      h *= 60;
    } else {
      s = l > 0 && l < 1 ? 0 : h;
    }
    return new Hsl(h, s, l, o.opacity);
  }

  function hsl(h, s, l, opacity) {
    return arguments.length === 1 ? hslConvert(h) : new Hsl(h, s, l, opacity == null ? 1 : opacity);
  }

  function Hsl(h, s, l, opacity) {
    this.h = +h;
    this.s = +s;
    this.l = +l;
    this.opacity = +opacity;
  }

  define(Hsl, hsl, extend(Color, {
    brighter(k) {
      k = k == null ? brighter : Math.pow(brighter, k);
      return new Hsl(this.h, this.s, this.l * k, this.opacity);
    },
    darker(k) {
      k = k == null ? darker : Math.pow(darker, k);
      return new Hsl(this.h, this.s, this.l * k, this.opacity);
    },
    rgb() {
      var h = this.h % 360 + (this.h < 0) * 360,
          s = isNaN(h) || isNaN(this.s) ? 0 : this.s,
          l = this.l,
          m2 = l + (l < 0.5 ? l : 1 - l) * s,
          m1 = 2 * l - m2;
      return new Rgb(
        hsl2rgb(h >= 240 ? h - 240 : h + 120, m1, m2),
        hsl2rgb(h, m1, m2),
        hsl2rgb(h < 120 ? h + 240 : h - 120, m1, m2),
        this.opacity
      );
    },
    clamp() {
      return new Hsl(clamph(this.h), clampt(this.s), clampt(this.l), clampa(this.opacity));
    },
    displayable() {
      return (0 <= this.s && this.s <= 1 || isNaN(this.s))
          && (0 <= this.l && this.l <= 1)
          && (0 <= this.opacity && this.opacity <= 1);
    },
    formatHsl() {
      const a = clampa(this.opacity);
      return `${a === 1 ? "hsl(" : "hsla("}${clamph(this.h)}, ${clampt(this.s) * 100}%, ${clampt(this.l) * 100}%${a === 1 ? ")" : `, ${a})`}`;
    }
  }));

  function clamph(value) {
    value = (value || 0) % 360;
    return value < 0 ? value + 360 : value;
  }

  function clampt(value) {
    return Math.max(0, Math.min(1, value || 0));
  }

  /* From FvD 13.37, CSS Color Module Level 3 */
  function hsl2rgb(h, m1, m2) {
    return (h < 60 ? m1 + (m2 - m1) * h / 60
        : h < 180 ? m2
        : h < 240 ? m1 + (m2 - m1) * (240 - h) / 60
        : m1) * 255;
  }

  const radians = Math.PI / 180;
  const degrees = 180 / Math.PI;

  var A = -0.14861,
      B = +1.78277,
      C = -0.29227,
      D = -0.90649,
      E = +1.97294,
      ED = E * D,
      EB = E * B,
      BC_DA = B * C - D * A;

  function cubehelixConvert(o) {
    if (o instanceof Cubehelix) return new Cubehelix(o.h, o.s, o.l, o.opacity);
    if (!(o instanceof Rgb)) o = rgbConvert(o);
    var r = o.r / 255,
        g = o.g / 255,
        b = o.b / 255,
        l = (BC_DA * b + ED * r - EB * g) / (BC_DA + ED - EB),
        bl = b - l,
        k = (E * (g - l) - C * bl) / D,
        s = Math.sqrt(k * k + bl * bl) / (E * l * (1 - l)), // NaN if l=0 or l=1
        h = s ? Math.atan2(k, bl) * degrees - 120 : NaN;
    return new Cubehelix(h < 0 ? h + 360 : h, s, l, o.opacity);
  }

  function cubehelix$2(h, s, l, opacity) {
    return arguments.length === 1 ? cubehelixConvert(h) : new Cubehelix(h, s, l, opacity == null ? 1 : opacity);
  }

  function Cubehelix(h, s, l, opacity) {
    this.h = +h;
    this.s = +s;
    this.l = +l;
    this.opacity = +opacity;
  }

  define(Cubehelix, cubehelix$2, extend(Color, {
    brighter(k) {
      k = k == null ? brighter : Math.pow(brighter, k);
      return new Cubehelix(this.h, this.s, this.l * k, this.opacity);
    },
    darker(k) {
      k = k == null ? darker : Math.pow(darker, k);
      return new Cubehelix(this.h, this.s, this.l * k, this.opacity);
    },
    rgb() {
      var h = isNaN(this.h) ? 0 : (this.h + 120) * radians,
          l = +this.l,
          a = isNaN(this.s) ? 0 : this.s * l * (1 - l),
          cosh = Math.cos(h),
          sinh = Math.sin(h);
      return new Rgb(
        255 * (l + a * (A * cosh + B * sinh)),
        255 * (l + a * (C * cosh + D * sinh)),
        255 * (l + a * (E * cosh)),
        this.opacity
      );
    }
  }));

  function basis(t1, v0, v1, v2, v3) {
    var t2 = t1 * t1, t3 = t2 * t1;
    return ((1 - 3 * t1 + 3 * t2 - t3) * v0
        + (4 - 6 * t2 + 3 * t3) * v1
        + (1 + 3 * t1 + 3 * t2 - 3 * t3) * v2
        + t3 * v3) / 6;
  }

  function basis$1(values) {
    var n = values.length - 1;
    return function(t) {
      var i = t <= 0 ? (t = 0) : t >= 1 ? (t = 1, n - 1) : Math.floor(t * n),
          v1 = values[i],
          v2 = values[i + 1],
          v0 = i > 0 ? values[i - 1] : 2 * v1 - v2,
          v3 = i < n - 1 ? values[i + 2] : 2 * v2 - v1;
      return basis((t - i / n) * n, v0, v1, v2, v3);
    };
  }

  var constant = x => () => x;

  function linear(a, d) {
    return function(t) {
      return a + t * d;
    };
  }

  function exponential(a, b, y) {
    return a = Math.pow(a, y), b = Math.pow(b, y) - a, y = 1 / y, function(t) {
      return Math.pow(a + t * b, y);
    };
  }

  function hue(a, b) {
    var d = b - a;
    return d ? linear(a, d > 180 || d < -180 ? d - 360 * Math.round(d / 360) : d) : constant(isNaN(a) ? b : a);
  }

  function gamma(y) {
    return (y = +y) === 1 ? nogamma : function(a, b) {
      return b - a ? exponential(a, b, y) : constant(isNaN(a) ? b : a);
    };
  }

  function nogamma(a, b) {
    var d = b - a;
    return d ? linear(a, d) : constant(isNaN(a) ? b : a);
  }

  var rgb = (function rgbGamma(y) {
    var color = gamma(y);

    function rgb(start, end) {
      var r = color((start = rgb$1(start)).r, (end = rgb$1(end)).r),
          g = color(start.g, end.g),
          b = color(start.b, end.b),
          opacity = nogamma(start.opacity, end.opacity);
      return function(t) {
        start.r = r(t);
        start.g = g(t);
        start.b = b(t);
        start.opacity = opacity(t);
        return start + "";
      };
    }

    rgb.gamma = rgbGamma;

    return rgb;
  })(1);

  function rgbSpline(spline) {
    return function(colors) {
      var n = colors.length,
          r = new Array(n),
          g = new Array(n),
          b = new Array(n),
          i, color;
      for (i = 0; i < n; ++i) {
        color = rgb$1(colors[i]);
        r[i] = color.r || 0;
        g[i] = color.g || 0;
        b[i] = color.b || 0;
      }
      r = spline(r);
      g = spline(g);
      b = spline(b);
      color.opacity = 1;
      return function(t) {
        color.r = r(t);
        color.g = g(t);
        color.b = b(t);
        return color + "";
      };
    };
  }

  var rgbBasis = rgbSpline(basis$1);

  function numberArray(a, b) {
    if (!b) b = [];
    var n = a ? Math.min(b.length, a.length) : 0,
        c = b.slice(),
        i;
    return function(t) {
      for (i = 0; i < n; ++i) c[i] = a[i] * (1 - t) + b[i] * t;
      return c;
    };
  }

  function isNumberArray(x) {
    return ArrayBuffer.isView(x) && !(x instanceof DataView);
  }

  function genericArray(a, b) {
    var nb = b ? b.length : 0,
        na = a ? Math.min(nb, a.length) : 0,
        x = new Array(na),
        c = new Array(nb),
        i;

    for (i = 0; i < na; ++i) x[i] = d3_interpolate(a[i], b[i]);
    for (; i < nb; ++i) c[i] = b[i];

    return function(t) {
      for (i = 0; i < na; ++i) c[i] = x[i](t);
      return c;
    };
  }

  function date(a, b) {
    var d = new Date;
    return a = +a, b = +b, function(t) {
      return d.setTime(a * (1 - t) + b * t), d;
    };
  }

  function number(a, b) {
    return a = +a, b = +b, function(t) {
      return a * (1 - t) + b * t;
    };
  }

  function object(a, b) {
    var i = {},
        c = {},
        k;

    if (a === null || typeof a !== "object") a = {};
    if (b === null || typeof b !== "object") b = {};

    for (k in b) {
      if (k in a) {
        i[k] = d3_interpolate(a[k], b[k]);
      } else {
        c[k] = b[k];
      }
    }

    return function(t) {
      for (k in i) c[k] = i[k](t);
      return c;
    };
  }

  var reA = /[-+]?(?:\d+\.?\d*|\.?\d+)(?:[eE][-+]?\d+)?/g,
      reB = new RegExp(reA.source, "g");

  function zero(b) {
    return function() {
      return b;
    };
  }

  function one(b) {
    return function(t) {
      return b(t) + "";
    };
  }

  function string(a, b) {
    var bi = reA.lastIndex = reB.lastIndex = 0, // scan index for next number in b
        am, // current match in a
        bm, // current match in b
        bs, // string preceding current number in b, if any
        i = -1, // index in s
        s = [], // string constants and placeholders
        q = []; // number interpolators

    // Coerce inputs to strings.
    a = a + "", b = b + "";

    // Interpolate pairs of numbers in a & b.
    while ((am = reA.exec(a))
        && (bm = reB.exec(b))) {
      if ((bs = bm.index) > bi) { // a string precedes the next number in b
        bs = b.slice(bi, bs);
        if (s[i]) s[i] += bs; // coalesce with previous string
        else s[++i] = bs;
      }
      if ((am = am[0]) === (bm = bm[0])) { // numbers in a & b match
        if (s[i]) s[i] += bm; // coalesce with previous string
        else s[++i] = bm;
      } else { // interpolate non-matching numbers
        s[++i] = null;
        q.push({i: i, x: number(am, bm)});
      }
      bi = reB.lastIndex;
    }

    // Add remains of b.
    if (bi < b.length) {
      bs = b.slice(bi);
      if (s[i]) s[i] += bs; // coalesce with previous string
      else s[++i] = bs;
    }

    // Special optimization for only a single match.
    // Otherwise, interpolate each of the numbers and rejoin the string.
    return s.length < 2 ? (q[0]
        ? one(q[0].x)
        : zero(b))
        : (b = q.length, function(t) {
            for (var i = 0, o; i < b; ++i) s[(o = q[i]).i] = o.x(t);
            return s.join("");
          });
  }

  function d3_interpolate(a, b) {
    var t = typeof b, c;
    return b == null || t === "boolean" ? constant(b)
        : (t === "number" ? number
        : t === "string" ? ((c = color(b)) ? (b = c, rgb) : string)
        : b instanceof color ? rgb
        : b instanceof Date ? date
        : isNumberArray(b) ? numberArray
        : Array.isArray(b) ? genericArray
        : typeof b.valueOf !== "function" && typeof b.toString !== "function" || isNaN(b) ? object
        : number)(a, b);
  }

  function cubehelix$1(hue) {
    return (function cubehelixGamma(y) {
      y = +y;

      function cubehelix(start, end) {
        var h = hue((start = cubehelix$2(start)).h, (end = cubehelix$2(end)).h),
            s = nogamma(start.s, end.s),
            l = nogamma(start.l, end.l),
            opacity = nogamma(start.opacity, end.opacity);
        return function(t) {
          start.h = h(t);
          start.s = s(t);
          start.l = l(Math.pow(t, y));
          start.opacity = opacity(t);
          return start + "";
        };
      }

      cubehelix.gamma = cubehelixGamma;

      return cubehelix;
    })(1);
  }

  cubehelix$1(hue);
  var cubehelixLong = cubehelix$1(nogamma);

  // TODO: support three or more stops
  function getGradientFunction(stops) {
    var min = stops[0] / 100,
        max = stops[1] / 100;
    if (stops.length != 2) {
      stop('Only two stops are currently supported');
    }
    if (!(min >= 0 && max <= 1 && min < max)) {
      stop('Invalid gradient stops:', stops);
    }
    return function(t) {
      return t * (max - min) + min;
    };
  }

  function getStoppedValues(values, stops) {
    var interpolate = getInterpolatedValueGetter(values, null);
    var n = values.length;
    var fstop = getGradientFunction(stops);
    var values2 = [];
    var t, val;
    for (var i=0; i<n; i++) {
      t = fstop(i / (n - 1));
      val = interpolate(t * (n - 1));
      values2.push(val);
    }
    return values2;
  }

  // convert a continuous index ([0, n-1], -1) to a corresponding interpolated value
  function getInterpolatedValueGetter(values, nullValue) {
    var interpolators = [];
    var tmax = values.length - 1;
    for (var i=1; i<values.length; i++) {
      interpolators.push(d3_interpolate(values[i-1], values[i]));
    }
    return function(t) {
      if (t == -1) return nullValue;
      if ((t >= 0 && t <= tmax) === false) {
        error('Range error');
      }
      var i = t == tmax ? tmax - 1 : Math.floor(t);
      var j = t == tmax ? 1 : t % 1;
      return interpolators[i](j);
    };
  }

  // return an array of n values
  // assumes that values can be interpolated by d3-interpolate
  // (colors and numbers should work)
  function interpolateValuesToClasses(values, n, stops) {
    if (values.length == n && !stops) return values;
    var numPairs = values.length - 1;
    var output = [values[0]];
    var k, j, t, intVal;
    for (var i=1; i<n-1; i++) {
      k = i / (n-1) * numPairs;
      j = Math.floor(k);
      t = k - j;
      // if (convert) t = convert(t);
      intVal = d3_interpolate(values[j], values[j+1])(t);
      output.push(intVal);
    }
    output.push(values[values.length - 1]);
    if (stops) {
      output = getStoppedValues(output, stops);
    }
    return output;
  }

  // convert an index (0 ... n-1, -1, -2) to a corresponding discreet value
  function getDiscreteValueGetter(values, nullValue, otherValue) {
    var n = values.length;
    return function(i) {
      if (i >= 0 && i < n) {
        return values[i];
      }
      if (i == -2) {
        return otherValue === undefined ? nullValue : otherValue;
      }
      return nullValue;
    };
  }

  function getOutputFunction(classValues, nullValue, opts) {
    // get a function to convert class indexes to output values
    //
    if (opts.continuous) {
      return getInterpolatedValueGetter(classValues, nullValue);
    } else {
      return  getDiscreteValueGetter(classValues, nullValue, opts.other);
    }
  }

  function getKeyStyle(type, opts) {
    return {
      width: opts.key_width || type == 'dataviz' && 500 || 300,
      tileHeight: opts.key_tile_height || 10,
      labelSuffix: opts.key_label_suffix || '',
      lastSuffix: opts.key_last_suffix || '',
      chartHeight: 90,
      chartColor: '#ddd',
      ticColor: 'rgba(0,0,0,0.3)',
      ticLen: opts.key_tic_length >= 0 ? +opts.key_tic_length : 6,
      fontFamily: 'sans-serif',
      fontSize: opts.key_font_size || 13,
      textColor: '#555'
    };
  }

  function makeSimpleKey(colors, breaks, minVal, maxVal, opts) {
    var style = getKeyStyle('simple', opts);
    var tileWidth = style.width / colors.length;
    var tileData = makeEqualTiles(tileWidth, style.tileHeight, colors);
    var layers = [tileData];
    var labels, tics, ticBreaks;
    if (colors.length == breaks.length + 1) {
      ticBreaks = getEvenlySpacedTicOffsets(breaks.length, style.width);
      labels = getTicLabels(breaks, ticBreaks, 0, style.width, style);
      tics = getTics(ticBreaks, 0, style.width, style);
      layers.push(tics, labels);
    } else if (colors.length == breaks.length + 2) {
      style.ticLen = 2; // kludge for label spacing
      labels = getInlineLabels(getFullBreaks(breaks, minVal, maxVal), style);
      layers.push(labels);
    }
    exportKey(opts.key_name || 'simple-key', layers, style.width);
  }

  function makeDatavizKey(colors, breaks, ascending, opts) {
    var style = getKeyStyle('dataviz', opts);
    var minVal = ascending[0];
    var maxVal = ascending[ascending.length - 1];
    var partitions = getFullBreaks(breaks, minVal, maxVal);
    var chart = getReferenceChart(ascending, style);
    var tiles = getProportionalTiles(colors, breaks, minVal, maxVal, style);
    var labels = getTicLabels(partitions, partitions, minVal, maxVal, style);
    var tics = getTics(partitions, minVal, maxVal, style);
    exportKey(opts.key_name || 'dataviz-key', [chart, tiles, tics, labels], style.width);
  }

  function makeGradientKey(classify, breaks, minVal, maxVal, opts) {
    var style = getKeyStyle('gradient', opts);
    var partitions = getFullBreaks(breaks, minVal, maxVal);
    var gradient = makeGradient(classify, partitions, style);
    var ticBreaks = getEvenlySpacedTicOffsets(breaks.length, style.width);
    var labels = getTicLabels(breaks, ticBreaks, 0, style.width, style);
    var tics = getTics(ticBreaks, 0, style.width, style);
    var layers = [gradient, tics, labels];
    exportKey(opts.key_name || 'gradient-key', layers, style.width);
  }

  // export function makeGradientDatavizKey(classify, breaks, ascending, opts) {
  //   var style = getKeyStyle('dataviz', opts);
  //   var minVal = ascending[0];
  //   var maxVal = ascending[ascending.length - 1];
  //   var partitions = getFullBreaks(breaks, minVal, maxVal);
  //   var chart = getReferenceChart(ascending, style);
  //   var gradient = makeGradient(classify, partitions, style);
  //   // var tiles = getProportionalTiles(colors, breaks, minVal, maxVal, style);
  //   var labels = getTicLabels(partitions, partitions, minVal, maxVal, style);
  //   var tics = getTics(partitions, minVal, maxVal, style);
  //   exportKey(opts.key_name || 'dataviz-key', [chart, gradient, tics, labels], style.width);
  // }

  function getXScale(keyWidth, minVal, maxVal) {
    return function(val) {
      return (val - minVal) / (maxVal - minVal) * keyWidth;
    };
  }

  function getLabelTexts(values, style) {
    var digits = getLabelDigits(values);
    return values.map(function(val, i) {
      var isLast = i == values.length - 1;
      var suffix = isLast && style.lastSuffix || style.labelSuffix || '';
      return roundToDigits(val, digits) + suffix;
    });
  }

  function getLabelDigits(values) {
    var min = values[0];
    var max = values[values.length - 1];
    var avg = (max - min) / values.length;
    var d = 0;
    if (avg < 1) d = 2;
    else if (avg < 10) d = 1;
    return d;
  }

  function getEvenlySpacedTicOffsets(n, width) {
    var arr = [];
    for (var i=0; i<n; i++) {
      arr.push((i + 1) / (n + 1) * width);
    }
    return arr;
  }

  function getTics(breaks, minVal, maxVal, style) {
    var getX = getXScale(style.width, minVal, maxVal);
    var tics = [];
    for (var i=0; i<breaks.length; i++) {
      tics.push(makeTic(getX(breaks[i]), style));
    }
    return featuresToDataset(tics);
  }

  function getInlineLabels(values, style) {
    var labels = [];
    var texts = getLabelTexts(values, style);
    getLabelShift(style);
    var x;
    for (var i=0; i<texts.length; i++) {
      x = (i + 0.5) * style.width / texts.length;
      labels.push(makeLabel(texts[i], x, style));
    }
    return featuresToDataset(labels);
  }

  function getLabelShift(style) {
    // kludge to nudge numbers towards the tic
    return style.labelSuffix ? 3 : 0;
  }

  function getFullBreaks(innerBreaks, minVal, maxVal) {
    return [minVal].concat(innerBreaks, maxVal);
  }

  function getTicLabels(values, breaks, minVal, maxVal, style) {
    var texts = getLabelTexts(values, style);
    var getX = getXScale(style.width, minVal, maxVal);
    var labels = [];
    for (var i=0; i<breaks.length; i++) {
      labels.push(makeLabel(texts[i], getX(breaks[i]), style));
    }
    return featuresToDataset(labels);
  }

  function getProportionalTiles(colors, breaks, minVal, maxVal, style) {
    var arr = getFullBreaks(breaks, minVal, maxVal);
    var getX = getXScale(style.width, minVal, maxVal);
    var tiles = [];
    var x, w;
    for (var i=0; i<arr.length; i++) {
      x = getX(arr[i]);
      w = getX(arr[i+1]) - x;
      tiles.push(makeTile(x, 0, w, style.tileHeight, colors[i]));
    }
    return featuresToDataset(tiles);
  }

  function getReferenceChart(ascending, style) {
    var barWidth = 5;
    var numBars = Math.floor(style.width / barWidth);
    var breaks = getEqualIntervalBreaks(ascending, numBars - 1);
    var counts = getDistributionData(breaks, ascending);
    var maxCount = Math.max.apply(counts, counts);
    var bars = [];
    var y0 = style.tileHeight; // shift chart above the tiles
    var c, h;
    for (var i=0; i<numBars; i++) {
      c = counts[i];
      if (!c) continue;
      h = c / maxCount * style.chartHeight;
      bars.push(makeTile(i*barWidth, y0, barWidth, h , style.chartColor));
    }
    return featuresToDataset(bars);
  }

  function exportKey(name, datasets, width) {
    var svgOpts = {
      width: width,
      crisp_paths: true,
      default_linecap: 'butt'
    };
    var filename = name + (name.endsWith('.svg') ? '' : '.svg');
    var dataset = datasets.length == 1 ? datasets[0] : mergeDatasets(datasets);
    var output = exportSVG(dataset, svgOpts);
    output[0].filename = filename;
    writeFiles(output, {});
  }

  function featuresToDataset(features) {
    var json = {
      type: 'FeatureCollection',
      features: features
    };
    return importGeoJSON(json);
  }

  function makeGradient(classify, partitions, style) {
    var tiles = [];
    var getVal = pixToValue(partitions, style.width);
    var w = 2;
    for (var x=0; x<style.width; x += w) {
      tiles.push(makeTile(x, 0, w, style.tileHeight, classify(getVal(x))));
    }
    return featuresToDataset(tiles);
  }

  function pixToValue(partitions, keyWidth) {
    var classes = partitions.length - 1;
    var sectionWidth = keyWidth / classes;
    return function(x) {
      var i = Math.min(Math.floor(x / sectionWidth), classes - 1); // clamp
      var k = (x - i * sectionWidth) / sectionWidth;
      return partitions[i] * (1 - k) + partitions[i+1] * k;
    };
  }


  function makeEqualTiles(w, h, colors) {
    var tiles = [];
    for (var i=0; i<colors.length; i++) {
      tiles.push(makeTile(i * w, 0, w, h, colors[i]));
    }
    return featuresToDataset(tiles);
  }

  function getRectangle(x, y, w, h) {
    return [[x, y], [x, y+h], [x+w, y+h], [x+w, y], [x, y]];
  }

  function makeLabel(str, x, style) {
    var y = -(style.ticLen + style.fontSize * 0.7 + 4);
    var align;
    if (x <= 0) {
      align = 'start';
    } else if (x >= style.width) {
      align = 'end';
    } else {
      align = 'middle';
      x += getLabelShift(style);
    }
    return {
      type: 'Feature',
      properties: {
        'label-text': str,
        'font-family': style.fontFamily,
        'font-size': style.fontSize,
        'text-anchor': align,
        fill: style.textColor
      },
      geometry: {
        type: 'Point',
        coordinates: [x, y]
      }
    };
  }

  function makeTic(x, style) {
    var y = style.tileHeight;
    var h = style.tileHeight + style.ticLen;
    return {
      type: 'Feature',
      properties: { stroke: style.ticColor },
      geometry: {
        type: 'LineString',
        coordinates: [[x, y], [x, y - h]]
      }
    };
  }

  function makeTile(x, y, w, h, fill) {
    var coords = getRectangle(x, y, w, h);
    return {
      type: 'Feature',
      properties: {fill: fill},
      geometry: {
        type: 'Polygon',
        coordinates: [coords]
      }
    };
  }

  function getSequentialClassifier$1(classValues, nullValue, dataValues, method, opts) {
    var numValues = classValues.length;
    var numBuckets = opts.continuous ? numValues - 1 : numValues;

    // continuously interpolated colors/values use one fewer breakpoint than
    // discreetly classed values
    var numBreaks = numBuckets - 1;
    var round = opts.precision ? getRoundingFunction(opts.precision) : null;
    var breaks, classifier, dataToClass, classToValue;

    if (round) {
      dataValues = dataValues.map(round);
    }

    var ascending = getAscendingNumbers(dataValues);
    if (opts.outer_breaks) {
      ascending = applyDataRange(ascending, opts.outer_breaks);
    }
    var nullCount = dataValues.length - ascending.length;
    var minVal = ascending[0];
    var maxVal = ascending[ascending.length - 1];

    var clamp = opts.outer_breaks ? function(val) {
      if (val < opts.outer_breaks[0]) val = opts.outer_breaks[0];
      if (val > opts.outer_breaks[1]) val = opts.outer_breaks[1];
      return val;
    } : null;

    if (opts.outer_breaks) {
      minVal = opts.outer_breaks[0];
      maxVal = opts.outer_breaks[1];
    }

    if (numBreaks === 0) {
      breaks = [];
    } else if (opts.breaks) {
      // user-defined breaks
      breaks = opts.breaks;
    } else if (method == 'equal-interval') {
      breaks = getEqualIntervalBreaks(ascending, numBreaks);
    } else if (method == 'quantile') {
      breaks = getQuantileBreaks(ascending, numBreaks);
    } else if (method == 'hybrid') {
      breaks = getHybridBreaks(ascending, numBreaks);
    } else if (method == 'nice') {
      breaks = getNiceBreaks(ascending, numBreaks);
      message('Nice breaks:', breaks);
    } else {
      stop('Unknown classification method:', method);
    }

    printDistributionInfo(ascending, breaks, nullCount);

    if (opts.continuous) {
      dataToClass = getContinuousClassifier(breaks, minVal, maxVal);
    } else {
      dataToClass = getDiscreteClassifier(breaks, round);
    }
    classToValue = getOutputFunction(classValues, nullValue, opts);
    classifier = function(val) {
      if (clamp) val = clamp(val);
      return classToValue(dataToClass(val));
    };

    // generate a key if we've got colors and a key style
    if (opts.colors && (opts.key || opts.key_style)) {
      if (opts.key_style == 'gradient' && opts.continuous) {
        makeGradientKey(classifier, breaks, minVal, maxVal, opts);
      // } else if (opts.key_style == 'dataviz' && opts.continuous) {
      //   makeGradientDatavizKey(classifier, breaks, ascending, opts);
      } else if (opts.key_style == 'dataviz') {
        makeDatavizKey(classValues, breaks, ascending, opts);
      } else if (opts.key || opts.key_style == 'simple') {
        makeSimpleKey(classValues, breaks, minVal, maxVal, opts);
      }
    }

    return classifier;
  }

  function getClassRanges(breaks, ascending) {
    var ranges = [];
    var ids, geBound, ltBound, range;
    for (var breakId=0, i=0; breakId <= breaks.length; breakId++) {
      geBound = breakId === 0 ? -Infinity : breaks[breakId-1];
      ltBound = breakId < breaks.length ? breaks[breakId] : Infinity;
      ids = getClassRange(ascending, geBound, ltBound, i);
      if (ids) {
        // the usual case: a bucket containing >0 values
        range = [ascending[ids[0]], ascending[ids[1]]];
        i = ids[1];
      } else if (breakId === 0) {
        // left-most bucket, empty
        range = [ltBound, ltBound];
      } else if (breakId < breaks.length) {
        // internal bucket, empty
        range = [geBound, ltBound];
      } else {
        // right-most bucket, empty
        range = [geBound, geBound];
      }
      ranges.push(range);
    }
    return ranges;
  }

  // Gets the first and last value in a sequential class (bucket)
  // Returns null if bucket is empty
  // i: an index into the array of sorted numbers,
  //    at or before the first number in the bucket
  function getClassRange(ascending, geBound, ltBound, i) {
    var n = ascending.length;
    var rangeStart = -1, rangeEnd = -1;
    var val;
    while (i < n) {
      val = ascending[i];
      if (val >= ltBound) break;
      if (rangeStart == -1 && val >= geBound) {
        rangeStart = i;
      }
      rangeEnd = i;
      i++;
    }
    return rangeStart > -1 && rangeEnd > -1 ? [rangeStart, rangeEnd] : null;
  }

  function printDistributionInfo(ascending, breaks, nulls) {
    var dist = getDistributionData(breaks, ascending);
    var tableRows = getClassRanges(breaks, ascending).map(function(range, i) {
      return [`${range[0]} - ${range[1]}`, `(${dist[i]})`];
    });
    tableRows.push(['null or non-numeric values', `(${nulls})`]);
    // message('Computed breaks:', breaks);
    // message('Distribution:', dist.join(','));
    message('Data ranges and (feature counts):\n' + formatColumns(tableRows, ['left', 'right']));
  }

  function getDiscreteClassifier(breaks, round) {
    var inverted = false; // breaks are in descending sequence
    // if (values.length != breaks.length + 1) {
    //   stop("Number of values should be one more than number of class breaks");
    // }
    // validate breaks
    // Accepts repeated values -- should this be allowed?
    if (testAscendingNumbers(breaks)) ; else if (testDescendingNumbers(breaks)) {
      breaks = breaks.concat().reverse();
      inverted = true;
    } else {
      stop('Invalid class breaks:', breaks.join(','));
    }
    return function(val) {
      var i = -1;
      if (Number(val) === val) { // exclude null, NaN, strings, etc.
        if (round) val = val(round);
        i = getClassId(val, breaks);
      }
      if (inverted && i > -1) {
        i = breaks.length - i;
      }
      return i;
    };
  }

  // uses linear interpolation between breakpoints
  // (perhaps not ideal for long-tail distributions)
  // breaks: array of (0 or more) inner breakpoints
  function getContinuousClassifier(breaks, minVal, maxVal) {
    return function(val) {
      var n = breaks.length;
      var min, max, j;
      if (!utils.isValidNumber(val) || val < minVal || val > maxVal){
        return -1;
      }
      for (var i=0; i<=n; i++) {
        max = i === n ? maxVal : breaks[i];
        if (i === n || val < max) {
          min = i === 0 ? minVal : breaks[i-1];
          j = (val - min) / (max - min);
          return i + j;
        }
      }
      error('Range error');
    };
  }

  function getEqualIntervalBreaks(ascending, numBreaks) {
    var numRanges = numBreaks + 1,
        minVal = ascending[0],
        maxVal = ascending[ascending.length - 1],
        interval = (maxVal - minVal) / numRanges,
        breaks = [],
        i;
    for (i = 1; i<numRanges; i++) {
      breaks.push(minVal + i * interval);
    }
    return breaks;
  }

  function getQuantileBreaks(ascending, numBreaks) {
    var numRanges = numBreaks + 1;
    var n = ascending.length / numRanges;
    var breaks = [];
    var i, j;
    for (i = 1; i<numRanges; i++) {
      j = Math.floor(i * n);
      breaks.push(ascending[j]);
    }
    return breaks;
  }

  // inner breaks have equal-interval spacing
  // first and last bucket are sized like quantiles (they are sized to contain
  // a proportional share of the data)
  function getHybridBreaks(ascending, numBreaks) {
    var quantileBreaks = getQuantileBreaks(ascending, numBreaks);
    if (numBreaks < 3) return quantileBreaks;
    var lowerBreak = quantileBreaks[0];
    var upperBreak = quantileBreaks[quantileBreaks.length-1];
    var innerValues = ascending.filter(function(val) {
      return val >= lowerBreak && val < upperBreak;
    });
    var innerBreaks = getEqualIntervalBreaks(innerValues, numBreaks - 2);
    var breaks = [lowerBreak].concat(innerBreaks).concat(upperBreak);
    return breaks;
  }

  function getDistributionData(breaks, ascending) {
    var arr = utils.initializeArray(new Array(breaks.length + 1), 0);
    ascending.forEach(function(val) {
      var i = getClassId(val, breaks);
      if (i == -1) {
        error('Indexing error');
      } else {
        arr[i]++;
      }
    });
    return arr;
  }

  function applyDataRange(values, range) {
    var minval = range[0];
    var maxval = range[1];
    if (maxval > minval === false) {
      stop('Invalid data range:', range);
    }
    var values2 = values.map(function(val) {
      if (val < minval) val = minval;
      if (val > maxval) val = maxval;
      return val;
    });
    if (values2[0] < minval) {
      values2.unshift(minval);
    }
    if (values2[values2.length - 1] < maxval) {
      values2.push(maxval);
    }
    return values2;
  }

  function getAscendingNumbers(values) {
    var numbers = values.filter(utils.isFiniteNumber);
    utils.genericSort(numbers, true);
    return numbers;
  }

  function arraysAreIdentical(a, b) {
    for (var i=0; i<a.length; i++) {
      if (a[i] !== b[i]) return false;
    }
    return a.length == b.length;
  }

  function testAscendingNumbers(arr) {
    return arraysAreIdentical(arr, utils.genericSort(arr.map(parseFloat)));
  }

  function testDescendingNumbers(arr) {
    return arraysAreIdentical(arr, utils.genericSort(arr.map(parseFloat), false));
  }

  // breaks: threshold values between ranges (ascending order)
  // Returns array index of a sequential range, or -1 if @val not numeric
  function getClassId(val, breaks) {
    var i = 0;
    if (!utils.isValidNumber(val)) {
      return -1;
    }
    while (i < breaks.length && val >= breaks[i]) i++;
    return i;
  }

  function getCategoricalClassifier(classValues, nullVal, opts) {
    // categories: strings to match in the data
    var categories = opts.categories;
    var classToValue = getDiscreteValueGetter(classValues, nullVal, opts.other);
    return function(val) {
      var i = categories.indexOf(val);
      var idx = -1;
      if (i >= 0) {
        idx = i;
      } else if (val) {
        idx = -2; // field contains an 'other' value
      } else {
        idx = -1; // field is empty (null value)
      }
      return classToValue(idx);
    };
  }

  // Returns a function for constructing a query function that accepts an arc id and
  // returns information about the polygon or polygons that use the given arc.
  // TODO: explain this better.
  //
  // options:
  //   filter: optional filter function; signature: function(idA, idB or -1) : boolean
  //   reusable: flag that lets an arc be queried multiple times.
  function getArcClassifier(lyr, arcs, optsArg) {
    var opts = optsArg || {},
        useOnce = !opts.reusable,
        n = arcs.size(),
        a = new Int32Array(n),
        b = new Int32Array(n),
        filter;
    if (opts.where) {
      filter = compileFeaturePairFilterExpression(opts.where, lyr, arcs);
    }

    utils.initializeArray(a, -1);
    utils.initializeArray(b, -1);

    traversePaths(lyr.shapes, function(o) {
      var i = absArcId(o.arcId);
      var shpId = o.shapeId;
      var aval = a[i];
      if (aval == -1) {
        a[i] = shpId;
      } else if (shpId < aval) {
        b[i] = aval;
        a[i] = shpId;
      } else {
        b[i] = shpId;
      }
    });

    function classify(arcId, getKey) {
      var i = absArcId(arcId);
      var shpA = a[i];
      var shpB = b[i];
      var key;
      if (shpA == -1) return null;
      key = getKey(shpA, shpB);
      if (key === null || key === false) return null;
      if (useOnce) {
        // arc can only be queried once
        a[i] = -1;
        b[i] = -1;
      }
      // use optional filter to exclude some arcs
      if (filter && !filter(shpA, shpB)) return null;
      return key;
    }

    return function(getKey) {
      return function(arcId) {
        return classify(arcId, getKey);
      };
    };
  }

  var ArcClassifier = /*#__PURE__*/Object.freeze({
    __proto__: null,
    getArcClassifier: getArcClassifier
  });

  // Returns a function for querying the neighbors of a given shape. The function
  // can be called in either of two ways:
  //
  // 1. function(shapeId, callback)
  //    Callback signature: function(adjacentShapeId, arcId)
  //    The callback function is called once for each arc that the given feature
  //    shares with another feature.
  //
  // 2. function(shapeId)
  //    The function returns an array of unique ids of neighboring shapes, or
  //    an empty array if a shape has no neighbors.
  //
  function getNeighborLookupFunction(lyr, arcs) {
    var classifier = getArcClassifier(lyr, arcs, {reusable: true});
    var classify = classifier(onShapes);
    var currShapeId;
    var neighbors;
    var callback;

    function onShapes(a, b) {
      if (b == -1) return -1; // outer edges are b == -1
      return a == currShapeId ? b : a;
    }

    function onArc(arcId) {
      var nabeId = classify(arcId);
      if (nabeId == -1) return;
      if (callback) {
        callback(nabeId, arcId);
      } else if (neighbors.indexOf(nabeId) == -1) {
        neighbors.push(nabeId);
      }
    }

    return function(shpId, cb) {
      currShapeId = shpId;
      if (cb) {
        callback = cb;
        forEachArcId(lyr.shapes[shpId], onArc);
        callback = null;
      } else {
        neighbors = [];
        forEachArcId(lyr.shapes[shpId], onArc);
        return neighbors;
      }
    };
  }


  // Returns an array containing all pairs of adjacent shapes
  // in a collection of polygon shapes. A pair of shapes is represented as
  // an array of two shape indexes [a, b].
  function findPairsOfNeighbors(lyr, arcs) {
    var getKey = function(a, b) {
      return b > -1 && a > -1 ? [a, b] : null;
    };
    var classify = getArcClassifier(lyr, arcs)(getKey);
    var arr = [];
    var index = {};
    var onArc = function(arcId) {
      var obj = classify(arcId);
      var key;
      if (obj) {
        key = obj.join('~');
        if (key in index === false) {
          arr.push(obj);
          index[key] = true;
        }
      }
    };
    forEachArcId(lyr.shapes, onArc);
    return arr;
  }

  var PolygonNeighbors = /*#__PURE__*/Object.freeze({
    __proto__: null,
    getNeighborLookupFunction: getNeighborLookupFunction,
    findPairsOfNeighbors: findPairsOfNeighbors
  });

  function getNonAdjacentClassifier(lyr, dataset, colors) {
    requirePolygonLayer(lyr);
    var getNeighbors = getNeighborLookupFunction(lyr, dataset.arcs);
    var errorCount = 0;
    var data = utils.range(getFeatureCount(lyr)).map(function(shpId) {
      var nabes = getNeighbors(shpId) || [];
      var d = {
        nabes: nabes,
        colorId: -1,
        nabeColors: [],
        uncolored: nabes.length, // number of uncolored neighbors
        saturation: 0, // number of unique colors of neighbors
        common: 0 // number of repeated colors in neighbors
      };
      return d;
    });
    var getSortedColorIds = getUpdateFunction(colors.length);
    var colorIds = getSortedColorIds();
    // Sort adjacency data by number of neighbors in descending order
    var iter = getNodeIterator(data);
    // Assign colors, starting with polygons with the largest number of neighbors
    iter.forEach(function(d) {
      var colorId = pickColor(d, data, colorIds);
      if (colorId == -1) {
        errorCount++;
        colorId = colorIds[0];
      }
      d.colorId = colorId;
      {
        colorIds = getSortedColorIds(colorId);
      }
    });

    if (errorCount > 0) {
      message(`Unable to find non-adjacent colors for ${errorCount} ${errorCount == 1 ? 'polygon' : 'polygons'}`);
    }
    return function(shpId) {
      return colors[data[shpId].colorId];
    };
  }

  function getNodeIterator(data) {
    var sorted = data.concat();
    utils.sortOn(sorted, 'uncolored', true);
    function forEach(cb) {
      var item;
      while(sorted.length > 0) {
        item = sorted.pop();
        cb(item);
        updateNeighbors(item, sorted, data);
      }
    }

    return {
      forEach: forEach
    };
  }

  function updateNeighbors(item, sorted, data) {
    var nabe;
    var ids = item.nabes;
    for (var i=0; i<ids.length; i++) {
      nabe = data[ids[i]];
      if (nabe.colorId > -1) continue;
      updateNeighbor(nabe, item.colorId, sorted);
    }
  }

  function updateNeighbor(a, colorId, sorted) {
    var i = findItem(a, sorted);
    var n = sorted.length;
    var b;
    if (i == -1) {
      error('Indexing error');
    }
    a.uncolored--;
    if (!a.nabeColors.includes(colorId)) {
      a.saturation++;
      a.nabeColors.push(colorId);
    } else {
      a.common++;
    }
    // bubble sort!!!
    while (++i < n) {
      b = sorted[i];
      if (!betterThan(a, b)) break;
      sorted[i-1] = b;
      sorted[i] = a;
    }
  }

  function findItem(a, sorted) {
    // return sorted.indexOf(a); // bottleneck
    // binary search in sorted array
    var start = 0, end = sorted.length, i;
    while (end - start > 50) {
      i = Math.floor((start + end) / 2);
      if (sorted[i].saturation >= a.saturation) {
        end = i;
      } else {
        start = i;
      }
    }
    return sorted.indexOf(a, start);
  }

  function betterThan(a, b) {
    if (a.saturation > b.saturation) return true;
    if (a.saturation < b.saturation) return false;
    if (a.common > b.common) return true;
    if (a.common < b.common) return false;
    // based on 4-color tests with counties and zipcodes, this condition adds a bit of strength
    if (a.uncolored < b.uncolored) return true;
    return false;
  }

  // Pick the id of a color that is not shared with a neighboring polygon
  function pickColor(d, data, colorIds) {
    var candidateId;
    for (var i=0; i<colorIds.length; i++) {
      candidateId = colorIds[i];
      if (isAvailableColor(d, data, candidateId)) {
        return candidateId;
      }
    }
    return -1; // no colors are available
  }

  function isAvailableColor(d, data, colorId) {
    var nabes = d.nabes;
    for (var i=0; i<nabes.length; i++) {
      if (data[nabes[i]].colorId === colorId) return false;
    }
    return true;
  }

  // Update function returns an array of ids, sorted in descending order of preference
  // (less-used ids are preferred).
  // Function recieves an (optional) id that was just used.
  function getUpdateFunction(n) {
    var ids = utils.range(n);
    var counts = new Uint32Array(n);
    return function(i) {
      if (i >= 0 && i < n) {
        counts[i]++;
        utils.sortArrayIndex(ids, counts, true);
      } else if (i !== undefined) {
        error('Unexpected color index:', i);
      }
      return ids;
    };
  }

  function getIndexedClassifier(values, nullVal, opts) {
    // TODO: handle continuous classification
    var numBuckets = values.length;
    var classToValue = getOutputFunction(values, nullVal, opts);

    return function(val) {
      var idx = utils.isInteger(val) && val >= 0 && val < numBuckets ? val : -1;
      return classToValue(idx);
    };
  }

  // returns the number of classes, based on the largest class index found
  function getIndexedClassCount(records, name) {
    var invalid = [];
    var maxId = -1;
    records.forEach(function(d) {
      var val = (d || {})[name];
      if (!utils.isInteger(val) || val < -2) {
        invalid.push(val);
      } else {
        maxId = Math.max(maxId, val);
      }
    });
    if (invalid.length > 0) {
      stop(`Class index field contains invalid value(s): ${invalid.slice(0, 5)}`);
    }
    return maxId + 1;
  }

  function colors(specifier) {
    var n = specifier.length / 6 | 0, colors = new Array(n), i = 0;
    while (i < n) colors[i] = "#" + specifier.slice(i * 6, ++i * 6);
    return colors;
  }

  var category10 = colors("1f77b4ff7f0e2ca02cd627289467bd8c564be377c27f7f7fbcbd2217becf");

  var Accent = colors("7fc97fbeaed4fdc086ffff99386cb0f0027fbf5b17666666");

  var Dark2 = colors("1b9e77d95f027570b3e7298a66a61ee6ab02a6761d666666");

  var Paired = colors("a6cee31f78b4b2df8a33a02cfb9a99e31a1cfdbf6fff7f00cab2d66a3d9affff99b15928");

  var Pastel1 = colors("fbb4aeb3cde3ccebc5decbe4fed9a6ffffcce5d8bdfddaecf2f2f2");

  var Pastel2 = colors("b3e2cdfdcdaccbd5e8f4cae4e6f5c9fff2aef1e2cccccccc");

  var Set1 = colors("e41a1c377eb84daf4a984ea3ff7f00ffff33a65628f781bf999999");

  var Set2 = colors("66c2a5fc8d628da0cbe78ac3a6d854ffd92fe5c494b3b3b3");

  var Set3 = colors("8dd3c7ffffb3bebadafb807280b1d3fdb462b3de69fccde5d9d9d9bc80bdccebc5ffed6f");

  var Tableau10 = colors("4e79a7f28e2ce1575976b7b259a14fedc949af7aa1ff9da79c755fbab0ab");

  var ramp$1 = scheme => rgbBasis(scheme[scheme.length - 1]);

  var scheme$q = new Array(3).concat(
    "d8b365f5f5f55ab4ac",
    "a6611adfc27d80cdc1018571",
    "a6611adfc27df5f5f580cdc1018571",
    "8c510ad8b365f6e8c3c7eae55ab4ac01665e",
    "8c510ad8b365f6e8c3f5f5f5c7eae55ab4ac01665e",
    "8c510abf812ddfc27df6e8c3c7eae580cdc135978f01665e",
    "8c510abf812ddfc27df6e8c3f5f5f5c7eae580cdc135978f01665e",
    "5430058c510abf812ddfc27df6e8c3c7eae580cdc135978f01665e003c30",
    "5430058c510abf812ddfc27df6e8c3f5f5f5c7eae580cdc135978f01665e003c30"
  ).map(colors);

  var BrBG = ramp$1(scheme$q);

  var scheme$p = new Array(3).concat(
    "af8dc3f7f7f77fbf7b",
    "7b3294c2a5cfa6dba0008837",
    "7b3294c2a5cff7f7f7a6dba0008837",
    "762a83af8dc3e7d4e8d9f0d37fbf7b1b7837",
    "762a83af8dc3e7d4e8f7f7f7d9f0d37fbf7b1b7837",
    "762a839970abc2a5cfe7d4e8d9f0d3a6dba05aae611b7837",
    "762a839970abc2a5cfe7d4e8f7f7f7d9f0d3a6dba05aae611b7837",
    "40004b762a839970abc2a5cfe7d4e8d9f0d3a6dba05aae611b783700441b",
    "40004b762a839970abc2a5cfe7d4e8f7f7f7d9f0d3a6dba05aae611b783700441b"
  ).map(colors);

  var PRGn = ramp$1(scheme$p);

  var scheme$o = new Array(3).concat(
    "e9a3c9f7f7f7a1d76a",
    "d01c8bf1b6dab8e1864dac26",
    "d01c8bf1b6daf7f7f7b8e1864dac26",
    "c51b7de9a3c9fde0efe6f5d0a1d76a4d9221",
    "c51b7de9a3c9fde0eff7f7f7e6f5d0a1d76a4d9221",
    "c51b7dde77aef1b6dafde0efe6f5d0b8e1867fbc414d9221",
    "c51b7dde77aef1b6dafde0eff7f7f7e6f5d0b8e1867fbc414d9221",
    "8e0152c51b7dde77aef1b6dafde0efe6f5d0b8e1867fbc414d9221276419",
    "8e0152c51b7dde77aef1b6dafde0eff7f7f7e6f5d0b8e1867fbc414d9221276419"
  ).map(colors);

  var PiYG = ramp$1(scheme$o);

  var scheme$n = new Array(3).concat(
    "998ec3f7f7f7f1a340",
    "5e3c99b2abd2fdb863e66101",
    "5e3c99b2abd2f7f7f7fdb863e66101",
    "542788998ec3d8daebfee0b6f1a340b35806",
    "542788998ec3d8daebf7f7f7fee0b6f1a340b35806",
    "5427888073acb2abd2d8daebfee0b6fdb863e08214b35806",
    "5427888073acb2abd2d8daebf7f7f7fee0b6fdb863e08214b35806",
    "2d004b5427888073acb2abd2d8daebfee0b6fdb863e08214b358067f3b08",
    "2d004b5427888073acb2abd2d8daebf7f7f7fee0b6fdb863e08214b358067f3b08"
  ).map(colors);

  var PuOr = ramp$1(scheme$n);

  var scheme$m = new Array(3).concat(
    "ef8a62f7f7f767a9cf",
    "ca0020f4a58292c5de0571b0",
    "ca0020f4a582f7f7f792c5de0571b0",
    "b2182bef8a62fddbc7d1e5f067a9cf2166ac",
    "b2182bef8a62fddbc7f7f7f7d1e5f067a9cf2166ac",
    "b2182bd6604df4a582fddbc7d1e5f092c5de4393c32166ac",
    "b2182bd6604df4a582fddbc7f7f7f7d1e5f092c5de4393c32166ac",
    "67001fb2182bd6604df4a582fddbc7d1e5f092c5de4393c32166ac053061",
    "67001fb2182bd6604df4a582fddbc7f7f7f7d1e5f092c5de4393c32166ac053061"
  ).map(colors);

  var RdBu = ramp$1(scheme$m);

  var scheme$l = new Array(3).concat(
    "ef8a62ffffff999999",
    "ca0020f4a582bababa404040",
    "ca0020f4a582ffffffbababa404040",
    "b2182bef8a62fddbc7e0e0e09999994d4d4d",
    "b2182bef8a62fddbc7ffffffe0e0e09999994d4d4d",
    "b2182bd6604df4a582fddbc7e0e0e0bababa8787874d4d4d",
    "b2182bd6604df4a582fddbc7ffffffe0e0e0bababa8787874d4d4d",
    "67001fb2182bd6604df4a582fddbc7e0e0e0bababa8787874d4d4d1a1a1a",
    "67001fb2182bd6604df4a582fddbc7ffffffe0e0e0bababa8787874d4d4d1a1a1a"
  ).map(colors);

  var RdGy = ramp$1(scheme$l);

  var scheme$k = new Array(3).concat(
    "fc8d59ffffbf91bfdb",
    "d7191cfdae61abd9e92c7bb6",
    "d7191cfdae61ffffbfabd9e92c7bb6",
    "d73027fc8d59fee090e0f3f891bfdb4575b4",
    "d73027fc8d59fee090ffffbfe0f3f891bfdb4575b4",
    "d73027f46d43fdae61fee090e0f3f8abd9e974add14575b4",
    "d73027f46d43fdae61fee090ffffbfe0f3f8abd9e974add14575b4",
    "a50026d73027f46d43fdae61fee090e0f3f8abd9e974add14575b4313695",
    "a50026d73027f46d43fdae61fee090ffffbfe0f3f8abd9e974add14575b4313695"
  ).map(colors);

  var RdYlBu = ramp$1(scheme$k);

  var scheme$j = new Array(3).concat(
    "fc8d59ffffbf91cf60",
    "d7191cfdae61a6d96a1a9641",
    "d7191cfdae61ffffbfa6d96a1a9641",
    "d73027fc8d59fee08bd9ef8b91cf601a9850",
    "d73027fc8d59fee08bffffbfd9ef8b91cf601a9850",
    "d73027f46d43fdae61fee08bd9ef8ba6d96a66bd631a9850",
    "d73027f46d43fdae61fee08bffffbfd9ef8ba6d96a66bd631a9850",
    "a50026d73027f46d43fdae61fee08bd9ef8ba6d96a66bd631a9850006837",
    "a50026d73027f46d43fdae61fee08bffffbfd9ef8ba6d96a66bd631a9850006837"
  ).map(colors);

  var RdYlGn = ramp$1(scheme$j);

  var scheme$i = new Array(3).concat(
    "fc8d59ffffbf99d594",
    "d7191cfdae61abdda42b83ba",
    "d7191cfdae61ffffbfabdda42b83ba",
    "d53e4ffc8d59fee08be6f59899d5943288bd",
    "d53e4ffc8d59fee08bffffbfe6f59899d5943288bd",
    "d53e4ff46d43fdae61fee08be6f598abdda466c2a53288bd",
    "d53e4ff46d43fdae61fee08bffffbfe6f598abdda466c2a53288bd",
    "9e0142d53e4ff46d43fdae61fee08be6f598abdda466c2a53288bd5e4fa2",
    "9e0142d53e4ff46d43fdae61fee08bffffbfe6f598abdda466c2a53288bd5e4fa2"
  ).map(colors);

  var Spectral = ramp$1(scheme$i);

  var scheme$h = new Array(3).concat(
    "e5f5f999d8c92ca25f",
    "edf8fbb2e2e266c2a4238b45",
    "edf8fbb2e2e266c2a42ca25f006d2c",
    "edf8fbccece699d8c966c2a42ca25f006d2c",
    "edf8fbccece699d8c966c2a441ae76238b45005824",
    "f7fcfde5f5f9ccece699d8c966c2a441ae76238b45005824",
    "f7fcfde5f5f9ccece699d8c966c2a441ae76238b45006d2c00441b"
  ).map(colors);

  var BuGn = ramp$1(scheme$h);

  var scheme$g = new Array(3).concat(
    "e0ecf49ebcda8856a7",
    "edf8fbb3cde38c96c688419d",
    "edf8fbb3cde38c96c68856a7810f7c",
    "edf8fbbfd3e69ebcda8c96c68856a7810f7c",
    "edf8fbbfd3e69ebcda8c96c68c6bb188419d6e016b",
    "f7fcfde0ecf4bfd3e69ebcda8c96c68c6bb188419d6e016b",
    "f7fcfde0ecf4bfd3e69ebcda8c96c68c6bb188419d810f7c4d004b"
  ).map(colors);

  var BuPu = ramp$1(scheme$g);

  var scheme$f = new Array(3).concat(
    "e0f3dba8ddb543a2ca",
    "f0f9e8bae4bc7bccc42b8cbe",
    "f0f9e8bae4bc7bccc443a2ca0868ac",
    "f0f9e8ccebc5a8ddb57bccc443a2ca0868ac",
    "f0f9e8ccebc5a8ddb57bccc44eb3d32b8cbe08589e",
    "f7fcf0e0f3dbccebc5a8ddb57bccc44eb3d32b8cbe08589e",
    "f7fcf0e0f3dbccebc5a8ddb57bccc44eb3d32b8cbe0868ac084081"
  ).map(colors);

  var GnBu = ramp$1(scheme$f);

  var scheme$e = new Array(3).concat(
    "fee8c8fdbb84e34a33",
    "fef0d9fdcc8afc8d59d7301f",
    "fef0d9fdcc8afc8d59e34a33b30000",
    "fef0d9fdd49efdbb84fc8d59e34a33b30000",
    "fef0d9fdd49efdbb84fc8d59ef6548d7301f990000",
    "fff7ecfee8c8fdd49efdbb84fc8d59ef6548d7301f990000",
    "fff7ecfee8c8fdd49efdbb84fc8d59ef6548d7301fb300007f0000"
  ).map(colors);

  var OrRd = ramp$1(scheme$e);

  var scheme$d = new Array(3).concat(
    "ece2f0a6bddb1c9099",
    "f6eff7bdc9e167a9cf02818a",
    "f6eff7bdc9e167a9cf1c9099016c59",
    "f6eff7d0d1e6a6bddb67a9cf1c9099016c59",
    "f6eff7d0d1e6a6bddb67a9cf3690c002818a016450",
    "fff7fbece2f0d0d1e6a6bddb67a9cf3690c002818a016450",
    "fff7fbece2f0d0d1e6a6bddb67a9cf3690c002818a016c59014636"
  ).map(colors);

  var PuBuGn = ramp$1(scheme$d);

  var scheme$c = new Array(3).concat(
    "ece7f2a6bddb2b8cbe",
    "f1eef6bdc9e174a9cf0570b0",
    "f1eef6bdc9e174a9cf2b8cbe045a8d",
    "f1eef6d0d1e6a6bddb74a9cf2b8cbe045a8d",
    "f1eef6d0d1e6a6bddb74a9cf3690c00570b0034e7b",
    "fff7fbece7f2d0d1e6a6bddb74a9cf3690c00570b0034e7b",
    "fff7fbece7f2d0d1e6a6bddb74a9cf3690c00570b0045a8d023858"
  ).map(colors);

  var PuBu = ramp$1(scheme$c);

  var scheme$b = new Array(3).concat(
    "e7e1efc994c7dd1c77",
    "f1eef6d7b5d8df65b0ce1256",
    "f1eef6d7b5d8df65b0dd1c77980043",
    "f1eef6d4b9dac994c7df65b0dd1c77980043",
    "f1eef6d4b9dac994c7df65b0e7298ace125691003f",
    "f7f4f9e7e1efd4b9dac994c7df65b0e7298ace125691003f",
    "f7f4f9e7e1efd4b9dac994c7df65b0e7298ace125698004367001f"
  ).map(colors);

  var PuRd = ramp$1(scheme$b);

  var scheme$a = new Array(3).concat(
    "fde0ddfa9fb5c51b8a",
    "feebe2fbb4b9f768a1ae017e",
    "feebe2fbb4b9f768a1c51b8a7a0177",
    "feebe2fcc5c0fa9fb5f768a1c51b8a7a0177",
    "feebe2fcc5c0fa9fb5f768a1dd3497ae017e7a0177",
    "fff7f3fde0ddfcc5c0fa9fb5f768a1dd3497ae017e7a0177",
    "fff7f3fde0ddfcc5c0fa9fb5f768a1dd3497ae017e7a017749006a"
  ).map(colors);

  var RdPu = ramp$1(scheme$a);

  var scheme$9 = new Array(3).concat(
    "edf8b17fcdbb2c7fb8",
    "ffffcca1dab441b6c4225ea8",
    "ffffcca1dab441b6c42c7fb8253494",
    "ffffccc7e9b47fcdbb41b6c42c7fb8253494",
    "ffffccc7e9b47fcdbb41b6c41d91c0225ea80c2c84",
    "ffffd9edf8b1c7e9b47fcdbb41b6c41d91c0225ea80c2c84",
    "ffffd9edf8b1c7e9b47fcdbb41b6c41d91c0225ea8253494081d58"
  ).map(colors);

  var YlGnBu = ramp$1(scheme$9);

  var scheme$8 = new Array(3).concat(
    "f7fcb9addd8e31a354",
    "ffffccc2e69978c679238443",
    "ffffccc2e69978c67931a354006837",
    "ffffccd9f0a3addd8e78c67931a354006837",
    "ffffccd9f0a3addd8e78c67941ab5d238443005a32",
    "ffffe5f7fcb9d9f0a3addd8e78c67941ab5d238443005a32",
    "ffffe5f7fcb9d9f0a3addd8e78c67941ab5d238443006837004529"
  ).map(colors);

  var YlGn = ramp$1(scheme$8);

  var scheme$7 = new Array(3).concat(
    "fff7bcfec44fd95f0e",
    "ffffd4fed98efe9929cc4c02",
    "ffffd4fed98efe9929d95f0e993404",
    "ffffd4fee391fec44ffe9929d95f0e993404",
    "ffffd4fee391fec44ffe9929ec7014cc4c028c2d04",
    "ffffe5fff7bcfee391fec44ffe9929ec7014cc4c028c2d04",
    "ffffe5fff7bcfee391fec44ffe9929ec7014cc4c02993404662506"
  ).map(colors);

  var YlOrBr = ramp$1(scheme$7);

  var scheme$6 = new Array(3).concat(
    "ffeda0feb24cf03b20",
    "ffffb2fecc5cfd8d3ce31a1c",
    "ffffb2fecc5cfd8d3cf03b20bd0026",
    "ffffb2fed976feb24cfd8d3cf03b20bd0026",
    "ffffb2fed976feb24cfd8d3cfc4e2ae31a1cb10026",
    "ffffccffeda0fed976feb24cfd8d3cfc4e2ae31a1cb10026",
    "ffffccffeda0fed976feb24cfd8d3cfc4e2ae31a1cbd0026800026"
  ).map(colors);

  var YlOrRd = ramp$1(scheme$6);

  var scheme$5 = new Array(3).concat(
    "deebf79ecae13182bd",
    "eff3ffbdd7e76baed62171b5",
    "eff3ffbdd7e76baed63182bd08519c",
    "eff3ffc6dbef9ecae16baed63182bd08519c",
    "eff3ffc6dbef9ecae16baed64292c62171b5084594",
    "f7fbffdeebf7c6dbef9ecae16baed64292c62171b5084594",
    "f7fbffdeebf7c6dbef9ecae16baed64292c62171b508519c08306b"
  ).map(colors);

  var Blues = ramp$1(scheme$5);

  var scheme$4 = new Array(3).concat(
    "e5f5e0a1d99b31a354",
    "edf8e9bae4b374c476238b45",
    "edf8e9bae4b374c47631a354006d2c",
    "edf8e9c7e9c0a1d99b74c47631a354006d2c",
    "edf8e9c7e9c0a1d99b74c47641ab5d238b45005a32",
    "f7fcf5e5f5e0c7e9c0a1d99b74c47641ab5d238b45005a32",
    "f7fcf5e5f5e0c7e9c0a1d99b74c47641ab5d238b45006d2c00441b"
  ).map(colors);

  var Greens = ramp$1(scheme$4);

  var scheme$3 = new Array(3).concat(
    "f0f0f0bdbdbd636363",
    "f7f7f7cccccc969696525252",
    "f7f7f7cccccc969696636363252525",
    "f7f7f7d9d9d9bdbdbd969696636363252525",
    "f7f7f7d9d9d9bdbdbd969696737373525252252525",
    "fffffff0f0f0d9d9d9bdbdbd969696737373525252252525",
    "fffffff0f0f0d9d9d9bdbdbd969696737373525252252525000000"
  ).map(colors);

  var Greys = ramp$1(scheme$3);

  var scheme$2 = new Array(3).concat(
    "efedf5bcbddc756bb1",
    "f2f0f7cbc9e29e9ac86a51a3",
    "f2f0f7cbc9e29e9ac8756bb154278f",
    "f2f0f7dadaebbcbddc9e9ac8756bb154278f",
    "f2f0f7dadaebbcbddc9e9ac8807dba6a51a34a1486",
    "fcfbfdefedf5dadaebbcbddc9e9ac8807dba6a51a34a1486",
    "fcfbfdefedf5dadaebbcbddc9e9ac8807dba6a51a354278f3f007d"
  ).map(colors);

  var Purples = ramp$1(scheme$2);

  var scheme$1 = new Array(3).concat(
    "fee0d2fc9272de2d26",
    "fee5d9fcae91fb6a4acb181d",
    "fee5d9fcae91fb6a4ade2d26a50f15",
    "fee5d9fcbba1fc9272fb6a4ade2d26a50f15",
    "fee5d9fcbba1fc9272fb6a4aef3b2ccb181d99000d",
    "fff5f0fee0d2fcbba1fc9272fb6a4aef3b2ccb181d99000d",
    "fff5f0fee0d2fcbba1fc9272fb6a4aef3b2ccb181da50f1567000d"
  ).map(colors);

  var Reds = ramp$1(scheme$1);

  var scheme = new Array(3).concat(
    "fee6cefdae6be6550d",
    "feeddefdbe85fd8d3cd94701",
    "feeddefdbe85fd8d3ce6550da63603",
    "feeddefdd0a2fdae6bfd8d3ce6550da63603",
    "feeddefdd0a2fdae6bfd8d3cf16913d948018c2d04",
    "fff5ebfee6cefdd0a2fdae6bfd8d3cf16913d948018c2d04",
    "fff5ebfee6cefdd0a2fdae6bfd8d3cf16913d94801a636037f2704"
  ).map(colors);

  var Oranges = ramp$1(scheme);

  function cividis(t) {
    t = Math.max(0, Math.min(1, t));
    return "rgb("
        + Math.max(0, Math.min(255, Math.round(-4.54 - t * (35.34 - t * (2381.73 - t * (6402.7 - t * (7024.72 - t * 2710.57))))))) + ", "
        + Math.max(0, Math.min(255, Math.round(32.49 + t * (170.73 + t * (52.82 - t * (131.46 - t * (176.58 - t * 67.37))))))) + ", "
        + Math.max(0, Math.min(255, Math.round(81.24 + t * (442.36 - t * (2482.43 - t * (6167.24 - t * (6614.94 - t * 2475.67)))))))
        + ")";
  }

  var cubehelix = cubehelixLong(cubehelix$2(300, 0.5, 0.0), cubehelix$2(-240, 0.5, 1.0));

  var warm = cubehelixLong(cubehelix$2(-100, 0.75, 0.35), cubehelix$2(80, 1.50, 0.8));

  var cool = cubehelixLong(cubehelix$2(260, 0.75, 0.35), cubehelix$2(80, 1.50, 0.8));

  var c$1 = cubehelix$2();

  function rainbow(t) {
    if (t < 0 || t > 1) t -= Math.floor(t);
    var ts = Math.abs(t - 0.5);
    c$1.h = 360 * t - 100;
    c$1.s = 1.5 - 1.5 * ts;
    c$1.l = 0.8 - 0.9 * ts;
    return c$1 + "";
  }

  var c = rgb$1(),
      pi_1_3 = Math.PI / 3,
      pi_2_3 = Math.PI * 2 / 3;

  function sinebow(t) {
    var x;
    t = (0.5 - t) * Math.PI;
    c.r = 255 * (x = Math.sin(t)) * x;
    c.g = 255 * (x = Math.sin(t + pi_1_3)) * x;
    c.b = 255 * (x = Math.sin(t + pi_2_3)) * x;
    return c + "";
  }

  function turbo(t) {
    t = Math.max(0, Math.min(1, t));
    return "rgb("
        + Math.max(0, Math.min(255, Math.round(34.61 + t * (1172.33 - t * (10793.56 - t * (33300.12 - t * (38394.49 - t * 14825.05))))))) + ", "
        + Math.max(0, Math.min(255, Math.round(23.31 + t * (557.33 + t * (1225.33 - t * (3574.96 - t * (1073.77 + t * 707.56))))))) + ", "
        + Math.max(0, Math.min(255, Math.round(27.2 + t * (3211.1 - t * (15327.97 - t * (27814 - t * (22569.18 - t * 6838.66)))))))
        + ")";
  }

  function ramp(range) {
    var n = range.length;
    return function(t) {
      return range[Math.max(0, Math.min(n - 1, Math.floor(t * n)))];
    };
  }

  var viridis = ramp(colors("44015444025645045745055946075a46085c460a5d460b5e470d60470e6147106347116447136548146748166848176948186a481a6c481b6d481c6e481d6f481f70482071482173482374482475482576482677482878482979472a7a472c7a472d7b472e7c472f7d46307e46327e46337f463480453581453781453882443983443a83443b84433d84433e85423f854240864241864142874144874045884046883f47883f48893e49893e4a893e4c8a3d4d8a3d4e8a3c4f8a3c508b3b518b3b528b3a538b3a548c39558c39568c38588c38598c375a8c375b8d365c8d365d8d355e8d355f8d34608d34618d33628d33638d32648e32658e31668e31678e31688e30698e306a8e2f6b8e2f6c8e2e6d8e2e6e8e2e6f8e2d708e2d718e2c718e2c728e2c738e2b748e2b758e2a768e2a778e2a788e29798e297a8e297b8e287c8e287d8e277e8e277f8e27808e26818e26828e26828e25838e25848e25858e24868e24878e23888e23898e238a8d228b8d228c8d228d8d218e8d218f8d21908d21918c20928c20928c20938c1f948c1f958b1f968b1f978b1f988b1f998a1f9a8a1e9b8a1e9c891e9d891f9e891f9f881fa0881fa1881fa1871fa28720a38620a48621a58521a68522a78522a88423a98324aa8325ab8225ac8226ad8127ad8128ae8029af7f2ab07f2cb17e2db27d2eb37c2fb47c31b57b32b67a34b67935b77937b87838b9773aba763bbb753dbc743fbc7340bd7242be7144bf7046c06f48c16e4ac16d4cc26c4ec36b50c46a52c56954c56856c66758c7655ac8645cc8635ec96260ca6063cb5f65cb5e67cc5c69cd5b6ccd5a6ece5870cf5773d05675d05477d1537ad1517cd2507fd34e81d34d84d44b86d54989d5488bd6468ed64590d74393d74195d84098d83e9bd93c9dd93ba0da39a2da37a5db36a8db34aadc32addc30b0dd2fb2dd2db5de2bb8de29bade28bddf26c0df25c2df23c5e021c8e020cae11fcde11dd0e11cd2e21bd5e21ad8e219dae319dde318dfe318e2e418e5e419e7e419eae51aece51befe51cf1e51df4e61ef6e620f8e621fbe723fde725"));

  var magma = ramp(colors("00000401000501010601010802010902020b02020d03030f03031204041405041606051806051a07061c08071e0907200a08220b09240c09260d0a290e0b2b100b2d110c2f120d31130d34140e36150e38160f3b180f3d19103f1a10421c10441d11471e114920114b21114e22115024125325125527125829115a2a115c2c115f2d11612f116331116533106734106936106b38106c390f6e3b0f703d0f713f0f72400f74420f75440f764510774710784910784a10794c117a4e117b4f127b51127c52137c54137d56147d57157e59157e5a167e5c167f5d177f5f187f601880621980641a80651a80671b80681c816a1c816b1d816d1d816e1e81701f81721f817320817521817621817822817922827b23827c23827e24828025828125818326818426818627818827818928818b29818c29818e2a81902a81912b81932b80942c80962c80982d80992d809b2e7f9c2e7f9e2f7fa02f7fa1307ea3307ea5317ea6317da8327daa337dab337cad347cae347bb0357bb2357bb3367ab5367ab73779b83779ba3878bc3978bd3977bf3a77c03a76c23b75c43c75c53c74c73d73c83e73ca3e72cc3f71cd4071cf4070d0416fd2426fd3436ed5446dd6456cd8456cd9466bdb476adc4869de4968df4a68e04c67e24d66e34e65e44f64e55064e75263e85362e95462ea5661eb5760ec5860ed5a5fee5b5eef5d5ef05f5ef1605df2625df2645cf3655cf4675cf4695cf56b5cf66c5cf66e5cf7705cf7725cf8745cf8765cf9785df9795df97b5dfa7d5efa7f5efa815ffb835ffb8560fb8761fc8961fc8a62fc8c63fc8e64fc9065fd9266fd9467fd9668fd9869fd9a6afd9b6bfe9d6cfe9f6dfea16efea36ffea571fea772fea973feaa74feac76feae77feb078feb27afeb47bfeb67cfeb77efeb97ffebb81febd82febf84fec185fec287fec488fec68afec88cfeca8dfecc8ffecd90fecf92fed194fed395fed597fed799fed89afdda9cfddc9efddea0fde0a1fde2a3fde3a5fde5a7fde7a9fde9aafdebacfcecaefceeb0fcf0b2fcf2b4fcf4b6fcf6b8fcf7b9fcf9bbfcfbbdfcfdbf"));

  var inferno = ramp(colors("00000401000501010601010802010a02020c02020e03021004031204031405041706041907051b08051d09061f0a07220b07240c08260d08290e092b10092d110a30120a32140b34150b37160b39180c3c190c3e1b0c411c0c431e0c451f0c48210c4a230c4c240c4f260c51280b53290b552b0b572d0b592f0a5b310a5c320a5e340a5f3609613809623909633b09643d09653e0966400a67420a68440a68450a69470b6a490b6a4a0c6b4c0c6b4d0d6c4f0d6c510e6c520e6d540f6d550f6d57106e59106e5a116e5c126e5d126e5f136e61136e62146e64156e65156e67166e69166e6a176e6c186e6d186e6f196e71196e721a6e741a6e751b6e771c6d781c6d7a1d6d7c1d6d7d1e6d7f1e6c801f6c82206c84206b85216b87216b88226a8a226a8c23698d23698f24699025689225689326679526679727669827669a28659b29649d29649f2a63a02a63a22b62a32c61a52c60a62d60a82e5fa92e5eab2f5ead305dae305cb0315bb1325ab3325ab43359b63458b73557b93556ba3655bc3754bd3853bf3952c03a51c13a50c33b4fc43c4ec63d4dc73e4cc83f4bca404acb4149cc4248ce4347cf4446d04545d24644d34743d44842d54a41d74b3fd84c3ed94d3dda4e3cdb503bdd513ade5238df5337e05536e15635e25734e35933e45a31e55c30e65d2fe75e2ee8602de9612bea632aeb6429eb6628ec6726ed6925ee6a24ef6c23ef6e21f06f20f1711ff1731df2741cf3761bf37819f47918f57b17f57d15f67e14f68013f78212f78410f8850ff8870ef8890cf98b0bf98c0af98e09fa9008fa9207fa9407fb9606fb9706fb9906fb9b06fb9d07fc9f07fca108fca309fca50afca60cfca80dfcaa0ffcac11fcae12fcb014fcb216fcb418fbb61afbb81dfbba1ffbbc21fbbe23fac026fac228fac42afac62df9c72ff9c932f9cb35f8cd37f8cf3af7d13df7d340f6d543f6d746f5d949f5db4cf4dd4ff4df53f4e156f3e35af3e55df2e661f2e865f2ea69f1ec6df1ed71f1ef75f1f179f2f27df2f482f3f586f3f68af4f88ef5f992f6fa96f8fb9af9fc9dfafda1fcffa4"));

  var plasma = ramp(colors("0d088710078813078916078a19068c1b068d1d068e20068f2206902406912605912805922a05932c05942e05952f059631059733059735049837049938049a3a049a3c049b3e049c3f049c41049d43039e44039e46039f48039f4903a04b03a14c02a14e02a25002a25102a35302a35502a45601a45801a45901a55b01a55c01a65e01a66001a66100a76300a76400a76600a76700a86900a86a00a86c00a86e00a86f00a87100a87201a87401a87501a87701a87801a87a02a87b02a87d03a87e03a88004a88104a78305a78405a78606a68707a68808a68a09a58b0aa58d0ba58e0ca48f0da4910ea3920fa39410a29511a19613a19814a099159f9a169f9c179e9d189d9e199da01a9ca11b9ba21d9aa31e9aa51f99a62098a72197a82296aa2395ab2494ac2694ad2793ae2892b02991b12a90b22b8fb32c8eb42e8db52f8cb6308bb7318ab83289ba3388bb3488bc3587bd3786be3885bf3984c03a83c13b82c23c81c33d80c43e7fc5407ec6417dc7427cc8437bc9447aca457acb4679cc4778cc4977cd4a76ce4b75cf4c74d04d73d14e72d24f71d35171d45270d5536fd5546ed6556dd7566cd8576bd9586ada5a6ada5b69db5c68dc5d67dd5e66de5f65de6164df6263e06363e16462e26561e26660e3685fe4695ee56a5de56b5de66c5ce76e5be76f5ae87059e97158e97257ea7457eb7556eb7655ec7754ed7953ed7a52ee7b51ef7c51ef7e50f07f4ff0804ef1814df1834cf2844bf3854bf3874af48849f48948f58b47f58c46f68d45f68f44f79044f79143f79342f89441f89540f9973ff9983ef99a3efa9b3dfa9c3cfa9e3bfb9f3afba139fba238fca338fca537fca636fca835fca934fdab33fdac33fdae32fdaf31fdb130fdb22ffdb42ffdb52efeb72dfeb82cfeba2cfebb2bfebd2afebe2afec029fdc229fdc328fdc527fdc627fdc827fdca26fdcb26fccd25fcce25fcd025fcd225fbd324fbd524fbd724fad824fada24f9dc24f9dd25f8df25f8e125f7e225f7e425f6e626f6e826f5e926f5eb27f4ed27f3ee27f3f027f2f227f1f426f1f525f0f724f0f921"));

  var d3Scales = /*#__PURE__*/Object.freeze({
    __proto__: null,
    schemeCategory10: category10,
    schemeAccent: Accent,
    schemeDark2: Dark2,
    schemePaired: Paired,
    schemePastel1: Pastel1,
    schemePastel2: Pastel2,
    schemeSet1: Set1,
    schemeSet2: Set2,
    schemeSet3: Set3,
    schemeTableau10: Tableau10,
    interpolateBrBG: BrBG,
    schemeBrBG: scheme$q,
    interpolatePRGn: PRGn,
    schemePRGn: scheme$p,
    interpolatePiYG: PiYG,
    schemePiYG: scheme$o,
    interpolatePuOr: PuOr,
    schemePuOr: scheme$n,
    interpolateRdBu: RdBu,
    schemeRdBu: scheme$m,
    interpolateRdGy: RdGy,
    schemeRdGy: scheme$l,
    interpolateRdYlBu: RdYlBu,
    schemeRdYlBu: scheme$k,
    interpolateRdYlGn: RdYlGn,
    schemeRdYlGn: scheme$j,
    interpolateSpectral: Spectral,
    schemeSpectral: scheme$i,
    interpolateBuGn: BuGn,
    schemeBuGn: scheme$h,
    interpolateBuPu: BuPu,
    schemeBuPu: scheme$g,
    interpolateGnBu: GnBu,
    schemeGnBu: scheme$f,
    interpolateOrRd: OrRd,
    schemeOrRd: scheme$e,
    interpolatePuBuGn: PuBuGn,
    schemePuBuGn: scheme$d,
    interpolatePuBu: PuBu,
    schemePuBu: scheme$c,
    interpolatePuRd: PuRd,
    schemePuRd: scheme$b,
    interpolateRdPu: RdPu,
    schemeRdPu: scheme$a,
    interpolateYlGnBu: YlGnBu,
    schemeYlGnBu: scheme$9,
    interpolateYlGn: YlGn,
    schemeYlGn: scheme$8,
    interpolateYlOrBr: YlOrBr,
    schemeYlOrBr: scheme$7,
    interpolateYlOrRd: YlOrRd,
    schemeYlOrRd: scheme$6,
    interpolateBlues: Blues,
    schemeBlues: scheme$5,
    interpolateGreens: Greens,
    schemeGreens: scheme$4,
    interpolateGreys: Greys,
    schemeGreys: scheme$3,
    interpolatePurples: Purples,
    schemePurples: scheme$2,
    interpolateReds: Reds,
    schemeReds: scheme$1,
    interpolateOranges: Oranges,
    schemeOranges: scheme,
    interpolateCividis: cividis,
    interpolateCubehelixDefault: cubehelix,
    interpolateRainbow: rainbow,
    interpolateWarm: warm,
    interpolateCool: cool,
    interpolateSinebow: sinebow,
    interpolateTurbo: turbo,
    interpolateViridis: viridis,
    interpolateMagma: magma,
    interpolateInferno: inferno,
    interpolatePlasma: plasma
  });

  var index = {
    categorical: [],
    sequential: [],
    rainbow: [],
    diverging: [],
    all: []
  };
  var ramps;

  function initSchemes() {
    if (ramps) return;
    ramps = {};
    addSchemesFromD3('categorical', 'Category10,Accent,Dark2,Paired,Pastel1,Pastel2,Set1,Set2,Set3,Tableau10');
    addSchemesFromD3('sequential', 'Blues,Greens,Greys,Purples,Reds,Oranges,BuGn,BuPu,GnBu,OrRd,PuBuGn,PuBu,PuRd,RdPu,YlGnBu,YlGn,YlOrBr,YlOrRd');
    addSchemesFromD3('rainbow', 'Cividis,CubehelixDefault,Rainbow,Warm,Cool,Sinebow,Turbo,Viridis,Magma,Inferno,Plasma');
    addSchemesFromD3('diverging', 'BrBG,PRGn,PRGn,PiYG,PuOr,RdBu,RdGy,RdYlBu,RdYlGn,Spectral');
    testLib(); // make sure these schemes are all available
    addCategoricalScheme('Category20',
      '1f77b4aec7e8ff7f0effbb782ca02c98df8ad62728ff98969467bdc5b0d58c564bc49c94e377c2f7b6d27f7f7fc7c7c7bcbd22dbdb8d17becf9edae5');
    addCategoricalScheme('Category20b',
      '393b795254a36b6ecf9c9ede6379398ca252b5cf6bcedb9c8c6d31bd9e39e7ba52e7cb94843c39ad494ad6616be7969c7b4173a55194ce6dbdde9ed6');
    addCategoricalScheme('Category20c',
      '3182bd6baed69ecae1c6dbefe6550dfd8d3cfdae6bfdd0a231a35474c476a1d99bc7e9c0756bb19e9ac8bcbddcdadaeb636363969696bdbdbdd9d9d9');
    addCategoricalScheme('Tableau20',
      '4c78a89ecae9f58518ffbf7954a24b88d27ab79a20f2cf5b43989483bcb6e45756ff9d9879706ebab0acd67195fcbfd2b279a2d6a5c99e765fd8b5a5');
    index.all = [].concat(index.sequential, index.rainbow, index.diverging, index.categorical);

  }

  function standardName(name) {
    if (!name) return null;
    var lcname = name.toLowerCase();
    for (var i=0; i<index.all.length; i++) {
      if (index.all[i].toLowerCase() == lcname) {
        return index.all[i];
      }
    }
    return null;
  }

  function addSchemesFromD3(type, names) {
    index[type] = index[type].concat(names.split(','));
  }

  function addCategoricalScheme(name, str) {
    index.categorical.push(name);
    ramps[name] = unpackRamp(str);
  }

  function unpackRamp(str) {
    var colors = [];
    for (var i=0, n=str.length; i<n; i+=6) {
      colors.push('#' + str.substr(i, 6));
    }
    return colors;
  }

  function testLib() {
    schemes(index.categorical);
    schemes(index.sequential);
    schemes(index.diverging);
    interpolators(index.sequential);
    interpolators(index.rainbow);
    interpolators(index.diverging);

    function schemes(arr) {
      arr.forEach(function(name) {
        if (!d3Scales['scheme' + name]) {
          message('Warning: missing data for', name);
        }
      });
    }

    function interpolators(arr) {
      arr.forEach(function(name) {
        if (!d3Scales['interpolate' + name]) {
          message('Missing interpolator for', name);
        }
      });
    }
  }

  function printColorSchemeNames() {
    initSchemes();
    print('Built-in color schemes (from d3):');
    print ('Categorical\n' + formatStringsAsGrid(index.categorical));
    print ('\nSequential\n' + formatStringsAsGrid(index.sequential));
    print ('\nDiverging\n' + formatStringsAsGrid(index.diverging));
    print ('\nMulti-hue/rainbow\n' + formatStringsAsGrid(index.rainbow));
  }

  function pickRandomColorScheme(type) {
    initSchemes();
    var names = index[type];
    if (!names) error('Unknown color scheme type:', type);
    var i = Math.floor(Math.random() * names.length);
    return names[i];
  }

  function getRandomColors(n) {
    initSchemes();
    var colors = getCategoricalColorScheme('Tableau20', 20);
    utils.shuffle(colors);
    colors = wrapColors(colors, n);
    return colors.slice(0, n);
  }

  function getCategoricalColorScheme(name, n) {
    var colors;
    initSchemes();
    name = standardName(name);
    if (!isColorSchemeName(name)) {
      stop('Unknown color scheme name:', name);
    } else if (isCategoricalColorScheme(name)) {
      colors = ramps[name] || d3Scales['scheme' + name];
    } else {
      colors = getColorRamp(name, n);
    }
    if (n > colors.length) {
      // stop(name, 'does not contain', n, 'colors');
      message('Color scheme has', colors.length, 'colors. Using duplication to match', n, 'categories.');
      colors = wrapColors(colors, n);
    } else {
      colors = colors.slice(0, n);
    }
    return colors;
  }

  function wrapColors(colors, n) {
    while (colors.length > 0 && colors.length < n) {
      colors = colors.concat(colors.slice(0, n - colors.length));
    }
    return colors;
  }

  function isColorSchemeName(name) {
    initSchemes();
    return index.all.includes(standardName(name));
  }

  function isCategoricalColorScheme(name) {
    initSchemes();
    return index.categorical.includes(standardName(name));
  }

  function getColorRamp(name, n, stops) {
    initSchemes();
    name = standardName(name);
    var ramps = d3Scales['scheme' + name];
    var interpolate = d3Scales['interpolate' + name];
    var ramp;
    if (!ramps && !interpolate) {
      stop('Unknown color scheme name:', name);
    }
    if (index.categorical.includes(name)) {
      stop(name, ' is a categorical color scheme (expected a sequential color scheme)');
    }
    if (ramps && ramps[n]) {
      ramp = ramps[n];
    } else {
      ramp = getInterpolatedRamp(interpolate, n);
    }
    if (stops) {
      ramp = getStoppedValues(ramp, stops);
    }
    return ramp;
  }

  function getInterpolatedRamp(interpolate, n) {
    if (n > 0 === false || !utils.isInteger(n)) {
      error('Expected a positive integer');
    }
    var ramp = [];
    for (var i=0; i<n; i++) {
      ramp.push(interpolate(i / (n - 1)));
    }
    return ramp;
  }

  function getNullValue(opts) {
    var nullValue;
    if ('null_value' in opts) {
      nullValue = parseNullValue(opts.null_value);
    } else if (opts.colors) {
      nullValue = '#eee';
    } else if (opts.values) {
      nullValue = null;
    } else {
      nullValue = -1; // kludge, to match behavior of getClassValues()
    }
    return nullValue;
  }

  // Parse command line string arguments to the correct data type
  function parseNullValue(val) {
    if (utils.isString(val) && !isNaN(+val)) {
      val = +val;
    }
    if (val === 'null') {
      val = null;
    }
    return val;
  }

  function getClassValues(method, n, opts) {
    var categorical = method == 'categorical' || method == 'non-adjacent';
    var colorArg = opts.colors && opts.colors.length == 1 ? opts.colors[0] : null;
    var colorScheme;

    if (method == 'blacki') return [];

    if (colorArg == 'random') {
      if (categorical) {
        return getRandomColors(n);
      }
      colorScheme = pickRandomColorScheme('sequential');
      message('Randomly selected color ramp:', colorScheme);
    } else if (isColorSchemeName(colorArg)) {
      colorScheme = colorArg;
    } else if (colorArg && !parseColor(colorArg)) {
      stop('Unrecognized color scheme name:', colorArg);
    } else if (opts.colors) {
      opts.colors.forEach(validateColor);
    }

    if (colorScheme) {
      if (categorical && isCategoricalColorScheme(colorScheme)) {
        return getCategoricalColorScheme(colorScheme, n);
      } else {
        return getColorRamp(colorScheme, n, opts.stops);
      }
    } else if (opts.colors || opts.values) {
      if (categorical) {
        return getCategoricalValues(opts.colors || opts.values, n);
      } else {
        return getInterpolableValues(opts.colors || opts.values, n, opts);
      }
    } else {
      // use numerical class indexes (0, 1, ...) if no values are given
      return getIndexes(n);
    }
  }

  function getCategoricalValues(values, n) {
    if (n != values.length) {
      stop('Mismatch in number of categories and number of values');
    }
    return parseValues(values); // convert numerical strings to numbers
  }

  function getIndexes(n) {
    var vals = [];
    for (var i=0; i<n; i++) {
      vals.push(i);
    }
    return vals;
  }

  // TODO: check for non-interpolatable value types (e.g. boolean, text)
  function getInterpolableValues(arr, n, opts) {
    var values = parseValues(arr);
    if (n != values.length || opts.stops) {
      return interpolateValuesToClasses(values, n, opts.stops);
    }
    return values;
  }

  // convert strings to numbers if they all parse as numbers
  // arr: an array of strings
  function parseValues(strings) {
    var values = strings;
    if (strings.every(utils.parseNumber)) {
      values = strings.map(function(str) {
        return +str;
      });
    }
    return values;
  }

  var sequential = ['quantile', 'nice', 'equal-interval', 'hybrid', 'breaks'];
  var all = ['non-adjacent', 'indexed', 'categorical', 'blacki'].concat(sequential);

  function getClassifyMethod(opts, dataType) {
    var method;
    if (opts.method) {
      method = opts.method;
    } else if (opts.breaks) {
      method = 'breaks';
    } else if (opts.index_field) {
      method = 'indexed';
    } else if (opts.categories || dataType == 'string') {
      method = 'categorical';
    } else  if (dataType == 'number') {
      method = 'quantile'; // TODO: validate data field
    } else if (dataType == 'date' || dataType == 'object') {
      stop('Data type does not support classification:', dataType);
    } else if (dataType === null) {
      // data field is empty
      return null; // kludge
    } else if (dataType === undefined) {
      // no data field was given
      stop('Expected a data field to classify or the non-adjacent option');
    } else {
      stop('Unable to determine which classification method to use.');
    }
    if (!all.includes(method)) {
      stop('Not a recognized classification method:', method);
    }
    if (sequential.includes(method) && dataType != 'number' && dataType !== null) {
      stop('The', method, 'method requires a numerical data field');
    }
    return method;
  }

  function getBlackiClassifier(lyr, dataField) {
  	var records = lyr.data.getRecords();
    // classes are integers, dataIds can be any scalar
    var dataToClassIndex = {};
    var classToDataIndex = [];
    var classCount = 0;

    records.forEach(function(rec, recId) {
      var dataIds = rec[dataField];
      var thisClass = -1;
      var thatClass, dataId;

      if (!Array.isArray(dataIds)) return;

      for (var i=0; i<dataIds.length; i++) {
        dataId = dataIds[i];
        thatClass = dataId in dataToClassIndex ? dataToClassIndex[dataId] : -1;
        if (thatClass == -1) {
          if (thisClass == -1) {
            thisClass = classCount++;
          }
          if (Array.isArray(classToDataIndex[thisClass])) {
            if (!classToDataIndex[thisClass].includes(dataId)) {
              classToDataIndex[thisClass].push(dataId);
            }
          } else {
            classToDataIndex[thisClass] = [dataId];
          }
          dataToClassIndex[dataId] = thisClass;

        } else {

          if (thisClass == -1) {
            thisClass = thatClass;
          } else if (thisClass > thatClass) {
            mergeClassIntoClass(thisClass, thatClass);
            thisClass = thatClass;
          } else if (thisClass < thatClass) {
            mergeClassIntoClass(thatClass, thisClass);
          }
        }
      }
    });

    var remapTable = compressClassIds();
    var classIds = records.map(function(rec) {
      var ids = rec[dataField];
      if (!Array.isArray(ids) || ids.length === 0) return -1;
      // TODO: assert that ids all belong to the same class
      if (ids[0] in dataToClassIndex === false) {
        error('Internal error');
      }
      return remapTable[dataToClassIndex[ids[0]]];
    });

    classToDataIndex = null;
    dataToClassIndex = null;

    return function(recId) {
      return classIds[recId];
    };

    function compressClassIds() {
      var newId = -1;
      return classToDataIndex.map(function(d, oldId) {
        if (d !== null) newId++;
        return newId;
      });
    }

    function mergeClassIntoClass(fromId, toId) {
      classToDataIndex[fromId].forEach(function(dataId) {
        dataToClassIndex[dataId] = toId;
      });
      classToDataIndex[toId] = utils.uniq(classToDataIndex[toId].concat(classToDataIndex[fromId]));
      classToDataIndex[fromId] = null;
    }
  }

  cmd.classify = function(lyr, dataset, optsArg) {
    if (!lyr.data) {
      initDataTable(lyr);
    }
    var opts = optsArg || {};
    var records = lyr.data && lyr.data.getRecords();
    var valuesAreColors = !!opts.colors;
    var dataField, fieldType, outputField;
    var values, nullValue;
    var classifyByValue, classifyByRecordId;
    var numClasses, numValues;
    var method;

    if (opts.color_scheme) {
      stop('color-scheme is not a valid option, use colors instead');
    }

    // get data field to use for classification
    //
    if (opts.index_field) {
      dataField = opts.index_field;
      fieldType = getColumnType(opts.field, records);
    } else if (opts.field) {
      dataField = opts.field;
      fieldType = getColumnType(opts.field, records);
    }
    if (dataField) {
      requireDataField(lyr.data, dataField);
    }

    // get classification method
    //
    method = getClassifyMethod(opts, fieldType);

    // validate classification method
    if (method == 'non-adjacent') {
      if (lyr.geometry_type != 'polygon') {
        stop('The non-adjacent option requires a polygon layer');
      }
      if (dataField) {
        stop('The non-adjacent option does not accept a data field argument');
      }
    } else if (!dataField) {
      stop('Missing a data field to classify');
    }

    // get the number of classes and the number of values
    //
    // expand categories if value is '*'
    // use all unique values if categories option is missing
    if (method == 'categorical') {
      if ((!opts.categories || opts.categories.includes('*')) && dataField) {
        opts.categories = getUniqFieldValues(records, dataField);
      }
      if (opts.categories && fieldType == 'number') {
        opts.categories = opts.categories.map(str => +str);
      }
    }

    if (opts.classes) {
      if (!utils.isInteger(opts.classes) || opts.classes > 1 === false) {
        stop('Invalid number of classes:', opts.classes, '(expected a value greater than 1)');
      }
      numClasses = opts.classes;
    } else if (method == 'blacki') {
      numClasses = 999; // dummy value
    } else if (method == 'indexed' && dataField) {
      numClasses = getIndexedClassCount(records, dataField);
    } else if (opts.breaks) {
      numClasses = opts.breaks.length + 1;
    } else if (method == 'categorical' && opts.categories) {
      numClasses = opts.categories.length;
    } else if (opts.colors && opts.colors.length > 1) {
      numClasses = opts.colors.length;
    } else if (opts.values && opts.values.length > 1) {
      numClasses = opts.values.length;
    } else if (method == 'non-adjacent') {
      numClasses = 5;
    } else {
      numClasses = 4;
    }
    numValues = opts.continuous ? numClasses + 1 : numClasses;
    if (numValues > 1 === false) {
      stop('Missing a valid number of values');
    }

    // get colors or other values
    //
    values = getClassValues(method, numValues, opts);
    if (opts.invert) {
      values = values.concat().reverse();
    }
    if (valuesAreColors) {
      message('Colors:', formatValuesForLogging(values));
    }

    nullValue = getNullValue(opts);

    // get a function to convert input data to class indexes
    //
    if (fieldType === null) {
      // no valid data -- always return null value
      classifyByRecordId = function() {return nullValue;};
    } else if (method == 'blacki') {
      classifyByRecordId = getBlackiClassifier(lyr, dataField);
    } else if (method == 'non-adjacent') {
      classifyByRecordId = getNonAdjacentClassifier(lyr, dataset, values);
    } else if (method == 'indexed') {
      // data is pre-classified... just read the index from a field
      classifyByValue = getIndexedClassifier(values, nullValue, opts);
    } else if (method == 'categorical') {
      classifyByValue = getCategoricalClassifier(values, nullValue, opts);
    } else {
      classifyByValue = getSequentialClassifier$1(values, nullValue, getFieldValues(records, dataField), method, opts);
    }

    if (classifyByValue) {
      classifyByRecordId = function(id) {
        var d = records[id] || {};
        return classifyByValue(d[dataField]);
      };
    }

    // get the name of the output field
    //
    if (valuesAreColors) {
      outputField = lyr.geometry_type == 'polyline' ? 'stroke' : 'fill';
    } else {
      outputField = 'class';
    }
    if (opts.save_as) {
      outputField = opts.save_as; // override the default field name
    } else {
      message(`Output was saved to "${outputField}" field (use save-as= to change)`);
      // message('Use save-as=<field> to save to a different field');
    }

    records.forEach(function(d, i) {
      d[outputField] = classifyByRecordId(i);
    });
  };

  function formatValuesForLogging(arr) {
    if (arr.some(val => utils.isString(val) && val.indexOf('rgb(') === 0)) {
      return formatColorsAsHex(arr);
    }
    return arr;
  }

  function formatColorsAsHex(colors) {
    return colors.map(function(col) {
      var o = color(col);
      if (!o) stop('Unable to parse color:', col);
      return o.formatHex();
    });
  }

  // Remove small-area polygon rings (very simple implementation of sliver removal)
  // TODO: more sophisticated sliver detection (e.g. could consider ratio of area to perimeter)
  // TODO: consider merging slivers into adjacent polygons to prevent gaps from forming
  // TODO: consider separate gap removal function as an alternative to merging slivers
  //
  cmd.filterSlivers = function(lyr, dataset, opts) {
    if (lyr.geometry_type != 'polygon') {
      return 0;
    }
    return filterSlivers(lyr, dataset, opts);
  };

  function filterSlivers(lyr, dataset, optsArg) {
    var opts = utils.extend({sliver_control: 1}, optsArg);
    var filterData = getSliverFilter(lyr, dataset, opts);
    var ringTest = filterData.filter;
    var removed = 0;
    var pathFilter = function(path, i, paths) {
      if (ringTest(path)) {
        removed++;
        return null;
      }
    };

    editShapes(lyr.shapes, pathFilter);
    message(utils.format("Removed %'d sliver%s using %s", removed, utils.pluralSuffix(removed), filterData.label));

    // Remove null shapes (likely removed by clipping/erasing, although possibly already present)
    if (opts.remove_empty) {
      cmd.filterFeatures(lyr, dataset.arcs, {remove_empty: true, verbose: false});
    }
    return removed;
  }

  function filterClipSlivers(lyr, clipLyr, arcs) {
    var threshold = getDefaultSliverThreshold(lyr, arcs);
    // message('Using variable sliver threshold (based on ' + (threshold / 1e6) + ' sqkm)');
    var ringTest = getSliverTest(arcs, threshold, 1);
    var flags = new Uint8Array(arcs.size());
    var removed = 0;
    var pathFilter = function(path) {
      var prevArcs = 0,
          newArcs = 0;
      for (var i=0, n=path && path.length || 0; i<n; i++) {
        if (flags[absArcId(path[i])] > 0) {
          newArcs++;
        } else {
          prevArcs++;
        }
      }
      // filter paths that contain arcs from both original and clip/erase layers
      //   and are small
      if (newArcs > 0 && prevArcs > 0 && ringTest(path)) {
        removed++;
        return null;
      }
    };

    countArcsInShapes(clipLyr.shapes, flags);
    editShapes(lyr.shapes, pathFilter);
    return removed;
  }

  // Assumes: Arcs have been divided
  //
  function clipPolylines(targetShapes, clipShapes, nodes, type) {
    var index = new PathIndex(clipShapes, nodes.arcs);

    return targetShapes.map(function(shp) {
      return clipPolyline(shp);
    });

    function clipPolyline(shp) {
      var clipped = null;
      if (shp) clipped = shp.reduce(clipPath, []);
      return clipped && clipped.length > 0 ? clipped : null;
    }

    function clipPath(memo, path) {
      var clippedPath = null,
          arcId, enclosed;
      for (var i=0; i<path.length; i++) {
        arcId = path[i];
        enclosed = index.arcIsEnclosed(arcId);
        if (enclosed && type == 'clip' || !enclosed && type == 'erase') {
          if (!clippedPath) {
            memo.push(clippedPath = []);
          }
          clippedPath.push(arcId);
        } else {
          clippedPath = null;
        }
      }
      return memo;
    }
  }

  var PolylineClipping = /*#__PURE__*/Object.freeze({
    __proto__: null,
    clipPolylines: clipPolylines
  });

  // TODO: to prevent invalid holes,
  // could erase the holes from the space-enclosing rings.
  function appendHolesToRings(cw, ccw) {
    for (var i=0, n=ccw.length; i<n; i++) {
      cw.push(ccw[i]);
    }
    return cw;
  }

  function getPolygonDissolver(nodes, spherical) {
    spherical = spherical && !nodes.arcs.isPlanar();
    var flags = new Uint8Array(nodes.arcs.size());
    var divide = getHoleDivider(nodes, spherical);
    var pathfind = getRingIntersector(nodes, flags);

    return function(shp) {
      if (!shp) return null;
      var cw = [],
          ccw = [];

      divide(shp, cw, ccw);
      cw = pathfind(cw, 'flatten');
      ccw.forEach(reversePath);
      ccw = pathfind(ccw, 'flatten');
      ccw.forEach(reversePath);
      var shp2 = appendHolesToRings(cw, ccw);
      var dissolved = pathfind(shp2, 'dissolve');

      if (dissolved.length > 1) {
        dissolved = fixNestingErrors(dissolved, nodes.arcs);
      }

      return dissolved.length > 0 ? dissolved : null;
    };
  }

  // TODO: remove dependency on old polygon dissolve function

  // assumes layers and arcs have been prepared for clipping
  function clipPolygons(targetShapes, clipShapes, nodes, type, optsArg) {
    var arcs = nodes.arcs;
    var opts = optsArg || {};
    var clipFlags = new Uint8Array(arcs.size());
    var routeFlags = new Uint8Array(arcs.size());
    var clipArcTouches = 0;
    var clipArcUses = 0;
    var usedClipArcs = [];
    var findPath = getPathFinder(nodes, useRoute, routeIsActive);
    var dissolvePolygon = getPolygonDissolver(nodes);

    // The following cleanup step is a performance bottleneck (it often takes longer than
    // other clipping operations) and is usually not needed. Furthermore, it only
    // eliminates a few kinds of problems, like target polygons with abnormal winding
    // or overlapping rings. TODO: try to optimize or remove it for all cases

    // skipping shape cleanup when using the experimental fast bbox clipping option
    if (!opts.bbox2) {
      // clean each target polygon by dissolving its rings
      targetShapes = targetShapes.map(dissolvePolygon);
    }

    // Originally, clip shapes were dissolved here as an optimization, using
    // an unreliable dissolve function.
    // Now, clip shapes are dissolved using a more reliable (but slower)
    // function in mapshaper-clip-erase.js
    // clipShapes = [dissolvePolygon(internal.concatShapes(clipShapes))];

    // Open pathways in the clip/erase layer
    // Need to expose clip/erase routes in both directions by setting route
    // in both directions to visible -- this is how cut-out shapes are detected
    // Or-ing with 0x11 makes both directions visible (so reverse paths will block)
    openArcRoutes(clipShapes, arcs, clipFlags, type == 'clip', type == 'erase', !!"dissolve", 0x11);
    var index = new PathIndex(clipShapes, arcs);
    var clippedShapes = targetShapes.map(function(shape, i) {
      if (shape) {
        return clipPolygon(shape, type, index);
      }
      return null;
    });

    markPathsAsUsed(clippedShapes, routeFlags); // to help us find unused paths later


    // add clip/erase polygons that are fully contained in a target polygon
    // need to index only non-intersecting clip shapes
    // (Intersecting shapes have one or more arcs that have been scanned)

    // first, find shapes that do not intersect the target layer
    // (these could be inside or outside the target polygons)

    var undividedClipShapes = findUndividedClipShapes(clipShapes);

    closeArcRoutes(clipShapes, arcs, routeFlags, true, true); // not needed?
    index = new PathIndex(undividedClipShapes, arcs);
    targetShapes.forEach(function(shape, shapeId) {
      // find clipping paths that are internal to this target polygon
      var paths = shape ? findInteriorPaths(shape, type, index) : null;
      if (paths) {
        clippedShapes[shapeId] = (clippedShapes[shapeId] || []).concat(paths);
      }
    });

    return clippedShapes;

    function clipPolygon(shape, type, index) {
      var dividedShape = [],
          clipping = type == 'clip',
          erasing = type == 'erase';

      // open pathways for entire polygon rather than one ring at a time --
      // need to create polygons that connect positive-space rings and holes
      openArcRoutes(shape, arcs, routeFlags, true, false, false);

      forEachShapePart(shape, function(ids) {
        var path;
        for (var i=0, n=ids.length; i<n; i++) {
          clipArcTouches = 0;
          clipArcUses = 0;
          path = findPath(ids[i]);
          if (path) {
            // if ring doesn't touch/intersect a clip/erase polygon, check if it is contained
            // if (clipArcTouches === 0) {
            // if ring doesn't incorporate an arc from the clip/erase polygon,
            // check if it is contained (assumes clip shapes are dissolved)
            if (clipArcTouches === 0 || clipArcUses === 0) { //
              var contained = index.pathIsEnclosed(path);
              if (clipping && contained || erasing && !contained) {
                dividedShape.push(path);
              }
              // TODO: Consider breaking if polygon is unchanged
            } else {
              dividedShape.push(path);
            }
          }
        }
      });


      // Clear pathways of current target shape to hidden/closed
      closeArcRoutes(shape, arcs, routeFlags, true, true, true);
      // Also clear pathways of any clip arcs that were used
      if (usedClipArcs.length > 0) {
        closeArcRoutes(usedClipArcs, arcs, routeFlags, true, true, true);
        usedClipArcs = [];
      }

      return dividedShape.length === 0 ? null : dividedShape;
    }

    function routeIsActive(id) {
      var fw = id >= 0,
          abs = fw ? id : ~id,
          visibleBit = fw ? 1 : 0x10,
          targetBits = routeFlags[abs],
          clipBits = clipFlags[abs];

      if (clipBits > 0) clipArcTouches++;
      return (targetBits & visibleBit) > 0 || (clipBits & visibleBit) > 0;
    }

    function useRoute(id) {
      var fw = id >= 0,
          abs = fw ? id : ~id,
          targetBits = routeFlags[abs],
          clipBits = clipFlags[abs],
          targetRoute, clipRoute;

      if (fw) {
        targetRoute = targetBits;
        clipRoute = clipBits;
      } else {
        targetRoute = targetBits >> 4;
        clipRoute = clipBits >> 4;
      }
      targetRoute &= 3;
      clipRoute &= 3;

      var usable = false;
      // var usable = targetRoute === 3 || targetRoute === 0 && clipRoute == 3;
      if (targetRoute == 3) {
        // special cases where clip route and target route both follow this arc
        if (clipRoute == 1) ; else if (clipRoute == 2 && type == 'erase') ; else {
          usable = true;
        }

      } else if (targetRoute === 0 && clipRoute == 3) {
        usedClipArcs.push(id);
        usable = true;
      }

      if (usable) {
        if (clipRoute == 3) {
          clipArcUses++;
        }
        // Need to close all arcs after visiting them -- or could cause a cycle
        //   on layers with strange topology
        if (fw) {
          targetBits = setBits(targetBits, 1, 3);
        } else {
          targetBits = setBits(targetBits, 0x10, 0x30);
        }
      }

      targetBits |= fw ? 4 : 0x40; // record as visited
      routeFlags[abs] = targetBits;
      return usable;
    }


    // Filter a collection of shapes to exclude paths that incorporate parts of
    // clip/erase polygons and paths that are hidden (e.g. internal boundaries)
    function findUndividedClipShapes(clipShapes) {
      return clipShapes.map(function(shape) {
        var usableParts = [];
        forEachShapePart(shape, function(ids) {
          var pathIsClean = true,
              pathIsVisible = false;
          for (var i=0; i<ids.length; i++) {
            // check if arc was used in fw or rev direction
            if (!arcIsUnused(ids[i], routeFlags)) {
              pathIsClean = false;
              break;
            }
            // check if clip arc is visible
            if (!pathIsVisible && arcIsVisible(ids[i], clipFlags)) {
              pathIsVisible = true;
            }
          }
          if (pathIsClean && pathIsVisible) usableParts.push(ids);
        });
        return usableParts.length > 0 ? usableParts : null;
      });
    }


    function arcIsUnused(id, flags) {
      var abs = absArcId(id),
          flag = flags[abs];
          return (flag & 0x88) === 0;
          // return id < 0 ? (flag & 0x80) === 0 : (flag & 0x8) === 0;
    }

    function arcIsVisible(id, flags) {
      var flag = flags[absArcId(id)];
      return (flag & 0x11) > 0;
    }

    // search for indexed clipping paths contained in a shape
    // dissolve them if needed
    function findInteriorPaths(shape, type, index) {
      var enclosedPaths = index.findPathsInsideShape(shape),
          dissolvedPaths = [];
      if (!enclosedPaths) return null;
      // ...
      if (type == 'erase') enclosedPaths.forEach(reversePath);
      if (enclosedPaths.length <= 1) {
        dissolvedPaths = enclosedPaths; // no need to dissolve single-part paths
      } else {
        openArcRoutes(enclosedPaths, arcs, routeFlags, true, false, true);
        enclosedPaths.forEach(function(ids) {
          var path;
          for (var j=0; j<ids.length; j++) {
            path = findPath(ids[j]);
            if (path) {
              dissolvedPaths.push(path);
            }
          }
        });
      }

      return dissolvedPaths.length > 0 ? dissolvedPaths : null;
    }
  } // end clipPolygons()

  //
  function clipPoints(points, clipShapes, arcs, type) {
    var index = new PathIndex(clipShapes, arcs);

    var points2 = points.reduce(function(memo, feat) {
      var n = feat ? feat.length : 0,
          feat2 = [],
          enclosed;

      for (var i=0; i<n; i++) {
        enclosed = index.findEnclosingShape(feat[i]) > -1;
        if (type == 'clip' && enclosed || type == 'erase' && !enclosed) {
          feat2.push(feat[i].concat());
        }
      }

      memo.push(feat2.length > 0 ? feat2 : null);
      return memo;
    }, []);

    return points2;
  }

  var ClipPoints = /*#__PURE__*/Object.freeze({
    __proto__: null,
    clipPoints: clipPoints
  });

  // Create a merged dataset by appending the overlay layer to the target dataset
  // so it is last in the layers array.
  // DOES NOT insert clipping points
  function mergeLayersForOverlay(targetLayers, targetDataset, clipSrc, opts) {
    utils.some(targetLayers, layerHasPaths);
    var bbox = opts.bbox || opts.bbox2;
    var mergedDataset, clipDataset, clipLyr;
    if (clipSrc && clipSrc.geometry_type) {
      // TODO: update tests to remove this case (clipSrc is a layer)
      clipSrc = {dataset: targetDataset, layer: clipSrc, disposable: true};
    }
    if (bbox) {
      clipDataset = convertClipBounds(bbox);
      clipLyr = clipDataset.layers[0];
    } else if (!clipSrc) {
      stop("Command requires a source file, layer id or bbox");
    } else if (clipSrc.layer && clipSrc.dataset) {
      clipLyr = clipSrc.layer;
      clipDataset = utils.defaults({layers: [clipLyr]}, clipSrc.dataset);
    } else if (clipSrc.layers && clipSrc.layers.length == 1) {
      clipLyr = clipSrc.layers[0];
      clipDataset = clipSrc;
    }
    if (targetDataset.arcs != clipDataset.arcs) {
      // using external dataset -- need to merge arcs
      if (clipSrc && !clipSrc.disposable) {
        // copy overlay layer shapes because arc ids will be reindexed during merging
        clipDataset.layers[0] = copyLayerShapes(clipDataset.layers[0]);
      }
      // merge external dataset with target dataset,
      // so arcs are shared between target layers and clipping lyr
      // Assumes that layers in clipDataset can be modified (if necessary, a copy should be passed in)
      mergedDataset = mergeDatasets([targetDataset, clipDataset]);
      buildTopology(mergedDataset); // identify any shared arcs between clipping layer and target dataset
    } else {
      // overlay layer belongs to the same dataset as target layers... move it to the end
      mergedDataset = utils.extend({}, targetDataset);
      mergedDataset.layers = targetDataset.layers.filter(function(lyr) {return lyr != clipLyr;});
      mergedDataset.layers.push(clipLyr);
    }
    return mergedDataset;
  }

  function convertClipBounds(bb) {
    var x0 = bb[0], y0 = bb[1], x1 = bb[2], y1 = bb[3],
        arc = [[x0, y0], [x0, y1], [x1, y1], [x1, y0], [x0, y0]];

    if (!(y1 > y0 && x1 > x0)) {
      stop("Invalid bbox (should be [xmin, ymin, xmax, ymax]):", bb);
    }
    return {
      arcs: new ArcCollection([arc]),
      layers: [{
        shapes: [[[0]]],
        geometry_type: 'polygon'
      }]
    };
  }

  var OverlayUtils = /*#__PURE__*/Object.freeze({
    __proto__: null,
    mergeLayersForOverlay: mergeLayersForOverlay
  });

  // Insert cutting points in arcs, where bbox intersects other shapes
  // Return a polygon layer containing the bounding box vectors, divided at cutting points.
  function divideDatasetByBBox(dataset, bbox) {
    var arcs = dataset.arcs;
    var data = findBBoxCutPoints(arcs, bbox);
    var map = insertCutPoints(data.cutPoints, arcs);
    arcs.dedupCoords();
    remapDividedArcs(dataset, map);
    // merge bbox dataset with target dataset,
    // so arcs are shared between target layers and bbox layer
    var clipDataset = bboxPointsToClipDataset(data.bboxPoints);
    var mergedDataset = mergeDatasets([dataset, clipDataset]);
    // TODO: detect if we need to rebuild topology (unlikely), like with the full clip command
    // buildTopology(mergedDataset);
    var clipLyr = mergedDataset.layers.pop();
    dataset.arcs = mergedDataset.arcs;
    dataset.layers = mergedDataset.layers;
    return clipLyr;
  }

  function bboxPointsToClipDataset(arr) {
    var arcs = [];
    var shape = [];
    var layer = {geometry_type: 'polygon', shapes: [[shape]]};
    var p1, p2;
    for (var i=0, n=arr.length - 1; i<n; i++) {
      p1 = arr[i];
      p2 = arr[i+1];
      arcs.push([[p1.x, p1.y], [p2.x, p2.y]]);
      shape.push(i);
    }
    return {
      arcs: new ArcCollection(arcs),
      layers: [layer]
    };
  }

  function findBBoxCutPoints(arcs, bbox) {
    var left = bbox[0],
        bottom = bbox[1],
        right = bbox[2],
        top = bbox[3];

    // arrays of intersection points along each bbox edge
    var tt = [],
        rr = [],
        bb = [],
        ll = [];

    arcs.forEachSegment(function(i, j, xx, yy) {
      var ax = xx[i],
          ay = yy[i],
          bx = xx[j],
          by = yy[j];
      var hit;
      if (segmentOutsideBBox(ax, ay, bx, by, left, bottom, right, top)) return;
      if (segmentInsideBBox(ax, ay, bx, by, left, bottom, right, top)) return;

      hit = geom.segmentIntersection(left, top, right, top, ax, ay, bx, by);
      if (hit) addHit(tt, hit, i, j, xx, yy);

      hit = geom.segmentIntersection(left, bottom, right, bottom, ax, ay, bx, by);
      if (hit) addHit(bb, hit, i, j, xx, yy);

      hit = geom.segmentIntersection(left, bottom, left, top, ax, ay, bx, by);
      if (hit) addHit(ll, hit, i, j, xx, yy);

      hit = geom.segmentIntersection(right, bottom, right, top, ax, ay, bx, by);
      if (hit) addHit(rr, hit, i, j, xx, yy);
    });

    return {
      cutPoints: ll.concat(bb, rr, tt),
      bboxPoints: getDividedBBoxPoints(bbox, ll, tt, rr, bb)
    };

    function addHit(arr, hit, i, j, xx, yy) {
      if (!hit) return;
      arr.push(formatHit(hit[0], hit[1], i, j, xx, yy));
      if (hit.length == 4) {
        arr.push(formatHit(hit[2], hit[3], i, j, xx, yy));
      }
    }

    function formatHit(x, y, i, j, xx, yy) {
      var ids = formatIntersectingSegment(x, y, i, j, xx, yy);
      return getCutPoint(x, y, ids[0], ids[1]);
    }
  }

  function segmentOutsideBBox(ax, ay, bx, by, xmin, ymin, xmax, ymax) {
    return ax < xmin && bx < xmin || ax > xmax && bx > xmax ||
        ay < ymin && by < ymin || ay > ymax && by > ymax;
  }

  function segmentInsideBBox(ax, ay, bx, by, xmin, ymin, xmax, ymax) {
    return ax > xmin && bx > xmin && ax < xmax && bx < xmax &&
        ay > ymin && by > ymin && ay < ymax && by < ymax;
  }

  // Returns an array of points representing the vertices in
  // the bbox with cutting points inserted.
  function getDividedBBoxPoints(bbox, ll, tt, rr, bb) {
    var bl = {x: bbox[0], y: bbox[1]},
        tl = {x: bbox[0], y: bbox[3]},
        tr = {x: bbox[2], y: bbox[3]},
        br = {x: bbox[2], y: bbox[1]};
    ll = utils.sortOn(ll.concat([bl, tl]), 'y', true);
    tt = utils.sortOn(tt.concat([tl, tr]), 'x', true);
    rr = utils.sortOn(rr.concat([tr, br]), 'y', false);
    bb = utils.sortOn(bb.concat([br, bl]), 'x', false);
    return ll.concat(tt, rr, bb).reduce(function(memo, p2) {
      var p1 = memo.length > 0 ? memo[memo.length-1] : null;
      if (p1 === null || p1.x != p2.x || p1.y != p2.y) memo.push(p2);
      return memo;
    }, []);
  }

  var Bbox2Clipping = /*#__PURE__*/Object.freeze({
    __proto__: null,
    divideDatasetByBBox: divideDatasetByBBox,
    segmentOutsideBBox: segmentOutsideBBox,
    segmentInsideBBox: segmentInsideBBox
  });

  cmd.clipLayers = function(target, src, dataset, opts) {
    return clipLayers(target, src, dataset, "clip", opts);
  };

  cmd.eraseLayers = function(target, src, dataset, opts) {
    return clipLayers(target, src, dataset, "erase", opts);
  };

  cmd.clipLayer = function(targetLyr, src, dataset, opts) {
    return cmd.clipLayers([targetLyr], src, dataset, opts)[0];
  };

  cmd.eraseLayer = function(targetLyr, src, dataset, opts) {
    return cmd.eraseLayers([targetLyr], src, dataset, opts)[0];
  };

  cmd.sliceLayers = function(target, src, dataset, opts) {
    return clipLayers(target, src, dataset, "slice", opts);
  };

  cmd.sliceLayer = function(targetLyr, src, dataset, opts) {
    return cmd.sliceLayers([targetLyr], src, dataset, opts);
  };

  function clipLayersInPlace(layers, clipSrc, dataset, type, opts) {
    var outputLayers = clipLayers(layers, clipSrc, dataset, type, opts);
    // remove arcs from the clipping dataset, if they are not used by any layer
    layers.forEach(function(lyr, i) {
      var lyr2 = outputLayers[i];
      lyr.shapes = lyr2.shapes;
      lyr.data = lyr2.data;
    });
    dissolveArcs(dataset);
  }

  // @clipSrc: layer in @dataset or filename
  // @type: 'clip' or 'erase'
  function clipLayers(targetLayers, clipSrc, targetDataset, type, opts) {
    var usingPathClip = utils.some(targetLayers, layerHasPaths);
    var mergedDataset, clipLyr, nodes;
    opts = opts || {no_cleanup: true}; // TODO: update testing functions
    if (opts.bbox2 && usingPathClip) { // assumes target dataset has arcs
      return clipLayersByBBox(targetLayers, targetDataset, opts);
    }
    mergedDataset = mergeLayersForOverlay(targetLayers, targetDataset, clipSrc, opts);
    clipLyr = mergedDataset.layers[mergedDataset.layers.length-1];
    if (usingPathClip) {
      // add vertices at all line intersections
      // (generally slower than actual clipping)
      nodes = addIntersectionCuts(mergedDataset, opts);
      targetDataset.arcs = mergedDataset.arcs;
      // dissolve clip layer shapes (to remove overlaps and other topological issues
      // that might confuse the clipping function)
      // use a data-free copy of the clip lyr, so data records are not dissolved
      // (this avoids triggering an unnecessary and expensive DBF read operation in some cases).
      clipLyr = utils.defaults({data: null}, clipLyr);
      clipLyr = dissolvePolygonLayer2(clipLyr, mergedDataset, {quiet: true, silent: true});

    } else {
      nodes = new NodeCollection(mergedDataset.arcs);
    }
    // clipLyr = mergedDataset.layers.pop();
    return clipLayersByLayer(targetLayers, clipLyr, nodes, type, opts);
  }

  function clipLayersByBBox(layers, dataset, opts) {
    var bbox = opts.bbox2;
    var clipLyr = divideDatasetByBBox(dataset, bbox);
    var nodes = new NodeCollection(dataset.arcs);
    var retn = clipLayersByLayer(layers, clipLyr, nodes, 'clip', opts);
    return retn;
  }

  function clipLayersByLayer(targetLayers, clipLyr, nodes, type, opts) {
    requirePolygonLayer(clipLyr, "Requires a polygon clipping layer");
    return targetLayers.reduce(function(memo, targetLyr) {
      if (type == 'slice') {
        memo = memo.concat(sliceLayerByLayer(targetLyr, clipLyr, nodes, opts));
      } else {
        memo.push(clipLayerByLayer(targetLyr, clipLyr, nodes, type, opts));
      }
      return memo;
    }, []);
  }

  function getSliceLayerName(clipLyr, field, i) {
    var id = field ? clipLyr.data.getRecords()[0][field] : i + 1;
    return 'slice-' + id;
  }

  function sliceLayerByLayer(targetLyr, clipLyr, nodes, opts) {
    // may not need no_replace
    var clipLayers = cmd.splitLayer(clipLyr, opts.id_field, {no_replace: true});
    return clipLayers.map(function(clipLyr, i) {
      var outputLyr = clipLayerByLayer(targetLyr, clipLyr, nodes, 'clip', opts);
      outputLyr.name = getSliceLayerName(clipLyr, opts.id_field, i);
      return outputLyr;
    });
  }

  function clipLayerByLayer(targetLyr, clipLyr, nodes, type, opts) {
    var arcs = nodes.arcs;
    var shapeCount = targetLyr.shapes ? targetLyr.shapes.length : 0;
    var nullCount = 0, sliverCount = 0;
    var clippedShapes, outputLyr;
    if (shapeCount === 0) {
      return targetLyr; // ignore empty layer
    }
    if (targetLyr === clipLyr) {
      stop('Can\'t clip a layer with itself');
    }

    // TODO: optimize some of these functions for bbox clipping
    if (targetLyr.geometry_type == 'point') {
      clippedShapes = clipPoints(targetLyr.shapes, clipLyr.shapes, arcs, type);
    } else if (targetLyr.geometry_type == 'polygon') {
      clippedShapes = clipPolygons(targetLyr.shapes, clipLyr.shapes, nodes, type, opts);
    } else if (targetLyr.geometry_type == 'polyline') {
      clippedShapes = clipPolylines(targetLyr.shapes, clipLyr.shapes, nodes, type);
    } else {
      stop('Invalid target layer:', targetLyr.name);
    }

    outputLyr = {
      name: targetLyr.name,
      geometry_type: targetLyr.geometry_type,
      shapes: clippedShapes,
      data: targetLyr.data // replaced post-filter
    };

    // Remove sliver polygons
    if (opts.remove_slivers && outputLyr.geometry_type == 'polygon') {
      sliverCount = filterClipSlivers(outputLyr, clipLyr, arcs);
    }

    // Remove null shapes (likely removed by clipping/erasing, although possibly already present)
    cmd.filterFeatures(outputLyr, arcs, {remove_empty: true, verbose: false});

    // clone data records (to avoid sharing records between layers)
    // TODO: this is not needed when replacing target with a single layer
    if (outputLyr.data) {
      outputLyr.data = outputLyr.data.clone();
    }

    // TODO: redo messages, now that many layers may be clipped
    nullCount = shapeCount - outputLyr.shapes.length;
    if (nullCount && sliverCount) {
      message(getClipMessage(nullCount, sliverCount));
    }
    return outputLyr;
  }

  function getClipMessage(nullCount, sliverCount) {
    var nullMsg = nullCount ? utils.format('%,d null feature%s', nullCount, utils.pluralSuffix(nullCount)) : '';
    var sliverMsg = sliverCount ? utils.format('%,d sliver%s', sliverCount, utils.pluralSuffix(sliverCount)) : '';
    if (nullMsg || sliverMsg) {
      return utils.format('Removed %s%s%s', nullMsg, (nullMsg && sliverMsg ? ' and ' : ''), sliverMsg);
    }
    return '';
  }

  var ClipErase = /*#__PURE__*/Object.freeze({
    __proto__: null,
    clipLayersInPlace: clipLayersInPlace,
    clipLayers: clipLayers,
    clipLayersByBBox: clipLayersByBBox,
    clipLayersByLayer: clipLayersByLayer,
    getClipMessage: getClipMessage
  });

  // Assign a cluster id to each polygon in a dataset, which can be used with
  //   one of the dissolve commands to dissolve the clusters
  // Works by iteratively grouping pairs of polygons with the smallest distance
  //   between centroids.
  // Results are not optimal -- may be useful for creating levels of detail on
  //   interactive maps, not useful for analysis.
  //
  cmd.cluster = function(lyr, arcs, opts) {
    requirePolygonLayer(lyr);
    var groups = calcPolygonClusters(lyr, arcs, opts);
    var idField = opts.id_field || "cluster";
    insertFieldValues(lyr, idField, groups);
    return lyr;
  };

  function calcPolygonClusters(lyr, arcs, opts) {
    var calcScore = getPolygonClusterCalculator(opts);
    var size = lyr.shapes.length;
    var pct = opts.pct ? utils.parsePercent(opts.pct) : 1;
    var count = Math.round(size * pct);
    var groupField = opts.group_by || null;

    // working set of polygon records
    var shapeItems = lyr.shapes.map(function(shp, i) {
      var groupId = groupField && lyr.data.getRecordAt(i)[groupField] || null;
      return {
        ids: [i],
        area: geom.getShapeArea(shp, arcs),
        bounds: arcs.getMultiShapeBounds(shp),
        centroid: geom.getShapeCentroid(shp, arcs), // centroid of largest ring
        group: groupId,
        friends: []
      };
    });

    var mergeItems = []; // list of pairs of shapes that can be merged
    var mergeIndex = {}; // keep track of merges, to prevent duplicates
    var next;

    if (groupField && !lyr.data) stop("Missing attribute data table");

    // Populate mergeItems array
    findPairsOfNeighbors(lyr, arcs).forEach(function(ab, i) {
      // ab: [a, b] indexes of two polygons
      var a = shapeItems[ab[0]],
          b = shapeItems[ab[1]],
          item, id;
      if (a.group !== b.group) return;
      item = {ids: ab};
      item.score = getScore(item);
      if (item.score < 0) return;
      id = mergeItems.length;
      a.friends.push(id);
      b.friends.push(id);
      mergeItems.push(item);
    });

    // main loop
    while (count-- > 0 && (next = nextItem())) {
      merge(next);
    }

    // Assign a sequential id to each of the remaining original shapes and the
    // new aggregated shapes
    return shapeItems.filter(Boolean).reduce(function(memo, shape, clusterId) {
      var ids = shape.ids;
      for (var i=0; i<ids.length; i++) {
        memo[ids[i]] = clusterId;
      }
      return memo;
    }, []);

    function merge(item) {
      var merged = mergeShapes(item.ids);
      var mergedId = shapeItems.length;
      shapeItems[mergedId] = merged;
      updateList(merged.friends, item.ids, mergedId);
    }

    // Find lowest-ranked merge candidate and remove it from the list
    // Scans entire list - n^2 performance - tested ~20sec for 50,000 polygons
    function nextItem() {
      var minId = -1,
          min = Infinity,
          item, i, n;
      for (i=0, n=mergeItems.length; i<n; i++) {
        item = mergeItems[i];
        if (item !== null && item.score < min) {
          min = item.score;
          minId = i;
        }
      }
      if (minId == -1) return null;
      item = mergeItems[minId];
      mergeItems[minId] = null;
      return item;
    }

    function getScore(item) {
      return calcScore(shapeItems[item.ids[0]], shapeItems[item.ids[1]]);
    }

    function mergeCentroids(dest, src) {
      var k = dest.area / (dest.area + src.area),
          a = dest.centroid,
          b = src.centroid;
      // TODO: consider using geodetic distance when appropriate
      a.x = a.x * k + b.x * (1 - k);
      a.y = a.y * k + b.y * (1 - k);
    }

    function mergeShapes(ids) {
      var dest = shapeItems[ids[0]];
      var src = shapeItems[ids[1]];
      dest.bounds.mergeBounds(src.bounds);
      dest.area += src.area;
      dest.ids = dest.ids.concat(src.ids);
      mergeCentroids(dest, src);
      shapeItems[ids[0]] = null;
      shapeItems[ids[1]] = null;
      dest.friends = filterFriends(dest.friends.concat(src.friends));
      return dest;
    }

    // remove ids of duplicate and invalid merge candidates
    function filterFriends(friends) {
      var index = {};
      var merged = [];
      var id;
      for (var i=0; i<friends.length; i++) {
        id = friends[i];
        if ((id in index === false) && mergeItems[id] !== null) {
          merged.push(id);
          index[id] = true;
        }
      }
      return merged;
    }

    // re-index merge candidates after merging two shapes into a new shape
    function updateList(friends, oldIds, newId) {
      var item, id;
      for (var i=0, n=friends.length; i<n; i++) {
        id = friends[i];
        item = mergeItems[id];
        if (contains(item.ids, oldIds)) {
          mergeItems[id] = updateItem(item, oldIds, newId);
        }
      }
    }

    // re-index a merge candidate; return null if it duplicates a previously merged
    //   pair of shapes
    function updateItem(item, oldIds, newId) {
      var a = item.ids[0];
      var b = item.ids[1];
      var key;
      if (oldIds[0] == a || oldIds[1] == a) a = newId;
      if (oldIds[0] == b || oldIds[1] == b) b = newId;
      if (a == b) return null;
      item.ids = [a, b];
      key = clusterKey(item);
      if (key in mergeIndex) return null;
      mergeIndex[key] = true;
      item.score = getScore(item);
      if (item.score < 0) return null;
      return item;
    }

    function contains(a, b) {
      return a[0] === b[0] || a[0] === b[1] || a[1] === b[0] || a[1] === b[1];
    }

    function clusterKey(friend) {
      var a = friend.ids[0],
          b = friend.ids[1];
      if (b < a) {
        a = b;
        b = friend.ids[0];
      }
      return a + ',' + b;
    }
  }

  function getPolygonClusterCalculator(opts) {
    var maxWidth = opts.max_width || Infinity;
    var maxHeight = opts.max_height || Infinity;
    var maxArea = opts.max_area || Infinity;
    return function(a, b) {
      var area = a.area + b.area,
          // TODO: use geodetic distance when appropriate
          score = geom.distance2D(a.centroid.x, a.centroid.y, b.centroid.x, b.centroid.y),
          bounds = a.bounds.clone().mergeBounds(b.bounds);
      if (area > maxArea || bounds.width() > maxWidth ||
          bounds.height() > maxHeight) {
        score = -1;
      }
      return score;
    };
  }

  cmd.colorizer = function(opts) {
    if (!opts.name) {
      stop("Missing required name= parameter");
    }
    if (isReservedName(opts.name)) {
      stop('"' + opts.name + '" is a reserved name');
    }
    getStashedVar('defs')[opts.name] = getColorizerFunction(opts);
  };

  function isReservedName(name) {
    return /^(stroke|stroke-width|stroke-dasharray|stroke-opacity|fill|fill-opacity|opacity|r|class)$/.test(name);
  }

  function getColorizerFunction(opts) {
    var nodataColor = opts.nodata || 'white';
    var round = opts.precision ? getRoundingFunction(opts.precision) : null;
    var colorFunction;

    if (!opts.random && (!opts.colors || !opts.colors.length)) {
      stop("Missing colors= parameter");
    }

    if (opts.random) {
      colorFunction = getRandomColorFunction(opts.colors);
    } else if (opts.breaks) {
      if (opts.colors.length != opts.breaks.length + 1) {
        stop("Number of colors should be one more than number of class breaks");
      }
      colorFunction = getSequentialClassifier(opts.breaks, opts.colors, nodataColor, round);
    } else if (opts.categories) {
      if (opts.colors.length != opts.categories.length) {
        stop("Number of colors should be equal to the number of categories");
      }
      colorFunction = getCategoricalClassifier(opts.colors, nodataColor, opts);
    } else {
      stop("Missing categories= or breaks= parameter");
    }

    return colorFunction;
  }

  function getSequentialClassifier(breaks, colors, nullVal, round) {
    var classify = getDiscreteClassifier(breaks, round);
    var toColor = getDiscreteValueGetter(colors, nullVal);
    return function(val) {
      return toColor(classify(val));
    };
  }

  function fastStringHash(val) {
    // based on https://github.com/darkskyapp/string-hash (public domain)
    var str = String(val),
        hash = 5381,
        i = str.length;
    while (i > 0) {
      hash = (hash * 33) ^ str.charCodeAt(--i);
    }
    return Math.abs(hash);
  }

  function getRandomColorFunction(colors) {
    if (!colors || !colors.length) {
      colors = '#ccc,#888,#444'.split(',');
    }
    return function(val) {
      var n = colors.length;
      var i = val === undefined ?
          Math.floor(Math.random() * n) : fastStringHash(val) % n;
      return colors[i];
    };
  }

  var Colorizer = /*#__PURE__*/Object.freeze({
    __proto__: null,
    getColorizerFunction: getColorizerFunction
  });

  cmd.comment = function(opts) {
    // TODO: print the comment in verbose mode
    // message('[comment]', opts.message);
  }; // no-op, so -comment doesn't trigger a parsing error

  cmd.dashlines = function(lyr, dataset, opts) {
    var crs = getDatasetCRS(dataset);
    var defs = getStashedVar('defs');
    var exp = `this.geojson = splitFeature(this.geojson)`;
    requirePolylineLayer(lyr);
    defs.splitFeature = getSplitFeatureFunction(crs, opts);
    cmd.evaluateEachFeature(lyr, dataset, exp, opts);
    delete defs.splitFeature;
  };

  function getSplitFeatureFunction(crs, opts) {
    var dashLen = opts.dash_length ? convertDistanceParam(opts.dash_length, crs) : 0;
    var gapLen = opts.gap_length ? convertDistanceParam(opts.gap_length, crs) : 0;
    if (dashLen > 0 === false) {
      stop('Missing required dash-length parameter');
    }
    if (gapLen >= 0 == false) {
      stop('Invalid gap-length option');
    }
    var splitLine = getSplitLineFunction(crs, dashLen, gapLen, opts);
    return function(feat) {
      var geom = feat.geometry;
      if (!geom) return feat;
      if (geom.type == 'LineString') {
        geom.type = 'MultiLineString';
        geom.coordinates = [geom.coordinates];
      }
      if (geom.type != 'MultiLineString') {
        error('Unexpected geometry:', geom.type);
      }
      geom.coordinates = geom.coordinates.reduce(function(memo, coords) {
        try {
          var parts = splitLine(coords);
          memo = memo.concat(parts);
        } catch(e) {
          console.error(e);
          throw e;
        }
        return memo;
      }, []);

      return feat;
    };
  }

  function getSplitLineFunction(crs, dashLen, gapLen, opts) {
    var planar = !!opts.planar;
    var interpolate = getInterpolationFunction(planar ? null : crs);
    var distance =  isLatLngCRS(crs) ? greatCircleDistance : distance2D;
    var inDash, parts2, interval, scale;
    function addPart(coords) {
      if (inDash) parts2.push(coords);
      if (gapLen > 0) {
        inDash = !inDash;
        interval = scale * (inDash ? dashLen : gapLen);
      }
    }

    return function splitLineString(coords) {
      var elapsedDist = 0;
      var p = coords[0];
      var coords2 = [p];
      var segLen, pct, prev;
      if (opts.scaled) {
        scale = scaleDashes(dashLen, gapLen, getLineLength(coords, distance));
      } else {
        scale = 1;
      }
      // init this LineString
      inDash = gapLen > 0 ? false : true;
      interval = scale * (inDash ? dashLen : gapLen);
      if (!inDash) {
        // start gapped lines with a half-gap
        // (a half-gap or a half-dash is probably better for rings and intersecting lines)
        interval *= 0.5;
      }
      parts2 = [];
      for (var i=1, n=coords.length; i<n; i++) {
        prev = p;
        p = coords[i];
        segLen = distance(prev[0], prev[1], p[0], p[1]);
        if (segLen <= 0) continue;
        while (elapsedDist + segLen >= interval) {
          // this segment contains a break either within it or at the far endpoint
          pct = (interval - elapsedDist) / segLen;
          if (pct > 0.999 && i == n - 1) {
            // snap to endpoint (so fp rounding errors don't result in a tiny
            // last segment)
            pct = 1;
          }
          if (pct < 1) {
            prev = interpolate(prev[0], prev[1], p[0], p[1], pct);
          } else {
            prev = p;
          }
          coords2.push(prev);
          addPart(coords2);
          // start a new part
          coords2 = pct < 1 ? [prev] : [];
          elapsedDist = 0;
          segLen = (1 - pct) * segLen;
        }
        coords2.push(p);
        elapsedDist += segLen;
      }
      if (elapsedDist > 0 && coords2.length > 1) {
        addPart(coords2);
      }
      return parts2;
    };
  }

  function getLineLength(coords, distance) {
    var len = 0;
    for (var i=1, n=coords.length; i<n; i++) {
      len += distance(coords[i-1][0], coords[i-1][1], coords[i][0], coords[i][1]);
    }
    return len;
  }

  function scaleDashes(dash, gap, len) {
    var n = len / (dash + gap); // number of dashes
    var n1 = Math.floor(n);
    var n2 = Math.ceil(n);
    var k1 = len / (n1 * (dash + gap)); // scaled-up dashes, >1
    var k2 = len / (n2 * (dash + gap)); // scaled-down dashes <1
    var k = k2;
    if (k1 < 1/k2 && n1 > 0) {
      k = k1; // pick the smaller of the two scales
    }
    return k;
  }

  // This function creates a continuous mosaic of data values in a
  // given field by assigning data from adjacent polygon features to polygons
  // that contain null values.
  // The 'contiguous' option removes data islands to create contiguous groups
  // that are likely to be the result of unreliable data (e.g. faulty geocodes).

  cmd.dataFill = function(lyr, arcs, opts) {
    var field = opts.field;
    if (!field) stop("Missing required field= parameter");
    requireDataField(lyr, field);
    if (lyr.geometry_type != 'polygon') stop("Target layer must be polygon type");
    var getNeighbors = getNeighborLookupFunction(lyr, arcs);
    var fillCount, islandCount;

    // get function to check if a shape was empty before data-fill
    var initiallyEmpty = (function() {
      var flags = lyr.data.getRecords().map(function(rec) {
        return isEmptyValue(rec[field]);
      });
      return function(i) {return flags[i];};
    }());

    // step one: fill empty units
    fillCount = dataFillEmpty(field, lyr, arcs, getNeighbors);

    // step two: smooth perimeters
    dataFillSmooth(field, lyr, arcs, getNeighbors, initiallyEmpty);

    // step three: remove non-contiguous data islands
    if (opts.contiguous) {
      islandCount = dataFillIslandGroups(field, lyr, arcs, getNeighbors, opts);
    }

    message('Filled', fillCount, 'empty polygons' + utils.pluralSuffix(fillCount));
    if (islandCount > 0) {
      message('Removed', islandCount, 'non-contiguous polygon group' + utils.pluralSuffix(islandCount));
    }
  };

  // Assign values to units without data, using the values of neighboring units.
  function dataFillEmpty(field, lyr, arcs, getNeighbors) {
    var records = lyr.data.getRecords();
    var onShape = getDataFillCalculator(field, lyr, arcs, getNeighbors);
    var isEmpty = getEmptyValueFilter(field, lyr);
    var groups = {}; // groups, indexed by key
    var assignCount = 0;

    // step one: place features in groups based on data values of non-empty neighbors.
    // (grouping is an attempt to avoid ragged edges between groups of same-value units,
    // which occured when data was assigned to units independently of adjacent units).
    lyr.shapes.forEach(function(shp, i) {
      if (!isEmpty(i)) return; // only assign shapes with missing values
      var data = onShape(i);
      if (!data.group) return; // e.g. if no neighbors have data
      addDataToGroup(data, groups);
    });

    // step two: assign the same value to all members of a group
    Object.keys(groups).forEach(function(groupId) {
      var group = groups[groupId];
      var value = getMaxWeightValue(group);
      assignValueToShapes(group.shapes, value);
    });

    function assignValueToShapes(ids, val) {
      ids.forEach(function(id) {
        assignCount++;
        records[id][field] = val;
      });
    }

    function addDataToGroup(d, groups) {
      var group = groups[d.group];
      var j;
      if (!group) {
        groups[d.group] = {
          shapes: [d.shape],
          weights: d.weights,
          values: d.values
        };
        return;
      }
      group.shapes.push(d.shape);
      for (var i=0, n=d.values.length; i<n; i++) {
        // add new weights to the group's total weights
        j = group.values.indexOf(d.values[i]);
        group.weights[j] += d.weights[i];
      }
    }

    if (assignCount > 0) {
      // recursively fill empty neighbors of the newly filled shapes
      assignCount += dataFillEmpty(field, lyr, arcs, getNeighbors);
    }
    return assignCount;
  }


  // Try to smooth out jaggedness resulting from filling empty units
  // This function assigns a different adjacent data value to formerly empty units,
  // if this would produce a shorter boundary.
  function dataFillSmooth(field, lyr, arcs, getNeighbors, wasEmpty) {
    var onShape = getDataFillCalculator(field, lyr, arcs, getNeighbors);
    var records = lyr.data.getRecords();
    var updates = 0;
    lyr.shapes.forEach(function(shp, i) {
      if (!wasEmpty(i)) return; // only edit shapes that were originally empty
      var data = onShape(i);
      if (data.values.length < 2) return; // no other values are available
      var currVal = records[i][field];
      var topVal = getMaxWeightValue(data);
      if (currVal != topVal) {
        records[i][field] = topVal;
        updates++;
      }
    });
    return updates;
  }

  // Remove less-important data islands to ensure that data groups are contiguous
  //
  function dataFillIslandGroups(field, lyr, arcs, getNeighbors, opts) {
    var records = lyr.data.getRecords();
    var groupsByValue = {}; // array of group objects, indexed by data values
    var unitIndex = new Uint8Array(lyr.shapes.length);
    var currGroup = null;
    var islandCount = 0;
    var weightField = opts.weight_field || null;

    if (weightField) {
      requireDataField(lyr, weightField);
    }

    // 1. form groups of contiguous units with the same attribute value
    lyr.shapes.forEach(function(shp, shpId) {
      onShape(shpId);
    });

    // 2. retain the most important group for each value; discard satellite groups
    Object.keys(groupsByValue).forEach(function(val) {
      var groups = groupsByValue[val];
      var maxIdx;
      if (groups.length < 2) return;
      maxIdx = indexOfMaxValue(groups);
      if (maxIdx == -1) return; // error condition...
      groups
        .filter(function(group, i) {return i != maxIdx;})
        .forEach(clearIslandGroup);
    });

    // 3. fill gaps left by removing groups
    if (islandCount > 0) {
      dataFillEmpty(field, lyr, arcs, getNeighbors);
    }
    return islandCount;

    function clearIslandGroup(group) {
      islandCount++;
      group.shapes.forEach(function(shpId) {
        records[shpId][field] = null;
      });
    }

    function onShape(shpId) {
      if (unitIndex[shpId] == 1) return; // already added to a group
      var val = records[shpId][field];
      var firstShape = false;
      if (isEmptyValue(val)) return;
      if (!currGroup) {
        // start a new group
        firstShape = true;
        currGroup = {
          value: val,
          shapes: [],
          weight: 0
        };
        if (val in groupsByValue === false) {
          groupsByValue[val] = [];
        }
        groupsByValue[val].push(currGroup);
      } else if (val != currGroup.value) {
        return;
      }
      if (weightField) {
        currGroup.weight += records[shpId][weightField];
      } else {
        currGroup.weight += geom.getShapeArea(lyr.shapes[shpId], arcs);
      }
      currGroup.shapes.push(shpId);
      unitIndex[shpId] = 1;
      // TODO: consider switching from depth-first traversal to breadth-first
      getNeighbors(shpId).forEach(onShape);
      if (firstShape) {
        currGroup = null;
      }
    }
  }


  // Return value with the greatest weight from a datafill object
  function getMaxWeightValue(d) {
    var maxWeight = Math.max.apply(null, d.weights);
    var i = d.weights.indexOf(maxWeight);
    return d.values[i]; // return highest weighted value
  }

  // TODO: move to a more sensible file... mapshaper-calc-utils?
  function indexOfMaxValue(arr, key) {
    var maxWeight = -Infinity;
    var idx = -1;
    arr.forEach(function(o, i) {
      if (o.weight > maxWeight) {
        idx = i;
        maxWeight = o.weight;
      }
    });
    return idx;
  }

  function isEmptyValue(val) {
     return !val && val !== 0;
  }

  function getEmptyValueFilter(field, lyr) {
    var records = lyr.data.getRecords();
    return function(i) {
      var rec = records[i];
      return rec ? isEmptyValue(rec[field]) : false;
    };
  }

  // Returns a function to fetch the values of a data field from the neighbors of
  // a polygon feature. Each value is assigned a weight in proportion to the
  // length of the borders between the polygon and its neighbors.
  function getDataFillCalculator(field, lyr, arcs, getNeighbors) {
    var isPlanar = arcs.isPlanar();
    var records = lyr.data.getRecords();
    var tmp;

    function onSharedArc(nabeId, arcId) {
      var weight, i;
      var val = records[nabeId][field];
      if (isEmptyValue(val)) return;
      // weight is the length of the shared border
      // TODO: consider support for alternate weighting schemes
      weight = geom.calcPathLen([arcId], arcs, !isPlanar);
      i = tmp.values.indexOf(val);
      if (i == -1) {
        tmp.values.push(val);
        tmp.weights.push(weight);
      } else {
        tmp.weights[i] += weight;
      }
    }

    return function(shpId) {
      tmp = {
        shape: shpId,
        weights: [],
        values: [],
        group: ''
      };
      getNeighbors(shpId, onSharedArc);
      tmp.group = tmp.values.concat().sort().join('~');
      return tmp;
    };
  }

  var MAX_RULE_LEN = 50;

  cmd.info = function(targets, opts) {
    var layers = expandCommandTargets(targets);
    var arr = layers.map(function(o) {
      return getLayerInfo(o.layer, o.dataset);
    });

    if (opts.save_to) {
      var output = [{
        filename: opts.save_to + (opts.save_to.endsWith('.json') ? '' : '.json'),
        content: JSON.stringify(arr, null, 2)
      }];
      writeFiles(output, opts);
    }
    if (opts.to_layer) {
      return {
        info: {},
        layers: [{
          name: opts.name || 'info',
          data: new DataTable(arr)
        }]
      };
    }
    message(formatInfo(arr));
  };

  cmd.printInfo = cmd.info; // old name

  function getLayerInfo(lyr, dataset) {
    var n = getFeatureCount(lyr);
    var o = {
      layer_name: lyr.name,
      geometry_type: lyr.geometry_type,
      feature_count: n,
      null_shape_count: 0,
      null_data_count: lyr.data ? countNullRecords(lyr.data.getRecords()) : n
    };
    if (lyr.shapes && lyr.shapes.length > 0) {
      o.null_shape_count = countNullShapes(lyr.shapes);
      o.bbox = getLayerBounds(lyr, dataset.arcs).toArray();
      o.proj4 = getProjInfo(dataset);
    }
    o.source_file = getLayerSourceFile(lyr, dataset) || null;
    o.attribute_data = getAttributeTableInfo(lyr);
    return o;
  }

  // i: (optional) record index
  function getAttributeTableInfo(lyr, i) {
    if (!lyr.data || lyr.data.size() === 0 || lyr.data.getFields().length === 0) {
      return null;
    }
    var fields = applyFieldOrder(lyr.data.getFields(), 'ascending');
    var valueName = i === undefined ? 'first_value' : 'value';
    return fields.map(function(fname) {
      return {
        field: fname,
        [valueName]: lyr.data.getReadOnlyRecordAt(i || 0)[fname]
      };
    });
  }

  function formatInfo(arr) {
    var str = '';
    arr.forEach(function(info, i) {
      var title =  'Layer:    ' + (info.layer_name || '[unnamed layer]');
      var tableStr = formatAttributeTableInfo(info.attribute_data);
      var tableWidth = measureLongestLine(tableStr);
      var ruleLen = Math.min(Math.max(title.length, tableWidth), MAX_RULE_LEN);
      str += '\n';
      str += utils.lpad('', ruleLen, '=') + '\n';
      str += title + '\n';
      str += utils.lpad('', ruleLen, '-') + '\n';
      str += formatLayerInfo(info);
      str += tableStr;
    });
    return str;
  }

  function formatLayerInfo(data) {
    var str = '';
    str += "Type:     " + (data.geometry_type || "tabular data") + "\n";
    str += utils.format("Records:  %,d\n",data.feature_count);
    if (data.null_shape_count > 0) {
      str += utils.format("Nulls:     %'d", data.null_shape_count) + "\n";
    }
    if (data.geometry_type && data.feature_count > data.null_shape_count) {
      str += "Bounds:   " + data.bbox.join(',') + "\n";
      str += "CRS:      " + data.proj4 + "\n";
    }
    str += "Source:   " + (data.source_file || 'n/a') + "\n";
    return str;
  }

  function formatAttributeTableInfo(arr) {
    if (!arr) return "Attribute data: [none]\n";
    var header = "\nAttribute data\n";
    var valKey = 'first_value' in arr[0] ? 'first_value' : 'value';
    var vals = [];
    var fields = [];
    arr.forEach(function(o) {
      fields.push(o.field);
      vals.push(o[valKey]);
    });
    var maxIntegralChars = vals.reduce(function(max, val) {
      if (utils.isNumber(val)) {
        max = Math.max(max, countIntegralChars(val));
      }
      return max;
    }, 0);
    var col1Arr = ['Field'].concat(fields);
    var col2Arr = vals.reduce(function(memo, val) {
      memo.push(formatTableValue(val, maxIntegralChars));
      return memo;
    }, [valKey == 'first_value' ? 'First value' : 'Value']);
    var col1Chars = maxChars(col1Arr);
    var col2Chars = maxChars(col2Arr);
    var sepStr = (utils.rpad('', col1Chars + 2, '-') + '+' +
        utils.rpad('', col2Chars + 2, '-')).substr(0, MAX_RULE_LEN);
    var sepLine = sepStr + '\n';
    var table = '';
    col1Arr.forEach(function(col1, i) {
      var w = stringDisplayWidth(col1);
      table += ' ' + col1 + utils.rpad('', col1Chars - w, ' ') + ' | ' +
        col2Arr[i] + '\n';
      if (i === 0) table += sepLine; // separator after first line
    });
    return header + sepLine + table + sepLine;
  }

  function measureLongestLine(str) {
    return Math.max.apply(null, str.split('\n').map(function(line) {return stringDisplayWidth(line);}));
  }

  function stringDisplayWidth(str) {
    var w = 0;
    for (var i = 0, n=str.length; i < n; i++) {
      w += charDisplayWidth(str.charCodeAt(i));
    }
    return w;
  }

  // see https://www.cl.cam.ac.uk/~mgk25/ucs/wcwidth.c
  // this is a simplified version, focusing on double-width CJK chars and ignoring nonprinting etc chars
  function charDisplayWidth(c) {
    if (c >= 0x1100 &&
      (c <= 0x115f || c == 0x2329 || c == 0x232a ||
      (c >= 0x2e80 && c <= 0xa4cf && c != 0x303f) || /* CJK ... Yi */
      (c >= 0xac00 && c <= 0xd7a3) || /* Hangul Syllables */
      (c >= 0xf900 && c <= 0xfaff) || /* CJK Compatibility Ideographs */
      (c >= 0xfe10 && c <= 0xfe19) || /* Vertical forms */
      (c >= 0xfe30 && c <= 0xfe6f) || /* CJK Compatibility Forms */
      (c >= 0xff00 && c <= 0xff60) || /* Fullwidth Forms */
      (c >= 0xffe0 && c <= 0xffe6) ||
      (c >= 0x20000 && c <= 0x2fffd) ||
      (c >= 0x30000 && c <= 0x3fffd))) return 2;
    return 1;
  }

  // TODO: consider polygons with zero area or other invalid geometries
  function countNullShapes(shapes) {
    var count = 0;
    for (var i=0; i<shapes.length; i++) {
      if (!shapes[i] || shapes[i].length === 0) count++;
    }
    return count;
  }

  function countNullRecords(records) {
    var count = 0;
    for (var i=0; i<records.length; i++) {
      if (!records[i]) count++;
    }
    return count;
  }

  function maxChars(arr) {
    return arr.reduce(function(memo, str) {
      var w = stringDisplayWidth(str);
      return w > memo ? w : memo;
    }, 0);
  }

  function formatString(str) {
    var replacements = {
      '\n': '\\n',
      '\r': '\\r',
      '\t': '\\t'
    };
    var cleanChar = function(c) {
      // convert newlines and carriage returns
      // TODO: better handling of non-printing chars
      return c in replacements ? replacements[c] : '';
    };
    str = str.replace(/[\r\t\n]/g, cleanChar);
    return "'" + str + "'";
  }

  function countIntegralChars(val) {
    return utils.isNumber(val) ? (utils.formatNumber(val) + '.').indexOf('.') : 0;
  }

  function formatTableValue(val, integralChars) {
    var str;
    if (utils.isNumber(val)) {
      str = utils.lpad("", integralChars - countIntegralChars(val), ' ') +
        utils.formatNumber(val);
    } else if (utils.isString(val)) {
      str = formatString(val);
    } else if (utils.isDate(val)) {
      str = utils.formatDateISO(val) + ' (Date)';
    } else if (utils.isObject(val)) { // if {} or [], display JSON
      str = JSON.stringify(val);
    } else {
      str = String(val);
    }

    if (typeof str != 'string') {
      // e.g. JSON.stringify converts functions to undefined
      str = '[' + (typeof val) + ']';
    }

    return str;
  }

  var Info = /*#__PURE__*/Object.freeze({
    __proto__: null,
    getLayerInfo: getLayerInfo,
    getAttributeTableInfo: getAttributeTableInfo,
    formatAttributeTableInfo: formatAttributeTableInfo,
    formatTableValue: formatTableValue
  });

  // import { importGeoJSON } from '../geojson/geojson-import';


  function addTargetProxies(targets, ctx) {
    if (targets && targets.length > 0) {
      var proxies = expandCommandTargets(targets).reduce(function(memo, target) {
        var proxy = getTargetProxy(target);
        memo.push(proxy);
        // index targets by layer name too
        if (target.layer.name) {
          memo[target.layer.name] = proxy;
        }
        return memo;
      }, []);
      Object.defineProperty(ctx, 'targets', {value: proxies});
      if (proxies.length == 1) {
        Object.defineProperty(ctx, 'target', {value: proxies[0]});
      }
    }
  }

  function getTargetProxy(target) {
    var proxy = getLayerInfo(target.layer, target.dataset); // layer_name, feature_count etc
    proxy.layer = target.layer;
    proxy.dataset = target.dataset;
    addGetters(proxy, {
      // export as an object, not a string or buffer
      geojson: getGeoJSON
    });

    function getGeoJSON() {
      var features = exportLayerAsGeoJSON(target.layer, target.dataset, {rfc7946: true}, true);
      return {
        type: 'FeatureCollection',
        features: features
      };
    }

    return proxy;
  }

  function compileIfCommandExpression(expr, catalog, opts) {
    return compileLayerExpression(expr, catalog, opts);
  }

  function compileLayerExpression(expr, catalog, opts) {
    var targetId = opts.layer || opts.target || null;
    var targets = catalog.findCommandTargets(targetId);
    var isSingle = targets.length == 1 && targets[0].layers.length == 1;
    if (targets.length === 0 && targetId) {
      stop('Layer not found:', targetId);
    }
    var defs = getStashedVar('defs') || {};

    var ctx;
    if (isSingle) {
      ctx = getLayerProxy(targets[0].layers[0], targets[0].dataset.arcs);
    } else {
      ctx = getNullLayerProxy(targets);
    }

    // add target/targets proxies, for consistency with the -run command
    addTargetProxies(targets, ctx);

    ctx.global = defs; // TODO: remove duplication with mapshaper.expressions.mjs
    var func = compileExpressionToFunction(expr, opts);

    // @geoType: optional geometry type (polygon, polyline, point, null);
    ctx.layer_exists = function(name, geoType) {
      try {
        var targets = catalog.findCommandTargets(name, geoType);
        if (targets.length > 0) return true;
      } catch(e) {}
      return false;
    };

    ctx.file_exists = function(file) {
      return cli.isFile(file);
    };

    return function() {
      try {
        return func.call(ctx, defs, ctx);
      } catch(e) {
        // if (opts.quiet) throw e;
        stop(e.name, "in expression [" + expr + "]:", e.message);
      }
    };
  }

  /*
  cmd.define_v2 = function(catalog, opts) {
    if (!opts.expression) {
      stop('Missing an assignment expression');
    }
    compileLayerExpression(opts.expression, catalog, opts)();
  };
  */

  cmd.define = function(catalog, opts) {
    if (!opts.expression) {
      stop('Missing an assignment expression');
    }
    var defs = getStashedVar('defs');
    var compiled = compileFeatureExpression(opts.expression, {}, null,
      {no_warn: true, no_return: true});
    compiled(null, defs);
  };

  // Removes small gaps and all overlaps
  cmd.dissolve2 = function(layers, dataset, opts) {
    layers.forEach(requirePolygonLayer);
    addIntersectionCuts(dataset, opts);
    return layers.map(function(lyr) {
      if (!layerHasPaths(lyr)) return lyr;
      return dissolvePolygonLayer2(lyr, dataset, opts);
    });
  };

  // Returns a function for filtering multiple source-table records
  // (used by -join command)
  function getJoinFilter(data, exp) {
    var test = getJoinFilterTestFunction(exp, data);
    var calc = null;
    if (expressionHasCalcFunction(exp)) {
      calc = getJoinFilterCalcFunction(exp, data);
    }

    return function(srcIds, destRec) {
      var d = calc ? calc(srcIds) : null;
      var filtered = [],
          retn, i;
      for (i=0; i<srcIds.length; i++) {
        retn = test(srcIds[i], destRec, d);
        requireBooleanResult(retn, '"where" expression must return true or false');
        if (retn === true) {
          filtered.push(srcIds[i]);
        }
      }
      return filtered;
    };
  }

  function expressionHasCalcFunction(exp) {
    return utils.some(['isMax', 'isMin', 'isMode'], function(name) {
      return exp.indexOf(name) > -1;
    });
  }


  function getJoinFilterCalcFunction(exp, data) {
    var values, max, min, context, calc;

    context = {
      isMax: function(val) {
        if (val > max) max = val;
      },
      isMin: function(val) {
        if (val < min) min = val;
      },
      isMode: function(val) {
        if (!values) {
          values = [];
        }
        values.push(val);
      }
    };

    calc = compileFeatureExpression(exp, {data: data}, null, {context: context, no_return: true});

    function reset() {
      max = -Infinity;
      min = Infinity;
      values = null;
    }

    return function(ids) {
      var mode;
      reset();
      for (var i=0; i<ids.length; i++) {
        calc(ids[i]);
      }
      mode = values ? getModeData(values) : null;
      return {
        max: max,
        min: min,
        modes: mode ? mode.modes : null,
        margin: mode ? mode.margin : null
      };
    };
  }


  function getJoinFilterTestFunction(exp, data) {
    var test, calcRec, destRec;
    var context = {
      isMax: function(val) {
        return val === calcRec.max;
      },
      isMin: function(val) {
        return val === calcRec.min;
      },
      isMode: function(val) {
        return calcRec.modes.indexOf(val) > -1;
      }
    };
    // 'target' property is an accessor function,
    // so the object it references can be updated.
    Object.defineProperty(context, 'target', {
      get: function() {
        return destRec;
      },
      enumerable: true // so it can be mixed-in to the actual expression context
    });

    test = compileFeatureExpression(exp, {data: data}, null, {context: context});

    // calcR: results from calculation phase, or null
    return function(srcId, destR, calcR) {
      calcRec = calcR;
      destRec = destR;
      return test(srcId);
    };
  }

  var JoinFilter = /*#__PURE__*/Object.freeze({
    __proto__: null,
    getJoinFilter: getJoinFilter
  });

  // Join data from @src table to records in @dest table
  function joinTables(dest, src, join, opts) {
    return joinTableToLayer({data: dest}, src, join, opts);
  }

  // Join data from @src table to records in @destLyr layer.
  // @join function
  //    Receives index of record in the dest table
  //    Returns array of matching records in src table, or null if no matches
  //
  function joinTableToLayer(destLyr, src, join, opts) {
    var dest = destLyr.data;

    if (src == dest) {
      // self-join... duplicate source records to prevent assignment problems
      // (in calc= expressions and possibly elsewhere)
      src = src.clone();
    }

    var useDuplication = !!opts.duplication,
        srcRecords = src.getRecords(),
        destRecords = dest.getRecords(),
        prefix = opts.prefix || '',
        unmatchedRecords = [],
        joinFields = getFieldsToJoin(dest.getFields(), src.getFields(), opts),
        sumFields = opts.sum_fields || [],
        copyFields = utils.difference(joinFields, sumFields),
        joinCounts = new Uint32Array(srcRecords.length),
        matchCount = 0,
        collisionCount = 0,
        collisionFields = [],
        skipCount = 0,
        retn = {},
        srcRec, srcId, destRec, joins, count, filter, calc, i, j, n, m;

    // support for duplication of destination records for many-to-one joins
    var duplicateRecords, destShapes;
    if (useDuplication) {
      if (opts.calc) stop('duplication and calc options cannot be used together');
      duplicateRecords = dest.clone().getRecords();
      destShapes = destLyr.shapes || [];
    }

    if (opts.where) {
      filter = getJoinFilter(src, opts.where);
    }

    if (opts.calc) {
      calc = getJoinCalc(src, opts.calc);
    }

    // join source records to target records
    n = destRecords.length;
    for (i=0; i<n; i++) {
      destRec = destRecords[i];
      joins = join(i);
      if (joins && filter) {
        skipCount += joins.length;
        joins = filter(joins, destRec);
        skipCount -= joins.length;
      }
      for (j=0, count=0, m=joins ? joins.length : 0; j<m; j++) {
        srcId = joins[j];
        srcRec = srcRecords[srcId];
        // duplication mode: many-to-one joins add new features to the target layer.
        if (count > 0 && useDuplication) {
          destRec = copyRecord(duplicateRecords[i]);
          destRecords.push(destRec);
          destShapes.push(cloneShape(destShapes[i]));
        }
        if (count === 0 || useDuplication) {
          if (copyFields.length > 0) {
            // only copying the first match
            joinByCopy(destRec, srcRec, copyFields, prefix);
          }
        } else if (count == 1) {
          if (copyFields.length > 0 && !prefix) {
            findCollisionFields(destRec, srcRec, copyFields, collisionFields);
          }
          collisionCount++; // count target records with multiple joins
        }
        if (sumFields.length > 0) {
          joinBySum(destRec, srcRec, sumFields, prefix);
        }
        joinCounts[srcId]++;
        count++;
      }
      if (calc) {
        calc(joins, destRec);
      }
      if (count > 0) {
        matchCount++;
      } else if (destRec) {
        if (opts.unmatched) {
          // Save a copy of unmatched record, before null values from join fields
          // are added.
          unmatchedRecords.push(utils.extend({}, destRec));
        }
        updateUnmatchedRecord(destRec, copyFields, sumFields, prefix);
      }
    }

    printJoinMessage(matchCount, n,
        countJoins(joinCounts), srcRecords.length, skipCount, collisionCount, collisionFields);

    if (opts.unjoined) {
      retn.unjoined = {
        name: 'unjoined',
        data: new DataTable(srcRecords.filter(function(o, i) {
          return joinCounts[i] === 0;
        }))
      };
    }
    if (opts.unmatched) {
      retn.unmatched = {
        name: 'unmatched',
        data: new DataTable(unmatchedRecords)
      };
    }
    return retn;
  }

  function validateFieldNames(arr) {
    arr.forEach(function(name) {
      if (/:(str|num)/.test(name)) {
        stop("Unsupported use of type hints. Use string-fields= or field-types= options instead");
      }
    });
  }


  function countJoins(counts) {
    var joinCount = 0;
    for (var i=0, n=counts.length; i<n; i++) {
      if (counts[i] > 0) {
        joinCount++;
      }
    }
    return joinCount;
  }

  // Unset fields of unmatched records get null/empty values
  function updateUnmatchedRecord(rec, copyFields, sumFields, prefix) {
    joinByCopy(rec, {}, copyFields, prefix);
    joinBySum(rec, {}, sumFields, prefix);
  }

  /*
  internal.getCountFieldName = function(fields) {
    var uniq = internal.getUniqFieldNames(fields.concat("joins"));
    return uniq.pop();
  };
  */

  function joinByCopy(dest, src, fields, prefix) {
    var f, f2;
    prefix = prefix || '';
    for (var i=0, n=fields.length; i<n; i++) {
      // dest[fields[i]] = src[fields[i]];
      // Use null when the source record is missing an expected value
      // TODO: think some more about whether this is desirable
      f = fields[i];
      f2 = prefix + f;
      if (Object.prototype.hasOwnProperty.call(src, f)) {
        dest[f2] = src[f];
      } else if (!Object.prototype.hasOwnProperty.call(dest, f2)) {
        dest[f2] = null;
      }
    }
  }

  function joinBySum(dest, src, fields, prefix) {
    var f, f2;
    prefix = prefix || '';
    for (var j=0; j<fields.length; j++) {
      f = fields[j];
      f2 = prefix + f;
      dest[f2] = (dest[f2] || 0) + (src[f] || 0);
    }
  }

  function findCollisionFields(dest, src, fields, collisionFields) {
    var f;
    for (var i=0, n=fields.length; i<n; i++) {
      f = fields[i];
      if (dest[f] !== src[f] && collisionFields.indexOf(f) === -1) {
        collisionFields.push(f);
      }
    }
  }

  function printJoinMessage(matches, n, joins, m, skipped, collisions, collisionFields) {
    // TODO: add tip for troubleshooting join problems, if join is less than perfect.
    var unmatched = n - matches;
    if (matches > 0 === false) {
      message("No records could be joined");
      return;
    }
    message(utils.format("Joined data from %'d source record%s to %'d target record%s",
        joins, utils.pluralSuffix(joins), matches, utils.pluralSuffix(matches)));
    if (unmatched > 0) {
      message(utils.format('%d target record%s received no data', unmatched, utils.pluralSuffix(unmatched)));
      // message(utils.format('%d target records received no data', n-matches));
    }
    if (joins < m) {
      message(utils.format("%d/%d source records could not be joined", m-joins, m));
    }
    if (skipped > 0) {
      message(utils.format("%d/%d source records were skipped", skipped, m));
    }
    if (collisions > 0) {
      message(utils.format('%d/%d target records were matched by multiple source records (many-to-one relationship)', collisions, n));
      if (collisionFields.length > 0) {
        message(utils.format('Inconsistent values were found in field%s [%s] during many-to-one join. Values in the first joining record were used.', utils.pluralSuffix(collisionFields.length), collisionFields.join(',')));
      }
    }
  }

  function getFieldsToJoin(destFields, srcFields, opts) {
    var joinFields;
    if (opts.fields) {
      if (opts.fields.indexOf('*') > -1) {
        joinFields = srcFields;
      } else {
        joinFields = opts.fields;
        validateFieldNames(joinFields);
      }
    } else if (opts.calc) {
      // presence of calc= option suggests a many-to-one or many-to-many join;
      // it usually doesn't make sense to join all fields by default
      joinFields = [];
    } else {
      // If a list of fields to join is not given, try to join all of the
      // source fields
      joinFields = srcFields;
      // exclude source key field from key-based join (if fields are not given explicitly)
      if (opts.keys) {
        joinFields = utils.difference(joinFields, [opts.keys[1]]);
      }
    }
    if (!opts.force && !opts.prefix) {
      // overwrite existing fields if the "force" option is set.
      // prefix also overwrites... TODO: consider changing this
      var duplicateFields = utils.intersection(joinFields, destFields);
      if (duplicateFields.length > 0) {
        message('Same-named fields not joined without the "force" flag:', duplicateFields);
        joinFields = utils.difference(joinFields, duplicateFields);
      }
    }
    return joinFields;
  }

  var JoinTables = /*#__PURE__*/Object.freeze({
    __proto__: null,
    joinTables: joinTables,
    joinTableToLayer: joinTableToLayer,
    validateFieldNames: validateFieldNames,
    updateUnmatchedRecord: updateUnmatchedRecord,
    findCollisionFields: findCollisionFields,
    getFieldsToJoin: getFieldsToJoin
  });

  cmd.divide = function(targetLayers, targetDataset, source, opts) {
    targetLayers.forEach(requirePolylineLayer);
    var mergedDataset = mergeLayersForOverlay(targetLayers, targetDataset, source, opts);
    var nodes = addIntersectionCuts(mergedDataset, opts);
    var polygonLyr = mergedDataset.layers.pop();
    requirePolygonLayer(polygonLyr);
    // Assume that topology is now built
    targetDataset.arcs = mergedDataset.arcs;
    targetLayers.forEach(function(polylineLyr) {
      dividePolylineLayer(polylineLyr, polygonLyr, nodes, opts);
    });
  };

  function dividePolylineLayer(polylineLyr, polygonLyr, nodes, opts) {
    var index = new PathIndex(polygonLyr.shapes, nodes.arcs);
    var records = polylineLyr.data ? polylineLyr.data.getRecords() : [];
    var shapes2 = [];
    var records2 = [];
    var index2 = [];
    var outputLines;
    var outputKeys;
    var outputMatches;
    polylineLyr.shapes.forEach(function(shp, i) {
      var rec = records[i] || {};
      if (!shp) {
        // case: record with no geometry -- retain in the output layer
        shapes2.push(null);
        records2.push(rec);
        return;
      }
      outputLines = [];
      outputKeys = [];
      outputMatches = [];
      forEachShapePart(shp, onPart);
      outputLines.forEach(function(shape2, i) {
        shapes2.push(shape2);
        records2.push(i > 0 ? utils.extend({}, rec) : rec); // assume input data is being replaced
        index2.push(outputMatches[i]);
      });
    });
    polylineLyr.shapes = shapes2;
    polylineLyr.data = new DataTable(records2);
    joinTables(polylineLyr.data, polygonLyr.data, function(i) {
      return index2[i] || [];
    }, opts);

    function addDividedParts(parts, keys, matches) {
      var keyId, key;
      for (var i=0; i<parts.length; i++) {
        key = keys[i];
        keyId = outputKeys.indexOf(key);
        if (keyId == -1) {
          outputKeys.push(key);
          outputLines.push([parts[i]]);
          outputMatches.push(matches[i]);
        } else {
          outputLines[keyId].push(parts[i]);
        }
      }
    }

    function getKey(shapeIds) {
      return shapeIds.sort().join(',');
      // multiple matches: treat like no match
      // return shapeIds.length == 1 ? String(shapeIds[0]) : '-1';
    }

    // Partition each part
    function onPart(ids) {
      var parts2 = [];
      var keys2 = [];
      var matches2 = [];
      var prevKey = null;
      var containingIds, key, part2, arcId;
      // assign each arc to a divided shape
      for (var i=0, n=ids.length; i<n; i++) {
        arcId = ids[i];
        containingIds = index.findShapesEnclosingArc(absArcId(arcId));
        key = getKey(containingIds);
        if (key === prevKey) {
          // case: continuation of a part
          part2.push(arcId);
        } else {
          // case: start of a new part
          part2 = [arcId];
          parts2.push(part2);
          keys2.push(key);
          matches2.push(containingIds);
        }
        prevKey = key;
      }
      addDividedParts(parts2, keys2, matches2);
    }
  }

  function MaxHeap() {
    return new Heap('max');
  }

  // A heap data structure used for computing Visvalingam simplification data.
  // type: 'max' or 'min' (min is default)
  //
  function Heap(type) {
    var heapBuf = utils.expandoBuffer(Int32Array),
        indexBuf = utils.expandoBuffer(Int32Array),
        heavierThan = type == 'max' ? lessThan : greaterThan,
        itemsInHeap = 0,
        dataArr,
        heapArr,
        indexArr;

    this.init = function(values) {
      var i;
      dataArr = values;
      itemsInHeap = values.length;
      heapArr = heapBuf(itemsInHeap);
      indexArr = indexBuf(itemsInHeap);
      for (i=0; i<itemsInHeap; i++) {
        insertValue(i, i);
      }
      // place non-leaf items
      for (i=(itemsInHeap-2) >> 1; i >= 0; i--) {
        downHeap(i);
      }
    };

    this.size = function() {
      return itemsInHeap;
    };

    // Update a single value and re-heap
    this.updateValue = function(valIdx, val) {
      var heapIdx = indexArr[valIdx];
      dataArr[valIdx] = val;
      if (!(heapIdx >= 0 && heapIdx < itemsInHeap)) {
        error("Out-of-range heap index.");
      }
      downHeap(upHeap(heapIdx));
    };

    this.popValue = function() {
      return dataArr[this.pop()];
    };

    this.getValue = function(idx) {
      return dataArr[idx];
    };

    this.peek = function() {
      return heapArr[0];
    };

    this.peekValue = function() {
      return dataArr[heapArr[0]];
    };

    // Return the idx of the lowest-value item in the heap
    this.pop = function() {
      var popIdx;
      if (itemsInHeap <= 0) {
        error("Tried to pop from an empty heap.");
      }
      popIdx = heapArr[0];
      insertValue(0, heapArr[--itemsInHeap]); // move last item in heap into root position
      downHeap(0);
      return popIdx;
    };

    function upHeap(idx) {
      var parentIdx;
      // Move item up in the heap until it's at the top or is not lighter than its parent
      while (idx > 0) {
        parentIdx = (idx - 1) >> 1;
        if (heavierThan(idx, parentIdx)) {
          break;
        }
        swapItems(idx, parentIdx);
        idx = parentIdx;
      }
      return idx;
    }

    // Swap item at @idx with any lighter children
    function downHeap(idx) {
      var minIdx = compareDown(idx);

      while (minIdx > idx) {
        swapItems(idx, minIdx);
        idx = minIdx; // descend in the heap
        minIdx = compareDown(idx);
      }
    }

    function swapItems(a, b) {
      var i = heapArr[a];
      insertValue(a, heapArr[b]);
      insertValue(b, i);
    }

    // Associate a heap idx with the index of a value in data arr
    function insertValue(heapIdx, valId) {
      indexArr[valId] = heapIdx;
      heapArr[heapIdx] = valId;
    }

    // comparator for Visvalingam min heap
    // @a, @b: Indexes in @heapArr
    function greaterThan(a, b) {
      var idx1 = heapArr[a],
          idx2 = heapArr[b],
          val1 = dataArr[idx1],
          val2 = dataArr[idx2];
      // If values are equal, compare array indexes.
      // This is not a requirement of the Visvalingam algorithm,
      // but it generates output that matches Mahes Visvalingam's
      // reference implementation.
      // See https://hydra.hull.ac.uk/assets/hull:10874/content
      return (val1 > val2 || val1 === val2 && idx1 > idx2);
    }

    // comparator for max heap
    function lessThan(a, b) {
      var idx1 = heapArr[a],
          idx2 = heapArr[b];
      return dataArr[idx1] < dataArr[idx2];
    }

    function compareDown(idx) {
      var a = 2 * idx + 1,
          b = a + 1,
          n = itemsInHeap;
      if (a < n && heavierThan(idx, a)) {
        idx = a;
      }
      if (b < n && heavierThan(idx, b)) {
        idx = b;
      }
      return idx;
    }
  }

  // TODO: optimize point-in-polygon tests for complex polygons and many points
  // import { PathIndex } from '../paths/mapshaper-path-index';

  function placeDotsInPolygon(shp, arcs, n, opts) {
    // TODO: skip tiny sliver polygons?
    if (n === 0) return [];
    if (opts.evenness === 0) return placeDotsRandomly(shp, arcs, n);
    // TODO: if n == 1, consider using the 'inner' point of a polygon
    return placeDotsEvenly(shp, arcs, n, opts);
  }

  function placeDotsRandomly(shp, arcs, n) {
    var bounds = arcs.getMultiShapeBounds(shp);
    var coords = [];
    for (var i=0; i<n; i++) {
      coords.push(placeRandomDot(shp, arcs, bounds));
    }
    return coords;
  }

  function placeRandomDot(shp, arcs, bounds) {
    var limit = 100;
    var i = 0;
    var x, y;
    while (++i < limit) {
      x = bounds.xmin + Math.random() * bounds.width();
      y = bounds.ymin + Math.random() * bounds.height();
      if (testPointInPolygon(x, y, shp, arcs)) {
        return [x, y];
      }
    }
    return null;
  }

  function placeDotsEvenly(shp, arcs, n, opts) {
    var evenness = opts.evenness >= 0 ? Math.min(opts.evenness, 1) : 1;
    var shpArea = geom.getPlanarShapeArea(shp, arcs);
    if (shpArea > 0 === false) return [];
    var bounds = arcs.getMultiShapeBounds(shp);
    var approxQueries = Math.round(n * bounds.area() / shpArea);
    if (opts.progressive) {
      // TODO: implement this properly
      approxQueries = Math.ceil(approxQueries / 6);
    }
    var grid = new DotGrid(bounds, approxQueries, evenness);
    var coords = [];
    for (var i=0; i<n; i++) {
      coords.push(placeDot(shp, arcs, grid));
    }
    grid.done();
    return coords;
  }

  function placeDot(shp, arcs, grid) {
    var i = 0;
    var limit = 100;
    var p;
    while (++i < limit) {
      p = grid.getPoint();
      if (!p) continue;
      if (testPointInPolygon(p[0], p[1], shp, arcs)) {
        return p;
      }
    }
    return null;
  }

  // A method for placing dots in a 2D rectangular space
  // evenness: varies from 0-1
  //   0 is purely random
  //   1 uses a hybrid approach, first creating a sparse structure of random
  //      dots, then progressively filling in the spaces between dots
  //   (0-1) first creates an evenish structure of dots, then places additional
  //      dots using "dart-throwing" -- picking random points until a point
  //      is found that exceeds a (variable) distance from any other point
  //
  function DotGrid(bounds, approxQueries, evenness) {
    var x0 = bounds.xmin;
    var y0 = bounds.ymin;
    var w = bounds.width();
    var h = bounds.height();
    var k =  0.5 * (evenness - 1) + 1; // k varies from 0.5 to 1
    var approxCells = approxQueries * 0.9 * k;
    var cols = Math.round(Math.sqrt(approxCells * w / h)) || 1;
    var rows = Math.ceil(cols * h / w); // overshoots bbox height
    var gridWidth = w;
    var cells = cols * rows;
    var cellId = -1;
    var shuffledIds;
    var grid = initGrid(cells);
    // data used by optimal method
    var bestPoints;
    var bestHeap;

    // Set the initial distance threshold between dots (based on a square grid)
    // When evenness < 1 (dart-throwing mode) the distance threshold is reduced in
    //   proportion to the value of evenness.
    // From trial and error, a 0.7 constant seems to give good results.
    var initialDotSpacing = gridWidth / cols * 0.7 * evenness;
    var dotSpacing = initialDotSpacing;

    this.done = done;
    this.getPoint = getPoint;

    function done() {
    }

    function getPoint() {
      if (evenness === 1) return getOptimalPoint();
      if (evenness === 0) return getRandomPoint();
      return getSpacedPoint();
    }

    function initGrid(n) {
      var arr = [];
      for (var i=0; i<n; i++) arr.push([]);
      return arr;
    }

    function getOptimalPoint() {
      var p = getFirstFillPoint();
      if (p) return usePoint(p);

      // fill in the gaps of the initial placement, starting with the largest gap
      if (!bestPoints) {
        initBestPoints();
      }
      return useBestPoint();
    }

    // try to place a random but spaced point in each grid cell
    // (to create an initial sparse structure that gets filled in later)
    function getFirstFillPoint() {
      var p;
      if (!shuffledIds) {
        shuffledIds = utils.range(cells);
        utils.shuffle(shuffledIds);
      }
      while (++cellId < cells) {
        p = getRandomPointInCell(shuffledIds[cellId]);
        if (pointIsUsable(p)) {
          return p;
        }
      }
    }

    function getSpacedPoint() {
      // use dart-throwing, reject points that are within the minimum distance
      var probesBeforeRelaxation = Math.ceil(Math.pow(cells, 0.8));
      var maxProbes = cells * 10;
      var probes = 0;
      var p = getFirstFillPoint();
      if (p) return usePoint(p);

      while (probes++ < maxProbes) {
        p = getRandomPoint();
        if (pointIsUsable(p)) {
          return usePoint(p);
        }
        if (probes % probesBeforeRelaxation === 0) {
          // relax min dist after a number of failed probes
          dotSpacing *= 0.9;
        }
      }
      return null;
    }

    // Add point to grid of used points
    function usePoint(p) {
      var i = pointToIdx(p);
      grid[i].push(p);
      return p;
    }

    function useBestPoint() {
      var bestId = bestHeap.peek();
      var p = bestPoints[bestId];
      usePoint(p); // add to grid of used points
      updateNeighbors(p, bestId); // update best point of this cell and neighbors
      dotSpacing = bestHeap.peekValue();
      return p;
    }

    function initBestPoints() {
      var values = [];
      bestPoints = [];
      for (var i=0; i<cells; i++) {
        values.push(findBestPointInCell(i));
      }
      bestHeap = new MaxHeap();
      bestHeap.init(values);
    }

    function updateNeighbors(p, i) {
      var r = idxToRow(i);
      var c = idxToCol(i);
      updateBestPointInCell(i);
      updateNeighbor(p, c+1, r);
      updateNeighbor(p, c, r+1);
      updateNeighbor(p, c-1, r);
      updateNeighbor(p, c, r-1);
      updateNeighbor(p, c+1, r+1);
      updateNeighbor(p, c-1, r+1);
      updateNeighbor(p, c-1, r-1);
      updateNeighbor(p, c+1, r-1);
    }

    function updateNeighbor(addedPt, c, r) {
      var i = colRowToIdx(c, r);
      if (i == -1) return;
      var bestPt = bestPoints[i];
      var dist = bestHeap.getValue(i);
      // don't need to update best point if the newly added point is too far away
      // to have an effect.
      // (about 80% of updates are skipped, typically)
      if (distSq(addedPt, bestPt) < dist * dist) {
        updateBestPointInCell(i);
      }
    }

    function updateBestPointInCell(i) {
      var dist = findBestPointInCell(i);
      bestHeap.updateValue(i, dist);
    }

    function findBestPointInCell(idx) {
      // Find a point by finding the best-placed center point in a grid of sub-cells,
      // then recursively dividing the winning sub-cell
      var r = idxToRow(idx);
      var c = idxToCol(idx);
      var p = findBestPointInSubCell(c, r, 0, 0, 1);
      bestPoints[idx] = p;
      return p.pop();
    }

    // c, r: location of parent cell in the grid
    // c1, r1: index of sub-cell at the given z-value
    // z: depth of recursive subdivision
    function findBestPointInSubCell(c, r, c1, r1, z) {
      // using a 3x3 grid instead of 2x2 ... testing showed that 2x2 was more
      // likely to misidentify the sub-cell with the optimal point
      var q = 3;
      var perSide = Math.pow(q, z); // number of cell divisions per axis at this z
      var maxDist = 0;
      var c2, r2, p, best, dist;
      for (var i=0; i<q; i++) {
        for (var j=0; j<q; j++) {
          p = getGridPointInCell(c, r, c1 + i, r1 + j, perSide);
          dist = findDistanceFromNearbyFeatures(maxDist, p, c, r);
          if (dist > maxDist) {
            maxDist = dist;
            best = p;
            c2 = i;
            r2 = j;
          }
        }
      }
      if (z == 2) { // stop subdividing the cell at this level
        best.push(maxDist); // return distance as third element
        return best;
      } else {
        return findBestPointInSubCell(c, r, (c1 + c2)*q, (r1 + r2)*q, z + 1);
      }
    }

    function getGridPointInCell(c, r, c2, r2, n) {
      var dx = (c2 + 0.5) / n;
      var dy = (r2 + 0.5) / n;
      var x = (dx + c) / cols * w + x0;
      var y = (dy + r) / rows * h + y0;
      return [x, y];
    }

    // col, row offsets of a cell and its 8 neighbors
    // (ordered to reject unsuitable points faster)
    var nabes = [
      [0, 0], [0, -1], [-1, 0], [1, 0], [0, 1],
      [-1, 1], [1, -1], [-1, -1], [1, 1]
    ];

    function findDistanceFromNearbyFeatures(memo, xy, c, r) {
      var minDistSq = Infinity;
      var offs, c2, r2, distSq, dist;
      for (var i=0; i<9; i++) {
        offs = nabes[i];
        c2 = offs[0];
        r2 = offs[1];
        distSq = distSqFromPointsInCell(xy, c + c2, r + r2);
        if (distSq < memo * memo) {
          // short-circuit rejection of this point (optimization)
          // -- it is closer than a previously tested point
          return 0;
        }
        if (distSq < minDistSq) {
          minDistSq = distSq;
        }
      }
      dist = Math.sqrt(minDistSq);
      // maintain distance from grid edge
      // (this prevents two sets of dots from appearing right along the edges of
      // rectangular polygons).
      dist = Math.min(dist, spaceFromEdge(xy, c, r));
      return dist;
    }

    function spaceFromEdge(xy, c, r) {
      // ignore edges if cell is internal to the grid
      if (c > 0 && r > 0 && c < cols-1 && r < rows-1) return Infinity;
      var x = xy[0], y = xy[1];
      // exaggerating the true distance to prevent a visible gutter from appearing
      // along the borders of shapes with rectangular edges.
      return Math.min(x - x0, x0 + w - x, y - y0, y0 + h - y) * 3;
    }

    function distSqFromPointsInCell(xy, c, r) {
      var minDist = Infinity, dist;
      var idx = colRowToIdx(c, r);
      var points = idx > -1 ? grid[idx] : []; // off the edge
      for (var i=0; i<points.length; i++) {
        dist = distSq(xy, points[i]);
        if (dist < minDist) minDist = dist;
      }
      return minDist;
    }

    function distSq(a, b) {
      var dx = a[0] - b[0];
      var dy = a[1] - b[1];
      return dx * dx + dy * dy;
    }

    function getRandomPointInCell(i) {
      var r = idxToRow(i);
      var c = idxToCol(i);
      var x = (Math.random() + c) / cols * w + x0;
      var y = (Math.random() + r) / rows * h + y0;
      var p = [x, y];
      return p;
    }

    function getRandomPoint() {
      return getRandomPointInCell(getRandomCell());
    }

    function getRandomCell() {
      return Math.floor(Math.random() * cells);
    }

    function pointIsUsable(xy) {
      var c = pointToCol(xy),
          r = pointToRow(xy);
      var collision = testCollision(xy, c, r) ||
        testEdgeCollision(xy, c, r) ||
        testCollision(xy, c+1, r) ||
        testCollision(xy, c, r+1) ||
        testCollision(xy, c-1, r) ||
        testCollision(xy, c, r-1) ||
        testCollision(xy, c+1, r+1) ||
        testCollision(xy, c-1, r+1) ||
        testCollision(xy, c-1, r-1) ||
        testCollision(xy, c+1, r-1);
      return !collision;
    }

    function testEdgeCollision(xy, c, r) {
      return spaceFromEdge(xy, c, r) < dotSpacing;
    }

    function testCollision(xy, c, r) {
      var i = colRowToIdx(c, r);
      if (i == -1) return false;
      var points = grid[i];
      return testPointCollision(xy, points, dotSpacing);
    }

    function testPointCollision(xy, points, dist) {
      var d2 = dist * dist;
      for (var i=0; i<points.length; i++) {
        if (distSq(xy, points[i]) < d2) {
          return true;
        }
      }
      return false;
    }

    function pointToCol(xy) {
      var dx = xy[0] - x0;
      var c = Math.floor(dx / w * cols);
      if (c < 0) c = 0;
      if (c >= cols) c = cols-1;
      return c;
    }

    function pointToRow(xy) {
      var dy = xy[1] - y0;
      var r = Math.floor(dy / h * rows);
      if (r < 0) r = 0;
      if (r >= rows) r = rows-1;
      return r;
    }

    function colRowToIdx(c, r) {
      if (c < 0 || r < 0 || c >= cols || r >= rows) return -1;
      return r * cols + c;
    }

    function pointToIdx(xy) {
      var c = pointToCol(xy);
      var r = pointToRow(xy);
      var idx = r * cols + c;
      return idx;
    }

    function idxToCol(i) {
      return i % cols;
    }

    function idxToRow(i) {
      return Math.floor(i / cols);
    }
  }

  cmd.dots = function(lyr, arcs, opts) {
    requirePolygonLayer(lyr);
    if (!Array.isArray(opts.fields)) {
      stop("Missing required fields parameter");
    }
    if (layerHasNonNullData(lyr)) {
      opts.fields.forEach(function(f, i) {
        requireDataField(lyr, f);
      });
      (opts.copy_fields || []).forEach(function(f) {
        requireDataField(lyr, f);
      });
    }
    // if (!Array.isArray(opts.colors)) {
    //   stop("Missing required colors parameter");
    // }
    if (Array.isArray(opts.colors)) {
      opts.colors.forEach(validateColor);
    }

    var records = lyr.data ? lyr.data.getRecords() : [];
    var shapes2 = [];
    var records2 = [];
    lyr.shapes.forEach(function(shp, i) {
      var d = records[i];
      if (!d) return;
      var data =  makeDotsForShape(shp, arcs, d, opts);
      for (var j=0, n=data.shapes.length; j<n; j++) {
        shapes2.push(data.shapes[j]);
        records2.push(data.attributes[j]);
      }
    });

    var lyr2 = {
      geometry_type: 'point',
      shapes: shapes2,
      data: new DataTable(records2)
    };
    setOutputLayerName(lyr2, lyr, null, opts);
    return [lyr2];
  };

  function makeDotsForShape(shp, arcs, rec, opts) {
    var retn = {
      shapes: [],
      attributes: []
    };
    if (!shp) return retn;
    var counts = opts.fields.map(function(f) {
      var val = rec[f] || 0;
      if (opts.per_dot > 0) {
        val = Math.round(val / opts.per_dot);
      }
      return val;
    });
    var indexes = expandCounts(counts);
    var dots = placeDots(shp, arcs, indexes.length, opts);

    // randomize dot sequence so dots of the same color do not always overlap dots of
    // other colors in dense areas.
    // TODO: instead of random shuffling, interleave dot classes more regularly?
    utils.shuffle(indexes);
    var idx, prevIdx = -1;
    var multipart = !!opts.multipart;
    var coords, p, d;
    for (var i=0; i<dots.length; i++) {
      p = dots[i];
      if (!p) continue;
      idx = indexes[i];
      if (p.length === 3 && opts.debug) {
        idx = p.pop(); // way to debug dot placement visually
      }
      if (!multipart || idx != prevIdx) {
        prevIdx = idx;
        retn.shapes.push(coords = []);
        d = getDataRecord(idx, rec, opts);
        retn.attributes.push(d);
      }
      coords.push(p);
    }
    return retn;
  }

  function placeDots(shp, arcs, n, opts) {
    // split apart multipart polygons for more efficient dot placement
    var polys = shp.length > 1 ? explodePolygon(shp, arcs) : [shp];
    var counts = apportionDotsByArea(polys, arcs, n);
    var dots = [];
    for (var i=0; i<polys.length; i++) {
      dots = dots.concat(placeDotsInPolygon(polys[i], arcs, counts[i], opts));
    }
    return dots;
  }

  function apportionDotsByArea(polys, arcs, n) {
    if (polys.length === 1) return [n];
    var areas = polys.map(function(shp) {
      return geom.getPlanarShapeArea(shp, arcs);
    });
    var remainingArea = utils.sum(areas);
    var remainingDots = n;
    return areas.map(function(area, i) {
      var pct = area / remainingArea;
      var count = Math.round(remainingDots * pct);
      remainingDots -= count;
      remainingArea -= area;
      return count;
    });
  }

  function expandCounts(counts) {
    var arr = [];
    counts.forEach(function(n, i) {
      while (n-- > 0) arr.push(i);
    });
    return arr;
  }

  // i: dot class index
  // d: properties of original polygon
  // opts: dots command options
  function getDataRecord(i, d, opts) {
    var o = {};
    var key = opts.save_as || 'fill';
    var values = opts.colors || opts.values;
    if (values) {
      o[key] = values[i];
      o.r = opts.r || 1.3;
    } else if (opts.r) {
      o.r = opts.r;
    }
    if (opts.copy_fields) {
      for (var j=0; j<opts.copy_fields.length; j++) {
        o[opts.copy_fields[j]] = d[opts.copy_fields[j]];
      }
    }
    return o;
  }

  cmd.drop2 = function(catalog, targets, opts) {
    targets.forEach(function(target) {
      cmd.drop(catalog, target.layers, target.dataset, opts);
    });
  };

  cmd.drop = function(catalog, layers, dataset, opts) {
    var updateArcs = false;

    layers.forEach(function(lyr) {
      var fields = lyr.data && opts.fields;
      var allFields = fields && fieldListContainsAll(fields, lyr.data.getFields());
      var deletion = !fields && !opts.geometry && !opts.holes || allFields && opts.geometry;
      if (opts.geometry) {
        updateArcs |= layerHasPaths(lyr);
        delete lyr.shapes;
        delete lyr.geometry_type;
      }
      if (opts.holes && lyr.geometry_type == 'polygon') {
        deleteHoles(lyr, dataset.arcs);
      }
      if (deletion) {
        catalog.deleteLayer(lyr, dataset);
      } else if (allFields) {
        delete lyr.data;
      } else if (fields) {
        opts.fields.forEach(lyr.data.deleteField, lyr.data);
      }
    });

    if (updateArcs) {
      pruneArcs(dataset);
    }
  };

  function expressionUsesGeoJSON(exp) {
    return exp.includes('this.geojson') || exp.includes('this.geometry') || exp.includes('this.feature');
  }

  function getFeatureEditor(lyr, dataset) {
    var api = {};
    // need to copy attribute to avoid circular references if geojson is assigned
    // to a data property.
    var copy = copyLayer(lyr);
    var features = exportLayerAsGeoJSON(copy, dataset, {rfc7946: true}, true);
    var features2 = [];

    api.get = function(i) {
      if (i > 0) features[i-1] = null; // garbage-collect old features
      return features[i];
    };

    api.getGeometry = function(i) {
      if (i > 0) features[i-1] = null; // garbage-collect old features
      return features[i] ? features[i].geometry : null;
    };

    api.setGeometry = function(geom, i) {
      if (utils.isString(geom)) {
        geom = JSON.parse(geom);
      }
      // TODO: validate? validate geometry in feature setter?
      var feat = {
        type: 'Feature',
        properties: features[i] ? features[i].properties : null,
        geometry: geom || null
      };
      api.set(feat, i);
    };

    api.set = function(feat, i) {
      var arr;

      if (utils.isString(feat)) {
        feat = JSON.parse(feat);
      }

      if (!feat) return;

      if (feat.type == 'GeometryCollection') {
        arr = feat.geometries.map(geom => GeoJSON.toFeature(geom));
      } else if (feat.type == 'FeatureCollection') {
        arr = feat.features;
      } else {
        feat = GeoJSON.toFeature(feat);
      }

      if (arr) {
        features2 = features2.concat(arr);
      } else {
        features2.push(feat);
      }
    };

    api.done = function() {
      if (features2.length === 0) return; // read-only expression
      var geojson = {
        type: 'FeatureCollection',
        features: features2
      };
      return importGeoJSON(geojson);
    };
    return api;
  }

  cmd.filterGeom = function(lyr, arcs, opts) {
    if (!layerHasGeometry(lyr)) {
      stop("Layer is missing geometry");
    }
    if (opts.bbox) {
      filterByBoundsIntersection(lyr, arcs, opts);
    }
    cmd.filterFeatures(lyr, arcs, {remove_empty: true, verbose: false});
  };

  function filterByBoundsIntersection(lyr, arcs, opts) {
    var filter = getBoundsIntersectionFilter(opts.bbox, lyr, arcs);
    editShapes(lyr.shapes, filter);
  }

  function getBoundsIntersectionFilter(bbox, lyr, arcs) {
    var bounds = new Bounds(bbox);
    var filter = lyr.geometry_type == 'point' ?
          getPointInBoundsTest(bounds) :
          getPathBoundsIntersectionTest(bounds, arcs);
    return filter;
  }

  function getPointInBoundsTest(bounds) {
    return function(xy) {
      var contains =  bounds.containsPoint(xy[0], xy[1]);
      return contains ? xy : null;
    };
  }

  // V1 too-simple test: bounding-box intersection
  // internal.getPathBoundsIntersectionTest = function(bounds, arcs) {
  //   return function(path) {
  //     return bounds.intersects(arcs.getSimpleShapeBounds(path)) ? path : null;
  //   };
  // };

  function getPathBoundsIntersectionTest(bounds, arcs) {
    var bbox = bounds.toArray(),
      left = bbox[0],
      bottom = bbox[1],
      right = bbox[2],
      top = bbox[3];

    return function(path) {
      // case: bounding boxes don't intersect -> the path doesn't intersect the box
      if (!bounds.intersects(arcs.getSimpleShapeBounds(path))) {
        return null;
      }
      var intersects = false;
      var ax, ay, bx, by;
      var iter = arcs.getShapeIter(path);

      if (iter.hasNext()) {
        ax = iter.x;
        ay = iter.y;
      }
      while (iter.hasNext()) {
        bx = ax;
        by = ay;
        ax = iter.x;
        ay = iter.y;
        if (segmentOutsideBBox(ax, ay, bx, by, left, bottom, right, top)) continue;
        if (segmentInsideBBox(ax, ay, bx, by, left, bottom, right, top)) {
          intersects = true;
          break;
        }
        if (geom.segmentIntersection(left, top, right, top, ax, ay, bx, by) ||
            geom.segmentIntersection(left, bottom, right, bottom, ax, ay, bx, by) ||
            geom.segmentIntersection(left, bottom, left, top, ax, ay, bx, by) ||
            geom.segmentIntersection(right, bottom, right, top, ax, ay, bx, by)) {
          intersects = true;
          break;
        }
      }

      // case: bbox is entirely inside this ring
      if (!intersects && geom.testPointInRing(left, bottom, path, arcs)) {
        intersects = true;
      }
      return intersects ? path : null;
    };
  }

  // Return a function for testing if a shape (path or point) intersects a bounding box
  // TODO: move this function to a different file
  function getBBoxIntersectionTest(bbox, lyr, arcs) {
    var filter = getBoundsIntersectionFilter(bbox, lyr, arcs);
    return function(shapeId) {
      var shp = lyr.shapes[shapeId];
      if (!shp) return false;
      for (var i=0; i<shp.length; i++) {
        if (filter(shp[i])) return true;
      }
      return false;
    };
  }

  // return array of shape ids
  function findShapesIntersectingBBox(bbox, lyr, arcs) {
    var test = getBBoxIntersectionTest(bbox, lyr, arcs);
    var ids = [];
    for (var i=0; i<lyr.shapes.length; i++) {
      if (test(i)) ids.push(i);
    }
    return ids;
  }

  var FilterGeom = /*#__PURE__*/Object.freeze({
    __proto__: null,
    getBBoxIntersectionTest: getBBoxIntersectionTest,
    findShapesIntersectingBBox: findShapesIntersectingBBox
  });

  cmd.filterFeatures = function(lyr, arcs, opts) {
    var records = lyr.data ? lyr.data.getRecords() : null,
        shapes = lyr.shapes || null,
        n = getFeatureCount(lyr),
        filteredShapes = shapes ? [] : null,
        filteredRecords = records ? [] : null,
        filteredLyr = getOutputLayer(lyr, opts),
        invert = !!opts.invert,
        filter;

    if (opts.expression) {
      filter = compileFeatureExpression(opts.expression, lyr, arcs);
    }

    if (opts.ids) {
      filter = combineFilters(filter, getIdFilter(opts.ids));
    }

    if (opts.remove_empty) {
      filter = combineFilters(filter, getNullGeometryFilter(lyr, arcs));
    }

    if (opts.bbox) {
      filter = combineFilters(filter, getBBoxIntersectionTest(opts.bbox, lyr, arcs));
    }

    if (!filter) {
      stop("Missing a filter criterion");
    }

    utils.repeat(n, function(shapeId) {
      var result = filter(shapeId);
      requireBooleanResult(result);
      if (invert) result = !result;
      if (result === true) {
        if (shapes) filteredShapes.push(shapes[shapeId] || null);
        if (records) filteredRecords.push(records[shapeId] || null);
      }
    });

    filteredLyr.shapes = filteredShapes;
    filteredLyr.data = filteredRecords ? new DataTable(filteredRecords) : null;
    if (opts.no_replace) {
      // if adding a layer, don't share objects between source and filtered layer
      filteredLyr = copyLayer(filteredLyr);
    }

    if (opts.verbose !== false && !opts.quiet) {
      message(utils.format('Retained %,d of %,d features', getFeatureCount(filteredLyr), n));
    }

    return filteredLyr;
  };

  // TODO: update filter command to use this function
  function filterLayerInPlace(lyr, filter, invert) {
    var records = lyr.data ? lyr.data.getRecords() : null,
        shapes = lyr.shapes || null,
        n = getFeatureCount(lyr),
        filteredShapes = shapes ? [] : null,
        filteredRecords = records ? [] : null;
    utils.repeat(n, function(shapeId) {
      var result = filter(shapeId);
      requireBooleanResult(result);
      if (invert) result = !result;
      if (result === true) {
        if (shapes) filteredShapes.push(shapes[shapeId] || null);
        if (records) filteredRecords.push(records[shapeId] || null);
      }
    });
    lyr.shapes = filteredShapes;
    lyr.data = filteredRecords ? new DataTable(filteredRecords) : null;
  }

  function getIdFilter(ids) {
    var set = new Set(ids);
    return function(i) {
      return set.has(i);
    };
  }

  function getNullGeometryFilter(lyr, arcs) {
    var shapes = lyr.shapes;
    if (lyr.geometry_type == 'polygon') {
      return getEmptyPolygonFilter(shapes, arcs);
    }
    return function(i) {return !!shapes[i];};
  }

  function getEmptyPolygonFilter(shapes, arcs) {
    return function(i) {
      var shp = shapes[i];
      return !!shp && geom.getPlanarShapeArea(shapes[i], arcs) > 0;
    };
  }

  function combineFilters(a, b) {
    return a && b ? function(id) {
        return a(id) && b(id);
      } : (a || b);
  }

  cmd.evaluateEachFeature = function(lyr, dataset, expArg, opts) {
    var n = getFeatureCount(lyr),
        arcs = dataset.arcs,
        exp = expArg || '',
        compiled, filter;

    var exprOpts = {
      no_return: true,
      geojson_editor: expressionUsesGeoJSON(exp) ? getFeatureEditor(lyr, dataset) : null
    };

    // TODO: consider not creating a data table -- not needed if expression only references geometry
    if (n > 0 && !lyr.data) {
      lyr.data = new DataTable(n);
    }
    if (opts && opts.where) {
      filter = compileFeatureExpression(opts.where, lyr, arcs);
    }
    if (opts && opts.ids) {
      filter = combineFilters(filter, getIdFilter(opts.ids));
    }
    compiled = compileFeatureExpression(exp, lyr, arcs, exprOpts);
    // call compiled expression with id of each record
    for (var i=0; i<n; i++) {
      if (!filter || filter(i)) {
        compiled(i);
      }
    }

    var replacement = exprOpts.geojson_editor ? exprOpts.geojson_editor.done() : null;
    if (replacement) {
      replaceLayerContents(lyr, dataset, replacement);
    }
  };

  var externalCommands = {};

  cmd.registerCommand = function(name, params) {
    var defn = {name: name, options: params.options || []};
    // Add definitions of options common to all commands (TODO: remove duplication)
    defn.options.push({name: 'target'});
    utils.defaults(defn, params);
    validateExternalCommand(defn);
    externalCommands[name] = defn;
  };

  function isValidExternalCommand(defn) {
    try {
      validateExternalCommand(defn);
      return true;
    } catch(e) {}
    return false;
  }

  function validateExternalCommand(defn) {
    var targetTypes = ['layer', 'layers'];
    if (typeof defn.command != 'function') {
      stop('Expected "command" parameter function');
    }
    if (!defn.target) {
      stop('Missing required "target" parameter');
    }
    if (!targetTypes.includes(defn.target)) {
      stop('Unrecognized command target type:', defn.target);
    }
  }

  cmd.runExternalCommand = function(cmdOpts, catalog) {
    var name = cmdOpts.name;
    var cmdDefn = externalCommands[name];
    if (!cmdDefn) {
      stop('Unsupported command:', name);
    }
    var targetType = cmdDefn.target;
    var opts = parseExternalCommand(name, cmdDefn, cmdOpts._);
    var targets = catalog.findCommandTargets(opts.target || '*');
    var target = targets[0];
    var output;
    if (!target) {
      stop('Missing a target');
    }
    if (targetType == 'layer' && (target.layers.length != 1 || targets.length > 1)) {
      stop('This command only supports targeting a single layer');
    }
    if (targets.length > 1) {
      stop("Targetting layers from multiple datasets is not supported");
    }
    if (targetType == 'layer') {
      output = cmdDefn.command(target.layers[0], target.dataset, opts.options);
    } else if (targetType == 'layers') {
      output = cmdDefn.command(target.layers, target.dataset, opts.options);
    }
    if (output) {
      integrateOutput(output, target, catalog, opts);
    }
  };

  // TODO: remove restrictions on output data
  function integrateOutput(output, input, catalog, opts) {
    if (!output.dataset || !output.layers || output.layers.length > 0 === false) {
      stop('Invalid command output');
    }
    if (output.dataset == input.dataset) {
      stop('External commands are not currently allowed to modify input datasets');
    }
    if (output.dataset.layers.length != output.layers.length) {
      stop('Currently not supported: targetting a subset of output layers');
    }
    if (!opts.no_replace) {
      input.layers.forEach(function(lyr) {
        catalog.deleteLayer(lyr, input.dataset);
      });
    }
    catalog.addDataset(output.dataset);
  }

  function parseExternalCommand(name, cmdDefn, tokens) {
    var parser = new CommandParser();
    var cmd = parser.command(name);
    (cmdDefn.options || []).forEach(function(o) {
      cmd.option(o.name, o);
    });
    var parsed = parser.parseArgv(['-' + name].concat(tokens));
    return parsed[0];
  }

  // Returns number of arcs that were removed
  function editArcs(arcs, onPoint) {
    var nn2 = [],
        xx2 = [],
        yy2 = [],
        errors = 0,
        n;

    arcs.forEach(function(arc, i) {
      editArc(arc, onPoint);
    });
    arcs.updateVertexData(nn2, xx2, yy2);
    return errors;

    function append(p) {
      if (p) {
        xx2.push(p[0]);
        yy2.push(p[1]);
        n++;
      }
    }

    function editArc(arc, cb) {
      var x, y, xp, yp, retn;
      var valid = true;
      var i = 0;
      n = 0;
      while (arc.hasNext()) {
        x = arc.x;
        y = arc.y;
        retn = cb(append, x, y, xp, yp, i++);
        if (retn === false) {
          valid = false;
          // assumes that it's ok for the arc iterator to be interrupted.
          break;
        }
        xp = x;
        yp = y;
      }
      if (valid && n == 1) {
        // only one valid point was added to this arc (invalid)
        // e.g. this could happen during reprojection.
        // making this arc empty
        // error("An invalid arc was created");
        message("An invalid arc was created");
        valid = false;
      }
      if (valid) {
        nn2.push(n);
      } else {
        // remove any points that were added for an invalid arc
        while (n-- > 0) {
          xx2.pop();
          yy2.pop();
        }
        nn2.push(0); // add empty arc (to preserve mapping from paths to arcs)
        errors++;
      }
    }
  }

  function DatasetEditor(dataset) {
    var layers = [];
    var arcs = [];

    this.done = function() {
      dataset.layers = layers;
      if (arcs.length) {
        dataset.arcs = new ArcCollection(arcs);
        buildTopology(dataset);
      }
    };

    this.editLayer = function(lyr, cb) {
      var type = lyr.geometry_type;
      if (dataset.layers.indexOf(lyr) != layers.length) {
        error('Layer was edited out-of-order');
      }
      if (!type) {
        layers.push(lyr);
        return;
      }
      var shapes = lyr.shapes.map(function(shape, shpId) {
        var shape2 = [], retn, input;
        for (var i=0, n=shape ? shape.length : 0; i<n; i++) {
          input = type == 'point' ? shape[i] : idsToCoords(shape[i]);
          retn = cb(input, i, shape);
          if (!Array.isArray(retn)) continue;
          if (type == 'point') {
            shape2.push(retn);
          } else if (type == 'polygon' || type == 'polyline') {
            extendPathShape(shape2, retn || []);
          }
        }
        return shape2.length > 0 ? shape2 : null;
      });
      layers.push(Object.assign(lyr, {shapes: shapes}));
    };

    function extendPathShape(shape, parts) {
      for (var i=0; i<parts.length; i++) {
        shape.push([arcs.length]);
        arcs.push(parts[i]);
      }
    }

    function idsToCoords(ids) {
      var coords = [];
      var iter = dataset.arcs.getShapeIter(ids);
      while (iter.hasNext()) {
        coords.push([iter.x, iter.y]);
      }
      return coords;
    }
  }

  // Planar densification by an interval
  function densifyPathByInterval(coords, interval, interpolate) {
    if (findMaxPathInterval(coords) < interval) return coords;
    if (!interpolate) {
      interpolate = getIntervalInterpolator(interval);
    }
    var coords2 = [coords[0]], a, b;
    for (var i=1, n=coords.length; i<n; i++) {
      a = coords[i-1];
      b = coords[i];
      if (geom.distance2D(a[0], a[1], b[0], b[1]) > interval + 1e-4) {
        appendArr(coords2, interpolate(a, b));
      }
      coords2.push(b);
    }
    return coords2;
  }

  function getIntervalInterpolator(interval) {
    return function(a, b) {
      var points = [];
      // var rev = a[0] == b[0] ? a[1] > b[1] : a[0] > b[0];
      var dist = geom.distance2D(a[0], a[1], b[0], b[1]);
      var n = Math.round(dist / interval) - 1;
      var dx = (b[0] - a[0]) / (n + 1),
          dy = (b[1] - a[1]) / (n + 1);
      for (var i=1; i<=n; i++) {
        points.push([a[0] + dx * i, a[1] + dy * i]);
      }
      return points;
    };
  }


  // Interpolate the same points regardless of segment direction
  function densifyAntimeridianSegment(a, b, interval) {
    var y1, y2;
    var coords = [];
    var ascending = a[1] < b[1];
    if (a[0] != b[0]) error('Expected an edge segment');
    if (interval > 0 === false) error('Expected a positive interval');
    if (ascending) {
      y1 = a[1];
      y2 = b[1];
    } else {
      y1 = b[1];
      y2 = a[1];
    }
    var y = Math.floor(y1 / interval) * interval + interval;
    while (y < y2) {
      coords.push([a[0], y]);
      y += interval;
    }
    if (!ascending) coords.reverse();
    return coords;
  }

  function appendArr(dest, src) {
    for (var i=0; i<src.length; i++) dest.push(src[i]);
  }

  function findMaxPathInterval(coords) {
    var maxSq = 0, intSq, a, b;
    for (var i=1, n=coords.length; i<n; i++) {
      a = coords[i-1];
      b = coords[i];
      intSq = geom.distanceSq(a[0], a[1], b[0], b[1]);
      if (intSq > maxSq) maxSq = intSq;
    }
    return Math.sqrt(maxSq);
  }

  function projectAndDensifyArcs(arcs, proj) {
    var interval = getDefaultDensifyInterval(arcs, proj);
    var minIntervalSq = interval * interval * 25;
    var p;
    return editArcs(arcs, onPoint);

    function onPoint(append, lng, lat, prevLng, prevLat, i) {
      var pp = p;
      p = proj(lng, lat);
      if (!p) return false; // signal that current arc contains an error

      // Don't try to densify shorter segments (optimization)
      if (i > 0 && geom.distanceSq(p[0], p[1], pp[0], pp[1]) > minIntervalSq) {
        densifySegment(prevLng, prevLat,  pp[0],  pp[1], lng, lat, p[0], p[1], proj, interval)
          .forEach(append);
      }
      append(p);
    }
  }

  // Use the median of intervals computed by projecting segments.
  // We're probing a number of points, because @proj might only be valid in
  // a sub-region of the dataset bbox (e.g. +proj=tpers)
  function findDensifyInterval(bounds, xy, proj) {
    var steps = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9];
    var points = [];
    for (var i=0; i<steps.length; i++) {
      for (var j=0; j<steps.length; j++) {
        points.push([steps[i], steps[j]]);
      }
    }
    var intervals = points.map(function(pos) {
      var x = bounds.xmin + bounds.width() * pos[0];
      var y = bounds.ymin + bounds.height() * pos[1];
      var a = proj(x, y);
      var b = proj(x + xy[0], y + xy[1]);
      return a && b ? geom.distance2D(a[0], a[1], b[0], b[1]) : Infinity;
    }).filter(function(int) {return int < Infinity;});
    return intervals.length > 0 ? utils.findMedian(intervals) : Infinity;
  }

  // Kludgy way to get a useful interval for densifying a bounding box.
  // Uses a fraction of average bbox side length)
  // TODO: improve
  function findDensifyInterval2(bb, proj) {
    var a = proj(bb.centerX(), bb.centerY()),
        c = proj(bb.centerX(), bb.ymin), // right center
        d = proj(bb.xmax, bb.centerY()); // bottom center
    var interval = a && c && d ? (geom.distance2D(a[0], a[1], c[0], c[1]) +
          geom.distance2D(a[0], a[1], d[0], d[1])) / 5000 : Infinity;
    return interval;
  }

  // Returns an interval in projected units
  function getDefaultDensifyInterval(arcs, proj) {
    var xy = getAvgSegment2(arcs),
        bb = arcs.getBounds(),
        intervalA = findDensifyInterval(bb, xy, proj),
        intervalB = findDensifyInterval2(bb, proj),
        interval = Math.min(intervalA, intervalB);
    if (interval == Infinity) {
      error('Densification error');
    }
    return interval;
  }

  // Interpolate points into a projected line segment if needed to prevent large
  //   deviations from path of original unprojected segment.
  // @points (optional) array of accumulated points
  function densifySegment(lng0, lat0, x0, y0, lng2, lat2, x2, y2, proj, interval, points) {
    // Find midpoint between two endpoints and project it (assumes longitude does
    // not wrap). TODO Consider bisecting along great circle path -- although this
    // would not be good for boundaries that follow line of constant latitude.
    var lng1 = (lng0 + lng2) / 2,
        lat1 = (lat0 + lat2) / 2,
        p = proj(lng1, lat1),
        distSq;
    if (!p) return; // TODO: consider if this is adequate for handling proj. errors
    distSq = geom.pointSegDistSq2(p[0], p[1], x0, y0, x2, y2); // sq displacement
    points = points || [];
    // Bisect current segment if the projected midpoint deviates from original
    //   segment by more than the @interval parameter.
    //   ... but don't bisect very small segments to prevent infinite recursion
    //   (e.g. if projection function is discontinuous)
    if (distSq > interval * interval * 0.25 && geom.distance2D(lng0, lat0, lng2, lat2) > 0.01) {
      densifySegment(lng0, lat0, x0, y0, lng1, lat1, p[0], p[1], proj, interval, points);
      points.push(p);
      densifySegment(lng1, lat1, p[0], p[1], lng2, lat2, x2, y2, proj, interval, points);
    }
    return points;
  }

  // Create rectangles around each feature in a layer
  cmd.rectangles = function(targetLyr, targetDataset, opts) {
    var crsInfo = getDatasetCrsInfo(targetDataset);
    var records = targetLyr.data ? targetLyr.data.getRecords() : null;
    var geometries;

    if (opts.bbox) {
      geometries = bboxExpressionToGeometries(opts.bbox, targetLyr, targetDataset);

    } else {
      if (!layerHasGeometry(targetLyr)) {
        stop("Layer is missing geometric shapes");
      }
      geometries = shapesToBoxGeometries(targetLyr, targetDataset, opts);
    }

    var geojson = {
      type: 'FeatureCollection',
      features: geometries.map(function(geom, i) {
        var rec = records && records[i] || null;
        if (rec && opts.no_replace) {
          rec = utils.extend({}, rec); // make a copy
        }
        return {
          type: 'Feature',
          properties: rec,
          geometry: geom
        };
      })
    };
    var dataset = importGeoJSON(geojson, {});
    setDatasetCrsInfo(dataset, crsInfo);
    var outputLayers = mergeDatasetsIntoDataset(targetDataset, [dataset]);
    setOutputLayerName(outputLayers[0], targetLyr, null, opts);
    return outputLayers;
  };




  function shapesToBoxGeometries(lyr, dataset, opts) {
    var crsInfo = getDatasetCrsInfo(dataset);
    return lyr.shapes.map(function(shp) {
      var bounds = lyr.geometry_type == 'point' ?
        getPointFeatureBounds(shp) : dataset.arcs.getMultiShapeBounds(shp);
      bounds = applyRectangleOptions(bounds, crsInfo.crs, opts);
      if (!bounds) return null;
      return bboxToPolygon(bounds.toArray(), opts);
    });
  }

  function bboxExpressionToGeometries(exp, lyr, dataset, opts) {
    var compiled = compileFeatureExpression(exp, lyr, dataset.arcs, {});
    var n = getFeatureCount(lyr);
    var result;
    var geometries = [];
    for (var i=0; i<n; i++) {
      result = compiled(i);
      if (!looksLikeBbox(result)) {
        stop('Invalid bbox value (expected a GeoJSON-type bbox):', result);
      }
      geometries.push(bboxToPolygon(result));
    }
    return geometries;
  }

  function looksLikeBbox(o) {
    if (!o || o.length != 4) return false;
    if (o.some(isNaN)) return false;
    if (o[0] <= o[2] == false || o[1] <= o[3] == false) return false;
    return true;
  }

  // Create rectangles around one or more target layers
  //
  cmd.rectangle2 = function(target, opts) {
    // if target layer is a rectangle and we're applying frame properties,
    // turn the target into a frame instead of creating a new rectangle
    if (target.layers.length == 1 && opts.width &&
      layerIsRectangle(target.layers[0], target.dataset.arcs)) {
      applyFrameProperties(target.layers[0], opts);
      return;
    }
    var datasets = target.layers.map(function(lyr) {
      var dataset = cmd.rectangle({layer: lyr, dataset: target.dataset}, opts);
      setOutputLayerName(dataset.layers[0], lyr, null, opts);
      if (!opts.no_replace) {
        dataset.layers[0].name = lyr.name || dataset.layers[0].name;
      }
      return dataset;
    });
    return mergeDatasetsIntoDataset(target.dataset, datasets);
  };

  cmd.rectangle = function(target, opts) {
    var bounds, crsInfo;
    if (opts.bbox) {
      bounds = new Bounds(opts.bbox);
      crsInfo = target && getDatasetCrsInfo(target.dataset) ||
        probablyDecimalDegreeBounds(bounds) && getCrsInfo('wgs84') || {};
    } else if (target) {
      bounds = getLayerBounds(target.layer, target.dataset.arcs);
      crsInfo = getDatasetCrsInfo(target.dataset);
    }
    bounds = bounds && applyRectangleOptions(bounds, crsInfo.crs, opts);
    if (!bounds || !bounds.hasBounds()) {
      stop('Missing rectangle extent');
    }
    var feature = {
      type: 'Feature',
      properties: {},
      geometry: bboxToPolygon(bounds.toArray(), opts)
    };
    var dataset = importGeoJSON(feature, {});
    applyFrameProperties(dataset.layers[0], opts);
    dataset.layers[0].name = opts.name || 'rectangle';
    setDatasetCrsInfo(dataset, crsInfo);
    return dataset;
  };

  function applyFrameProperties(lyr, opts) {
    if (!opts.width) return;
    if (!lyr.data) initDataTable(lyr);
    var d = lyr.data.getRecords()[0] || {};
    d.width = parseSizeParam(opts.width);
    d.type = 'frame';
  }

  function applyRectangleOptions(bounds, crs, opts) {
    var isGeoBox = probablyDecimalDegreeBounds(bounds);
    if (opts.offset) {
      bounds = applyBoundsOffset(opts.offset, bounds, crs);
    }
    if (bounds.area() > 0 === false) return null;
    if (opts.aspect_ratio) {
      bounds = applyAspectRatio(opts.aspect_ratio, bounds);
    }
    if (isGeoBox) {
      bounds = clampToWorldBounds(bounds);
    }
    return bounds;
  }

  // opt: aspect ratio as a single number or a range (e.g. "1,2");
  function applyAspectRatio(opt, bounds) {
    var range = String(opt).split(',').map(parseFloat),
      aspectRatio = bounds.width() / bounds.height(),
      min, max; // min is height limit, max is width limit
    if (range.length == 1) {
      range.push(range[0]);
    } else if (range[0] > range[1]) {
      range.reverse();
    }
    min = range[0];
    max = range[1];
    if (!min && !max) return bounds;
    if (!min) min = -Infinity;
    if (!max) max = Infinity;
    if (aspectRatio < min) {
      bounds.fillOut(min);
    } else if (aspectRatio > max) {
      bounds.fillOut(max);
    }
    return bounds;
  }

  function applyBoundsOffset(offsetOpt, bounds, crs) {
    var offsets = convertFourSides(offsetOpt, crs, bounds);
    bounds.padBounds(offsets[0], offsets[1], offsets[2], offsets[3]);
    return bounds;
  }

  function bboxToPolygon(bbox, optsArg) {
    var opts = optsArg || {};
    var coords = bboxToCoords(bbox);
    if (opts.interval > 0) {
      coords = densifyPathByInterval(coords, opts.interval);
    }
    return {
      type: 'Polygon',
      coordinates: [coords]
    };
  }

  var Rectangle = /*#__PURE__*/Object.freeze({
    __proto__: null,
    applyAspectRatio: applyAspectRatio,
    bboxToPolygon: bboxToPolygon
  });

  cmd.frame = function(catalog, targets, opts) {
    var widthPx, heightPx, aspectRatio, bbox;
    if (opts.width) {
      widthPx = parseSizeParam(opts.width);
      if (widthPx > 0 === false) {
        stop('Invalid width parameter:', opts.width);
      }
    }
    if (opts.height) {
      heightPx = parseSizeParam(opts.height);
      if (heightPx > 0 === false) {
        stop('Invalid height parameter:', opts.height);
      }
    }
    if (!widthPx && !heightPx) {
      widthPx = 800;
      message('Using default 800px frame width');
    }

    if (opts.aspect_ratio) {
      if (opts.aspect_ratio > 0 === false) {
        stop('Invalid aspect-ratio parameter:', opts.aspect_ratio);
      }
      if (!heightPx) {
        heightPx = roundToDigits(widthPx / opts.aspect_ratio, 1);
      } else if (!widthPx) {
        widthPx = roundToDigits(heightPx * opts.aspect_ratio, 1);
      }
    }

    if (opts.bbox) {
      bbox = opts.bbox;
      // TODO: validate
    } else {
      var datasets = utils.pluck(targets, 'dataset');
      requireDatasetsHaveCompatibleCRS(datasets, 'Targets include both projected and unprojected coordinates');
      bbox = getTargetBbox(targets);
      if (!bbox) {
        stop('Command target is missing geographical bounds');
      }
    }

    applyPercentageOffsets(bbox, opts.offset || opts.offsets);
    applyPixelOffsets(bbox, widthPx, heightPx, opts.offset || opts.offsets);

    if (bbox[3] - bbox[1] > 0 === false || bbox[2] - bbox[0] > 0 === false) {
      stop('Frame has a collapsed bbox');
    }

    aspectRatio = (bbox[2] - bbox[0]) / (bbox[3] - bbox[1]);
    if (!widthPx) {
      widthPx = roundToDigits(heightPx * aspectRatio, 1);
    } else if (!heightPx) {
      heightPx = roundToDigits(widthPx / aspectRatio, 1);
    }

    var feature = {
      type: 'Feature',
      properties: {type: 'frame', width: widthPx, height: heightPx},
      geometry: bboxToPolygon(bbox)
    };
    var frameDataset = importGeoJSON(feature);
    // set CRS from target dataset
    // TODO: handle case: targets have different projections
    // TODO: handle case: first target is missing CRS
    if (targets.length > 0) {
      var crsInfo = getDatasetCrsInfo(targets[0].dataset);
      setDatasetCrsInfo(frameDataset, crsInfo);
    }
    frameDataset.layers[0].name = opts.name || 'frame';
    catalog.addDataset(frameDataset);
  };

  function fillOutBbox(bbox, widthPx, heightPx) {
    var hpad = 0, vpad = 0;
    var w = bbox[2] - bbox[0];
    var h = bbox[3] - bbox[1];
    if (widthPx / heightPx > w / h) { // need to add horizontal padding
      hpad = h * widthPx / heightPx - w;
    } else {
      vpad = w * heightPx / widthPx - h;
    }
    bbox[0] -= hpad / 2;
    bbox[1] -= vpad / 2;
    bbox[2] += hpad / 2;
    bbox[3] += vpad / 2;
  }

  function applyPercentageOffsets(bbox, arg) {
    var sides = getPctOffsets(arg);
    var l = sides[0],
      b = sides[1],
      r = sides[2],
      t = sides[3],
      w2 = (bbox[2] - bbox[0]) / (1 - l - r),
      h2 = (bbox[3] - bbox[1]) / (1 - t - b);
    bbox[0] -= l * w2;
    bbox[1] -= b * h2;
    bbox[2] += r * w2;
    bbox[3] += t * h2;
  }

  function applyPixelOffsets(bbox, widthPx, heightPx, arg) {
    var sides = getPixelOffsets(arg);
    var l = sides[0],
      b = sides[1],
      r = sides[2],
      t = sides[3],
      scale, w;

    if (widthPx && heightPx) {
      // add padding to bbox to match pixel dimensions, if needed
      fillOutBbox(bbox, widthPx, heightPx);
    }

    w = bbox[2] - bbox[0];
    bbox[3] - bbox[1];

    if (widthPx) {
      scale = w / (widthPx - l - r);
    } else {
      scale = w / (heightPx - t - b);
    }

    bbox[0] -= scale * l;
    bbox[1] -= scale * b;
    bbox[2] += scale * r;
    bbox[3] += scale * t;
    return scale;
  }

  function getPctOffsets(arg) {
    return adjustOffsetsArg(arg).map(str => {
      return str.includes('%') ? utils.parsePercent(str) : 0;
    });
  }

  function getPixelOffsets(arg) {
    return adjustOffsetsArg(arg).map(str => {
      return str.includes('%') ? 0 : parseSizeParam(str);
    });
  }

  function adjustOffsetsArg(arg) {
    if (!arg) arg = ['0'];
    if (arg.length == 1) {
      return [arg[0], arg[0], arg[0], arg[0]];
    }
    if (arg.length != 4) {
      stop('List of offsets should have 4 values');
    }
    return arg;
  }

  function getTargetBbox(targets) {
    var expanded = expandCommandTargets(targets);
    var bounds = expanded.reduce(function(memo, o) {
      return memo.mergeBounds(getLayerBounds(o.layer, o.dataset.arcs));
    }, new Bounds());
    return bounds.hasBounds() ? bounds.toArray() : null;
  }

  // Convert width and height args to aspect ratio arg for the rectangle() function
  function getAspectRatioArg(widthArg, heightArg) {
    // heightArg is a string containing either a number or a
    // comma-sep. pair of numbers (range);
    return heightArg.split(',').map(function(opt) {
      var height = Number(opt),
          width = Number(widthArg);
      if (!opt) return '';
      return width / height;
    }).reverse().join(',');
  }

  var Frame = /*#__PURE__*/Object.freeze({
    __proto__: null,
    getAspectRatioArg: getAspectRatioArg
  });

  cmd.filterIslands = function(lyr, dataset, optsArg) {
    var opts = utils.extend({sliver_control: 0}, optsArg); // no sliver control
    var arcs = dataset.arcs;
    var removed = 0;
    var filter;
    if (lyr.geometry_type != 'polygon') {
      return;
    }
    if (!opts.min_area && !opts.min_vertices) {
      message("Missing a criterion for filtering islands; use min-area or min-vertices");
      return;
    }

    if (opts.min_area) {
      filter = getSliverFilter(lyr, dataset, opts).filter;
    } else {
      filter = getVertexCountTest(opts.min_vertices, arcs);
    }
    removed += filterIslands(lyr, arcs, filter);
    if (opts.remove_empty) {
      cmd.filterFeatures(lyr, arcs, {remove_empty: true, verbose: false});
    }
    message(utils.format("Removed %'d island%s", removed, utils.pluralSuffix(removed)));
  };

  function getVertexCountTest(minVertices, arcs) {
    return function(path) {
      // first and last vertex in ring count as one
      return geom.countVerticesInPath(path, arcs) <= minVertices;
    };
  }

  function filterIslands(lyr, arcs, ringTest) {
    var removed = 0;
    var counts = new Uint8Array(arcs.size());
    countArcsInShapes(lyr.shapes, counts);

    var pathFilter = function(path, i, paths) {
      if (path.length == 1) { // got an island ring
        if (counts[absArcId(path[0])] === 1) { // and not part of a donut hole
          if (!ringTest || ringTest(path)) { // and it meets any filtering criteria
            // and it does not contain any holes itself
            // O(n^2), so testing this last
            if (!ringHasHoles(path, paths, arcs)) {
              removed++;
              return null;
            }
          }
        }
      }
    };
    editShapes(lyr.shapes, pathFilter);
    return removed;
  }

  function ringIntersectsBBox(ring, bbox, arcs) {
    for (var i=0, n=ring.length; i<n; i++) {
      if (arcs.arcIntersectsBBox(absArcId(ring[i]), bbox)) {
        return true;
      }
    }
    return false;
  }

  // Assumes that ring boundaries to not cross
  function ringHasHoles(ring, rings, arcs) {
    var bbox = arcs.getSimpleShapeBbox(ring);
    var sibling, p;
    for (var i=0, n=rings.length; i<n; i++) {
      sibling = rings[i];
      // try to avoid expensive point-in-ring test
      if (sibling && sibling != ring && ringIntersectsBBox(sibling, bbox, arcs)) {
        p = arcs.getVertex(sibling[0], 0);
        if (geom.testPointInRing(p.x, p.y, ring, arcs)) {
          return true;
        }
      }
    }
    return false;
  }

  cmd.filterIslands2 = function(lyr, dataset, optsArg) {
    var opts = utils.extend({sliver_control: 0}, optsArg); // no sliver control
    var arcs = dataset.arcs;
    var removed = 0;
    var filter;
    if (lyr.geometry_type != 'polygon') {
      return;
    }
    if (!opts.min_area && !opts.min_vertices) {
      message("Missing a criterion for filtering islands; use min-area or min-vertices");
      return;
    }

    if (opts.min_area) {
      filter = getSliverFilter(lyr, dataset, opts).filter;
    } else {
      filter = getVertexCountTest(opts.min_vertices, arcs);
    }
    removed += filterIslands2(lyr, arcs, filter);
    if (opts.remove_empty) {
      cmd.filterFeatures(lyr, arcs, {remove_empty: true, verbose: false});
    }
    message(utils.format("Removed %'d island%s", removed, utils.pluralSuffix(removed)));
  };


  function filterIslands2(lyr, arcs, ringTest) {
    var removed = 0;
    var counts = new Uint8Array(arcs.size());
    countArcsInShapes(lyr.shapes, counts);

    var pathFilter = function(path, i, paths) {
      if (path.length == 1) { // got an island ring
        if (counts[absArcId(path[0])] === 1) { // and not part of a donut hole
          if (!ringTest || ringTest(path)) { // and it meets any filtering criteria
            // and it does not contain any holes itself
            // O(n^2), so testing this last
            if (!ringHasHoles(path, paths, arcs)) {
              removed++;
              return null;
            }
          }
        }
      }
    };
    editShapes(lyr.shapes, pathFilter);
    return removed;
  }

  cmd.filterFields = function(lyr, names, opts) {
    var table = lyr.data;
    names = names || [];
    requireDataFields(table, names);
    if (!table) return;
    // old method: does not set field order e.g. in CSV output files
    // utils.difference(table.getFields(), names).forEach(table.deleteField, table);
    // the below method sets field order of CSV output, and is generally faster
    var map = mapFieldNames(names);
    if (opts.invert) {
      map = invertFieldMap(map, table.getFields());
    }
    lyr.data.update(getRecordMapper(map));
  };

  cmd.renameFields = function(lyr, names) {
    var map = mapFieldNames(names);
    requireDataFields(lyr.data, Object.keys(map));
    utils.defaults(map, mapFieldNames(lyr.data.getFields()));
    lyr.data.update(getRecordMapper(map));
  };

  function invertFieldMap(map, fields) {
    return fields.reduce(function(memo, name) {
      if (!(name in map)) {
        memo[name] = name;
      }
      return memo;
    }, {});
  }

  function mapFieldNames(names) {
    return (names || []).reduce(function(memo, str) {
      var parts = str.split('='),
          dest = utils.trimQuotes(parts[0]),
          src = parts.length > 1 ? utils.trimQuotes(parts[1]) : dest;
      if (!src || !dest) stop("Invalid name assignment:", str);
      memo[src] = dest;
      return memo;
    }, {});
  }

  function getRecordMapper(map) {
    var fields = Object.keys(map);
    return function(src) {
      var dest = {}, key;
      for (var i=0, n=fields.length; i<n; i++) {
        key = fields[i];
        dest[map[key]] = src[key];
      }
      return dest;
    };
  }

  // internal.getRecordMapper = function(map) {
  //   var fields = Object.keys(map);
  //   return new Function("rec", "return {" + fields.map(function(name, i) {
  //     var key = JSON.stringify(name);
  //     return key + ": rec[" + key + "]";
  //   }).join(",") + "}");
  // };

  // Removes points that are far from other points
  cmd.filterPoints = function(lyr, dataset, opts) {
    requireSinglePointLayer(lyr);
    if (opts.group_interval > 0 === false) {
      stop('Expected a positive group_interval parameter');
    }

    // TODO: remove duplication with mapshaper-alpha-shapes.js
    var alphaFilter = getAlphaDistanceFilter(dataset, opts.group_interval);
    var points = getPointsInLayer(lyr);
    var del = Delaunator.from(points);
    var triangles = del.triangles;
    var index = new Uint8Array(points.length);
    var a, b, c, ai, bi, ci;
    for (var i=0, n=triangles.length; i<n; i+=3) {
      // a, b, c: triangle vertices in CCW order
      ai = triangles[i];
      bi = triangles[i+1];
      ci = triangles[i+2];
      a = points[ai];
      b = points[bi];
      c = points[ci];
      if (alphaFilter(a, b) && alphaFilter(b, c) && alphaFilter(a, c)) {
        index[ai] = 1;
        index[bi] = 1;
        index[ci] = 1;
      }
    }
    filterLayerInPlace(lyr, function(shpId) {
      return index[shpId] == 1;
    });
  };

  function joinPointsToPolygons(targetLyr, arcs, pointLyr, opts) {
    // TODO: option to copy points that can't be joined to a new layer
    var joinFunction = getPolygonToPointsFunction(targetLyr, arcs, pointLyr, opts);
    prepJoinLayers(targetLyr, pointLyr);
    return joinTableToLayer(targetLyr, pointLyr.data, joinFunction, opts);
  }

  function joinPolygonsToPoints(targetLyr, polygonLyr, arcs, opts) {
    var joinFunction = getPointToPolygonsFunction(targetLyr, polygonLyr, arcs);
    prepJoinLayers(targetLyr, polygonLyr);
    return joinTableToLayer(targetLyr, polygonLyr.data, joinFunction, opts);
  }

  function prepJoinLayers(targetLyr, srcLyr) {
    if (!targetLyr.data) {
      // create an empty data table if target layer is missing attributes
      targetLyr.data = new DataTable(targetLyr.shapes.length);
    }
    if (!srcLyr.data) {
      stop("Can't join a layer that is missing attribute data");
    }
  }

  function getPolygonToPointsFunction(polygonLyr, arcs, pointLyr, opts) {
    // Build a reverse lookup table for mapping polygon ids to point ids.
    var joinFunction = getPointToPolygonsFunction(pointLyr, polygonLyr, arcs);
    var index = [];
    var firstMatch = !!opts.first_match; // a point is assigned to the first matching polygon
    pointLyr.shapes.forEach(function(shp, pointId) {
      var polygonIds = joinFunction(pointId);
      var n = polygonIds ? polygonIds.length : 0;
      var polygonId;
      for (var i=0; i<n; i++) {
        polygonId = polygonIds[i];
        if (polygonId in index) {
          index[polygonId].push(pointId);
        } else {
          index[polygonId] = [pointId];
        }
        if (firstMatch) break;
      }
    });

    return function(polygonId) {
      return index[polygonId] || null;
    };
  }


  // Returned function gets ids of all polygons that intersect a point (or the first
  //   point of multipoint features). TODO: handle multipoint features properly.
  function getPointToPolygonsFunction(pointLyr, polygonLyr, arcs, opts) {
    var index = new PathIndex(polygonLyr.shapes, arcs),
        points = pointLyr.shapes;

    return function(pointId) {
      var shp = points[pointId],
          polygonIds = shp ? index.findEnclosingShapes(shp[0]) : [];
      return polygonIds.length > 0 ? polygonIds : null;
    };
  }

  var PointPolygonJoin = /*#__PURE__*/Object.freeze({
    __proto__: null,
    joinPointsToPolygons: joinPointsToPolygons,
    joinPolygonsToPoints: joinPolygonsToPoints,
    prepJoinLayers: prepJoinLayers,
    getPolygonToPointsFunction: getPolygonToPointsFunction
  });

  // This is a special-purpose function designed to copy a data field from a points
  // layer to a target polygon layer using a spatial join. It tries to create a continuous
  // mosaic of data values, even if some of the polygons are not intersected by points.
  // It is "fuzzy" because it treats locations in the points file as potentially unreliable.
  //
  // A typical use case is joining geocoded address data containing a neighborhood
  // or precinct field to a Census Block file, in preparation to dissolving the
  // blocks into larger polygons.
  //
  cmd.fuzzyJoin = function(polygonLyr, arcs, src, opts) {
    var pointLyr = src ? src.layer : null;
    if (!pointLyr || !layerHasPoints(pointLyr)) {
      stop('Missing a point layer to join from');
    }
    requireDataField(pointLyr, opts.field);
    requirePolygonLayer(polygonLyr);
    if (opts.dedup_points) {
      cmd.uniq(pointLyr, null, {expression: 'this.x + "~" + this.y + "~" + this.properties[' + JSON.stringify(opts.field) + ']', verbose: false});
    }
    fuzzyJoin(polygonLyr, arcs, pointLyr, opts);
  };

  function fuzzyJoin(polygonLyr, arcs, pointLyr, opts) {
    var field = opts.field;
    // using first_match param: don't let a point be assigned to multiple polygons
    var getPointIds = getPolygonToPointsFunction(polygonLyr, arcs, pointLyr, {first_match: true});
    var getFieldValues = getFieldValuesFunction(pointLyr, field);
    var assignedValues = [];
    var countData = [];
    var modeCounts = [];

    // Step one: assign join values to mode value; resolve ties
    polygonLyr.shapes.forEach(function(shp, i) {
      var pointIds = getPointIds(i) || [];
      var values = getFieldValues(pointIds);
      var modeData = getModeData(values, true);
      var modeValue = modeData.margin > 0 ? modeData.modes[0] : null;
      var isTie = modeValue === null && modeData.modes.length > 1;
      if (isTie) {
        // resolve ties by picking between the candidate data values
        // todo: consider using this method to evaluate near-ties as well
        modeValue = resolveFuzzyJoinTie(modeData.modes, pointLyr, pointIds, field, shp, arcs);
      }
      modeCounts[i] = modeData.count || 0;
      // retain count/mode data, to use later for restoring dropouts
      if (opts.no_dropouts) {
        countData.push(modeData);
      }
      assignedValues.push(modeValue);
    });

    insertFieldValues(polygonLyr, 'join-count', modeCounts);
    insertFieldValues(polygonLyr, field, assignedValues);

    // fill in missing values, etc. using the data-fill function
    cmd.dataFill(polygonLyr, arcs,
      {field: field, weight_field: 'join-count', contiguous: opts.contiguous});

    // restore dropouts
    if (opts.no_dropouts) {
      var missingValues = findDropoutValues(polygonLyr, pointLyr, field);
      if (missingValues.length > 0) {
        restoreDropoutValues(polygonLyr, field, missingValues, countData);
      }
    }

  }

  // Returns a function for converting an array of feature ids to an array of values from a given data field.
  function getFieldValuesFunction(lyr, field) {
    var records = lyr.data.getRecords();
    return function getFieldValues(ids) {
      var values = [], rec;
      for (var i=0; i<ids.length; i++) {
        rec = records[ids[i]];
        values.push(rec[field]);
      }
      return values;
    };
  }

  function findDropoutValues(targetLyr, sourceLyr, field) {
    var sourceValues = getUniqFieldValues(sourceLyr.data.getRecords(), field);
    var targetValues = getUniqFieldValues(targetLyr.data.getRecords(), field);
    var missing = utils.difference(sourceValues, targetValues);
    return missing;
  }

  function restoreDropoutValues(lyr, field, missingValues, countData) {
    var records = lyr.data.getRecords();
    var failures = [];
    var restoredIds = [];

    missingValues.map(function(missingValue) {
      var shpId = findDropoutInsertionShape(missingValue, countData);
      if (shpId > -1 && restoredIds.indexOf(shpId) === -1) {
        records[shpId][field] = missingValue;
        restoredIds.push(shpId);
      } else {
        failures.push(missingValue);
      }
    });

    message('Restored', restoredIds.length, 'dropout value' + utils.pluralSuffix(restoredIds.length));

    // TODO: handle different kinds of failure differently:
    // a. values that point-to-polygon failed to match to a polygon
    // b. multiple dropout values are assigned to the same target polygon
    // c. restoring a dropout results in replacing the only instance of another value
    if (failures.length > 0) {
      message('Failed to restore dropout value(s):', failures.join(', '));
    }
  }

  function findDropoutInsertionShape(value, countData) {
    var id = -1;
    var count = 0;
    countData.forEach(function(d, shpId) {
      var i = d.values.indexOf(value);
      var n = i > -1 ? d.counts[i] : 0;
      if (n > count) {
        id = shpId;
        count = n;
      }
    });
    return id;
  }

  // TODO: move to more appropriate file
  function getPointsToPolygonDistance(points, poly, arcs) {
    // todo: handle multipoint geometry (this function will return an invalid distance
    // if the first point in a multipoint feature falls outside the target polygon
    var p = points[0];
    // unsigned distance to nearest polygon boundary
    return geom.getPointToShapeDistance(p[0], p[1], poly, arcs);
  }

  function resolveFuzzyJoinTie(modeValues, pointLyr, pointIds, field, shp, arcs) {
    var weights = modeValues.map(function() {return 0;}); // initialize to 0
    pointIds.forEach(function(pointId) {
      var coords = pointLyr.shapes[pointId];
      var val = pointLyr.data.getRecordAt(pointId)[field];
      var i = modeValues.indexOf(val);
      if (i === -1) return;
      var dist = getPointsToPolygonDistance(coords, shp, arcs);
      weights[i] += dist;
    });
    // use value with the highest weight
    var maxWeight = Math.max.apply(null, weights);
    var maxValue = modeValues[weights.indexOf(maxWeight)];
    return maxValue;
  }

  function getSemiMinorAxis(P) {
    return P.a * Math.sqrt(1 - (P.es || 0));
  }

  function getCircleRadiusFromAngle(P, angle) {
    // Using semi-minor axis radius, to prevent overflowing projection bounds
    // when clipping up to the edge of the projectable area
    // TODO: improve (this just gives a safe minimum distance, not the best distance)
    // TODO: modify point buffer function to use angle + ellipsoidal geometry
    return angle * Math.PI / 180 * getSemiMinorAxis(P);
  }

  function getCrsSlug(P) {
    return P.params.proj.param; // kludge
  }

  // 'normal' = the projection is aligned to the Earth's axis
  // (i.e. it has a normal aspect)
  function isRotatedNormalProjection(P) {
    return isAxisAligned(P) && P.lam0 !== 0;
  }

  // Projection is vertically aligned to earth's axis
  function isAxisAligned(P) {
    // TODO: consider projections that may or may not be aligned,
    // depending on parameters
    if (inList(P, 'cassini,gnom,bertin1953,chamb,ob_tran,tpeqd,healpix,rhealpix,' +
      'ocea,omerc,tmerc,etmerc,nicol')) {
      return false;
    }
    if (isAzimuthal(P)) {
      return false;
    }
    return true;
  }

  function getBoundingMeridian(P) {
    if (P.lam0 === 0) return 180;
    return getAntimeridian(P.lam0 * 180 / Math.PI);
  }

  // Are the projection's bounds meridians?
  function isMeridianBounded(P) {
    // TODO: add azimuthal projection with lat0 == 0
    // if (inList(P, 'ortho') && P.lam0 === 0) return true;
    return isAxisAligned(P); // TODO: look for exceptions to this
  }

  function isAzimuthal(P) {
    return inList(P,
      'aeqd,gnom,laea,mil_os,lee_os,gs48,alsk,gs50,nsper,tpers,ortho,qsc,stere,ups,sterea');
  }

  function inList(P, str) {
    return str.split(',').includes(getCrsSlug(P));
  }

  // based on d3 implementation of Euler-angle rotation
  // https://github.com/d3/d3-geo/blob/master/src/rotation.js
  // license: https://github.com/d3/d3-geo/blob/master/LICENSE

  function rotateDatasetCoords(dataset, rotation, inv) {
    var proj = getRotationFunction(rotation, inv);
    dataset.layers.filter(layerHasPoints).forEach(function(lyr) {
      projectPointLayer(lyr, proj);
    });
    if (dataset.arcs) {
      projectArcs(dataset.arcs, proj);
    }
  }

  function getRotationFunction(rotation, inv) {
    var f = getRotationFunction2(rotation, inv);
    return function(lng, lat) {
      return f([lng, lat]);
    };
  }

  function getRotationFunction2(rotation, inv) {
    var a = (rotation[0] || 0) * D2R,
        b = (rotation[1] || 0) * D2R,
        c = (rotation[2] || 0) * D2R;
    return function(p) {
      p[0] *= D2R;
      p[1] *= D2R;
      var rotate = inv ? rotatePointInv : rotatePoint;
      rotate(p, a, b, c);
      p[0] *= R2D;
      p[1] *= R2D;
      return p;
    };
  }

  function rotatePoint(p, deltaLam, deltaPhi, deltaGam) {
    if (deltaLam != 0) rotateLambda(p, deltaLam);
    if (deltaPhi !== 0 || deltaGam !== 0) {
      rotatePhiGamma(p, deltaPhi, deltaGam, false);
    }
    return p;
  }

  function rotatePointInv(p, deltaLam, deltaPhi, deltaGam) {
    if (deltaPhi !== 0 || deltaGam !== 0) {
      rotatePhiGamma(p, deltaPhi, deltaGam, true);
    }
    if (deltaLam != 0) rotateLambda(p, -deltaLam);
    return p;
  }

  function rotateLambda(p, deltaLam) {
    var lam = p[0] + deltaLam;
    if (lam > Math.PI) lam -= 2 * Math.PI;
    else if (lam < -Math.PI) lam += 2 * Math.PI;
    p[0] = lam;
  }

  function rotatePhiGamma(p, deltaPhi, deltaGam, inv) {
    var cosDeltaPhi = Math.cos(deltaPhi),
        sinDeltaPhi = Math.sin(deltaPhi),
        cosDeltaGam = Math.cos(deltaGam),
        sinDeltaGam = Math.sin(deltaGam),
        cosPhi = Math.cos(p[1]),
        x = Math.cos(p[0]) * cosPhi,
        y = Math.sin(p[0]) * cosPhi,
        z = Math.sin(p[1]),
        k;
    if (inv) {
      k = z * cosDeltaGam - y * sinDeltaGam;
      p[0] = Math.atan2(y * cosDeltaGam + z * sinDeltaGam, x * cosDeltaPhi + k * sinDeltaPhi);
      p[1] = Math.asin(k * cosDeltaPhi - x * sinDeltaPhi);
    } else {
      k = z * cosDeltaPhi + x * sinDeltaPhi;
      p[0] = Math.atan2(y * cosDeltaGam - k * sinDeltaGam, x * cosDeltaPhi - z * sinDeltaPhi);
      p[1] = Math.asin(k * cosDeltaGam + y * sinDeltaGam);
    }
  }

  cmd.rotate = rotateDataset;

  function rotateDataset(dataset, opts) {
    if (!isLatLngCRS(getDatasetCRS(dataset))) {
      stop('Command requires a lat-long dataset.');
    }
    if (!Array.isArray(opts.rotation) || !opts.rotation.length) {
      stop('Invalid rotation parameter');
    }
    var rotatePoint = getRotationFunction2(opts.rotation, opts.invert);
    var editor = new DatasetEditor(dataset);
    if (dataset.arcs) {
      dataset.arcs.flatten();
    }

    dataset.layers.forEach(function(lyr) {
      var type = lyr.geometry_type;
      editor.editLayer(lyr, getGeometryRotator(type, rotatePoint, opts));
    });
    editor.done();
    if (!opts.debug) {
      buildTopology(dataset);
      cleanProjectedPathLayers(dataset);
    }
  }

  function getGeometryRotator(layerType, rotatePoint, opts) {
    var rings;
    if (layerType == 'point') {
      return function(coords) {
        coords.forEach(rotatePoint);
        return coords;
      };
    }
    if (layerType == 'polyline') {
      return function(coords) {
        coords = densifyPathByInterval(coords, 0.5);
        coords.forEach(rotatePoint);
        return removePolylineCrosses(coords);
      };
    }
    if (layerType == 'polygon') {
      return function(coords, i, shape) {
        if (isWholeWorld(coords)) {
          coords = densifyPathByInterval(coords, 0.5);
        } else {
          coords.forEach(snapToEdge);
          coords = removeCutSegments(coords);
          coords = densifyPathByInterval(coords, 0.5, getInterpolator(0.5));
          coords.forEach(rotatePoint);
          // coords.forEach(snapToEdge);
        }
        if (i === 0) { // first part
          rings = [];
        }
        if (coords.length < 4) {
          debug('Short ring', coords);
          return;
        }
        if (!samePoint(coords[0], lastEl(coords))) {
          error('Open polygon ring');
        }
        rings.push(coords); // accumulate rings
        if (i == shape.length - 1) { // last part
          return opts.debug ? rings : removePolygonCrosses(rings);
        }
      };
    }
    return null; // assume layer has no geometry -- callback should not be called
  }

  function getInterpolator(interval) {
    var interpolate = getIntervalInterpolator(interval);
    return function(a, b) {
      var points;
      if (onPole(a) || onPole(b)) {
        points = [];
      } else if (isEdgeSegment(a, b)) {
        points = densifyAntimeridianSegment(a, b, interval);
      } else if (segmentCrossesAntimeridian(a, b)) {
        // TODO: interpolate up to antimeridian?
        points = [];
      } else {
        points = interpolate(a, b);
      }
      return points;
    };
  }

  cmd.lines = function(lyr, dataset, opts) {
    opts = opts || {};
    if (opts.callouts) {
      requirePointLayer(lyr);
      return pointsToCallouts(lyr, dataset, opts);
    } else if (lyr.geometry_type == 'point') {
      return pointsToLines(lyr, dataset, opts);
    } else if (opts.segments) {
      return [convertShapesToSegments(lyr, dataset)];
    } else if (opts.arcs) {
      return [convertShapesToArcs(lyr, dataset)];
    } else if (lyr.geometry_type == 'polygon') {
      return polygonsToLines(lyr, dataset.arcs, opts);
    } else {
      requirePolygonLayer(lyr, "Command requires a polygon or point layer");
    }
  };

  function convertShapesToArcs(lyr, dataset) {
    var arcs = dataset.arcs;
    var test = getArcPresenceTest(lyr.shapes, arcs);
    var records = [];
    var shapes = [];
    for (var i=0, n=arcs.size(); i<n; i++) {
      if (!test(i)) continue;
      records.push({arcid: i});
      shapes.push([[i]]);
    }
    return {
      geometry_type: 'polyline',
      data: new DataTable(records),
      shapes: shapes
    };
  }

  function convertShapesToSegments(lyr, dataset) {
    var arcs = dataset.arcs;
    var geojson = {type: 'FeatureCollection', features: []};
    var test = getArcPresenceTest(lyr.shapes, arcs);
    var arcId;
    for (var i=0, n=arcs.size(); i<n; i++) {
      arcId = i;
      if (!test(arcId)) continue;
      arcs.forEachArcSegment(arcId, onSeg);
    }
    function onSeg(i1, i2, xx, yy) {
      var a = xx[i1],
          b = yy[i1],
          c = xx[i2],
          d = yy[i2];
      geojson.features.push({
        type: 'Feature',
        properties: {arc: arcId, i1: i1, i2: i2, x1: a, y1: b, x2: c, y2: d},
        geometry: {type: 'LineString', coordinates: [[a, b], [c, d]]}
      });
    }
    var merged = mergeDatasets([dataset, importGeoJSON(geojson, {})]);
    dataset.arcs = merged.arcs;
    // buildTopology(dataset);
    return merged.layers.pop();
  }

  function pointsToLines(lyr, dataset, opts) {
    var geojson = opts.groupby ?
      groupedPointsToLineGeoJSON(lyr, opts.groupby, opts) :
      pointShapesToLineGeometry(lyr.shapes); // no grouping: return single line with no attributes
    var dataset2 = importGeoJSON(geojson);
    var outputLayers = mergeDatasetsIntoDataset(dataset, [dataset2]);
    // if (!opts.no_replace) {
    //   outputLayers[0].name = lyr.name || outputLayers[0].name;
    // }
    setOutputLayerName(outputLayers[0], lyr, null, opts);
    return outputLayers;
  }

  function pointsToCallouts(lyr, dataset, opts) {
    var records = lyr.data ? lyr.data.getRecords() : null;
    var calloutLen = getLayerBounds(lyr).width() / 50;
    var pointToSegment = function(p) {
      return [p, [p[0] + calloutLen, p[1]]];
    };
    var geojson = {
      type: 'FeatureCollection',
      features: lyr.shapes.map(function(shp, i) {
        return {
          type: 'Feature',
          properties: records ? records[i] : null,
          geometry: {
            type: 'MultiLineString',
            coordinates: shp.map(pointToSegment)
          }
        };
      })
    };
    var dataset2 = importGeoJSON(geojson);
    var outputLayers = mergeDatasetsIntoDataset(dataset, [dataset2]);
    setOutputLayerName(outputLayers[0], lyr.name, null, opts);
    return outputLayers;
  }

  function groupedPointsToLineGeoJSON(lyr, field, opts) {
    var groups = [];
    var getGroupId = getCategoryClassifier([field], lyr.data);
    var dataOpts = utils.defaults({fields: [field]}, opts);
    var records = aggregateDataRecords(lyr.data.getRecords(), getGroupId, dataOpts);
    var features;
    lyr.shapes.forEach(function(shape, i) {
      var groupId = getGroupId(i);
      if (groupId in groups === false) {
        groups[groupId] = [];
      }
      groups[groupId].push(shape);
    });
    features = groups.map(function(shapes, i) {
      return {
        type: 'Feature',
        properties: records[i],
        geometry: shapes.length > 1 ? pointShapesToLineGeometry(shapes) : null
      };
    });
    return {
      type: 'FeatureCollection',
      features: features
    };
  }

  // TOOD: automatically convert rings into separate shape parts
  function pointShapesToLineGeometry(shapes) {
    var coords = [];
    forEachPoint(shapes, function(p) {
      coords.push(p.concat());
    });
    return {type: 'LineString', coordinates: coords};
  }

  function polygonsToLines(lyr, arcs, opts) {
    opts = opts || {};
    var decorateRecord = opts.each ? getLineRecordDecorator(opts.each, lyr, arcs) : null,
        classifier = getArcClassifier(lyr, arcs, {where: opts.where}),
        fields = utils.isArray(opts.fields) ? opts.fields : [],
        rankId = 0,
        shapes = [],
        records = [],
        outputLyr;

    if (fields.length > 0 && !lyr.data) {
      stop("Missing a data table");
    }

    addLines(extractOuterLines(lyr.shapes, classifier), 'outer');

    fields.forEach(function(field) {
      var data = lyr.data.getRecords();
      var key = function(a, b) {
        var arec = data[a];
        var brec = data[b];
        if (!arec || !brec || arec[field] === brec[field]) {
          return null;
        }
        return a + '-' + b;
      };
      requireDataField(lyr, field);
      addLines(extractLines(lyr.shapes, classifier(key)), field);
    });

    addLines(extractInnerLines(lyr.shapes, classifier), 'inner');
    outputLyr = createLineLayer(shapes, records);
    setOutputLayerName(outputLyr, lyr, null, opts);
    return outputLyr;

    function addLines(lines, typeName) {
      var attr = lines.map(function(shp, i) {
        var rec = {RANK: rankId, TYPE: typeName};
        if (decorateRecord) decorateRecord(rec, shp);
        return rec;
      });
      shapes = utils.merge(lines, shapes);
      records = utils.merge(attr, records);
      rankId++;
    }
  }


  // kludgy way to implement each= option of -lines command
  function getLineRecordDecorator(exp, lyr, arcs) {
    // repurpose arc classifier function to convert arc ids to shape ids of original polygons
    var procArcId = getArcClassifier(lyr, arcs)(procShapeIds);
    var compiled = compileFeaturePairExpression(exp, lyr, arcs);
    var tmp;

    function procShapeIds(shpA, shpB) {
      compiled(shpA, shpB, tmp);
    }

    return function(rec, shp) {
      tmp = rec;
      procArcId(shp[0][0]);
      return rec;
    };
  }


  function createLineLayer(lines, records) {
    return {
      geometry_type: 'polyline',
      shapes: lines,
      data: records ? new DataTable(records) : null
    };
  }

  function extractOuterLines(shapes, classifier) {
    var key = function(a, b) {return b == -1 ? String(a) : null;};
    return extractLines(shapes, classifier(key));
  }

  function extractInnerLines(shapes, classifier) {
    var key = function(a, b) {return b > -1 ? a + '-' + b : null;};
    return extractLines(shapes, classifier(key));
  }

  function extractLines(shapes, classify) {
    var lines = [],
        index = {},
        prev = null,
        prevKey = null,
        part;

    traversePaths(shapes, onArc, onPart);

    function onArc(o) {
      var arcId = o.arcId,
          key = classify(arcId),
          isContinuation, line;
      if (key) {
        line = key in index ? index[key] : null;
        isContinuation = key == prevKey && o.shapeId == prev.shapeId && o.partId == prev.partId;
        if (!line) {
          line = [[arcId]]; // new shape
          index[key] = line;
          lines.push(line);
        } else if (isContinuation) {
          line[line.length-1].push(arcId); // extending prev part
        } else {
          line.push([arcId]); // new part
        }

        // if extracted line is split across endpoint of original polygon ring, then merge
        if (o.i == part.arcs.length - 1 &&  // this is last arc in ring
            line.length > 1 &&              // extracted line has more than one part
            line[0][0] == part.arcs[0]) {   // first arc of first extracted part is first arc in ring
          line[0] = line.pop().concat(line[0]);
        }
      }
      prev = o;
      prevKey = key;
    }

    function onPart(o) {
      part = o;
    }

    return lines;
  }

  var Lines = /*#__PURE__*/Object.freeze({
    __proto__: null,
    polygonsToLines: polygonsToLines,
    createLineLayer: createLineLayer,
    extractInnerLines: extractInnerLines
  });

  function getClippingDataset(src, dest, opts) {
    return getUnprojectedBoundingPolygon(src, dest, opts);
  }

  function getUnprojectedBoundingPolygon(src, dest, opts) {
    var dataset;
    if (isCircleClippedProjection(dest) || opts.clip_angle || dest.clip_angle) {
      dataset = getBoundingCircle(src, dest, opts);
    } else if (isRectangleClippedProjection(dest) || opts.clip_bbox) {
      dataset = getBoundingRectangle(dest, opts);
    }
    return dataset || null;
  }

  // If possible, return a lat-long bbox that can be used to
  // test whether data exceeds the projection bounds ands needs to be clipped
  // export function getInnerBoundingBBox(P, opts) {
  //   var bbox = null;
  //   if (opts.clip_bbox) {
  //     bbox = opts.clip_bbox;
  //   } else if (isRectangleClippedProjection(dest)) {
  //     bbox
  //   }
  //   return bbox;
  // }

  // Return projected polygon extent of both clipped and unclipped projections
  function getPolygonDataset$1(src, dest, opts) {
    // use clipping area if projection is clipped
    var dataset = getUnprojectedBoundingPolygon(src, dest, opts);
    if (!dataset) {
      // use entire world if projection is not clipped
      dataset = getBoundingRectangle(dest, {clip_bbox: [-180,-90,180,90]});
    }
    projectDataset(dataset, src, dest, {no_clip: false, quiet: true});
    return dataset;
  }

  // Return projected outline of clipped projections
  function getOutlineDataset(src, dest, opts) {
    var dataset = getUnprojectedBoundingPolygon(src, dest, opts);
    if (dataset) {
      // project, with cutting & cleanup
      projectDataset(dataset, src, dest, {no_clip: false, quiet: true});
      dataset.layers[0].geometry_type = 'polyline';
    }
    return dataset || null;
  }

  function getBoundingRectangle(dest, opts) {
    var bbox = opts.clip_bbox || getDefaultClipBBox(dest);
    var rotation = getRotationParams(dest);
    if (!bbox) error('Missing expected clip bbox.');
    opts = Object.assign({interval: 0.5}, opts); // make sure edges can curve
    var dataset = importGeoJSON(bboxToPolygon(bbox, opts));
    if (rotation) {
      rotateDataset(dataset, {rotation: rotation, invert: true});
    }
    return dataset;
  }

  function getBoundingCircle(src, dest, opts) {
    var angle = opts.clip_angle || dest.clip_angle || getDefaultClipAngle(dest);
    if (!angle) return null;
    verbose(`Using clip angle of ${ +angle.toFixed(2) } degrees`);
    var dist = getClippingRadius(src, angle);
    var cp = getProjCenter(dest);
    // kludge: attach the clipping angle to the CRS, so subsequent commands
    // (e.g. -graticule) can create an outline
    dest.clip_angle = angle;
    var geojson = getCircleGeoJSON(cp, dist, null, opts);
    return importGeoJSON(geojson);
  }

  function isRectangleClippedProjection(P) {
    // TODO: add tmerc, etmerc, ...
    // return inList(P, 'tmerc,utm,etmerc,merc,bertin1953');
    return inList(P, 'merc,bertin1953');
  }

  function getDefaultClipBBox(P) {
    var e = 1e-3;
    var slug = getCrsSlug(P);
    var tmerc = [-179,-90,179,90];
    var bbox = {
      // longlat: [-180, -90, 180, 90],
      tmerc: tmerc,
      utm: tmerc,
      etmerc: tmerc,
      merc: [-180, -89, 180, 89],
      lcc: [-180, -89, 180, 89],
      bertin1953: [-180 + e, -90 + e, 180 - e, 90 - e]
    }[slug];
    return bbox;
  }

  function getClampBBox(P) {
    var bbox;
    if (inList(P, 'merc,lcc')) {
      bbox = getDefaultClipBBox(P);
    }
    return bbox;
  }

  function isCircleClippedProjection(P) {
    return inList(P, 'stere,sterea,ups,ortho,gnom,laea,nsper,tpers,geos,nicol');
  }

  function getPerspectiveClipAngle(P) {
    var h = parseFloat(P.params.h.param);
    if (!h || h < 0) {
      return 0;
    }
    var theta = Math.acos(P.a / (P.a + h)) * 180 / Math.PI;
    theta *= 0.995; // reducing a bit to avoid out-of-range errors
    return theta;
  }

  function getDefaultClipAngle(P) {
    var slug = getCrsSlug(P);
    if (slug == 'nsper' || slug == 'geos') return getPerspectiveClipAngle(P);
    if (slug == 'tpers') {
      message('Automatic clipping is not supported for the Tilted Perspective projection');
      return 0;
    }
    return {
      gnom: 60,
      laea: 179,
      //ortho: 89.9, // projection errors betwen lat +/-35 to 55
      ortho: 89.85, // TODO: investigate
      nicol: 89.85,
      stere: 142,
      sterea: 142,
      ups: 10.5 // TODO: should be 6.5 deg at north pole
    }[slug] || 0;
  }

  function getRotationParams(P) {
    var slug = getCrsSlug(P);
    if (slug == 'bertin1953') return [-16.5,-42];
    if (slug == 'tmerc' || slug == 'utm' || slug == 'etmerc') {
      if (P.lam0 !== 0) return [P.lam0 * 180 / Math.PI];
    }
    return null;
  }


  function getProjCenter(P) {
    var rtod = 180 / Math.PI;
    return [P.lam0 * rtod, P.phi0 * rtod];
  }

  // Convert a clip angle to a distance in meters
  function getClippingRadius(P, angle) {
    return getCircleRadiusFromAngle(P, angle);
  }

  function preProjectionClip(dataset, src, dest, opts) {
    if (!isLatLngCRS(src) || opts.no_clip) return false;
    // rotated normal-aspect projections can generally have a thin slice removed
    // from the rotated antimeridian, instead of clipping them
    var cut = insertPreProjectionCuts(dataset, src, dest);
    var clipped = false;
    var clipData;
    // experimental -- we can probably get away with just clamping some CRSs that
    // have a slightly restricted coord range (e.g. Mercator), instead of doing
    // a clip (more expensive)
    var clampBox = getClampBBox(dest);
    if (clampBox) {
      clampDataset(dataset, clampBox);
    } else {
      clipData = getClippingDataset(src, dest, opts);
    }
    // clip data to projection limits (some projections), if content exceeds the limit
    //
    if (clipData) {
      clipped = clipLayersIfNeeded(dataset, clipData);
    }
    return cut || clipped;
  }

  function clipLayersIfNeeded(dataset, clipData) {
    // Avoid clipping layers that are fully enclosed within the projectable
    // coordinate space (represented by a dataset containing a single
    // polygon layer, @clipData). This avoids performing unnecessary intersection
    // tests on each line segment.
    var layers = dataset.layers.filter(function(lyr) {
      return layerHasGeometry(lyr) && !layerIsFullyEnclosed(lyr, dataset, clipData);
    });
    if (layers.length > 0) {
      clipLayersInPlace(layers, clipData, dataset, 'clip');
      return true;
    }
    return false;
  }

  // @clipData: a dataset containing a polygon layer
  function layerIsFullyEnclosed(lyr, dataset, clipData) {
    // This test uses the layer's bounding box to represent the extent of the
    // layer, and can produce false negatives.
    var dataBounds = getLayerBounds(lyr, dataset.arcs);
    var enclosed = false;
    clipData.layers[0].shapes.forEach(function(shp, i) {
      enclosed = enclosed || testBoundsInPolygon(dataBounds, shp, clipData.arcs);
    });
    return enclosed;
  }


  function insertPreProjectionCuts(dataset, src, dest) {
    var antimeridian = getAntimeridian(dest.lam0 * 180 / Math.PI);
    // currently only supports adding a single vertical cut to earth axis-aligned
    // map projections centered on a non-zero longitude.
    // TODO: need a more sophisticated kind of cutting to handle other cases
    if (dataset.arcs && isRotatedNormalProjection(dest) && datasetCrossesLon(dataset, antimeridian)) {
      insertVerticalCut(dataset, antimeridian);
      dissolveArcs(dataset);
      return true;
    }
    return false;
  }

  function clampDataset(dataset, bbox) {
    transformPoints(dataset, function(x, y) {
      return [utils.clamp(x, bbox[0], bbox[2]), utils.clamp(y, bbox[1], bbox[3])];
    });
  }

  function datasetCrossesLon(dataset, lon) {
    var crosses = 0;
    dataset.arcs.forEachSegment(function(i, j, xx, yy) {
      var ax = xx[i],
          bx = xx[j];
      if (ax <= lon && bx >= lon || ax >= lon && bx <= lon) crosses++;
    });
    return crosses > 0;
  }

  function insertVerticalCut(dataset, lon) {
    var pathLayers = dataset.layers.filter(layerHasPaths);
    if (pathLayers.length === 0) return;
    var e = 1e-8;
    var bbox = [lon-e, -91, lon+e, 91];
    // densify (so cut line can curve, e.g. Cupola projection)
    var geojson = bboxToPolygon(bbox, {interval: 0.5});
    var clip = importGeoJSON(geojson);
    clipLayersInPlace(pathLayers, clip, dataset, 'erase');
  }

  // Converts a Proj.4 projection name (e.g. lcc, tmerc) to a Proj.4 string
  // by picking parameters that are appropriate to the extent of the dataset
  // being projected (e.g. standard parallels, longitude of origin)
  // Works for lcc, aea, tmerc, etc.
  // TODO: add more projections
  //
  function expandProjDefn(str, dataset) {
    var mproj = require$1('mproj');
    var proj4, params, bbox, isConic2SP, isCentered, decimals;
    if (str in mproj.internal.pj_list === false) {
      // not a bare projection code -- assume valid projection string in other format
      return str;
    }
    isConic2SP = ['lcc', 'aea'].includes(str);
    isCentered = ['tmerc', 'etmerc'].includes(str);
    proj4 = '+proj=' + str;
    if (isConic2SP || isCentered) {
      bbox = getBBox(dataset); // TODO: support projected datasets
      decimals = getBoundsPrecisionForDisplay(bbox);
      params = isCentered ? getCenterParams(bbox, decimals) : getConicParams(bbox, decimals);
      proj4 += ' ' + params;
      message(`Converted "${str}" to "${proj4}"`);
    }
    return proj4;
  }

  function getBBox(dataset) {
    if (!isLatLngCRS(getDatasetCRS(dataset))) {
      stop('Expected unprojected data');
    }
    return getDatasetBounds(dataset).toArray();
  }

  // See: Savric & Jenny, "Automating the selection of standard parallels for conic map projections"
  // Using one-sixth rule, not the more complicated formula proposed by the authors
  function getConicParams(bbox, decimals) {
    var cx = (bbox[0] + bbox[2]) / 2;
    var h = bbox[3] - bbox[1];
    var sp1 = bbox[1] + 1/6 * h;
    var sp2 = bbox[1] + 5/6 * h;
    return `+lon_0=${ cx.toFixed(decimals) } +lat_1=${ sp1.toFixed(decimals) } +lat_2=${ sp2.toFixed(decimals) }`;
  }

  function getCenterParams(bbox, decimals) {
    var cx = (bbox[0] + bbox[2]) / 2;
    var cy = (bbox[1] + bbox[3]) / 2;
    return `+lon_0=${ cx.toFixed(decimals) } +lat_0=${ cy.toFixed(decimals) }`;
  }

  var ProjectionParams = /*#__PURE__*/Object.freeze({
    __proto__: null,
    expandProjDefn: expandProjDefn,
    getConicParams: getConicParams,
    getCenterParams: getCenterParams
  });

  cmd.proj = function(dataset, catalog, opts) {
    var srcInfo, destInfo, destStr;
    if (opts.init) {
      srcInfo = fetchCrsInfo(opts.init, catalog);
      if (!srcInfo.crs) stop("Unknown projection source:", opts.init);
      setDatasetCrsInfo(dataset, srcInfo);
    }
    if (opts.match) {
      destInfo = fetchCrsInfo(opts.match, catalog);
    } else if (opts.crs) {
      destStr = expandProjDefn(opts.crs, dataset);
      destInfo = getCrsInfo(destStr);
    }
    if (destInfo) {
      projCmd(dataset, destInfo, opts);
    }
  };

  function projCmd(dataset, destInfo, opts) {
    // modify copy of coordinate data when running in web UI, so original shapes
    // are preserved if an error occurs
    var modifyCopy = runningInBrowser(),
        originals = [],
        target = {info: dataset.info || {}};

    if (!destInfo.crs) {
      stop("Missing projection data");
    }

    if (!datasetHasGeometry(dataset)) {
      // still set the crs of datasets that are missing geometry
      setDatasetCrsInfo(dataset, destInfo);
      return;
    }

    var srcInfo = getDatasetCrsInfo(dataset);
    if (!srcInfo.crs) {
      stop("Unable to project -- source coordinate system is unknown");
    }

    if (crsAreEqual(srcInfo.crs, destInfo.crs)) {
      message("Source and destination CRS are the same");
      return;
    }

    if (dataset.arcs) {
      dataset.arcs.flatten(); // bake in any pending simplification
      target.arcs = modifyCopy ? dataset.arcs.getCopy() : dataset.arcs;
    }

    target.layers = dataset.layers.map(function(lyr) {
      if (modifyCopy) {
        originals.push(lyr);
        lyr = copyLayerShapes(lyr);
      }
      return lyr;
    });

    projectDataset(target, srcInfo.crs, destInfo.crs, opts || {});

    // dataset.info.prj = destInfo.prj; // may be undefined
    setDatasetCrsInfo(target, destInfo);

    dataset.arcs = target.arcs;
    originals.forEach(function(lyr, i) {
      // replace original layers with modified layers
      utils.extend(lyr, target.layers[i]);
    });
  }


  // name: a layer identifier, .prj file or projection defn
  // Converts layer ids and .prj files to CRS defn
  // Returns projection defn
  function fetchCrsInfo(name, catalog) {
    var dataset, source, info = {};
    if (/\.prj$/i.test(name)) {
      dataset = importFile(name, {});
      if (dataset) {
        info.prj = dataset.info.prj;
        info.crs = parsePrj(info.prj);
      }
      return info;
    }
    if (catalog && (source = catalog.findSingleLayer(name))) {
      dataset = source.dataset;
      return getDatasetCrsInfo(dataset);
    }
    // assume name is a projection defn
    return getCrsInfo(name);
  }

  function projectDataset(dataset, src, dest, opts) {
    var proj = getProjTransform2(src, dest); // v2 returns null points instead of throwing an error
    var badArcs = 0;
    var badPoints = 0;
    var clipped = preProjectionClip(dataset, src, dest, opts);
    dataset.layers.forEach(function(lyr) {
      if (layerHasPoints(lyr)) {
        badPoints += projectPointLayer(lyr, proj); // v2 compatible (invalid points are removed)
      }
    });
    if (dataset.arcs) {
      if (opts.densify) {
        badArcs = projectAndDensifyArcs(dataset.arcs, proj);
      } else {
        badArcs = projectArcs2(dataset.arcs, proj);
      }
    }

    if (clipped) {
      // TODO: could more selective in cleaning clipped layers
      // (probably only needed when clipped area crosses the antimeridian or includes a pole)
      cleanProjectedPathLayers(dataset);
    }

    if (badArcs > 0 && !opts.quiet) {
      message(`Removed ${badArcs} ${badArcs == 1 ? 'path' : 'paths'} containing unprojectable vertices.`);
    }
    if (badPoints > 0 && !opts.quiet) {
      message(`Removed ${badPoints} unprojectable ${badPoints == 1 ? 'point' : 'points'}.`);
    }
    dataset.info.crs = dest;
  }

  // * Heals cuts in previously split-apart polygons
  // * Removes line intersections
  // * TODO: what if a layer contains polygons with desired overlaps? should
  //   we ignore overlaps between different features?
  function cleanProjectedPathLayers(dataset) {
    // TODO: only clean affected polygons (cleaning all polygons can be slow)
    var polygonLayers = dataset.layers.filter(lyr => lyr.geometry_type == 'polygon');
    // clean options: force a topology update (by default, this only happens when
    // vertices change during cleaning, but reprojection can require a topology update
    // even if clean does not change vertices)
    var cleanOpts = {
      allow_overlaps: true,
      rebuild_topology: true,
      no_arc_dissolve: true,
      quiet: true,
      verbose: false};
    cleanLayers(polygonLayers, dataset, cleanOpts);
   // remove unused arcs from polygon and polyline layers
    // TODO: fix bug that leaves uncut arcs in the arc table
    //   (e.g. when projecting a graticule)
    dissolveArcs(dataset);
  }

  // proj: function to project [x, y] point; should return null if projection fails
  // TODO: fatal error if no points project?
  function projectPointLayer(lyr, proj) {
    var errors = 0;
    editShapes(lyr.shapes, function(p) {
      var p2 = proj(p[0], p[1]);
      if (!p2) errors++;
      return p2; // removes points that fail to project
    });
    return errors;
  }

  function projectArcs(arcs, proj) {
    var data = arcs.getVertexData(),
        xx = data.xx,
        yy = data.yy,
        // old simplification data  will not be optimal after reprojection;
        // re-using for now to avoid error in web ui
        zz = data.zz,
        z = arcs.getRetainedInterval(),
        p;

    for (var i=0, n=xx.length; i<n; i++) {
      p = proj(xx[i], yy[i]);
      if (!p) error('Unprojectable point:', xx[i], yy[i]);
      xx[i] = p[0];
      yy[i] = p[1];
    }
    arcs.updateVertexData(data.nn, xx, yy, zz);
    arcs.setRetainedInterval(z);
  }

  function projectArcs2(arcs, proj) {
    return editArcs(arcs, onPoint);
    function onPoint(append, x, y, prevX, prevY, i) {
      var p = proj(x, y);
      // TODO: prevent arcs with just one point
      if (p) {
        append(p);
      } else {
        return false; // signal that the arc is invalid (no more points will be projected in this arc)
      }
    }
  }

  var Proj = /*#__PURE__*/Object.freeze({
    __proto__: null,
    fetchCrsInfo: fetchCrsInfo,
    projectDataset: projectDataset,
    cleanProjectedPathLayers: cleanProjectedPathLayers,
    projectPointLayer: projectPointLayer,
    projectArcs: projectArcs,
    projectArcs2: projectArcs2
  });

  cmd.graticule = function(dataset, opts) {
    var name = opts.name || opts.polygon && 'polygon' || 'graticule';
    var graticule, destInfo;
    if (dataset && !isLatLngDataset(dataset)) {
      // project graticule to match dataset
      destInfo = getDatasetCrsInfo(dataset);
      if (!destInfo.crs) stop("Coordinate system is unknown, unable to create a graticule");
      graticule = opts.polygon ?
        createProjectedPolygon(destInfo.crs, opts) :
        createProjectedGraticule(destInfo.crs, opts);
      setDatasetCrsInfo(graticule, destInfo);
    } else {
      graticule = opts.polygon ?
        createUnprojectedPolygon(opts) :
        createUnprojectedGraticule(opts);
      setDatasetCrsInfo(graticule, getCrsInfo('wgs84'));
    }
    graticule.layers[0].name = name;
    return graticule;
  };

  function createUnprojectedPolygon(opts) {
    var crs = parseCrsString('wgs84');
    return getPolygonDataset$1(crs, crs, opts);
  }

  function createProjectedPolygon(dest, opts) {
    var src = parseCrsString('wgs84');
    return getPolygonDataset$1(src, dest, opts);
  }

  function createUnprojectedGraticule(opts) {
    var src = parseCrsString('wgs84');
    var graticule = importGeoJSON(createGraticule(src, false, opts));
    return graticule;
  }

  function createProjectedGraticule(dest, opts) {
    var src = parseCrsString('wgs84');
    var outline = getOutlineDataset(src, dest, {});
    var graticule = importGeoJSON(createGraticule(dest, !!outline, opts));
    projectDataset(graticule, src, dest, {no_clip: false}); // TODO: densify?
    if (outline) {
      graticule = addOutlineToGraticule(graticule, outline);
    }
    buildTopology(graticule); // needed for cleaning to work
    cleanLayers(graticule.layers, graticule, {verbose: false});
    return graticule;
  }

  function addOutlineToGraticule(graticule, outline) {
    var merged = mergeDatasets([graticule, outline]);
    var src = merged.layers.pop();
    var dest = merged.layers[0];
    var records = dest.data.getRecords();
    src.shapes.forEach(function(shp) {
      dest.shapes.push(shp);
      records.push({type: 'outline', value: null});
    });
    return merged;
  }

  // Create graticule as a polyline dataset
  //
  function createGraticule(P, outlined, opts) {
    var interval = opts.interval || 10;
    if (Math.round(interval) != interval || interval > 0 === false) {
      stop('Invalid interval:', interval);
    }
    P.lam0 * 180 / Math.PI;
    var precision = interval > 10 ? 1 : 0.5; // degrees between each vertex
    var xstep = interval;
    var ystep = interval;
    var xstepMajor = 90;
    var xn = Math.round(360 / xstep);
    var yn = Math.round(180 / ystep) + 1;
    var xx = utils.range(xn, -180 + xstep, xstep);
    var yy = utils.range(yn, -90, ystep);
    var meridians = [];
    var parallels = [];
    var edgeMeridians = isMeridianBounded(P) ? getEdgeMeridians(P) : null;
    xx.forEach(function(x) {
      if (edgeMeridians && (tooClose(x, edgeMeridians[0]) || tooClose(x, edgeMeridians[1]))) {
        return;
      }
      createMeridian(x, x % xstepMajor === 0);
    });

    if (edgeMeridians && !outlined) {
      // add meridian lines that will appear on the left and right sides of the
      // projected graticule
      createMeridian(edgeMeridians[0], true);
      createMeridian(edgeMeridians[1], true);
    }

    yy.forEach(function(y) {
      createParallel(y);
    });

    var geojson = {
      type: 'FeatureCollection',
      features: meridians.concat(parallels)
    };
    return geojson;

    function tooClose(a, b) {
      return Math.abs(a - b) < interval / 5;
    }

    // extended: meridian extends to pole
    function createMeridian(x, extended) {
      var y0 = ystep <= 15 ? ystep : 0;
      createMeridianPart(x, -90 + y0, 90 - y0);
      if (extended && y0 > 0) {
        // adding extensions as separate parts, so if the polar coordinates
        // fail to project, at least the rest of the meridian line will remain
        createMeridianPart(x, -90, -90 + y0);
        createMeridianPart(x, 90 - y0, 90);
      }
    }

    function createMeridianPart(x, ymin, ymax) {
      var coords = densifyPathByInterval([[x, ymin], [x, ymax]], precision);
      meridians.push(graticuleFeature(coords, {type: 'meridian', value: roundCoord$1(x)}));
    }

    function createParallel(y) {
      var coords = densifyPathByInterval([[-180, y], [180, y]], precision);
      parallels.push(graticuleFeature(coords, {type: 'parallel', value: y}));
    }
  }

  // remove tiny offsets
  function roundCoord$1(x) {
    return +x.toFixed(3) || 0;
  }

  function getEdgeMeridians(P) {
    var lon = getBoundingMeridian(P);
    // offs must be larger than gutter width in mapshaper-spherical-cutting.js
    var offs = 2e-8;
    return lon == 180 ? [-180, 180] : [lon - offs, lon + offs];
  }

  function graticuleFeature(coords, o) {
    return {
      type: 'Feature',
      properties: o,
      geometry: {
        type: 'LineString',
        coordinates: coords
      }
    };
  }

  cmd.printHelp = function(opts) {
    var str = getOptionParser().getHelpMessage(opts.command);
    print(str);
  };

  function stopJob(job) {
    job.stopped = true;
  }

  function jobIsStopped(job) {
    return job.stopped === true;
  }

  function inControlBlock(job) {
    return getStack(job).length > 0;
  }

  function enterBlock(job) {
    var stack = getStack(job);
    // skip over a block if it is inside an inactive branch
    stack.push({
      active: false,
      complete: !inActiveBranch(job)
    });
  }

  function leaveBlock(job) {
    var stack = getStack(job);
    stack.pop();
  }

  function enterActiveBranch(job) {
    var block = getCurrentBlock(job);
    block.active = true;
    block.complete = true;
  }

  function enterInactiveBranch(job) {
    var block = getCurrentBlock(job);
    block.active = false;
  }

  function blockIsComplete(job) {
    var block = getCurrentBlock(job);
    return block.complete;
  }

  function getCurrentBlock(job) {
    var stack = getStack(job);
    return stack[stack.length-1];
  }

  // A branch is considered to be active if it and all its parents are active
  // (Main branch is considered to be active)
  function inActiveBranch(job) {
    var stack = getStack(job);
    return stack.length === 0 || stack.every(block => block.active);
  }

  function getStack(job) {
    job.control = job.control || {stack: []};
    return job.control.stack;
  }

  function skipCommand(cmdName, job) {
    if (jobIsStopped(job)) return true;
    if (isControlFlowCommand(cmdName)) return false;
    return !inActiveBranch(job);
  }

  cmd.if = function(job, opts) {
    enterBlock(job);
    evaluateIf(job, opts);
  };

  cmd.elif = function(job, opts) {
    if (!inControlBlock(job)) {
      stop('-elif command must be preceded by an -if command.');
    }
    evaluateIf(job, opts);
  };

  cmd.else = function(job) {
    if (!inControlBlock(job)) {
      stop('-else command must be preceded by an -if command.');
    }
    if (blockIsComplete(job)) {
      enterInactiveBranch(job);
    } else {
      enterActiveBranch(job);
    }
  };

  cmd.endif = function(job) {
    if (!inControlBlock(job)) {
      stop('-endif command must be preceded by an -if command.');
    }
    leaveBlock(job);
  };

  function isControlFlowCommand(cmd) {
    return ['if','elif','else','endif'].includes(cmd);
  }

  function test(catalog, opts) {
    if (opts.expression) {
      return compileIfCommandExpression(opts.expression, catalog, opts)();
    }
    return true;
  }

  function evaluateIf(job, opts) {
    if (!blockIsComplete(job) && test(job.catalog, opts)) {
      enterActiveBranch(job);
    } else {
      enterInactiveBranch(job);
    }
  }

  cmd.ignore = function(targetLayer, dataset, opts) {
    if (opts.empty && layerIsEmpty(targetLayer)) {
      interrupt('Layer is empty, stopping processing');
    }
  };

  cmd.include = function(opts) {
    var content, obj, context;
    // TODO: handle web context
    if (!opts.file) {
      stop("Missing name of a JS file to load");
    }
    // opts.input is an optional file cache (used by applyCommands())
    cli.checkFileExists(opts.file, opts.input);
    content = cli.readFile(opts.file, 'utf8', opts.input);
    if (typeof content == 'string') {
      if (!/^\s*\{[\s\S]*\}\s*$/.test(content)) {
        stop("Expected a JavaScript object containing key:value pairs");
      }
      try {
        // Try to isolate the imported JS code from the program scope and global environment
        // TODO: consider whether this is desirable... it may be pointless anyway
        //   as long as we're passing through the 'require()' function
        context = getBaseContext();
        context.require = require;
        obj = Function('ctx', 'with(ctx) {return (' + content + ');}').call({}, context);
        // obj = eval('(' + content + ')');
      } catch(e) {
        stop(e.name, 'in JS source:', e.message);
      }
    } else if (typeof content == 'object') {
      // content could be an object if an object is passed to applyCommands()
      obj = content;
    }

    utils.extend(getStashedVar('defs'), obj);
  };

  // TODO: make sure that the inlay shapes and data are not shared
  cmd.inlay = function(targetLayers, src, targetDataset, opts) {
    var mergedDataset = mergeLayersForOverlay(targetLayers, targetDataset, src, opts);
    var inlayLyr = mergedDataset.layers[mergedDataset.layers.length - 1];
    requirePolygonLayer(inlayLyr);
    targetLayers.forEach(requirePolygonLayer);
    var eraseSrc = {layer: copyLayer(inlayLyr), dataset: mergedDataset};
    var erasedLayers = cmd.eraseLayers(targetLayers, eraseSrc, mergedDataset, opts);
    var outputLayers = erasedLayers.map(function(lyr0) {
      // similar to applyCommandToLayerSelection() (mapshaper-command-utils.js)
      var lyr1 = copyLayer(inlayLyr);
      var lyr2 = cmd.mergeLayers([lyr0, lyr1], {force: true})[0];
      lyr2.name = lyr0.name;
      return lyr2;
    });
    targetDataset.arcs = mergedDataset.arcs;
    return outputLayers;
  };

  cmd.innerlines = function(lyr, arcs, opts) {
    opts = opts || {};
    requirePolygonLayer(lyr);
    var classifier = getArcClassifier(lyr, arcs, {where: opts.where});
    var lines = extractInnerLines(lyr.shapes, classifier);
    var outputLyr = createLineLayer(lines, null);

    if (lines.length === 0) {
      message("No shared boundaries were found");
    }
    setOutputLayerName(outputLyr, lyr, null, opts);
    return outputLyr;
  };

  cmd.inspect = function(lyr, arcs, opts) {
    var ids = selectFeatures(lyr, arcs, opts);
    var msg;
    if (ids.length == 1) {
      msg = getFeatureInfo(ids[0], lyr, arcs);
    } else {
      msg = utils.format("Expression matched %d feature%s. Select one feature for details", ids.length, utils.pluralSuffix(ids.length));
    }
    message(msg);
  };

  function getFeatureInfo(id, lyr, arcs) {
      var msg = "Feature " + id + '\n';
      msg += getShapeInfo(id, lyr, arcs);
      msg += formatAttributeTableInfo(getAttributeTableInfo(lyr, id));
      return msg;
  }

  function getShapeInfo(id, lyr, arcs) {
    var shp = lyr.shapes ? lyr.shapes[id] : null;
    var type = lyr.geometry_type;
    var info, msg;
    if (!shp || !type) {
      return 'Geometry: [null]\n';
    }
    msg = 'Geometry\n  Type: ' + type + '\n';
    if (type == 'point') {
      msg += '  Points: ' + shp.length + '\n';
    } else if (type == 'polyline') {
      msg += '  Parts: ' + shp.length + '\n';
    } else if (type == 'polygon') {
      info = getPolygonInfo(shp, arcs);
      msg += utils.format('  Rings: %d cw, %d ccw\n', info.cw, info.ccw);
      msg += '  Planar area: ' + info.area + '\n';
      if (info.sph_area) {
        msg += '  Spherical area: ' + info.sph_area + ' sq. meters\n';
      }
    }
    return msg;
  }

  function getPolygonInfo(shp, arcs) {
    var o = {rings: shp.length, cw: 0, ccw: 0, area: 0};
    var area;
    for (var i=0; i<shp.length; i++) {
      area = geom.getPlanarPathArea(shp[i], arcs);
      if (area > 0) {
        o.cw++;
      } else if (area < 0) {
        o.ccw++;
      }
      o.area += area;
    }
    if (!arcs.isPlanar()) {
      o.sph_area = geom.getSphericalShapeArea(shp, arcs);
    }
    return o;
  }

  function selectFeatures(lyr, arcs, opts) {
    var n = getFeatureCount(lyr),
        ids = [],
        filter;
    if (!opts.expression) {
      stop("Missing a JS expression for selecting a feature");
    }
    filter = compileFeatureExpression(opts.expression, lyr, arcs);
    utils.repeat(n, function(id) {
      var result = filter(id);
      requireBooleanResult(result, 'Expression must return true or false');
      if (result === true) {
        ids.push(id);
      }
    });
    return ids;
  }

  function joinPolygonsViaMosaic(targetLyr, targetDataset, source, opts) {
    // merge source and target layers
    var mergedDataset = mergeLayersForOverlay([targetLyr], targetDataset, source, opts);
    var nodes = addIntersectionCuts(mergedDataset, opts);
    var sourceLyr = mergedDataset.layers.pop();
    targetDataset.arcs = mergedDataset.arcs;
    prepJoinLayers(targetLyr, sourceLyr);
    var mergedLyr = {
      geometry_type: 'polygon',
      shapes: targetLyr.shapes.concat(sourceLyr.shapes)
    };
    // make a mosaic from merged shapes of both layers
    var mosaicIndex = new MosaicIndex(mergedLyr, nodes, {flat: false});

    var joinOpts = utils.extend({}, opts);
    var joinFunction = getPolygonToPolygonFunction(targetLyr, sourceLyr, mosaicIndex, opts);
    var retn = joinTableToLayer(targetLyr, sourceLyr.data, joinFunction, joinOpts);

    if (opts.interpolate) {
      if (opts.duplication) stop('duplication and interpolate options cannot be used together');
      interpolateFieldsByArea(targetLyr, sourceLyr, mosaicIndex, opts);
    }
    return retn;
  }


  function interpolateFieldsByArea(destLyr, sourceLyr, mosaicIndex, opts) {
    var mosaicRecords = getOverlapDataByTile(destLyr, sourceLyr, mosaicIndex, opts);
    var sourceFields = opts.interpolate;
    var sourceRecords = sourceLyr.data.getRecords();

    // for each destination polygon, calculate interpolated values,
    // using the data calculated in previous steps
    destLyr.data.getRecords().forEach(function(destRec, destId) {
      var tileIds = mosaicIndex.getTileIdsByShapeId(destId);
      var tileRecords = [], i, field;
      for (i=0; i<tileIds.length; i++) {
        tileRecords.push(mosaicRecords[tileIds[i]]);
      }
      for (i=0; i<sourceFields.length; i++) {
        field = sourceFields[i];
        destRec[field] = getInterpolatedValue(field, tileRecords, sourceRecords);
      }
    });
  }

  function getOverlapDataByTile(destLyr, sourceLyr, mosaicIndex, opts) {
    var getShapeArea = opts.planar ? geom.getPlanarShapeArea : geom.getShapeArea;
    var destLen = destLyr.shapes.length;
    var mosaicShapes = mosaicIndex.mosaic;
    var arcs = mosaicIndex.nodes.arcs;
    // initialize data objects for each mosaic tile
    var mosaicRecords = mosaicShapes.map(function(tile, i) {
      var rec = {
        area: getShapeArea(tile, arcs),
        weights: null,
        sourceIds: null
      };
      return rec;
    });

    // identify the source polygon that overlaps each tile,
    // and calculate the percentage of the source shape represented by each tile
    sourceLyr.shapes.forEach(function(sourceShp, sourceId) {
      var tileIds = mosaicIndex.getTileIdsByShapeId(sourceId + destLen);
      var shapeArea = getShapeArea(sourceShp, arcs);
      var tileRec, weight;
      for (var i=0; i<tileIds.length; i++) {
        tileRec = mosaicRecords[tileIds[i]];
        weight = tileRec.area / shapeArea;
        if (!tileRec.weights) {
          tileRec.weights = [];
          tileRec.sourceIds = [];
        }
        tileRec.weights.push(weight);
        tileRec.sourceIds.push(sourceId);
      }
    });
    return mosaicRecords;
  }


  // function getInterpolatedValue(field, tileRecords, sourceRecords) {
  //   var value = 0, tileRec, sourceRec;
  //   for (var i=0; i<tileRecords.length; i++) {
  //     tileRec = tileRecords[i];
  //     if (tileRec.sourceId == -1) continue;

  //     sourceRec = sourceRecords[tileRec.sourceId];
  //     value += tileRec.weight * sourceRec[field];
  //   }
  //   return value;
  // }

  function getInterpolatedValue(field, tileRecords, sourceRecords) {
    var value = 0, tileRec, sourceRec, sourceId;
    for (var i=0; i<tileRecords.length; i++) {
      tileRec = tileRecords[i];
      if (!tileRec.sourceIds) continue;
      for (var j=0; j<tileRec.sourceIds.length; j++) {
        sourceId = tileRec.sourceIds[j];
        sourceRec = sourceRecords[sourceId];
        value += tileRec.weights[j] * sourceRec[field];
      }
    }
    return value;
  }


  function getIdConversionFunction(offset, length) {
    return function (mergedIds) {
      var ids = [], id;
      for (var i=0; i<mergedIds.length; i++) {
        id = mergedIds[i] - offset;
        if (id >= 0 && id < length) ids.push(id);
      }
      return ids;
    };
  }

  function getMaxOverlapFunction(destLyr, srcLyr, mosaicIndex) {
    var arcs = mosaicIndex.nodes.arcs;
    var destLen = destLyr.shapes.length;

    function getTotalArea(tileIds) {
      var area = 0;
      for (var i=0; i<tileIds.length; i++) {
        area += geom.getShapeArea(mosaicIndex.mosaic[tileIds[i]], arcs);
      }
      return area;
    }

    return function(destId, srcIds) {
      var destTileIds = mosaicIndex.getTileIdsByShapeId(destId);
      var maxArea = 0;
      var maxId = -1;
      srcIds.forEach(function(srcId, i) {
        var srcTileIds = mosaicIndex.getTileIdsByShapeId(srcId + destLen);
        var sharedIds = utils.intersection(destTileIds, srcTileIds);
        var area = getTotalArea(sharedIds);
        if (area >= maxArea) {
          maxId = srcId;
          maxArea = area;
        }
      });
      if (maxId == -1) error('Geometry error');
      return [maxId];
    };
  }


  // Returned function converts a target layer feature id to multiple source feature ids
  // TODO: option to join the source polygon with the greatest overlapping area
  // TODO: option to ignore source polygon with small overlaps
  //       (as a percentage of the area of one or the other polygon?)
  function getPolygonToPolygonFunction(targetLyr, srcLyr, mosaicIndex, opts) {
    var mergedToSourceIds = getIdConversionFunction(targetLyr.shapes.length, srcLyr.shapes.length);
    var selectMaxOverlap;
    if (opts.largest_overlap) {
      selectMaxOverlap = getMaxOverlapFunction(targetLyr, srcLyr, mosaicIndex);
    }

    return function(targId) {
      var tileIds = mosaicIndex.getTileIdsByShapeId(targId);
      var sourceIds = [], tmp;
      for (var i=0; i<tileIds.length; i++) {
        tmp = mosaicIndex.getSourceIdsByTileId(tileIds[i]);
        tmp = mergedToSourceIds(tmp);
        sourceIds = sourceIds.length > 0 ? sourceIds.concat(tmp) : tmp;
      }
      sourceIds = utils.uniq(sourceIds);
      if (sourceIds.length > 1 && opts.largest_overlap) {
        sourceIds = selectMaxOverlap(targId, sourceIds);
      }
      return sourceIds;
    };
  }

  // Returns x,y coordinates of the point that is at the midpoint of each polyline feature
  // Uses 2d cartesian geometry
  // TODO: optionally use spherical geometry
  function polylineToMidpoints(shp, arcs, opts) {
    if (!shp) return null;
    var points = shp.map(function(path) {
      return findPathMidpoint(path, arcs, false);
    });
    return points;
  }

  function findPathMidpoint(path, arcs, useNearestVertex) {
    var halfLen = calcPathLen(path, arcs, false) / 2;
    var partialLen = 0;
    var p;
    forEachSegmentInPath(path, arcs, function(i, j, xx, yy) {
      var a = xx[i],
          b = yy[i],
          c = xx[j],
          d = yy[j];
      if (p) return;
      if (halfLen > 0 === false) {
        return [a, b];
      }
      var segLen = distance2D(a, b, c, d);
      var k;
      if (partialLen + segLen >= halfLen) {
        k = (halfLen - partialLen) / segLen;
        if (useNearestVertex) {
          k = k < 0.5 ? 0 : 1;
        }
        // p = [a + k * (c - a), b + k * (d - b)];
        p = [(1 - k) * a + k * c, (1 - k) * b + k * d];
      }
      partialLen += segLen;
    });
    if (!p) {
      error('Geometry error');
    }
    return p;
  }

  // Returns x,y coordinates of the vertex that is closest to the bbox center point
  //   (uses part with the largest-area bbox in )
  // TODO: explore other methods for replacing a polyline with a point.
  function polylineToPoint(shp, arcs, opts) {
    var spherical = !arcs.isPlanar();
    var part = !shp ? null : (shp.length == 1 ? shp[0] : findLongestPolylinePart(shp, arcs, spherical));
    if (!part) return null;
    var bbox = arcs.getSimpleShapeBounds(part);
    var p = findNearestVertex(bbox.centerX(), bbox.centerY(), [part], arcs, spherical);
    return p;
  }

  function findLongestPolylinePart(shp, arcs, spherical) {
    var maxLen = 0;
    var maxPart = null;
    shp.forEach(function(path) {
      var len = geom.calcPathLen(path, arcs, spherical);
      if (len > maxLen) {
        maxLen = len;
        maxPart = path;
      }
    });
    return maxPart;
  }

  cmd.createPointLayer = function(srcLyr, dataset, opts) {
    var destLyr = getOutputLayer(srcLyr, opts);
    var arcs = dataset.arcs;
    if (opts.intersections) {
      testIntersections(arcs);
      destLyr = srcLyr;
    } else if (opts.interpolated) {
      // TODO: consider making attributed points, including distance from origin
      destLyr.shapes = interpolatedPointsFromVertices(srcLyr, dataset, opts);
    } else if (opts.vertices) {
      destLyr.shapes = pointsFromVertices(srcLyr, arcs);
    } else if (opts.vertices2) {
      destLyr.shapes = pointsFromVertices2(srcLyr, arcs);
    } else if (opts.endpoints) {
      destLyr.shapes = pointsFromEndpoints(srcLyr, arcs);
    } else if (opts.x || opts.y) {
      destLyr.shapes = pointsFromDataTable(srcLyr.data, opts);
    } else if (srcLyr.geometry_type == 'polygon') {
      destLyr.shapes = pointsFromPolygons(srcLyr, arcs, opts);
    } else if (opts.midpoints) {
      requirePolylineLayer(srcLyr);
      destLyr.shapes = midpointsFromPolylines(srcLyr, arcs);
    } else if (srcLyr.geometry_type == 'polyline') {
      destLyr.shapes = pointsFromPolylines(srcLyr, arcs);
    } else if (!srcLyr.geometry_type) {
      destLyr.shapes = pointsFromDataTableAuto(srcLyr.data);
    } else {
      stop("Expected a polygon or polyline layer");
    }
    destLyr.geometry_type = 'point';

    var nulls = destLyr.shapes.reduce(function(sum, shp) {
      if (!shp) sum++;
      return sum;
    }, 0);

    if (nulls > 0) {
      message(utils.format('%,d of %,d points are null', nulls, destLyr.shapes.length));
    }
    if (srcLyr.data) {
      destLyr.data = opts.no_replace ? srcLyr.data.clone() : srcLyr.data;
    }
    return destLyr;
  };

  // TODO: finish testing stripe count functions and remove
  function testIntersections(arcs) {
    var pointCount =  arcs.getFilteredPointCount(),
        arcCount = arcs.size(),
        segCount = pointCount - arcCount,
        stripes = calcSegmentIntersectionStripeCount2(arcs),
        stripes2 = Math.ceil(stripes / 10),
        stripes3 = stripes * 10,
        stripes4 = calcSegmentIntersectionStripeCount(arcs);

    console.log("points:", pointCount, "arcs:", arcCount, "segs:", segCount);
    [stripes2, stripes, stripes3, stripes4].forEach(function(n) {
      console.time(n + ' stripes');
      findSegmentIntersections(arcs, {stripes: n});
      console.timeEnd(n + ' stripes');
    });
  }

  function interpolatePointsAlongArc(ids, arcs, interval) {
    var iter = arcs.getShapeIter(ids);
    var distance = arcs.isPlanar() ? geom.distance2D : geom.greatCircleDistance;
    var coords = [];
    var elapsedDist = 0;
    var prevX, prevY;
    var segLen, k, p;
    if (iter.hasNext()) {
      coords.push([iter.x, iter.y]);
      prevX = iter.x;
      prevY = iter.y;
    }
    while (iter.hasNext()) {
      segLen = distance(prevX, prevY, iter.x, iter.y);
      while (elapsedDist + segLen >= interval) {
        k = (interval - elapsedDist) / segLen;
        // TODO: consider using great-arc distance for lat-long points
        p = interpolatePoint2D(prevX, prevY, iter.x, iter.y, k);
        elapsedDist = 0;
        coords.push(p);
        prevX = p[0];
        prevY = p[1];
        segLen = distance(prevX, prevY, iter.x, iter.y);
      }
      elapsedDist += segLen;
      prevX = iter.x;
      prevY = iter.y;
    }
    if (elapsedDist > 0) {
      coords.push([prevX, prevY]);
    }
    return coords;
  }

  function interpolatedPointsFromVertices(lyr, dataset, opts) {
    var interval = convertIntervalParam(opts.interval, getDatasetCRS(dataset));
    var coords;
    if (interval > 0 === false) stop("Invalid interpolation interval:", opts.interval);
    if (lyr.geometry_type != 'polyline') stop("Expected a polyline layer");
    return lyr.shapes.map(function(shp, shpId) {
      coords = [];
      if (shp) shp.forEach(nextPart);
      return coords.length > 0 ? coords : null;
    });
    function nextPart(ids) {
      var points = interpolatePointsAlongArc(ids, dataset.arcs, interval);
      coords = coords.concat(points);
    }
  }

  // Unique vertices within each feature
  function pointsFromVertices(lyr, arcs, opts) {
    var coords, index;
    if (lyr.geometry_type != "polygon" && lyr.geometry_type != 'polyline') {
      stop("Expected a polygon or polyline layer");
    }
    return lyr.shapes.map(function(shp, shpId) {
      coords = [];
      index = {}; // TODO: use more efficient index
      (shp || []).forEach(nextPart);
      return coords.length > 0 ? coords : null;
    });

    function addPoint(p) {
      var key = p.x + '~' + p.y;
      if (key in index === false) {
        index[key] = true;
        coords.push([p.x, p.y]);
      }
    }

    function nextPart(ids) {
      var iter = arcs.getShapeIter(ids);
      while (iter.hasNext()) {
        addPoint(iter);
      }
    }
  }

  // Simple conversion of path vertices to points (duplicate locations not removed)
  // TODO: Provide some way to rebuild paths from points (e.g. multipart features)
  function pointsFromVertices2(lyr, arcs, opts) {
    var coords;
    if (lyr.geometry_type != "polygon" && lyr.geometry_type != 'polyline') {
      stop("Expected a polygon or polyline layer");
    }
    return lyr.shapes.map(function(shp, shpId) {
      coords = [];
      (shp || []).forEach(nextPart);
      return coords.length > 0 ? coords : null;
    });

    function nextPart(ids) {
      var iter = arcs.getShapeIter(ids);
      while (iter.hasNext()) {
        coords.push([iter.x, iter.y]);
      }
    }
  }

  function pointsFromEndpoints(lyr, arcs) {
    var coords, index;
    if (lyr.geometry_type != "polygon" && lyr.geometry_type != 'polyline') {
      stop("Expected a polygon or polyline layer");
    }
    return lyr.shapes.map(function(shp, shpId) {
      coords = [];
      index = {}; // TODO: use more efficient index
      (shp || []).forEach(nextPart);
      return coords.length > 0 ? coords : null;
    });

    function addPoint(p) {
      var key = p.x + '~' + p.y;
      if (key in index === false) {
        index[key] = true;
        coords.push([p.x, p.y]);
      }
    }

    function nextPart(ids) {
      for (var i=0; i<ids.length; i++) {
        addPoint(arcs.getVertex(ids[i], 0));
        addPoint(arcs.getVertex(ids[i], -1));
      }
    }
  }

  function midpointsFromPolylines(lyr, arcs, opts) {
    return lyr.shapes.map(function(shp) {
      return polylineToMidpoints(shp, arcs);
    });
  }

  function pointsFromPolylines(lyr, arcs, opts) {
    return lyr.shapes.map(function(shp) {
      var p = polylineToPoint(shp, arcs);
      return p ? [[p.x, p.y]] : null;
    });
  }

  function pointsFromPolygons(lyr, arcs, opts) {
    var func = opts.inner ? findAnchorPoint : geom.getShapeCentroid;
    return lyr.shapes.map(function(shp) {
      var p = func(shp, arcs);
      return p ? [[p.x, p.y]] : null;
    });
  }

  function coordinateFromValue(val) {
    var tmp;
    if (utils.isFiniteNumber(val)) {
      return val;
    }
    // exclude empty string (not a valid coordinate, but would get coerced to 0)
    if (utils.isString(val) && val !== '') {
      tmp = +val;
      if (utils.isFiniteNumber(tmp)) {
        return tmp;
      }
      tmp = parseDMS(val); // try to parse as DMS
      if (utils.isFiniteNumber(tmp)) {
        return tmp;
      }
    }
    return NaN;
  }

  function findXField(fields) {
    var rxp = /^(lng|long?|longitude|x)$/i;
    return utils.find(fields, function(name) {
      return rxp.test(name);
    });
  }

  function findYField(fields) {
    var rxp = /^(lat|latitude|y)$/i;
    return utils.find(fields, function(name) {
      return rxp.test(name);
    });
  }

  function pointsFromDataTableAuto(data) {
    var fields = data ? data.getFields() : [];
    var opts = {
      x: findXField(fields),
      y: findYField(fields)
    };
    return pointsFromDataTable(data, opts);
  }

  function pointsFromDataTable(data, opts) {
    if (!data) stop("Layer is missing a data table");
    if (!opts.x || !opts.y || !data.fieldExists(opts.x) || !data.fieldExists(opts.y)) {
      stop("Missing x,y data fields");
    }

    return data.getRecords().map(function(rec) {
      var x = coordinateFromValue(rec[opts.x]),
          y = coordinateFromValue(rec[opts.y]);
      if (isNaN(x) || isNaN(y)) {
        return null;
      }
      return [[x, y]];
    });
  }

  var Points = /*#__PURE__*/Object.freeze({
    __proto__: null,
    pointsFromPolygons: pointsFromPolygons,
    coordinateFromValue: coordinateFromValue,
    findXField: findXField,
    findYField: findYField
  });

  function joinPolygonsViaPoints(targetLyr, targetDataset, source, opts) {

    var sourceLyr = source.layer,
        sourceDataset = source.dataset,
        pointLyr, retn;

    if (targetLyr.shapes.length > sourceLyr.shapes.length) {
      // convert target polygons to points, then join source data to points
      pointLyr = pointsFromPolygonsForJoin(targetLyr, targetDataset);
      retn = joinPolygonsToPoints(pointLyr, sourceLyr, sourceDataset.arcs, opts);
      targetLyr.data = pointLyr.data;
    } else {
      // convert source polygons to points, then join points to target polygons
      pointLyr = pointsFromPolygonsForJoin(sourceLyr, sourceDataset);
      retn = joinPointsToPolygons(targetLyr, targetDataset.arcs, pointLyr, opts);
    }
    return retn;
  }

  function pointsFromPolygonsForJoin(lyr, dataset) {
    // TODO use faster method to get inner points
    return {
      geometry_type: 'point',
      shapes: pointsFromPolygons(lyr, dataset.arcs, {inner: true}),
      data: lyr.data // TODO copy if needed
    };
  }

  function joinPolygonsToPolygons(targetLyr, targetDataset, source, opts) {
    if (opts.point_method) {
      return joinPolygonsViaPoints(targetLyr, targetDataset, source, opts);
    } else {
      return joinPolygonsViaMosaic(targetLyr, targetDataset, source, opts);
    }
  }

  function pointsFromPolylinesForJoin(lyr, dataset) {
    var shapes = lyr.shapes.map(function(shp) {
      return polylineToMidpoints(shp, dataset.arcs);
    });
    return {
      geometry_type: 'point',
      shapes: shapes,
      data: lyr.data // TODO copy if needed
    };
  }

  function validateOpts(opts) {
    if (!opts.point_method) {
      stop('The "point-method" flag is required for polyline-polygon joins');
    }
  }

  function joinPolylinesToPolygons(targetLyr, targetDataset, source, opts) {
    validateOpts(opts);
    var pointLyr = pointsFromPolylinesForJoin(source.layer, source.dataset);
    var retn = joinPointsToPolygons(targetLyr, targetDataset.arcs, pointLyr, opts);
    return retn;
  }

  function joinPolygonsToPolylines(targetLyr, targetDataset, source, opts) {
    validateOpts(opts);
    var pointLyr = pointsFromPolylinesForJoin(targetLyr, targetDataset);
    var retn = joinPolygonsToPoints(pointLyr, source.layer, source.dataset.arcs, opts);
    targetLyr.data = pointLyr.data;
    return retn;
  }

  class TinyQueue {
      constructor(data = [], compare = defaultCompare) {
          this.data = data;
          this.length = this.data.length;
          this.compare = compare;

          if (this.length > 0) {
              for (let i = (this.length >> 1) - 1; i >= 0; i--) this._down(i);
          }
      }

      push(item) {
          this.data.push(item);
          this.length++;
          this._up(this.length - 1);
      }

      pop() {
          if (this.length === 0) return undefined;

          const top = this.data[0];
          const bottom = this.data.pop();
          this.length--;

          if (this.length > 0) {
              this.data[0] = bottom;
              this._down(0);
          }

          return top;
      }

      peek() {
          return this.data[0];
      }

      _up(pos) {
          const {data, compare} = this;
          const item = data[pos];

          while (pos > 0) {
              const parent = (pos - 1) >> 1;
              const current = data[parent];
              if (compare(item, current) >= 0) break;
              data[pos] = current;
              pos = parent;
          }

          data[pos] = item;
      }

      _down(pos) {
          const {data, compare} = this;
          const halfLength = this.length >> 1;
          const item = data[pos];

          while (pos < halfLength) {
              let left = (pos << 1) + 1;
              let best = data[left];
              const right = left + 1;

              if (right < this.length && compare(data[right], best) < 0) {
                  left = right;
                  best = data[right];
              }
              if (compare(best, item) >= 0) break;

              data[pos] = best;
              pos = left;
          }

          data[pos] = item;
      }
  }

  function defaultCompare(a, b) {
      return a < b ? -1 : a > b ? 1 : 0;
  }

  /*
  ISC License

  Copyright (c) 2017, Vladimir Agafonkin

  Permission to use, copy, modify, and/or distribute this software for any purpose
  with or without fee is hereby granted, provided that the above copyright notice
  and this permission notice appear in all copies.

  THE SOFTWARE IS PROVIDED "AS IS" AND THE AUTHOR DISCLAIMS ALL WARRANTIES WITH
  REGARD TO THIS SOFTWARE INCLUDING ALL IMPLIED WARRANTIES OF MERCHANTABILITY AND
  FITNESS. IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR ANY SPECIAL, DIRECT,
  INDIRECT, OR CONSEQUENTIAL DAMAGES OR ANY DAMAGES WHATSOEVER RESULTING FROM LOSS
  OF USE, DATA OR PROFITS, WHETHER IN AN ACTION OF CONTRACT, NEGLIGENCE OR OTHER
  TORTIOUS ACTION, ARISING OUT OF OR IN CONNECTION WITH THE USE OR PERFORMANCE OF
  THIS SOFTWARE.
  */

  var earthRadius = 6371;
  var rad = Math.PI / 180;

  function around(index, lng, lat, maxResults, maxDistance, predicate) {
      var maxHaverSinDist = 1, result = [];

      if (maxResults === undefined) maxResults = Infinity;
      if (maxDistance !== undefined) maxHaverSinDist = haverSin(maxDistance / earthRadius);

      // a distance-sorted priority queue that will contain both points and kd-tree nodes
      var q = new TinyQueue([], compareDist);

      // an object that represents the top kd-tree node (the whole Earth)
      var node = {
          left: 0, // left index in the kd-tree array
          right: index.ids.length - 1, // right index
          axis: 0, // 0 for longitude axis and 1 for latitude axis
          dist: 0, // will hold the lower bound of children's distances to the query point
          minLng: -180, // bounding box of the node
          minLat: -90,
          maxLng: 180,
          maxLat: 90
      };

      var cosLat = Math.cos(lat * rad);
      var right, left, item;

      while (node) {
          right = node.right;
          left = node.left;

          if (right - left <= index.nodeSize) { // leaf node

              // add all points of the leaf node to the queue
              for (var i = left; i <= right; i++) {
                  item = index.points[index.ids[i]];
                  if (!predicate || predicate(item)) {
                      q.push({
                          i: index.ids[i],
                          item: item,
                          dist: haverSinDist(lng, lat, index.coords[2 * i], index.coords[2 * i + 1], cosLat)
                      });
                  }
              }

          } else { // not a leaf node (has child nodes)

              var m = (left + right) >> 1; // middle index
              var midLng = index.coords[2 * m];
              var midLat = index.coords[2 * m + 1];

              // add middle point to the queue
              item = index.points[index.ids[m]];
              if (!predicate || predicate(item)) {
                  q.push({
                      i: index.ids[m],
                      item: item,
                      dist: haverSinDist(lng, lat, midLng, midLat, cosLat)
                  });
              }

              var nextAxis = (node.axis + 1) % 2;

              // first half of the node
              var leftNode = {
                  left: left,
                  right: m - 1,
                  axis: nextAxis,
                  minLng: node.minLng,
                  minLat: node.minLat,
                  maxLng: node.axis === 0 ? midLng : node.maxLng,
                  maxLat: node.axis === 1 ? midLat : node.maxLat,
                  dist: 0
              };
              // second half of the node
              var rightNode = {
                  left: m + 1,
                  right: right,
                  axis: nextAxis,
                  minLng: node.axis === 0 ? midLng : node.minLng,
                  minLat: node.axis === 1 ? midLat : node.minLat,
                  maxLng: node.maxLng,
                  maxLat: node.maxLat,
                  dist: 0
              };

              leftNode.dist = boxDist(lng, lat, cosLat, leftNode);
              rightNode.dist = boxDist(lng, lat, cosLat, rightNode);

              // add child nodes to the queue
              q.push(leftNode);
              q.push(rightNode);
          }

          // fetch closest points from the queue; they're guaranteed to be closer
          // than all remaining points (both individual and those in kd-tree nodes),
          // since each node's distance is a lower bound of distances to its children
          while (q.length && q.peek().item) {
              var candidate = q.pop();
              if (candidate.dist > maxHaverSinDist) return result;
              // result.push(candidate.item);
              result.push(candidate.i);
              if (result.length === maxResults) return result;
          }

          // the next closest kd-tree node
          node = q.pop();
      }

      return result;
  }

  // lower bound for distance from a location to points inside a bounding box
  function boxDist(lng, lat, cosLat, node) {
      var minLng = node.minLng;
      var maxLng = node.maxLng;
      var minLat = node.minLat;
      var maxLat = node.maxLat;

      // query point is between minimum and maximum longitudes
      if (lng >= minLng && lng <= maxLng) {
          if (lat < minLat) return haverSin((lat - minLat) * rad);
          if (lat > maxLat) return haverSin((lat - maxLat) * rad);
          return 0;
      }

      // query point is west or east of the bounding box;
      // calculate the extremum for great circle distance from query point to the closest longitude;
      var haverSinDLng = Math.min(haverSin((lng - minLng) * rad), haverSin((lng - maxLng) * rad));
      var extremumLat = vertexLat(lat, haverSinDLng);

      // if extremum is inside the box, return the distance to it
      if (extremumLat > minLat && extremumLat < maxLat) {
          return haverSinDistPartial(haverSinDLng, cosLat, lat, extremumLat);
      }
      // otherwise return the distan e to one of the bbox corners (whichever is closest)
      return Math.min(
          haverSinDistPartial(haverSinDLng, cosLat, lat, minLat),
          haverSinDistPartial(haverSinDLng, cosLat, lat, maxLat)
      );
  }

  function compareDist(a, b) {
      return a.dist - b.dist;
  }

  function haverSin(theta) {
      var s = Math.sin(theta / 2);
      return s * s;
  }

  function haverSinDistPartial(haverSinDLng, cosLat1, lat1, lat2) {
      return cosLat1 * Math.cos(lat2 * rad) * haverSinDLng + haverSin((lat1 - lat2) * rad);
  }

  function haverSinDist(lng1, lat1, lng2, lat2, cosLat1) {
      var haverSinDLng = haverSin((lng1 - lng2) * rad);
      return haverSinDistPartial(haverSinDLng, cosLat1, lat1, lat2);
  }

  function vertexLat(lat, haverSinDLng) {
      var cosDLng = 1 - 2 * haverSinDLng;
      if (cosDLng <= 0) return lat > 0 ? 90 : -90;
      return Math.atan(Math.tan(lat * rad) / cosDLng) / rad;
  }

  function PointIndex(srcLyr, crs, opts) {
    requireSinglePointLayer(srcLyr);
    var points = getPointsInLayer(srcLyr);
    var maxDist = opts.max_distance ? convertDistanceParam(opts.max_distance, crs) : 1e-3;
    var kdbush = require$1('kdbush');
    var index = new kdbush(points);
    var lookup = getLookupFunction(index, crs, maxDist);
    var uniqIndex = new IdTestIndex(points.length);

    this.lookupByMultiPoint = function(shape) {
      var hits = [], p, i, j, n;
      for (i=0, n=shape ? shape.length : 0; i<n; i++) {
        p = shape[i];
        hits = lookup(p);
        for (j=0; j<hits.length; j++) {
          uniqIndex.setId(hits[j]);
        }
      }
      hits = uniqIndex.getIds();
      uniqIndex.clear();
      return hits;
    };
  }

  function getLookupFunction(index, crs, meterDist) {
    var geodetic = crs ? isLatLngCRS(crs) : false;
    var toMeter = crs && crs.to_meter || 1;
    if (geodetic) {
      return function(p) {
        // kdbush uses km
        return around(index, p[0], p[1], Infinity, meterDist / 1000);
      };
    }
    return function(p) {
      return index.within(p[0], p[1], meterDist / toMeter);
    };
  }

  function joinPointsToPoints(targetLyr, srcLyr, crs, opts) {
    var joinFunction = getPointToPointFunction(targetLyr, srcLyr, crs, opts);
    prepJoinLayers(targetLyr, srcLyr);
    return joinTableToLayer(targetLyr, srcLyr.data, joinFunction, opts);
  }

  function getPointToPointFunction(targetLyr, srcLyr, crs, opts) {
    var shapes = targetLyr.shapes;
    var index = new PointIndex(srcLyr, crs, opts);
    return function(targId) {
      var matches = index.lookupByMultiPoint(shapes[targId]);
      return matches.length > 0 ? matches : null;
    };
  }

  cmd.join = function(targetLyr, targetDataset, src, opts) {
    var srcType, targetType, retn;
    if (!src || !src.dataset) {
      stop("Missing a joinable data source");
    }
    if (opts.keys) {
      // join using data in attribute fields
      if (opts.keys.length != 2) {
        stop("Expected two key fields: a target field and a source field");
      }
      if (!src.layer.data) {
        stop("Source layer is missing attribute data");
      }
      retn = joinAttributesToFeatures(targetLyr, src.layer.data, opts);
    } else {
      // spatial join
      if (!src.layer.data) {
        // KLUDGE -- users might want to join a layer without attributes
        // to test for intersection... the simplest way to support this is
        // to add an empty data table to the source layer
        initDataTable(src.layer);
      }
      requireDatasetsHaveCompatibleCRS([targetDataset, src.dataset]);
      srcType = src.layer.geometry_type;
      targetType = targetLyr.geometry_type;
      if (srcType == 'point' && targetType == 'polygon') {
        retn = joinPointsToPolygons(targetLyr, targetDataset.arcs, src.layer, opts);
      } else if (srcType == 'polygon' && targetType == 'point') {
        retn = joinPolygonsToPoints(targetLyr, src.layer, src.dataset.arcs, opts);
      } else if (srcType == 'point' && targetType == 'point') {
        retn = joinPointsToPoints(targetLyr, src.layer, getDatasetCRS(targetDataset), opts);
      } else if (srcType == 'polygon' && targetType == 'polygon') {
        retn = joinPolygonsToPolygons(targetLyr, targetDataset, src, opts);
      } else if (srcType == 'polyline' && targetType == 'polygon') {
        retn = joinPolylinesToPolygons(targetLyr, targetDataset, src, opts);
      } else if (srcType == 'polygon' && targetType == 'polyline') {
        retn = joinPolygonsToPolylines(targetLyr, targetDataset, src, opts);
      } else {
        stop(utils.format("Unable to join %s geometry to %s geometry",
            srcType || 'null', targetType || 'null'));
      }
    }

    if (retn.unmatched) {
      targetDataset.layers.push(retn.unmatched);
    }
    if (retn.unjoined) {
      targetDataset.layers.push(retn.unjoined);
    }
  };

  function joinAttributesToFeatures(destLyr, srcTable, opts) {
    var keys = opts.keys,
        destKey = keys[0],
        srcKey = keys[1],
        destTable = destLyr.data,
        joinFunction = getJoinByKey(destTable, destKey, srcTable, srcKey);
    validateFieldNames(keys);
    return joinTableToLayer(destLyr, srcTable, joinFunction, opts);
  }

  // Return a function for translating a target id to an array of source ids based on values
  // of two key fields.
  function getJoinByKey(dest, destKey, src, srcKey) {
    if (!dest) {
      stop('Target layer is missing an attribute table');
    }
    if (!src) {
      stop('Source layer is missing an attribute table');
    }
    var destRecords = dest.getRecords();
    var srcRecords = src.getRecords();
    var index = createTableIndex(srcRecords, srcKey);
    var srcType, destType;
    if (srcRecords.length == 0) {
      // allow empty external tables
      return function(i) {return [];};
    }
    requireDataField(src, srcKey, 'External table is missing a field named:');
    requireDataField(dest, destKey, 'Target layer is missing key field:');
    srcType = getColumnType(srcKey, src.getRecords());
    destType = getColumnType(destKey, destRecords);
    validateJoinFieldType(srcKey, srcType);
    validateJoinFieldType(destKey, destType);
    if (srcType != destType) {
      stop("Join keys have mismatched data types:", destType, "and", srcType);
    }
    return function(i) {
      var destRec = destRecords[i],
          val = destRec ? destRec[destKey] : null,
          retn = null;
      if (destRec && val in index) {
        retn = index[val];
        if (!Array.isArray(retn)) retn = [retn];
      }
      return retn;
    };
  }

  function validateJoinFieldType(field, type) {
    if (!type || type == 'object') {
      stop('[' + field + '] field has an unsupported data type. Expected string or number.');
    }
  }

  function createTableIndex(records, f) {
    var index = {}, rec, key;
    for (var i=0, n=records.length; i<n; i++) {
      rec = records[i];
      key = rec[f];
      if (key in index === false) {
        index[key] = i;
      } else if (Array.isArray(index[key])) {
        index[key].push(i);
      } else {
        index[key] = [index[key], i];
      }
    }
    return index;
  }

  var Join = /*#__PURE__*/Object.freeze({
    __proto__: null,
    joinAttributesToFeatures: joinAttributesToFeatures
  });

  cmd.mosaic = function(layers, dataset, opts) {
    var lyr = layers[0];
    if (!lyr || layers.length > 1) {
      stop('Command takes a single target layer');
    }
    requirePolygonLayer(lyr);
    var nodes = addIntersectionCuts(dataset, opts);
    // ignore arcs that don't belong to this layer
    nodes.setArcFilter(getArcPresenceTest(lyr.shapes, nodes.arcs));
    var mosaicIndex = new MosaicIndex(lyr, nodes, {flat: false});
    var mosaicShapes = mosaicIndex.mosaic;
    var records2;

    var lyr2 = {
      name: 'name' in lyr ? lyr.name : undefined,
      shapes: mosaicShapes,
      geometry_type: 'polygon',
    };

    if (opts.calc) {
      if (!lyr.data) initDataTable(lyr);
      records2 = recombineDataRecords(lyr.data.getRecords(), mosaicIndex.getSourceIdsByTileId, mosaicShapes.length, opts);
      lyr2.data = new DataTable(records2);
    }

    return [lyr2];
  };

  // Columns are vertical and rows are horizontal in the "flat-top" orientation;
  //   columns are horizontal in the "pointy-top" orientation
  // Array indexes are column-first in both orientations
  // The 0,0 cell is in the bottom left corner
  // Currently the origin cell is always an "outie" (protruding); in the future
  //   "innie" origin cells may be supported

  function getHexGridParams(bbox, interval, opts) {
    opts.type != 'hex2'; // hex2 is "pointy-top" orientation

    // get origin and counts for centered grid
    // params.u0 = _getUOrigin();
    // params.v0 = _getVOrigin();
    // params.colCounts = _getColCounts(bbox, interval);
    // params.rowCounts = _getRowCounts(bbox, interval);

    if (opts.aligned) ;
  }


  // interval: side length in projected coordinates
  // bbox: bounding box of area to be enclosed by grid
  //
  function getHexGridMaker(bbox, interval, opts) {
    var flatTop = opts.type != 'hex2'; // hex2 is "pointy-top" orientation
    // origin cell (bottom left) may be "outie" or "innie" ... could be settable
    var outieOrigin = true;
    var minorInterval = interval * Math.sqrt(3) / 2;
    var _colCounts = _getColCounts(bbox, interval);
    var _rowCounts = _getRowCounts(bbox, interval);
    // coordinates of the center of the bottom left cell
    var _uOrigin = _getUOrigin();
    var _vOrigin = _getVOrigin();

    getHexGridParams(bbox, interval, opts);

    function cells() {
      return _rowCounts[0] * _colCounts[0] + _rowCounts[1] * _colCounts[1];
    }

    // a is col in flatTop orientation
    function colRowToIdx(col, row) {
      // fatCol: a pair of adjacent (offset) columns
      var fatColSize = _rowCounts[0] + _rowCounts[1];
      var fatColId = Math.floor(col / 2);
      var idx = fatColId * fatColSize;
      // oddCol: cell is in an odd-numbered column (or row)
      var oddCols = col % 2 == 1;
      if (oddCols) {
        idx += _rowCounts[1];
      }
      idx += row;

      // check index bounds
      if (col < 0 || row < 0) error('negative grid index');
      if (oddCols && row >= _rowCounts[1] || !oddCols && row >= _rowCounts[0]) {
        error('out-of-bounds minor axis index');
      }
      if (oddCols && col >= _colCounts[1] || !oddCols && col >= _colCounts[0]) {
        error('out-of-bounds major axis index');
      }
      return idx;
    }

    function pointToIdx(xy) {
      return flatTop ?
        _uvToIdx(xy[0], xy[1]) :
        _uvToIdx(xy[1], xy[0]);
    }

    // Col,row numbering and array indexing are aligned (same for both flat-top and pointed-top orientations)
    function idxToColRow(id) {
      var fatColSize = _rowCounts[0] + _rowCounts[1];
      var fatColId = Math.floor(id / fatColSize);
      var col = fatColId * 2;
      var extra = id - fatColId * fatColSize;
      if (extra >= _rowCounts[0]) {
        col++;
        extra -= _rowCounts[0];
      }
      return [col, extra];
    }

    function idxToBBox(id) {
      var bbox = _idxToBBox(id);
      return flatTop ? bbox: [bbox[1], bbox[0], bbox[3], bbox[2]];
    }

    function makeCellPolygon(idx, opts) {
      var geom = {
        type: 'Polygon',
        coordinates: [_makeCellCoords(idx)]
      };
      if (!flatTop) {
        flipPolygonCoords(geom);
      }
      return geom;
    }

    function forEachNeighbor(c, r, cb) {
      var rowShift;
      {
        rowShift = isOdd(c) ? 0 : -1;
      }
      cb(c, r+1);
      cb(c+1, r + rowShift + 1);
      cb(c+1, r + rowShift);
      cb(c, r-1);
      cb(c-1, r + rowShift + 1);
    }

    // horizontal origin (x coord) in flat-top orientation
    function _getUOrigin() {
      var range = _getUAxisRange(bbox);
      var extent = range[1] - range[0];
      var cols = _colCounts[0] + _colCounts[1];
      var outerExtent = 1.5 * cols * interval + 0.5 * interval;
      var margin = (outerExtent - extent) / 2; // center data bbox within grid
      // origin is one side length to the right of the left boundary
      var origin = range[0] - margin + interval;
      return origin;
    }

    // vertical origin (y coord) in flat-top orientation
    function _getVOrigin() {
      var range = _getVAxisRange(bbox);
      var extent = range[1] - range[0];
      var rows = _rowCounts[0] + _rowCounts[1];
      var outerExtent = (rows + 1) * minorInterval;
      var margin = (outerExtent - extent) / 2;
      var origin = range[0] - margin + minorInterval;
      return origin;
    }

    function _getUAxisRange(bbox) {
      return flatTop ? [bbox[0], bbox[2]] : [bbox[1], bbox[3]];
    }

    function _getVAxisRange(bbox) {
      return flatTop ? [bbox[1], bbox[3]] : [bbox[0], bbox[2]];
    }

    function _uvToIdx(u, v) {
      var [c, r] = _uvToColRow(u, v);
      return colRowToIdx(c, r);
    }

    // x, y are reversed in pointy-top orientation
    function _uvToColRow(u, v) {
      var left = _uOrigin - 1.5 * interval;
      var vOffs = 0 ;
      var bottom = _vOrigin - minorInterval + vOffs;
      var ui = Math.floor((u - left) / (1.5 * interval));
      var vi = Math.floor((v - bottom) / minorInterval);
      var cwBar = isOdd(ui) != isOdd(vi);
      var u1 = left + ui * 1.5 * interval + interval * 0.5;
      var u2 = u1 + interval * 0.5;
      var v1 = bottom + vi * minorInterval;
      var v2 = v1 + minorInterval;
      var orientation = cwBar ?
        orient2D(u1, v1, u2, v2, u, v) :
        orient2D(u2, v1, u1, v2, u, v);
      var colId = orientation > 0 ? ui - 1 : ui;
      var rowId = Math.floor(vi / 2);
      return [colId, rowId];
    }

    function _idxToBBox(id) {
      var uv = _idxToPoint(id);
      return [
        uv[0] - interval,
        uv[1] - minorInterval,
        uv[0] + interval,
        uv[1] + minorInterval
      ];
    }

    // center point of cell
    function idxToPoint(id) {
      var p = _idxToPoint(id);
      return flatTop ? p : flipPoint(p);
    }

    function _isUpperCell(col) {
      return isOdd(col) || !outieOrigin ;
    }

    function _idxToPoint(id) {
      var [c, r] = idxToColRow(id);
      return _colRowToPoint(c, r);
    }

    function _colRowToPoint(c, r) {
      var vShift = isOdd(c) ? (minorInterval ) : 0;
      var u = _uOrigin + c * 1.5 * interval;
      var v = _vOrigin + vShift + r * minorInterval * 2;
      return [u, v];
    }

    function _colRowToVertex(c, r, half) {
      var [u, v] = _colRowToPoint(c, r);
      return [u - (half ? interval : interval / 2), v - (half ? 0 : minorInterval)];
    }

    function _makeCellCoords(idx) {
      var [c, r] = idxToColRow(idx);
      var rowOffs = _isUpperCell(c) ? 0 : -1;
      var v0 = _colRowToVertex(c, r, false);
      return [
        v0,
        _colRowToVertex(c, r, false),
        _colRowToVertex(c, r, true),
        _colRowToVertex(c, r + 1, false),
        _colRowToVertex(c + 1, r + 1 + rowOffs, true),
        _colRowToVertex(c + 1, r + 1 + rowOffs, false),
        _colRowToVertex(c + 1, r + rowOffs, true),
        v0
      ];
    }

    function _getColCounts(bbox, interval) {
      var extent = flatTop ? bbox[2] - bbox[0] : bbox[3] - bbox[1];
      var n = Math.ceil((2 * extent + interval) / (3 * interval));
      var a = Math.ceil(n / 2);
      var b = Math.floor(n / 2);
      return [a, b] ;
    }

    function _getRowCounts(bbox, interval) {
      var extent = flatTop ? bbox[3] - bbox[1] : bbox[2] - bbox[0];
      var n = Math.ceil(1 + 2 * extent / (interval * Math.sqrt(3)));
      var a = Math.ceil(n / 2);
      var b = Math.floor(n / 2);
      return [a, b] ;
    }

    return {
      cells,
      colRowToIdx,
      idxToColRow,
      pointToIdx,
      idxToPoint,
      idxToBBox,
      makeCellPolygon,
      forEachNeighbor
    };
  }

  function isOdd(int) {
    return int % 2 !== 0;
  }

  function flipPolygonCoords(geom) {
    for (var i=0, n=geom ? geom.coordinates.length : 0; i<n; i++) {
      geom.coordinates[i].forEach(flipPoint);
    }
  }

  function flipPoint(p) {
    p[1];
    p[1] = p[0];
    p[0] = p[1];
    return p;
  }

  function getAlignedGridBounds(bbox, interval) {
    var xx = getAlignedRange(bbox[0], bbox[2], interval);
    var yy = getAlignedRange(bbox[1], bbox[3], interval);
    return [xx[0], yy[0], xx[1], yy[1]];
  }

  function getCenteredGridBounds(bbox, interval) {
    var xx = getCenteredRange(bbox[0], bbox[2], interval);
    var yy = getCenteredRange(bbox[1], bbox[3], interval);
    return [xx[0], yy[0], xx[1], yy[1]];
  }

  // grid boundaries includes the origin
  // (this way, grids calculated from different sets of points will all align)
  function getAlignedRange(minCoord, maxCoord, interval) {
    var idx = Math.floor(minCoord / interval) - 1;
    var idx2 = Math.ceil(maxCoord / interval) + 1;
    return [idx * interval, idx2 * interval];
  }

  function getCenteredRange(minCoord, maxCoord, interval) {
    var w = maxCoord - minCoord;
    var w2 = Math.ceil(w / interval) * interval;
    var pad = (w2 - w) / 2 + interval;
    return [minCoord - pad, maxCoord + pad];
  }

  // TODO: Use this function for other grid-based commands
  function getSquareGridMaker(bbox, interval, opts) {
    var extent = opts && opts.aligned ?
      getAlignedGridBounds(bbox, interval) :
      getCenteredGridBounds(bbox, interval);
    var xmin = extent[0];
    var ymin = extent[1];
    var w = extent[2] - xmin;
    var h = extent[3] - ymin;
    var cols = Math.round(w / interval);
    var rows = Math.round(h / interval);
    // var xmin = bbox[0] - interval;
    // var ymin = bbox[1] - interval;
    // var xmax = bbox[2] + interval;
    // var ymax = bbox[3] + interval;
    // var w = xmax - xmin;
    // var h = ymax - ymin;
    // var cols = Math.ceil(w / interval);
    // var rows = Math.ceil(h / interval);

    // function size() {
    //   return [cols, rows];
    // }

    function cells() {
      return cols * rows;
    }

    function pointToCol(xy) {
      var dx = xy[0] - xmin;
      return Math.floor(dx / w * cols);
    }

    function pointToRow(xy) {
      var dy = xy[1] - ymin;
      return Math.floor(dy / h * rows);
    }

    function colRowToIdx(c, r) {
      if (c < 0 || r < 0 || c >= cols || r >= rows) return -1;
      return r * cols + c;
    }

    function pointToIdx(xy) {
      var c = pointToCol(xy);
      var r = pointToRow(xy);
      return colRowToIdx(c, r);
    }

    function idxToColRow(i) {
      return [i % cols, Math.floor(i / cols)];
    }

    function idxToPoint(idx) {
      var [c, r] = idxToColRow(idx);
      var x = xmin + (c + 0.5) * interval;
      var y = ymin + (r + 0.5) * interval;
      return [x, y];
    }

    function idxToBBox(idx) {
      var cr = idxToColRow(idx);
      return [
        xmin + cr[0] * interval, ymin + cr[1] * interval,
        xmin + (cr[0] + 1) * interval, ymin + (cr[1] + 1) * interval
      ];
    }

    function makeCellPolygon(idx, opts) {
      var coords = opts.circles ?
        makeCircleCoords(idx, opts) :
        makeCellCoords(idx, opts);
      return {
        type: 'Polygon',
        coordinates: [coords]
      };
    }

    function makeCellCoords(idx, opts) {
      var bbox = idxToBBox(idx);
      var margin = opts.interval * (opts.cell_margin || 0);
      var a = bbox[0] + margin,
          b = bbox[1] + margin,
          c = bbox[2] - margin,
          d = bbox[3] - margin;
      return [[a, b],[a, d],[c, d],[c, b],[a, b]];
    }

    function makeCircleCoords(idx, opts) {
      var center = idxToPoint(idx);
      var margin = opts.cell_margin > 0 ? opts.cell_margin : 1e-6;
      var radius = opts.interval / 2 * (1 - margin);
      var vertices = opts.vertices || 20;
      return getPointBufferCoordinates(center, radius, vertices, getPlanarSegmentEndpoint);
    }

    function forEachNeighbor(c, r, cb) {
      cb(c+1, r+1);
      cb(c+1, r);
      cb(c+1, r-1);
      cb(c, r+1);
      cb(c, r-1);
      cb(c-1, r+1);
      cb(c-1, r);
      cb(c-1, r-1);
    }

    return {
      // size,
      // pointToCol,
      // pointToRow,
      // makeCellCoords,
      // makeCircleCoords,
      cells,
      colRowToIdx,
      pointToIdx,
      idxToColRow,
      // idxToRow,
      idxToBBox,
      idxToPoint,
      makeCellPolygon,
      forEachNeighbor
    };
  }

  cmd.polygonGrid = function(targetLayers, targetDataset, opts) {
    requireProjectedDataset(targetDataset);
    var params = getGridParams(targetLayers, targetDataset, opts);
    var gridDataset = makeGridDataset(params); // grid is a new dataset
    gridDataset.info = copyDatasetInfo(targetDataset.info);
    setOutputLayerName(gridDataset.layers[0], null, 'grid', opts);
    if (opts.debug) gridDataset.layers.push(cmd.pointGrid2(targetLayers, targetDataset, opts));
    return gridDataset;
  };


  // TODO: Update -point-grid command to use this function
  cmd.polygonGrid2 = function(targetLayers, targetDataset, opts) {
    requireProjectedDataset(targetDataset);
    var params = getGridParams(targetLayers, targetDataset, opts);
    // alignGridToBounds(geojson, params.bbox);
    var gridDataset = makeGridDataset2(params, opts);
    gridDataset.info = copyDatasetInfo(targetDataset.info);
    setOutputLayerName(gridDataset.layers[0], null, 'grid', opts);
    return gridDataset;
  };

  function makeGridDataset2(params, opts) {
    var geojson, dataset, grid;
    if (params.type == 'square') {
      grid = getSquareGridMaker(params.bbox, params.interval, opts);
    } else if (params.type == 'hex') {
      grid = getHexGridMaker(params.bbox, params.interval, opts);
    } else {
      stop('Unsupported grid type');
    }
    var features = [];
    for (var i=0, n=grid.cells(); i<n; i++) {
      features.push({
        type: 'Feature',
        properties: null,
        geometry: grid.makeCellPolygon(i, opts)
      });
    }
    geojson = {
      type: 'FeatureCollection',
      features: features
    };
    dataset = importGeoJSON(geojson, {});
    buildTopology(dataset);
    return dataset;
  }

  // TODO: Update -point-grid command to use this function
  cmd.pointGrid2 = function(targetLayers, targetDataset, opts) {
    var params = getGridParams(targetLayers, targetDataset, opts);
    var geojson;
    if (params.type == 'square') {
      geojson = getPointGridGeoJSON(getSquareGridCoordinates(params));
    } else if (params.type == 'hex') {
      geojson = getPointGridGeoJSON(getHexGridCoordinates(params));
    } else {
      stop('Unsupported grid type');
    }
    alignGridToBounds(geojson, params.bbox);
    var gridDataset = importGeoJSON(geojson, {});
    if (opts.name) gridDataset.layers[0].name = opts.name;
    return gridDataset.layers[0];
  };

  function makeGridDataset(params, opts) {
    var geojson, dataset;
    if (params.type == 'square') {
      geojson = getSquareGridGeoJSON(getSquareGridCoordinates(params));
    } else if (params.type == 'hex') {
      geojson = getHexGridGeoJSON(getHexGridCoordinates(params));
    } else if (params.type == 'hex2') {
      // use rotated grid
      geojson = getHexGridGeoJSON(getHexGridCoordinates(swapGridParams(params)));
      swapPolygonCoords(geojson);
    } else {
      stop('Unsupported grid type');
    }
    alignGridToBounds(geojson, params.bbox);
    dataset = importGeoJSON(geojson, {});
    buildTopology(dataset);
    return dataset;
  }

  function swapGridParams(params) {
    var bbox = params.bbox;
    return utils.defaults({
      width: params.height,
      height: params.width,
      bbox: [bbox[1], bbox[0], bbox[3], bbox[2]]
    }, params);
  }

  function swapPolygonCoords(json) {
    json.geometries.forEach(function(geom) {
      geom.coordinates[0] = geom.coordinates[0].map(function(p) {
        return [p[1], p[0]];
      });
    });
  }

  function getGridParams(layers, dataset, opts) {
    var params = {};
    var crs = dataset ? getDatasetCRS(dataset) : null;
    if (opts.interval) {
      params.interval = convertIntervalParam(opts.interval, crs);
    } else {
      stop('Missing required interval option');
    }
    if (opts.bbox) {
      params.bbox = opts.bbox;
    } else if (dataset) {
      dataset = utils.defaults({layers: layers}, dataset);
      params.bbox = getDatasetBounds(dataset).toArray();
    } else {
      stop('Missing grid bbox');
    }
    params.width = params.bbox[2] - params.bbox[0];
    params.height = params.bbox[3] - params.bbox[1];
    params.type = opts.type || 'square';
    return params;
  }

  function getPointGridGeoJSON(arr) {
    var geometries = [];
    arr.forEach(function(row) {
      row.forEach(function(xy) {
        geometries.push({
          type: 'Point',
          coordinates: xy
        });
      });
    });
    return {type: 'GeometryCollection', geometries: geometries};
  }

  function getHexGridGeoJSON(arr) {
    var geometries = [], a, b, c, d, e, f;
    var rows = arr.length - 2;
    var row, col, midOffset, evenRow;
    for (row = 0; row < rows; row++) {
      evenRow = row % 2 === 0;
      col = evenRow ? 0 : 2;
      midOffset = evenRow ? 0 : -1;
      for (; true; col += 3) {
        a = arr[row][col];
        b = arr[row + 1][col + midOffset]; // middle-left
        c = arr[row + 2][col];
        d = arr[row + 2][col + 1];
        e = arr[row + 1][col + 2 + midOffset]; // middle-right
        f = arr[row][col + 1];
        if (!d || !e) break; // end of row
        geometries.push({
          type: 'Polygon',
          coordinates: [[a, b, c, d, e, f, a]]
        });
      }
    }
    return {type: 'GeometryCollection', geometries: geometries};
  }

  function getSquareGridGeoJSON(arr) {
    var geometries = [], a, b, c, d;
    for (var row = 0, rows = arr.length - 1; row < rows; row++) {
      for (var col = 0, cols = arr[row].length - 1; col < cols; col++) {
        a = arr[row][col];
        b = arr[row + 1][col];
        c = arr[row + 1][col + 1];
        d = arr[row][col + 1];
        geometries.push({
          type: 'Polygon',
          coordinates: [[a, b, c, d, a]]
        });
      }
    }
    return {type: 'GeometryCollection', geometries: geometries};
  }

  function getHexGridCoordinates(params) {
    var xInterval = params.interval;
    var yInterval = Math.sqrt(3) * xInterval / 2;
    var xOddRowShift = xInterval / 2;
    var xmax = params.width + xInterval * 2; // width of hexagon is 2 * xInterval
    var ymax = params.height + yInterval * 2; // height of hexagon is 2 * yInterval
    var y = -yInterval;
    var rows = [];
    var x, row;
    while (y < ymax) {
      x = rows.length % 2 === 0 ? 0 : -xOddRowShift;
      row = [];
      rows.push(row);
      while (x < xmax) {
        row.push([x, y]);
        x += xInterval;
      }
      y += yInterval;
    }
    return rows;
  }

  function getSquareGridCoordinates(params) {
    var y = 0, rows = [],
        interval = params.interval,
        xmax = params.width + interval,
        ymax = params.height + interval,
        x, row;
    while (y < ymax) {
      x = 0;
      row = [];
      rows.push(row);
      while (x < xmax) {
        row.push([x, y]);
        x += interval;
      }
      y += interval;
    }
    return rows;
  }

  function alignGridToBounds(geojson, bbox) {
    var geojsonBbox = findPolygonGridBounds(geojson);
    var dx = (bbox[2] + bbox[0]) / 2 - (geojsonBbox[2] + geojsonBbox[0]) / 2;
    var dy = (bbox[3] + bbox[1]) / 2 - (geojsonBbox[3] + geojsonBbox[1]) / 2;
    shiftPolygonGrid(geojson, dx, dy);
  }

  function shiftPolygonGrid(geojson, dx, dy) {
    geojson.geometries.forEach(function(geom) {
      if (geom.type == 'Point') {
        geom.coordinates = [geom.coordinates[0] + dx, geom.coordinates[1] + dy];
      }
      if (geom.type == 'Polygon') {
        geom.coordinates[0] = geom.coordinates[0].map(function(xy) {
          return [xy[0] + dx, xy[1] + dy];
        });
      }
    });
  }

  function findPolygonGridBounds(geojson) {
    var boundsFunctions = {
      Point: pointBounds,
      Polygon: polygonBounds
    };
    return geojson.geometries.reduce(function(memo, geom) {
      var getBounds = boundsFunctions[geom.type];
      var bbox = getBounds(geom);
      if (!memo) return bbox;
      updateBounds(memo, bbox[0], bbox[1]);
      updateBounds(memo, bbox[2], bbox[3]);
      return memo;
    }, null);

    function polygonBounds(geom) {
      return geom.coordinates[0].reduce(function(bbox, p) {
        if (!bbox) return [p[0], p[1], p[0], p[1]];
        updateBounds(bbox, p[0], p[1]);
        return bbox;
      }, null);
    }

    function pointBounds(geom) {
      var p = geom.coordinates;
      return [p[0], p[1], p[0], p[1]];
    }

    function updateBounds(bbox, x, y) {
      if (x < bbox[0]) bbox[0] = x;
      if (y < bbox[1]) bbox[1] = y;
      if (x > bbox[2]) bbox[2] = x;
      if (y > bbox[3]) bbox[3] = y;
    }
  }

  cmd.pointGrid = function(dataset, opts) {
    var gridOpts = getPointGridParams(dataset, opts);
    var lyr = createPointGridLayer(createPointGrid(gridOpts));
    setOutputLayerName(lyr, null, 'grid', opts);
    return lyr;
  };

  function getPointGridParams(dataset, opts) {
    var params = {};
    var crs = dataset ? getDatasetCRS(dataset) : null;
    if (opts.interval) {
      params.interval = convertIntervalParam(opts.interval, crs);
    } else if (opts.rows > 0 && opts.cols > 0) {
      params.rows = opts.rows;
      params.cols = opts.cols;
    } else ;
    if (opts.bbox) {
      params.bbox = opts.bbox;
    } else if (dataset) {
      params.bbox = getDatasetBounds(dataset).toArray();
    } else {
      params.bbox = [-180, -90, 180, 90];
    }
    return params;
  }

  function createPointGridLayer(rows, opts) {
    var points = [];
    rows.forEach(function(row, rowId) {
      for (var i=0; i<row.length; i++) {
        points.push([row[i]]);
      }
    });
    return {
      geometry_type: 'point',
      shapes: points
    };
  }


  // Returns a grid of [x,y] points so that point(c,r) == arr[r][c]
  function createPointGrid(opts) {
    var bbox = opts.bbox,
        w = bbox[2] - bbox[0],
        h = bbox[3] - bbox[1],
        rowsArr = [], rowArr,
        cols, rows, dx, dy, x0, y0, x, y;

    if (opts.interval > 0) {
      dx = opts.interval;
      dy = opts.interval;
      cols = Math.round(w / dx) - 1;
      rows = Math.round(h / dy) - 1;
      x0 = bbox[0] + (w - cols * dx) / 2;
      y0 = bbox[1] + (h - rows * dy) / 2;
    } else if (opts.rows > 0 && opts.cols > 0) {
      cols = opts.cols;
      rows = opts.rows;
      dx = (w / cols);
      dy = (h / rows);
      x0 = bbox[0] + dx / 2;
      y0 = bbox[1] + dy / 2;
    }

    if (dx > 0 === false || dy > 0 === false) {
      stop('Invalid grid parameters');
    }

    y = y0;
    while (y <= bbox[3]) {
      x = x0;
      rowsArr.push(rowArr = []);
      while (x <= bbox[2]) {
        rowArr.push([x, y]);
        x += dx;
      }
      y += dy;
    }
    return rowsArr;
  }

  // Source: https://diego.assencio.com/?index=8d6ca3d82151bad815f78addf9b5c1c6
  function twoCircleIntersection(c1, r1, c2, r2) {
    var d = distance2D(c1[0], c1[1], c2[0], c2[1]);
    if (d >= r1 + r2) return 0;
    var r1sq = r1 * r1,
        r2sq = r2 * r2,
        d1 = (r1sq - r2sq + d * d) / (2 * d),
        d2 = d - d1;
    if (d <= Math.abs(r1 - r2)) {
      return Math.PI * Math.min(r1sq, r2sq);
    }
    return r1sq * Math.acos(d1/r1) - d1 * Math.sqrt(r1sq - d1 * d1) +
      r2sq * Math.acos(d2/r2) - d2 * Math.sqrt(r2sq - d2 * d2);
  }

  // Returns a function that receives a cell index and returns indices of points
  //   within a given distance of the cell.
  function getGridToPointIndex(points, grid, radius) {
    var Flatbush = require('flatbush');
    var gridIndex = new IdTestIndex(grid.cells());
    var bboxIndex = new Flatbush(points.length);
    var empty = [];
    points.forEach(function(p) {
      var bbox = getPointBounds(p, radius);
      var addNeighbors = true; // TODO: only if radius is > 0?
      addPointToGridIndex(p, gridIndex, grid, addNeighbors);
      bboxIndex.add.apply(bboxIndex, bbox);
    });
    bboxIndex.finish();

    return function(i) {
      if (!gridIndex.hasId(i)) {
        return empty;
      }
      var bbox = grid.idxToBBox(i);
      var indices = bboxIndex.search.apply(bboxIndex, bbox);
      return indices;
    };
  }

  // TODO: support spherical coords
  function getPointBounds(p, radius) {
    return [p[0] - radius, p[1] - radius, p[0] + radius, p[1] + radius];
  }

  function addPointToGridIndex(p, index, grid, addNeighbors) {
    var i = grid.pointToIdx(p);
    var [c, r] = grid.idxToColRow(i);
    addCellToGridIndex(c, r, grid, index);
    if (addNeighbors) {
      grid.forEachNeighbor(c, r, function(c, r) {
        addCellToGridIndex(c, r, grid, index);
      });
    }
  }

  function addCellToGridIndex(c, r, grid, index) {
    var i = grid.colRowToIdx(c, r);
    if (i > -1) index.setId(i);
  }

  cmd.pointToGrid = function(targetLayers, targetDataset, opts) {
    targetLayers.forEach(requirePointLayer);
    if (opts.interval > 0 === false) {
      stop('Expected a non-negative interval parameter');
    }
    if (opts.radius > 0 === false) ;
    // var bbox = getLayerBounds(pointLyr).toArray();
    // Use target dataset, so grids are aligned between layers
    // TODO: align grids between datasets
    var bbox = getDatasetBounds(targetDataset).toArray();

    var datasets = [targetDataset];
    var outputLayers = targetLayers.map(function(pointLyr) {
      if (countMultiPartFeatures(pointLyr) > 0) {
        stop('This command requires single points');
      }
      var dataset = getPolygonDataset(pointLyr, bbox, opts);
      var gridLyr = dataset.layers[0];
      datasets.push(dataset);
      setOutputLayerName(gridLyr, pointLyr, 'grid', opts);
      return gridLyr;
    });

    var merged = mergeDatasets(datasets);
    // build topology for the entire dataset, in case the command is used on
    // multiple target layers.
    buildTopology(merged);
    targetDataset.arcs = merged.arcs;
    return outputLayers;
  };

  function getPolygonDataset(pointLyr, gridBBox, opts) {
    var points = getPointsInLayer(pointLyr);
    var cellSize = opts.interval;
    var grid = getSquareGridMaker(gridBBox, cellSize, opts);
    var pointCircleRadius = getPointCircleRadius(opts);
    var findPointIdsByCellId = getGridToPointIndex(points, grid, pointCircleRadius);
    var geojson = {
      type: 'FeatureCollection',
      features: []
    };
    var calc = opts.calc ? getJoinCalc(pointLyr.data, opts.calc) : null;
    var candidateIds, weights, center, d;

    for (var i=0, n=grid.cells(); i<n; i++) {
      candidateIds = findPointIdsByCellId(i);
      if (!candidateIds.length) continue;
      center = grid.idxToPoint(i);
      weights = calcWeights(center, cellSize, points, candidateIds, pointCircleRadius);
      d = calcCellProperties(candidateIds, weights, calc);
      if (d.weight > 0.05 === false) continue;
      d.id = i;
      geojson.features.push({
        type: 'Feature',
        properties: d,
        geometry: grid.makeCellPolygon(i, opts)
      });
    }
    return importGeoJSON(geojson, {});
  }

  function getPointCircleRadius(opts) {
    var cellRadius = opts.interval * Math.sqrt(1 / Math.PI);
    return opts.radius > 0 ? opts.radius : cellRadius;
  }

  function calcCellProperties(pointIds, weights, calc) {
    var hitIds = [];
    var weight = 0;
    var partial;
    var d;
    for (var i=0; i<pointIds.length; i++) {
      partial = weights[i];
      if (partial > 0 === false) continue;
      weight += partial;
      hitIds.push(pointIds[i]);
    }
    d = {weight: weight};
    if (calc) {
      calc(hitIds, d);
    }
    return d;
  }

  function calcWeights(cellCenter, cellSize, points, pointIds, pointRadius) {
    var weights = [];
    var cellRadius = cellSize * Math.sqrt(1 / Math.PI); // radius of circle with same area as cell
    var cellArea = cellSize * cellSize;
    var w;
    for (var i=0; i<pointIds.length; i++) {
      w = twoCircleIntersection(cellCenter, cellRadius, points[pointIds[i]], pointRadius) / cellArea;
      weights.push(w);
    }
    return weights;
  }

  // function getPointsByIndex(points, indices) {
  //   var arr = [];
  //   for (var i=0; i<indices.length; i++) {
  //     arr.push(points[indices[i]]);
  //   }
  //   return arr;
  // }

  var PointToGrid = /*#__PURE__*/Object.freeze({
    __proto__: null,
    getPointCircleRadius: getPointCircleRadius,
    calcCellProperties: calcCellProperties,
    calcWeights: calcWeights
  });

  function closeUndershoots(lyr, dataset, opts) {
    var maxGapLen = opts.gap_tolerance ? convertIntervalParam(opts.gap_tolerance, getDatasetCRS(dataset)) : 0;
    var arcs = dataset.arcs;
    var arcFilter = getArcPresenceTest(lyr.shapes, arcs);
    var nodes = new NodeCollection(dataset.arcs, arcFilter);
    var dangles = findPotentialUndershoots(nodes, maxGapLen);
    if (dangles.length === 0) return nodes;
    var arcShapes = arcsToShapes(arcs, arcFilter);
    var index = new PathIndex(arcShapes, arcs);
    var extensions = dangles.reduce(function(memo, dangle) {
      var candidates = index.findPointEnclosureCandidates(dangle.point, maxGapLen);
      var nearestHit = findUndershootTarget(dangle, candidates, arcs, maxGapLen);
      if (nearestHit) {
        memo.push(getArcExtension(nearestHit, dangle.arc, arcs));
      }
      return memo;
    }, []);

    // TODO: consider alternative: append small patch arcs to paths instead of shifting endpoints
    dataset.arcs = insertArcExtensions(arcs, extensions);
    return addIntersectionCuts(dataset, {});
  }

  // Return information about an arc that @endpoint can connect with to close a gap
  // @candidates: array of ids of possible target arcs
  function findUndershootTarget(endpoint, candidates, arcs, maxGapLen) {
    var absId = absArcId(endpoint.arc);
    var target = null;
    candidates.forEach(function(candId) {
      var hit;
      if (candId == absId) return; // ignore self-intersections
      if (absArcId(candId) >= arcs.size()) {
        return;
      }
      hit = geom.getPointToPathInfo(endpoint.point[0], endpoint.point[1], [candId], arcs);
      if (hit && hit.distance <= maxGapLen && (!target || hit.distance < target.distance)) {
        target = hit;
      }
    });
    return target;
  }


  // Create a polyline shape for each arc in an ArcCollection
  function arcsToShapes(arcs, filter) {
    var shapes = [];
    for (var i=0, n=arcs.size(); i<n; i++) {
      shapes.push(filter(i) ? [[i]] : null);
    }
    return shapes;
  }

  // Find unconnected (dangling) arcs that don't look like overshoots
  function findPotentialUndershoots(nodes, maxLen) {
    return nodes.findDanglingEndpoints().filter(function(o) {
      return geom.calcPathLen([o.arc], nodes.arcs) > maxLen;
    });
  }

  function insertArcExtensions(arcs, extensions) {
    var data = arcs.getVertexData();
    extensions.forEach(function(obj) {
      var i = arcs.indexOfVertex(obj.arc, -1);
      data.xx[i] = obj.point[0];
      data.yy[i] = obj.point[1];
    });

    // re-index arc bounds
    arcs.updateVertexData(data.nn, data.xx, data.yy, data.zz);
    return arcs;
  }

  function chooseCloserPoint(p, a, b) {
    return geom.distance2D(p[0], p[1], a[0], a[1]) < geom.distance2D(p[0], p[1], b[0], b[1]) ? a : b;
  }

  function pointIsEndpoint(p, a, b) {
    return p[0] == a[0] && p[1] == a[1] || p[0] == b[0] && p[1] == b[1];
  }

  // move point <b> a bit farther away from <a>
  function addTinyOvershoot(a, b) {
    var dist = geom.distance2D(a[0], a[1], b[0], b[1]);
    var k = (dist + 1e-6) / dist;
    return [a[0] + k * (b[0] - a[0]), a[1] + k * (b[1] - a[1])];
  }

  function getArcExtension(hit, arcId, arcs) {
    var v0 = arcs.getVertex(arcId, -1),
        endPtOld = [v0.x, v0.y],
        v1 = arcs.getVertex(arcId, -2),
        p1 = [v1.x, v1.y],
        s1 = hit.segment[0],
        s2 = hit.segment[1],
        endPtNew = geom.findClosestPointOnSeg(endPtOld[0], endPtOld[1], s1[0], s1[1], s2[0], s2[1]);
    if (!pointIsEndpoint(endPtNew, s1, s2)) {
      // add small overshoot if new endpoint is not a vertex, to make sure intersection
      // is correctly detected later
      endPtNew = addTinyOvershoot(p1, endPtNew);
      // handle floating point rounding errors by snapping to a segment endpoint
      if (!geom.segmentIntersection(p1[0], p1[1], endPtNew[0], endPtNew[1], s1[0], s1[1], s2[0], s2[1])) {
        endPtNew = chooseCloserPoint(p1, s1, s2);
      }
      // TODO: test edge cases; moving the endpoint of a dangling arc could create
      //   invalid geometry, e.g. duplicate points
    }
    return {
      arc: arcId,
      point: endPtNew
    };
  }

  cmd.polygons = function(layers, dataset, opts) {
    layers.forEach(requirePolylineLayer);
    // use larger-than-default snapping in addIntersectionCuts()
    // (kludge, snaps together some almost-identical pairs of lines in ne_10m_land_ocean_seams.shp)
    // if (opts.gap_tolerance) {
      //opts = utils.defaults({snap_interval: opts.gap_tolerance * 0.1}, opts);
    // }
    if (!opts.no_cuts) {
      addIntersectionCuts(dataset, opts);
    }
    return layers.map(function(lyr) {
      if (lyr.geometry_type != 'polyline') stop("Expected a polyline layer");
      if (opts.from_rings) {
        return createPolygonLayerFromRings(lyr, dataset);
      }
      return createPolygonLayer(lyr, dataset, opts);
    });
  };

  // Convert a polyline layer of rings to a polygon layer
  function createPolygonLayerFromRings(lyr, dataset) {
    var arcs = dataset.arcs;
    var openCount = 0;
    editShapes(lyr.shapes, function(part) {
      if (geom.pathIsClosed(part, arcs)) {
        return part;
      }
      openCount++;
      return null;
    });
    if (openCount > 0) {
      message('Removed', openCount, 'open ' + (openCount == 1 ? 'ring' : 'rings'));
    }
    lyr.geometry_type = 'polygon';
    rewindPolygons(lyr, arcs);
    return lyr;
  }

  function createPolygonLayer(lyr, dataset, opts) {
    var nodes;
    if (opts.no_cuts) {
      nodes = new NodeCollection(dataset.arcs);
    } else {
      nodes = closeUndershoots(lyr, dataset, opts);
    }
    // ignore arcs that don't belong to this layer
    nodes.setArcFilter(getArcPresenceTest(lyr.shapes, nodes.arcs));
    var data = buildPolygonMosaic(nodes);
    return {
      geometry_type: 'polygon',
      name: lyr.name,
      shapes: data.mosaic
    };
  }

  cmd.print = function(msgArg) {
    print(msgArg || '');
  };

  cmd.renameLayers = function(layers, names, catalog) {
    if (names && names.join('').indexOf('=') > -1) {
      renameByAssignment(names, catalog);
    } else {
      renameTargetLayers(names, layers);
    }
  };

  function renameByAssignment(names, catalog) {
    var index = mapLayerNames(names);
    catalog.forEachLayer(function(lyr) {
      if (index[lyr.name]) {
        lyr.name = index[lyr.name];
      }
    });
  }

  function renameTargetLayers(names, layers) {
    var nameCount = names && names.length || 0;
    var name = '';
    var suffix = '';
    layers.forEach(function(lyr, i) {
      if (i < nameCount) {
        name = names[i];
      }
      if (name && nameCount < layers.length && (i >= nameCount - 1)) {
        suffix = (suffix || 0) + 1;
      }
      lyr.name = name + suffix;
    });
  }

  // TODO: remove duplication with mapFieldNames()
  function mapLayerNames(names) {
    return (names || []).reduce(function(memo, str) {
      var parts = str.split('='),
          dest = utils.trimQuotes(parts[0]),
          src = utils.trimQuotes(parts[1] || '');
      if (!src) stop("Invalid name assignment:", str);
      memo[src] = dest;
      return memo;
    }, {});
  }

  // Support for evaluating expressions embedded in curly-brace templates

  // Returns: a string (e.g. a command string used by the -run command)
  async function evalTemplateExpression(expression, targets, ctx) {
    ctx = ctx || getBaseContext();
    // TODO: throw an error if target is used when there are multiple targets
    addTargetProxies(targets, ctx);
    // Add global functions and data to the expression context
    // (e.g. functions imported via the -require command)
    var globals = getStashedVar('defs') || {};
    ctx.global = globals;
    utils.extend(ctx, ctx.global);

    var output = await compileTemplate(expression, ctx);
    if (hasFunctionCall(output, ctx)) {
      // also evaluate function calls that are not enclosed in curly braces
      // (convenience syntax)
      output = await evalExpression(output, ctx);
    }
    return output;
  }

  async function compileTemplate(template, ctx) {
    var subExpressions = parseTemplate(template);
    var promises = subExpressions.map(expr => evalExpression(expr, ctx));
    var replacements = await Promise.all(promises);
    return applyReplacements(template, replacements);
  }

  async function evalExpression(expression, ctx) {
    var output;
    try {
      output = Function('ctx', 'with(ctx) {return (' + expression + ');}').call({}, ctx);
    } catch(e) {
      stop(e.name, 'in JS source:', e.message);
    }
    return output;
  }

  // Returns array of 0 or more embedded curly-brace expressions
  function parseTemplate(str) {
    var arr = [];
    parseTemplateParts(str).forEach(function(s, i) {
      if (i % 2 == 1) {
        arr.push(s.substring(1, s.length-1)); // remove braces
      }
    });
    return arr;
  }

  // template: template string
  // replacements: array of strings or values that can be coerced to strings
  function applyReplacements(template, replacements) {
    var parts = parseTemplateParts(template);
    return parts.reduce(function(memo, s, i) {
      if (i % 2 == 1) {
        memo += replacements.length ? replacements.shift() : '';
      } else {
        memo += s;
      }
      return memo;
    }, '');
  }

  // Divides a string into substrings; even-index strings contain literal strings,
  // Odd-indexed strings contain curly-brace-delimited template expressions.
  // JSON objects are treated as literal strings; other top-level curly braces are
  //    assumed to be embedded expressions.
  // For example:  parseTemplateParts('{"hello"}, world!') => ['', '{"hello"}', ', world!']
  //
  function parseTemplateParts(str) {
    // TODO: consider adding \ escapes
    var depth=0;
    var parts = [];
    var part = '';
    var c;

    for (var i=0, n=str.length; i<n; i++) {
      c = str.charAt(i);
      if (c == '{') {
        if (depth == 0) {
          parts.push(part);
          part = '';
        }
        depth++;
      }
      part += c;
      if (c == '}') {
        depth--;
        if (depth < 0) {
          // unexpected... throw an error?
          depth++;
        } else if (depth == 0 && isValidJSON(part)) {
          // embedded JSON objects are not template parts -- undo
          part = parts.pop() + part;
        } else if (depth == 0) {
          parts.push(part);
          part = '';
        }
      }
    }
    parts.push(part);
    return parts;
  }

  // Tests if an expression string contains a call to an indexed function
  // defs: Object containing functions indexed by function name
  function hasFunctionCall(str, defs) {
    var rxp = /([$_a-z][$_a-z0-9]*)\(/ig;
    return Array.from(str.matchAll(rxp)).some(match => match[1] in defs);
  }

  function isValidJSON(str) {
    try {
      JSON.parse(str);
    } catch(e) {
      return false;
    }
    return true;
  }

  cmd.require = async function(opts) {
    var globals = getStashedVar('defs');
    var moduleFile, moduleName, mod;
    if (!opts.module) {
      stop("Missing module name or path to module");
    }
    if (cli.isFile(opts.module)) {
      moduleFile = opts.module;
    } else if (cli.isFile(opts.module + '.js')) {
      moduleFile = opts.module + '.js';
    } else {
      moduleName = opts.module;
    }
    try {
      // import CJS and ES modules
      mod = await import(moduleFile ? require$1('url').pathToFileURL(moduleFile) : moduleName);
      if (mod.default) {
        mod = mod.default;
      }
      if (typeof mod == 'function') {
        // assuming that functions are mapshaper command generators...
        // this MUST be changed asap.
        var retn = mod(api);
        if (retn && isValidExternalCommand(retn)) {
          cmd.registerCommand(retn.name, retn);
        }
      }
    } catch(e) {
      if (!mod) {
        stop('Unable to load external module:', e.message, getErrorDetail(e));
      }
    }
    if (moduleName || opts.alias) {
      globals[opts.alias || moduleName] = mod;
    } else {
      Object.assign(globals, mod);
    }
    // instead of an init expression, you could use -run <expression>
    // if (opts.init) {
    //   await evalTemplateExpression(opts.init, targets);
    // }
  };

  // Parse an array or a string of command line tokens into an array of
  // command objects.
  function parseCommands(tokens) {
    if (Array.isArray(tokens) && utils.isObject(tokens[0])) {
      // argv seems to contain parsed commands already... make a copy
      return tokens.map(function(cmd) {
        return {name: cmd.name, options: Object.assign({}, cmd.options)};
      });
    }
    if (utils.isString(tokens)) {
      tokens = splitShellTokens(tokens);
    }
    return getOptionParser().parseArgv(tokens);
  }

  function standardizeConsoleCommands(raw) {
    var str = raw.replace(/^mapshaper\b/, '').trim();
    getOptionParser();
    // support multiline string of commands pasted into console
    str = str.split(/\n+/g).map(function(str) {
      var match = /^[a-z][\w-]*/i.exec(str = str.trim());
      //if (match && parser.isCommandName(match[0])) {
      if (match) {
        // add hyphen prefix to bare command
        // also add hyphen to non-command strings, for a better error message
        // ("unsupported command" instead of "The -i command cannot be run in the browser")
        str = '-' + str;
      }
      return str;
    }).join(' ');
    return str;
  }

  // Parse a command line string for the browser console
  function parseConsoleCommands(raw) {
    var str = standardizeConsoleCommands(raw);
    var parsed = parseCommands(str);
    parsed.forEach(function(cmd) {
      if (['i', 'include', 'require', 'external'].includes(cmd.name)) {
        stop('The ' + cmd.name + ' command cannot be run in the web console.');
      }
    });
    return parsed;
  }

  var ParseCommands = /*#__PURE__*/Object.freeze({
    __proto__: null,
    parseCommands: parseCommands,
    standardizeConsoleCommands: standardizeConsoleCommands,
    parseConsoleCommands: parseConsoleCommands
  });

  function getIOProxy(job) {
    async function addInputFile(filename, content) {
      if (utils.isPromise(content)) {
        content = await content;
      }
      io._cache[filename] = content;
      return filename; // return filename to support -run '-i {io.ifile()}'
    }
    var io = {
      _cache: {},
      addInputFile,
      ifile: addInputFile // ifile() is an alias for addInputFile
    };
    return io;
  }

  function commandTakesFileInput(name) {
    return (name == 'i' || name == 'join' || name == 'erase' || name == 'clip' || name == 'include');
  }

  // TODO: implement these and other functions
  // TODO: move this info into individual command definitions (to make
  //   commands more modular and support a future plugin system)

  // export function commandMayRemoveArcs(cmd) {

  // }

  // export function commandMayChangeArcs(cmd) {
  //   // return arcsMayHaveChanged({[cmd]: true});
  // }

  // export function arcsMayNeedCleanup(flags) {
  //   return flags.clip || flags.erase || flags.slice || flags.rectangle || flags.buffer ||
  //   flags.union || flags.clean || flags.drop || false;
  // }

  // export function arcsMayBeChanged(flags) {
  //   return arcsMayNeedCleanup(flags) || flags.proj || flags.simplify ||
  //     flags.simplify_method || flags.arc_count || flags.repair || flags.affine ||
  //     flags.mosaic || flags.snap;
  // }

  cmd.run = async function(job, targets, opts) {
    var tmp, commands, ctx;
    if (!opts.expression) {
      stop("Missing expression parameter");
    }
    ctx = getBaseContext();
    // io proxy adds ability to add datasets dynamically in a required function
    ctx.io = getIOProxy();
    tmp = await evalTemplateExpression(opts.expression, targets, ctx);
    if (tmp && !utils.isString(tmp)) {
      stop('Expected a string containing mapshaper commands; received:', tmp);
    }
    if (tmp) {
      // truncate message (command might include a large GeoJSON string in an -i command)
      message(`command: [${truncateString(tmp, 150)}]`);
      commands = parseCommands(tmp);

      // TODO: remove duplication with mapshaper-run-commands.mjs
      commands.forEach(function(cmd) {
        if (commandTakesFileInput(cmd.name)) {
          cmd.options.input = ctx.io._cache;
        }
      });

      await utils.promisify(runParsedCommands)(commands, job);
    }
  };

  cmd.shape = function(targetDataset, opts) {
    var geojson, dataset;
    if (opts.coordinates) {
      geojson = makeShapeFromCoords(opts);
    } else if (opts.type == 'circle') {
      geojson = makeCircle(opts);
    } else if (opts.type == 'rectangle' && opts.bbox) {
      geojson = getRectangleGeoJSON(opts);
    } else {
      stop('Missing coordinates parameter');
    }
    // TODO: project shape if targetDataset is projected
    dataset = importGeoJSON(geojson, {});
    if (opts.rotation) {
      rotateDatasetCoords(dataset, opts.rotation);
    }
    dataset.layers[0].name = opts.name || opts.type || 'shape';
    return dataset;
  };

  function getRectangleGeoJSON(opts) {
    var bbox = opts.bbox,
        xmin = bbox[0],
        ymin = bbox[1],
        xmax = bbox[2],
        ymax = bbox[3],
        interval = 0.5,
        coords = [],
        type = opts.geometry == 'polyline' ? 'LineString' : 'Polygon';
    addSide(xmin, ymin, xmin, ymax);
    addSide(xmin, ymax, xmax, ymax);
    addSide(xmax, ymax, xmax, ymin);
    addSide(xmax, ymin, xmin, ymin);
    coords.push([xmin, ymin]);
    return {
      type: type,
      coordinates: type == 'Polygon' ? [coords] : coords
    };

    function addSide(x1, y1, x2, y2) {
      var dx = x2 - x1,
          dy = y2 - y1,
          n = Math.ceil(Math.max(Math.abs(dx) / interval, Math.abs(dy) / interval)),
          xint = dx / n,
          yint = dy / n;
      for (var i=0; i<n; i++) {
        coords.push([x1 + i * xint, y1 + i * yint]);
      }
    }
  }

  function makeCircle(opts) {
    if (opts.radius > 0 === false && opts.radius_angle > 0 === false) {
      stop('Missing required radius parameter.');
    }
    var cp = opts.center || [0, 0];
    var radius = opts.radius || getCircleRadiusFromAngle(parseCrsString('wgs84'), opts.radius_angle);
    return getCircleGeoJSON(cp, radius, null, {geometry_type : opts.geometry || 'polygon'});
  }

  function makeShapeFromCoords(opts) {
    var coordinates = [];
    var offsets = opts.offsets || [];
    var coords = opts.coordinates;
    var type, i, x, y;
    if (coords.length >= 2 === false) {
      stop('Invalid coordinates parameter.');
    }
    for (i=0; i<coords.length; i+= 2) {
      x = coords[i];
      y = coords[i + 1];
      coordinates.push([x, y]);
    }
    for (i=0; i<offsets.length; i+=2) {
      x += offsets[i];
      y += offsets[i + 1];
      coordinates.push([x, y]);
    }
    if (GeoJSON.pathIsRing(coordinates)) {
      type = 'Polygon';
    } else if (opts.closed && coordinates.length >= 3) {
      type = 'Polygon';
      coordinates.push(coordinates[0]);
    } else {
      type = 'LineString';
    }
    return {
      type: type,
      coordinates: type == 'Polygon' ? [coordinates] : coordinates
    };

  }

  function calcSimplifyStats(arcs, use3D) {
    var distSq = use3D ? pointSegGeoDistSq : geom.pointSegDistSq,
        calcAngle = use3D ? geom.signedAngleSph : geom.signedAngle,
        removed = 0,
        retained = 0,
        collapsedRings = 0,
        max = 0,
        sum = 0,
        iprev = -1,
        jprev = -1,
        measures = [],
        angles = [],
        zz = arcs.getVertexData().zz,
        stats;

    arcs.forEachSegment(function(i, j, xx, yy) {
      var ax, ay, bx, by, d2, d, skipped, angle, tmp;
      ax = xx[i];
      ay = yy[i];
      bx = xx[j];
      by = yy[j];

      if (i == jprev) {
        angle = calcAngle(xx[iprev], yy[iprev], ax, ay, bx, by);
        if (angle > Math.PI) angle = 2 * Math.PI - angle;
        if (!isNaN(angle)) {
          angles.push(angle * 180 / Math.PI);
        }
      }
      iprev = i;
      jprev = j;

      if (zz[i] < Infinity) {
        retained++;
      }
      skipped = j - i - 1;
      if (skipped < 1) return;
      removed += skipped;

      if (ax == bx && ay == by) {
        collapsedRings++;
      } else {
        d2 = 0;
        while (++i < j) {
          tmp = distSq(xx[i], yy[i], ax, ay, bx, by);
          d2 = Math.max(d2, tmp);
        }
        d = Math.sqrt(d2);
        sum += d;
        measures.push(d);
        max = Math.max(max, d);
      }
    });

    function pointSegGeoDistSq(alng, alat, blng, blat, clng, clat) {
      var xx = [], yy = [], zz = [];
      geom.convLngLatToSph([alng, blng, clng], [alat, blat, clat], xx, yy, zz);
      return geom.pointSegDistSq3D(xx[0], yy[0], zz[0], xx[1], yy[1], zz[1],
            xx[2], yy[2], zz[2]);
    }

    stats = {
      angleMean: 0,
      displacementMean: 0,
      displacementMax: max,
      collapsedRings: collapsedRings,
      removed: removed,
      retained: retained,
      uniqueCount: countUniqueVertices(arcs),
      removableCount: removed + retained
    };

    if (angles.length > 0) {
      // stats.medianAngle = utils.findMedian(angles);
      stats.angleMean = utils.sum(angles) / angles.length;
      // stats.lt30 = utils.findRankByValue(angles, 30) / angles.length * 100;
      // stats.lt45 = utils.findRankByValue(angles, 45) / angles.length * 100;
      // stats.lt60 = utils.findRankByValue(angles, 60) / angles.length * 100;
      // stats.lt90 = utils.findRankByValue(angles, 90) / angles.length * 100;
      // stats.lt120 = utils.findRankByValue(angles, 120) / angles.length * 100;
      // stats.lt135 = utils.findRankByValue(angles, 135) / angles.length * 100;
      stats.angleQuartiles = [
        utils.findValueByPct(angles, 0.75),
        utils.findValueByPct(angles, 0.5),
        utils.findValueByPct(angles, 0.25)
      ];
    }

    if (measures.length > 0) {
      stats.displacementMean = sum / measures.length;
      // stats.median = utils.findMedian(measures);
      // stats.stdDev = Math.sqrt(sumSq / measures.length);
      stats.displacementQuartiles = [
        utils.findValueByPct(measures, 0.75),
        utils.findValueByPct(measures, 0.5),
        utils.findValueByPct(measures, 0.25)
      ];
    }
    return stats;
  }

  function countUniqueVertices(arcs) {
    // TODO: exclude any zero-length arcs
    var endpoints = arcs.size() * 2;
    var nodes = new NodeCollection(arcs).size();
    return arcs.getPointCount() - endpoints + nodes;
  }

  var Visvalingam = {};

  Visvalingam.getArcCalculator = function(metric, is3D) {
    var heap = new Heap(),
        prevBuf = utils.expandoBuffer(Int32Array),
        nextBuf = utils.expandoBuffer(Int32Array),
        calc = is3D ?
          function(b, c, d, xx, yy, zz) {
            return metric(xx[b], yy[b], zz[b], xx[c], yy[c], zz[c], xx[d], yy[d], zz[d]);
          } :
          function(b, c, d, xx, yy) {
            return metric(xx[b], yy[b], xx[c], yy[c], xx[d], yy[d]);
          };

    // Calculate Visvalingam simplification data for an arc
    // @kk (Float64Array|Array) Receives calculated simplification thresholds
    // @xx, @yy, (@zz) Buffers containing vertex coordinates
    return function calcVisvalingam(kk, xx, yy, zz) {
      var arcLen = kk.length,
          prevArr = prevBuf(arcLen),
          nextArr = nextBuf(arcLen),
          val, maxVal = -Infinity,
          b, c, d; // indexes of points along arc

      if (zz && !is3D) {
        error("[visvalingam] Received z-axis data for 2D simplification");
      } else if (!zz && is3D) {
        error("[visvalingam] Missing z-axis data for 3D simplification");
      } else if (kk.length > xx.length) {
        error("[visvalingam] Incompatible data arrays:", kk.length, xx.length);
      }

      // Initialize Visvalingam "effective area" values and references to
      //   prev/next points for each point in arc.
      for (c=0; c<arcLen; c++) {
        b = c-1;
        d = c+1;
        if (b < 0 || d >= arcLen) {
          val = Infinity; // endpoint maxVals
        } else {
          val = calc(b, c, d, xx, yy, zz);
        }
        kk[c] = val;
        nextArr[c] = d;
        prevArr[c] = b;
      }
      heap.init(kk);

      // Calculate removal thresholds for each internal point in the arc
      //
      while (heap.size() > 0) {
        c = heap.pop(); // Remove the point with the least effective area.
        val = kk[c];
        if (val === Infinity) {
          break;
        }
        if (val < maxVal) {
          // don't assign current point a lesser value than the last removed vertex
          kk[c] = maxVal;
        } else {
          maxVal = val;
        }

        // Recompute effective area of neighbors of the removed point.
        b = prevArr[c];
        d = nextArr[c];
        if (b > 0) {
          val = calc(prevArr[b], b, d, xx, yy, zz);
          heap.updateValue(b, val);
        }
        if (d < arcLen-1) {
          val = calc(b, d, nextArr[d], xx, yy, zz);
          heap.updateValue(d, val);
        }
        nextArr[b] = d;
        prevArr[d] = b;
      }
    };
  };

  Visvalingam.standardMetric = geom.triangleArea;
  Visvalingam.standardMetric3D = geom.triangleArea3D;

  Visvalingam.getWeightedMetric = function(opts) {
    var weight = Visvalingam.getWeightFunction(opts);
    return function(ax, ay, bx, by, cx, cy) {
      var area = geom.triangleArea(ax, ay, bx, by, cx, cy),
          cos = geom.cosine(ax, ay, bx, by, cx, cy);
      return weight(cos) * area;
    };
  };

  Visvalingam.getWeightedMetric3D = function(opts) {
    var weight = Visvalingam.getWeightFunction(opts);
    return function(ax, ay, az, bx, by, bz, cx, cy, cz) {
      var area = geom.triangleArea3D(ax, ay, az, bx, by, bz, cx, cy, cz),
          cos = geom.cosine3D(ax, ay, az, bx, by, bz, cx, cy, cz);
      return weight(cos) * area;
    };
  };

  Visvalingam.getWeightCoefficient = function(opts) {
    return opts && utils.isNumber(opts && opts.weighting) ? opts.weighting : 0.7;
  };

  // Get a parameterized version of Visvalingam.weight()
  Visvalingam.getWeightFunction = function(opts) {
    var k = Visvalingam.getWeightCoefficient(opts);
    return function(cos) {
      return -cos * k + 1;
    };
  };

  // Weight triangle area by inverse cosine
  // Standard weighting favors 90-deg angles; this curve peaks at 120 deg.
  Visvalingam.weight = function(cos) {
    var k = 0.7;
    return -cos * k + 1;
  };

  Visvalingam.getEffectiveAreaSimplifier = function(use3D) {
    var metric = use3D ? Visvalingam.standardMetric3D : Visvalingam.standardMetric;
    return Visvalingam.getPathSimplifier(metric, use3D);
  };

  Visvalingam.getWeightedSimplifier = function(opts, use3D) {
    var metric = use3D ? Visvalingam.getWeightedMetric3D(opts) : Visvalingam.getWeightedMetric(opts);
    return Visvalingam.getPathSimplifier(metric, use3D);
  };

  Visvalingam.getPathSimplifier = function(metric, use3D) {
    return Visvalingam.scaledSimplify(Visvalingam.getArcCalculator(metric, use3D));
  };


  Visvalingam.scaledSimplify = function(f) {
    return function(kk, xx, yy, zz) {
      f(kk, xx, yy, zz);
      for (var i=1, n=kk.length - 1; i<n; i++) {
        // convert area metric to a linear equivalent
        kk[i] = Math.sqrt(kk[i]) * 0.65;
      }
    };
  };

  function getSimplifyMethodLabel(slug) {
    return {
      dp: "Ramer-Douglas-Peucker",
      visvalingam: "Visvalingam",
      weighted_visvalingam: "Weighted Visvalingam"
    }[slug] || "Unknown";
  }

  function printSimplifyInfo(arcs, opts) {
    var method = getSimplifyMethod(opts);
    var name = getSimplifyMethodLabel(method);
    var spherical = useSphericalSimplify(arcs, opts);
    var stats = calcSimplifyStats(arcs, spherical);
    var pct1 = (stats.removed + stats.collapsedRings) / stats.uniqueCount || 0;
    var pct2 = stats.removed / stats.removableCount || 0;
    var aq = stats.angleQuartiles;
    var dq = stats.displacementQuartiles;
    var lines = ["Simplification statistics"];
    lines.push(utils.format("Method: %s (%s) %s", name, spherical ? 'spherical' : 'planar',
        method == 'weighted_visvalingam' ? '(weighting=' + Visvalingam.getWeightCoefficient(opts) + ')' : ''));
    lines.push(utils.format("Removed vertices: %,d", stats.removed + stats.collapsedRings));
    lines.push(utils.format("   %.1f% of %,d unique coordinate locations", pct1 * 100, stats.uniqueCount));
    lines.push(utils.format("   %.1f% of %,d filterable coordinate locations", pct2 * 100, stats.removableCount));
    lines.push(utils.format("Simplification threshold: %.4f %s", arcs.getRetainedInterval(),
        spherical ? 'meters' : ''));
    lines.push(utils.format("Collapsed rings: %,d", stats.collapsedRings));
    lines.push("Displacement statistics");
    lines.push(utils.format("   Mean displacement: %.4f", stats.displacementMean));
    lines.push(utils.format("   Max displacement: %.4f", stats.displacementMax));
    if (dq) {
      lines.push(utils.format("   Quartiles: %.2f, %.2f, %.2f", dq[0], dq[1], dq[2]));
    }
    lines.push("Vertex angle statistics");
    lines.push(utils.format("   Mean angle: %.2f degrees", stats.angleMean));
    // lines.push(utils.format("   Angles < 45: %.2f%", stats.lt45));
    if (aq) {
      lines.push(utils.format("   Quartiles: %.2f, %.2f, %.2f", aq[0], aq[1], aq[2]));
    }

    message(lines.join('\n   '));
  }

  // Remove line-segment intersections introduced by simplification by rolling
  // back simplification along intersecting segments.
  //
  // Limitation of this method: it can't remove intersections that are present
  // in the original dataset.
  // TODO: don't roll back simplification for unrepairable intersections.
  //
  function postSimplifyRepair(arcs) {
    var intersections = findSegmentIntersections(arcs),
        unfixable = repairIntersections(arcs, intersections),
        countPre = intersections.length,
        countPost = unfixable.length,
        countFixed = countPre > countPost ? countPre - countPost : 0,
        msg;
    if (countPre > 0) {
      msg = utils.format("Repaired %'i intersection%s", countFixed,
          utils.pluralSuffix(countFixed));
      if (countPost > 0) {
        msg += utils.format("; %'i intersection%s could not be repaired", countPost,
            utils.pluralSuffix(countPost));
      }
      message(msg);
    }
  }

  // @intersections (Array) Output from findSegmentIntersections()
  // Returns array of unresolved intersections, or empty array if none.
  // (export for GUI)
  function repairIntersections(arcs, intersections) {
    while (unwindIntersections(arcs, intersections) > 0) {
      intersections = findSegmentIntersections(arcs);
    }
    return intersections;
  }

  function unwindIntersections(arcs, intersections) {
    var data = arcs.getVertexData(),
        zlim = arcs.getRetainedInterval(),
        changes = 0,
        loops = 0,
        replacements, queue, target, i;

    // create a queue of unwind targets
    queue = getUnwindTargets(intersections, zlim, data.zz);
    utils.sortOn(queue, 'z', !!"ascending");

    while (queue.length > 0) {
      target = queue.pop();
      // redetect unwind target, in case a previous unwind operation has changed things
      // TODO: don't redetect if target couldn't have been affected
      replacements = redetectIntersectionTarget(target, zlim, data.xx, data.yy, data.zz);
      if (replacements.length == 1) {
        replacements = unwindIntersection(replacements[0], zlim, data.zz);
        changes++;
      }

      for (i=0; i<replacements.length; i++) {
        insertUnwindTarget(queue, replacements[i]);
      }
    }
    if (++loops > 500000) {
      verbose("Caught an infinite loop at intersection:", target);
      return 0;
    }
    return changes;
  }

  function getUnwindTargets(intersections, zlim, zz) {
    return intersections.reduce(function(memo, o) {
      var target = getUnwindTarget(o, zlim, zz);
      if (target !== null) {
        memo.push(target);
      }
      return memo;
    }, []);
  }

  // @o an intersection object
  // returns null if no vertices can be added along both segments
  // else returns an object with properties:
  //   a: intersecting segment to be partitioned
  //   b: intersecting segment to be retained
  //   z: threshold value of one or more points along [a] to be re-added
  function getUnwindTarget(o, zlim, zz) {
    var ai = findNextRemovableVertex(zz, zlim, o.a[0], o.a[1]),
        bi = findNextRemovableVertex(zz, zlim, o.b[0], o.b[1]),
        targ;
    if (ai == -1 && bi == -1) {
      targ = null;
    } else if (bi == -1 || ai != -1 && zz[ai] > zz[bi]) {
      targ = {
        a: o.a,
        b: o.b,
        z: zz[ai]
      };
    } else {
      targ = {
        a: o.b,
        b: o.a,
        z: zz[bi]
      };
    }
    return targ;
  }

  // Insert an intersection into sorted position
  function insertUnwindTarget(arr, obj) {
    var ins = arr.length;
    while (ins > 0) {
      if (arr[ins-1].z <= obj.z) {
        break;
      }
      arr[ins] = arr[ins-1];
      ins--;
    }
    arr[ins] = obj;
  }

  // Partition one of two intersecting segments by setting the removal threshold
  // of vertices indicated by @target equal to @zlim (the current simplification
  // level of the ArcCollection)
  function unwindIntersection(target, zlim, zz) {
    var replacements = [];
    var start = target.a[0],
        end = target.a[1],
        z = target.z;
    for (var i = start + 1; i <= end; i++) {
      if (zz[i] == z || i == end) {
        replacements.push({
          a: [start, i],
          b: target.b,
          z: z
        });
        if (i != end) zz[i] = zlim;
        start = i;
      }
    }
    if (replacements.length < 2) error("Error in unwindIntersection()");
    return replacements;
  }

  function redetectIntersectionTarget(targ, zlim, xx, yy, zz) {
    var segIds = getIntersectionCandidates(targ, zlim, xx, yy, zz);
    var intersections = intersectSegments(segIds, xx, yy);
    return getUnwindTargets(intersections, zlim, zz);
  }

  function getIntersectionCandidates(o, zlim, xx, yy, zz) {
    var segIds = getSegmentVertices(o.a, zlim, xx, yy, zz);
    segIds = segIds.concat(getSegmentVertices(o.b, zlim, xx, yy, zz));
    return segIds;
  }

  // Get all segments defined by two endpoints and the vertices between
  // them that are at or above the current simplification threshold.
  // TODO: test intersections with identical start + end ids
  function getSegmentVertices(seg, zlim, xx, yy, zz) {
    var start, end, prev, ids = [];
    if (seg[0] <= seg[1]) {
      start = seg[0];
      end = seg[1];
    } else {
      start = seg[1];
      end = seg[0];
    }
    prev = start;
    for (var i=start+1; i<=end; i++) {
      if (zz[i] >= zlim) {
        if (xx[prev] < xx[i]) {
          ids.push(prev, i);
        } else {
          ids.push(i, prev);
        }
        prev = i;
      }
    }
    return ids;
  }

  var PostSimplifyRepair = /*#__PURE__*/Object.freeze({
    __proto__: null,
    postSimplifyRepair: postSimplifyRepair,
    repairIntersections: repairIntersections
  });

  var DouglasPeucker = {};

  DouglasPeucker.metricSq3D = geom.pointSegDistSq3D;
  DouglasPeucker.metricSq = geom.pointSegDistSq;

  // @dest array to contain point removal thresholds
  // @xx, @yy arrays of x, y coords of a path
  // @zz (optional) array of z coords for spherical simplification
  //
  DouglasPeucker.calcArcData = function(dest, xx, yy, zz) {
    var len = dest.length,
        useZ = !!zz;

    dest[0] = dest[len-1] = Infinity;
    if (len > 2) {
      procSegment(0, len-1, 1, Number.MAX_VALUE);
    }

    function procSegment(startIdx, endIdx, depth, distSqPrev) {
      // get endpoint coords
      var ax = xx[startIdx],
          ay = yy[startIdx],
          cx = xx[endIdx],
          cy = yy[endIdx],
          az, cz;
      if (useZ) {
        az = zz[startIdx];
        cz = zz[endIdx];
      }

      var maxDistSq = 0,
          maxIdx = 0,
          distSqLeft = 0,
          distSqRight = 0,
          distSq;

      for (var i=startIdx+1; i<endIdx; i++) {
        if (useZ) {
          distSq = DouglasPeucker.metricSq3D(xx[i], yy[i], zz[i], ax, ay, az, cx, cy, cz);
        } else {
          distSq = DouglasPeucker.metricSq(xx[i], yy[i], ax, ay, cx, cy);
        }

        if (distSq >= maxDistSq) {
          maxDistSq = distSq;
          maxIdx = i;
        }
      }

      // Case -- threshold of parent segment is less than threshold of curr segment
      // Curr max point is assigned parent's threshold, so parent is not removed
      // before child as simplification is increased.
      //
      if (distSqPrev < maxDistSq) {
        maxDistSq = distSqPrev;
      }

      if (maxIdx - startIdx > 1) {
        distSqLeft = procSegment(startIdx, maxIdx, depth+1, maxDistSq);
      }
      if (endIdx - maxIdx > 1) {
        distSqRight = procSegment(maxIdx, endIdx, depth+1, maxDistSq);
      }

      // Case -- max point of curr segment is highest-threshold point of an island polygon
      // Give point the same threshold as the next-highest point, to prevent
      // a 3-vertex degenerate ring.
      if (depth == 1 && ax == cx && ay == cy) {
        maxDistSq = Math.max(distSqLeft, distSqRight);
      }

      dest[maxIdx] =  Math.sqrt(maxDistSq);
      return maxDistSq;
    }
  };

  function keepEveryPolygon(arcData, layers) {
    layers.forEach(function(lyr) {
      if (lyr.geometry_type == 'polygon') {
        protectLayerShapes(arcData, lyr.shapes);
      }
    });
  }

  function protectLayerShapes(arcData, shapes) {
    shapes.forEach(function(shape) {
      protectShape(arcData, shape);
    });
  }

  // Protect a single shape from complete removal by simplification
  // @arcData an ArcCollection
  // @shape an array containing one or more arrays of arc ids, or null if null shape
  //
  function protectShape(arcData, shape) {
    var maxArea = 0,
        arcCount = shape ? shape.length : 0,
        maxRing, area;
    // Find ring with largest bounding box
    for (var i=0; i<arcCount; i++) {
      area = arcData.getSimpleShapeBounds(shape[i]).area();
      if (area > maxArea) {
        maxRing = shape[i];
        maxArea = area;
      }
    }

    if (!maxRing || maxRing.length === 0) {
      // invald shape
      verbose("[protectShape()] Invalid shape:", shape);
    } else {
      protectPolygonRing(arcData, maxRing);
    }
  }

  // Re-inflate a polygon ring that has collapsed due to simplification by
  //   adding points in reverse order of removal until polygon is inflated.
  function protectPolygonRing(arcData, ring) {
    var zlim = arcData.getRetainedInterval(),
        // use epsilon as min area instead of 0, in case f.p. rounding produces
        // a positive area for a collapsed polygon.
        minArea = 1e-10,
        area, added;
    arcData.setRetainedInterval(Infinity);
    area = geom.getPlanarPathArea(ring, arcData);
    while (area <= minArea) {
      added = lockMaxThreshold(arcData, ring);
      if (added === 0) {
        verbose("[protectMultiRing()] Failed on ring:", ring);
        break;
      }
      area = geom.getPlanarPathArea(ring, arcData);
    }
    arcData.setRetainedInterval(zlim);
  }

  // Protect the vertex or vertices with the largest non-infinite
  // removal threshold in a ring.
  //
  function lockMaxThreshold(arcData, ring) {
    var targZ = 0,
        targArcId,
        raw = arcData.getVertexData(),
        arcId, id, z,
        start, end;

    for (var i=0; i<ring.length; i++) {
      arcId = ring[i];
      if (arcId < 0) arcId = ~arcId;
      start = raw.ii[arcId];
      end = start + raw.nn[arcId] - 1;
      id = findNextRemovableVertex(raw.zz, Infinity, start, end);
      if (id == -1) continue;
      z = raw.zz[id];
      if (z > targZ) {
        targZ = z;
        targArcId = arcId;
      }
    }
    if (targZ > 0) {
      // There may be more than one vertex with the target Z value; lock them all.
      start = raw.ii[targArcId];
      end = start + raw.nn[targArcId] - 1;
      return replaceInArray(raw.zz, targZ, Infinity, start, end);
    }
    return 0;
  }

  function replaceInArray(zz, value, replacement, start, end) {
    var count = 0;
    for (var i=start; i<=end; i++) {
      if (zz[i] === value) {
        zz[i] = replacement;
        count++;
      }
    }
    return count;
  }

  var KeepShapes = /*#__PURE__*/Object.freeze({
    __proto__: null,
    keepEveryPolygon: keepEveryPolygon,
    protectShape: protectShape,
    replaceInArray: replaceInArray
  });

  cmd.simplify = function(dataset, opts) {
    var arcs = dataset.arcs;
    if (!arcs || arcs.size() === 0) return; // removed in v0.4.125: stop("Missing path data");
    opts = getStandardSimplifyOpts(dataset, opts); // standardize options
    simplifyPaths(arcs, opts);

    // calculate and apply simplification interval
    if (opts.percentage || opts.percentage === 0) {
      arcs.setRetainedPct(utils.parsePercent(opts.percentage));
    } else if (opts.interval || opts.interval === 0) {
      arcs.setRetainedInterval(convertSimplifyInterval(opts.interval, dataset, opts));
    } else if (opts.resolution) {
      arcs.setRetainedInterval(convertSimplifyResolution(opts.resolution, arcs, opts));
    } else if (opts.presimplify) {
      return;
    } else {
      stop("Missing a simplification amount");
    }

    finalizeSimplification(dataset, opts);
  };

  function finalizeSimplification(dataset, opts) {
    var arcs = dataset.arcs;
    if (opts.keep_shapes) {
      keepEveryPolygon(arcs, dataset.layers);
    }

    if (!opts.no_repair && arcs.getRetainedInterval() > 0) {
      postSimplifyRepair(arcs);
    }

    if (opts.stats) {
      printSimplifyInfo(arcs, opts);
    }

    // stash simplification options (used by gui settings dialog)
    dataset.info = utils.defaults({simplify: opts}, dataset.info);
  }

  function getStandardSimplifyOpts(dataset, opts) {
    opts = opts || {};
    return utils.defaults({
      method: getSimplifyMethod(opts),
      spherical: useSphericalSimplify(dataset.arcs, opts)
    }, opts);
  }

  function useSphericalSimplify(arcs, opts) {
    return !opts.planar && !arcs.isPlanar();
  }

  // Calculate simplification thresholds for each vertex of an arc collection
  // (modifies @arcs ArcCollection in-place)
  function simplifyPaths(arcs, opts) {
    var simplifyPath = getSimplifyFunction(opts);
    arcs.setThresholds(new Float64Array(arcs.getPointCount())); // Create array to hold simplification data
    if (opts.spherical) {
      simplifyPaths3D(arcs, simplifyPath);
      protectWorldEdges(arcs);
    } else {
      simplifyPaths2D(arcs, simplifyPath);
    }
    if (opts.lock_box) {
      protectContentEdges(arcs);
    }
  }

  function simplifyPaths2D(arcs, simplify) {
    arcs.forEach3(function(xx, yy, kk, i) {
      simplify(kk, xx, yy);
    });
  }

  function simplifyPaths3D(arcs, simplify) {
    var xbuf = utils.expandoBuffer(Float64Array),
        ybuf = utils.expandoBuffer(Float64Array),
        zbuf = utils.expandoBuffer(Float64Array);
    arcs.forEach3(function(xx, yy, kk, i) {
      var n = xx.length,
          xx2 = xbuf(n),
          yy2 = ybuf(n),
          zz2 = zbuf(n);
      geom.convLngLatToSph(xx, yy, xx2, yy2, zz2);
      simplify(kk, xx2, yy2, zz2);
    });
  }

  function getSimplifyMethod(opts) {
    var m = opts.method;
    if (!m || m == 'weighted' || m == 'visvalingam' && opts.weighting) {
      m =  'weighted_visvalingam';
    }
    return m;
  }

  function getSimplifyFunction(opts) {
    var f;
    if (opts.method == 'dp') {
      f = DouglasPeucker.calcArcData;
    } else if (opts.method == 'visvalingam') {
      f = Visvalingam.getEffectiveAreaSimplifier(opts.spherical);
    } else if (opts.method == 'weighted_visvalingam') {
      f = Visvalingam.getWeightedSimplifier(opts, opts.spherical);
    } else {
      stop('Unsupported simplify method:', opts.method);
    }
    return f;
  }

  function protectContentEdges(arcs) {
    var e = 1e-14;
    var bb = arcs.getBounds();
    bb.padBounds(-e, -e, -e, -e);
    limitSimplificationExtent(arcs, bb.toArray(), true);
  }

  // @hardLimit
  //    true: never remove edge vertices
  //    false: never remove before other vertices
  function limitSimplificationExtent(arcs, bb, hardLimit) {
    var arcBounds = arcs.getBounds().toArray();
    // return if content doesn't reach edges
    if (geom.containsBounds(bb, arcBounds) === true) return;
    arcs.forEach3(function(xx, yy, zz) {
      var lockZ = hardLimit ? Infinity : 0,
      x, y;
      for (var i=0, n=zz.length; i<n; i++) {
        x = xx[i];
        y = yy[i];
        if (x >= bb[2] || x <= bb[0] || y <= bb[1] || y >= bb[3]) {
          if (lockZ === 0) {
            lockZ = findMaxThreshold(zz);
          }
          if (zz[i] !== Infinity) { // don't override lock value
            zz[i] = lockZ;
          }
        }
      }
    });
  }

  // Protect polar coordinates and coordinates at the prime meridian from
  // being removed before other points in a path.
  // Assume: coordinates are in decimal degrees
  //
  function protectWorldEdges(arcs) {
    // Need to handle coords with rounding errors:
    // -179.99999999999994 in test/data/ne/ne_110m_admin_0_scale_rank.shp
    // 180.00000000000003 in ne/ne_50m_admin_0_countries.shp
    limitSimplificationExtent(arcs, getWorldBounds(1e-12), false);
  }

  // Return largest value in an array, ignoring Infinity (lock value)
  //
  function findMaxThreshold(zz) {
    var z, maxZ = 0;
    for (var i=0, n=zz.length; i<n; i++) {
      z = zz[i];
      if (z > maxZ && z < Infinity) {
        maxZ = z;
      }
    }
    return maxZ;
  }

  function parseSimplifyResolution(raw) {
    var parts, w, h;
    if (utils.isNumber(raw)) {
      w = raw;
      h = raw;
    }
    else if (utils.isString(raw)) {
      parts = raw.split(/[x ,]/);
      w = Number(parts[0]) || 0;
      h = parts.length == 2 ? Number(parts[1]) || 0 : w;
    }
    if (!(w >= 0 && h >= 0 && w + h > 0)) {
      stop("Invalid simplify resolution:", raw);
    }
    return [w, h]; // TODO: validate;
  }

  function calcPlanarInterval(xres, yres, width, height) {
    var fitWidth = xres !== 0 && width / height > xres / yres || yres === 0;
    return fitWidth ? width / xres : height / yres;
  }

  // Calculate a simplification interval for unprojected data, given an output resolution
  // (This is approximate, since we don't know how the data will be projected for display)
  function calcSphericalInterval(xres, yres, bounds) {
    // Using length of arc along parallel through center of bbox as content width
    // TODO: consider using great circle instead of parallel arc to calculate width
    //    (doesn't work if width of bbox is greater than 180deg)
    var width = geom.degreesToMeters(bounds.width()) * Math.cos(bounds.centerY() * geom.D2R);
    var height = geom.degreesToMeters(bounds.height());
    return calcPlanarInterval(xres, yres, width, height);
  }

  function convertSimplifyInterval(param, dataset, opts) {
    var crs = getDatasetCRS(dataset);
    var interval;
    if (useSphericalSimplify(dataset.arcs, opts)) {
      interval = convertDistanceParam(param, crs);
    } else {
      interval = convertIntervalParam(param, crs);
    }
    return interval;
  }

  // convert resolution to an interval
  function convertSimplifyResolution(param, arcs, opts) {
    var res = parseSimplifyResolution(param);
    var bounds = arcs.getBounds();
    var interval;
    if (useSphericalSimplify(arcs, opts)) {
      interval = calcSphericalInterval(res[0], res[1], bounds);
    } else {
      interval = calcPlanarInterval(res[0], res[1], bounds.width(), bounds.height());
    }
    // scale interval to double the resolution (single-pixel resolution creates
    //  visible artifacts)
    interval *= 0.5;
    return interval;
  }

  var Simplify = /*#__PURE__*/Object.freeze({
    __proto__: null,
    finalizeSimplification: finalizeSimplification,
    getStandardSimplifyOpts: getStandardSimplifyOpts,
    useSphericalSimplify: useSphericalSimplify,
    simplifyPaths: simplifyPaths,
    getSimplifyMethod: getSimplifyMethod,
    protectWorldEdges: protectWorldEdges,
    parseSimplifyResolution: parseSimplifyResolution,
    calcPlanarInterval: calcPlanarInterval,
    calcSphericalInterval: calcSphericalInterval,
    convertSimplifyInterval: convertSimplifyInterval,
    convertSimplifyResolution: convertSimplifyResolution
  });

  cmd.sortFeatures = function(lyr, arcs, opts) {
    var n = getFeatureCount(lyr),
        ascending = !opts.descending,
        compiled = compileFeatureExpression(opts.expression, lyr, arcs),
        values = [];

    utils.repeat(n, function(i) {
      values.push(compiled(i));
    });

    var ids = utils.getSortedIds(values, ascending);
    if (lyr.shapes) {
      utils.reorderArray(lyr.shapes, ids);
    }
    if (lyr.data) {
      utils.reorderArray(lyr.data.getRecords(), ids);
    }
  };

  cmd.snap = function(target, opts) {
    var interval = 0;
    var snapCount = 0;
    var dataset = target.dataset;
    var arcs = dataset.arcs;
    var repairArcs;
    var arcBounds = arcs && arcs.getBounds();
    if (!arcBounds || !arcBounds.hasBounds()) {
      stop('Dataset is missing path data');
    }

    arcs.flatten(); // bake in any simplification
    if (opts.fix_geometry) {
      repairArcs = arcs && getRepairFunction(arcs);
    }
    if (opts.precision) {
      setCoordinatePrecision(dataset, opts.precision);
    } else if (opts.interval) {
      interval = convertIntervalParam(opts.interval, getDatasetCRS(dataset));
    } else {
      interval = getHighPrecisionSnapInterval(arcBounds.toArray());
    }
    if (interval > 0 && opts.endpoints) {
      // snaps line endpoints together
      // TODO: also snap endpoints to line segments to remove undershoots and overshoots
      snapCount = snapEndpointsByInterval(arcs, interval);
      message(utils.format("Snapped %s endpoint%s", snapCount, utils.pluralSuffix(snapCount)));
    } else if (interval > 0) {
      snapCount = snapCoordsByInterval(arcs, interval);
      message(utils.format("Snapped %s point%s", snapCount, utils.pluralSuffix(snapCount)));
    }
    if (snapCount > 0 || opts.precision) {
      if (repairArcs) {
        repairArcs(arcs);
      }
      arcs.dedupCoords();
      buildTopology(dataset);
    }
  };

  // @expression: optional field name or expression
  //
  cmd.splitLayer = function(src, expression, optsArg) {
    var opts = optsArg || {},
        lyr0 = opts.no_replace ? copyLayer(src) : src,
        properties = lyr0.data ? lyr0.data.getRecords() : null,
        shapes = lyr0.shapes,
        index = {},
        splitLayers = [],
        n = getFeatureCount(lyr0),
        namer;

    if (opts.ids) {
      namer = getIdSplitFunction(opts.ids);
    } else {
      namer = getSplitNameFunction(lyr0, expression);
    }

    // // halt if split field is missing
    // if (splitField) {
    //   internal.requireDataField(lyr0, splitField);
    // }

    // if input layer is empty, return original layer
    // TODO: consider halting
    if (n === 0) {
      return [lyr0];
    }

    utils.repeat(n, function(i) {
      var name = namer(i),
          lyr;

      if (name in index === false) {
        index[name] = splitLayers.length;
        lyr = {
          geometry_type: lyr0.geometry_type,
          name: name,
          data: properties ? new DataTable() : null,
          shapes: shapes ? [] : null
        };
        splitLayers.push(lyr);
      } else {
        lyr = splitLayers[index[name]];
      }
      if (shapes) {
        lyr.shapes.push(shapes[i]);
      }
      if (properties) {
        lyr.data.getRecords().push(properties[i]);
      }
    });

    return splitLayers;
  };

  function getIdSplitFunction(ids) {
    var set = new Set(ids);
    return function(i) {
      return set.has(i) ? '1' : '2';
    };
  }

  function getSplitNameFunction(lyr, arg) {
    var compiled;
    if (!arg) {
      // if not splitting on an expression and layer is unnamed, name split-apart layers
      // like: split-1, split-2, ...
      return function(i) {
        return (lyr && lyr.name || 'split') + '-' + (i + 1);
      };
    }
    if (lyr.data && lyr.data.fieldExists(arg)) {
      // Argument is a field name
      return function(i) {
        var rec = lyr.data.getRecords()[i];
        return rec ? valueToLayerName(rec[arg]) : '';
      };
    }
    // Assume: argument is an expression
    lyr = {name: lyr.name, data: lyr.data}; // remove shape info
    compiled = compileFeatureExpression(arg, lyr, null);
    return function(i) {
      var val = compiled(i);
      return valueToLayerName(val);
    };
  }

  function valueToLayerName(val) {
    return String(val);
  }

  // internal.getSplitKey = function(i, field, properties) {
  //   var rec = field && properties ? properties[i] : null;
  //   return String(rec ? rec[field] : i + 1);
  // };

  // internal.getSplitLayerName = function(base, key) {
  //   return (base ? base + '-' : '') + key;
  // };

  // internal.getStringInterpolator = function(str) {
  //   var body = 'with($$ctx) { return `' + str + '`; }';
  //   var f = new Function("$$ctx", body);
  //   return function(o) {
  //     var s = '';
  //     try {
  //       s = f(ctx);
  //     } catch(e) {
  //       stop("Unable to interpolate [" + str + "]");
  //     }
  //     return s;
  //   }
  // };

  var Split = /*#__PURE__*/Object.freeze({
    __proto__: null,
    getSplitNameFunction: getSplitNameFunction
  });

  cmd.stop = function(job) {
    stopJob(job);
  };

  cmd.svgStyle = function(lyr, dataset, opts) {
    var filter;
    if (getFeatureCount(lyr) === 0) {
      return;
    }
    if (!lyr.data) {
      initDataTable(lyr);
    }
    if (opts.where) {
      filter = compileFeatureExpression(opts.where, lyr, dataset.arcs);
    }
    Object.keys(opts).forEach(function(optName) {
      var svgName = optName.replace('_', '-'); // undo cli parser name conversion
      if (!isSupportedSvgStyleProperty(svgName)) {
        return;
      }
      var strVal = opts[optName].trim();
      var accessor = getSymbolPropertyAccessor(strVal, svgName, lyr);
      getLayerDataTable(lyr).getRecords().forEach(function(rec, i) {
        if (filter && !filter(i)) {
          // make sure field exists if record is excluded by filter
          if (svgName in rec === false) {
            rec[svgName] = undefined;
          }
        } else {
          rec[svgName] = accessor(i);
        }
      });
    });
  };

  var roundCoord = getRoundingFunction(0.01);

  function getSymbolFillColor(d) {
    return d.fill || 'magenta';
  }

  function getSymbolStrokeColor(d) {
    return d.stroke || d.fill || 'magenta';
  }

  function applySymbolStyles(sym, d) {
    if (sym.type == 'polyline') {
      sym.stroke = getSymbolStrokeColor(d);
    } else {
      sym.fill = getSymbolFillColor(d);
    }
    if (d.opacity) {
      sym.opacity = d.opacity;
    }
    return sym;
  }

  function getSymbolRadius(d) {
    if (d.radius === 0 || d.length === 0 || d.r === 0) return 0;
    return d.radius || d.length || d.r || 5; // use a default value
  }

  function forEachSymbolCoord(coords, cb) {
    var isPoint = coords && utils.isNumber(coords[0]);
    var isNested = !isPoint && coords && Array.isArray(coords[0]);
    if (isPoint) return cb(coords);
    for (var i=0; i<coords.length; i++) {
      if (isNested) forEachSymbolCoord(coords[i], cb);
    }
  }

  function flipY(coords) {
    forEachSymbolCoord(coords, function(p) {
      p[1] = -p[1];
    });
  }

  function scaleAndShiftCoords(coords, scale, shift) {
    forEachSymbolCoord(coords, function(xy) {
      xy[0] = xy[0] * scale + shift[0];
      xy[1] = xy[1] * scale + shift[1];
    });
  }

  function roundCoordsForSVG(coords) {
    forEachSymbolCoord(coords, function(p) {
      p[0] = roundCoord(p[0]);
      p[1] = roundCoord(p[1]);
    });
  }

  function rotateCoords(coords, rotation) {
    if (!rotation) return;
    var f = getAffineTransform(rotation, 1, [0, 0], [0, 0]);
    forEachSymbolCoord(coords, function(p) {
      var p2 = f(p[0], p[1]);
      p[0] = p2[0];
      p[1] = p2[1];
    });
  }

  function getStickArrowCoords(d) {
    return getArrowCoords(d, 'stick');
  }

  function getFilledArrowCoords(d) {
    return getArrowCoords(d, 'standard');
  }

  function getArrowCoords(d, style) {
    var stickArrow = style == 'stick',
        // direction = d.rotation || d.direction || 0,
        direction = d.direction || 0, // rotation is an independent parameter
        stemTaper = d['stem-taper'] || 0,
        curvature = d['stem-curve'] || 0,
        size = calcArrowSize(d, stickArrow);
    if (!size) return null;
    var stemLen = size.stemLen,
        headLen = size.headLen,
        totalLen = stickArrow ? Math.max(stemLen, headLen) : stemLen + headLen,
        headDx = size.headWidth / 2,
        stemDx = size.stemWidth / 2,
        baseDx = stemDx * (1 - stemTaper),
        coords, dx, dy;

    if (curvature) {
      // make curved stem
      if (direction > 0) curvature = -curvature;
      var theta = Math.abs(curvature) / 180 * Math.PI;
      var sign = curvature > 0 ? 1 : -1;
      var ax = baseDx * Math.cos(theta); // rotate arrow base
      var ay = baseDx * Math.sin(theta) * -sign;
      dx = stemLen * Math.sin(theta / 2) * sign;
      dy = stemLen * Math.cos(theta / 2);

      if (stickArrow) {
        coords = getCurvedStemCoords(-ax, -ay, dx, dy);
      } else {
        var leftStem = getCurvedStemCoords(-ax, -ay, -stemDx + dx, dy);
        var rightStem = getCurvedStemCoords(ax, ay, stemDx + dx, dy);
        coords = leftStem.concat(rightStem.reverse());
      }

    } else {
      // make straight stem
      dx = 0;
      dy = stemLen;
      if (stickArrow) {
        coords = [[0, 0], [0, stemLen]];
      } else {
        coords = [[-baseDx, 0], [baseDx, 0]];
      }
    }

    if (stickArrow) {
      // make stick arrow
      coords = [coords]; // MultiLineString coords
      if (headLen > 0) {
        coords.push([[-headDx + dx, stemLen - headLen], [dx, stemLen], [headDx + dx, stemLen - headLen]]);
      }
    } else {
      // make filled arrow
      // coordinates go counter clockwise, starting from the leftmost head coordinate
      coords.push([stemDx + dx, dy]);
      if (headLen > 0) {
        coords.push([headDx + dx, dy], [dx, headLen + dy], [-headDx + dx, dy]);
      }
      coords.push([-stemDx + dx, dy], coords[0].concat()); // close path
      coords = [coords]; // Polygon coords
    }

    if (d.anchor == 'end') {
      scaleAndShiftCoords(coords, 1, [-dx, -totalLen]);
    } else if (d.anchor == 'middle') {
      // shift midpoint away from the head a bit for a more balanced placement
      scaleAndShiftCoords(coords, 1, [-dx * 0.5, -dy * 0.5 - totalLen * 0.25]);
    }

    rotateCoords(coords, direction);
    if (d.flipped) {
      flipY(coords);
    }
    return coords;
  }

  // function calcStraightArrowCoords(stemLen, headLen, stemDx, headDx, baseDx) {
  //   return [[baseDx, 0], [stemDx, stemLen], [headDx, stemLen], [0, stemLen + headLen],
  //         [-headDx, stemLen], [-stemDx, stemLen], [-baseDx, 0], [baseDx, 0]];
  // }

  function calcArrowSize(d, stickArrow) {
    // don't display arrows with negative length
    var o = initArrowSize(d), // calc several parameters
        dataLen = Math.max(d.radius || d.length || d.r || 0),
        totalLen = Math.max(dataLen, o.headLen, 0),
        scale = 1;
    if (totalLen >= 0) {
      scale = calcScale(totalLen, o.headLen, d);
      o.stemWidth *= scale;
      o.headWidth *= scale;
      o.headLen *= scale;
      o.stemLen = stickArrow ? dataLen : totalLen - o.headLen;
    }

    if (o.headWidth < o.stemWidth && o.headWidth > 0) {
      stop('Arrow head must be at least as wide as the stem.');
    }
    return o;
  }

  function calcScale(totalLen, headLen, d) {
    var minStemRatio = d['min-stem-ratio'] >= 0 ? d['min-stem-ratio'] : 0;
    var stemLen = d['stem-length'] || 0;
    var maxHeadPct = 1 - minStemRatio;
    var headPct = headLen / totalLen;
    var scale = 1;

    if (headPct > maxHeadPct) {
      scale = maxHeadPct / headPct;
    } else if (stemLen + headLen > totalLen) {
      scale = totalLen / (stemLen + headLen);
    }
    return scale || 0;
  }

  function initArrowSize(d) {
    var sizeRatio = getHeadSizeRatio(d['head-angle'] || 40); // length to width
    var o = {
      stemWidth: d['stem-width'] || 2,
      stemLen: d['stem-length'] || 0,
      headWidth: d['head-width'],
      headLen: d['head-length']
    };
    if (o.headWidth === 0) {
      o.headLen = 0;
    } else if (o.headWidth > 0 === false) {
      if (o.headLen > 0) {
        o.headWidth = o.headLen / sizeRatio;
      } else if (o.headLen === 0) {
        o.headWidth = 0;
      } else {
        o.headWidth = o.stemWidth * 3; // assumes stemWidth has been set
      }
    }
    if (o.headLen >= 0 === false) {
      o.headLen = o.headWidth * sizeRatio;
    }
    return o;
  }

  // Returns ratio of head length to head width
  function getHeadSizeRatio(headAngle) {
    return 1 / Math.tan(Math.PI * headAngle / 180 / 2) / 2;
  }

  // ax, ay: point on the base
  // bx, by: point on the stem
  function getCurvedStemCoords(ax, ay, bx, by) {
    // case: curved side intrudes into head (because stem is too short)
    if (ay > by) {
      return [[ax * by / ay, by]];
    }
    var dx = bx - ax,
        dy = by - ay,
        dy1 = (dy * dy - dx * dx) / (2 * dy),
        dy2 = dy - dy1,
        dx2 = Math.sqrt(dx * dx + dy * dy) / 2,
        theta = Math.PI - Math.asin(dx2 / dy2) * 2,
        degrees = theta * 180 / Math.PI,
        radius = dy2 / Math.tan(theta / 2),
        leftBend = bx > ax,
        sign = leftBend ? 1 : -1,
        points = Math.round(degrees / 5) + 2,
        increment = theta / (points + 1),
        coords = [[bx, by]];

    for (var i=1; i<= points; i++) {
      var phi = i * increment / 2;
      var sinPhi = Math.sin(phi);
      var cosPhi = Math.cos(phi);
      var c = sinPhi * radius * 2;
      var a = sinPhi * c;
      var b = cosPhi * c;
      coords.push([bx - a * sign, by - b]);
    }
    coords.push([ax, ay]);
    return coords;
  }

  function makeCircleSymbol(d, opts) {
    var radius = getSymbolRadius(d);
    // TODO: remove duplication with svg-symbols.js
    if (+opts.scale) radius *= +opts.scale;
    var sym = { type: 'circle', r: radius };
    return applySymbolStyles(sym, d);
  }

  function getPolygonCoords(d) {
    var radius = getSymbolRadius(d),
        sides = +d.sides || getSidesByType(d.type),
        rotated = sides % 2 == 1,
        coords = [],
        angle, b;

    if (radius > 0 === false) return null;
    if (sides >= 3 === false) {
      stop(`Invalid number of sides (${sides})`);
    }
    if (d.orientation == 'b' || d.flipped || d.rotated) {
      rotated = !rotated;
    }
    b = rotated ? 0 : 0.5;
    for (var i=0; i<sides; i++) {
      angle = (i + b) / sides * 360;
      coords.push(getPlanarSegmentEndpoint(0, 0, angle, radius));
    }
    coords.push(coords[0].concat());
    return [coords];
  }

  function getSidesByType(type) {
    return {
      circle: 72,
      triangle: 3,
      square: 4,
      pentagon: 5,
      hexagon: 6,
      heptagon: 7,
      octagon: 8,
      nonagon: 9,
      decagon: 10
    }[type] || 4;
  }

  function getStarCoords(d) {
    var radius = getSymbolRadius(d),
        points = d.points || d.sides && d.sides / 2 || 5,
        sides = points * 2,
        minorRadius = getMinorRadius(points) * radius,
        b = d.orientation == 'b' || d.flipped || d.rotated ? 0 : 1,
        coords = [],
        angle, len;

    if (radius > 0 === false) return null;
    if (points < 5) {
      stop(`Invalid number of points for a star (${points})`);
    }
    for (var i=0; i<sides; i++) {
      len = i % 2 == 0 ? minorRadius : radius;
      angle = (i + b) / sides * 360;
      coords.push(getPlanarSegmentEndpoint(0, 0, angle, len));
    }
    coords.push(coords[0].concat());
    return [coords];
  }

  function getMinorRadius(points) {
    var innerAngle = 360 / points;
    var pointAngle = getDefaultPointAngle(points);
    var thetaA = Math.PI / 180 * innerAngle / 2;
    var thetaB = Math.PI / 180 * pointAngle / 2;
    var a = Math.tan(thetaB) / (Math.tan(thetaB) + Math.tan(thetaA));
    var c = a / Math.cos(thetaA);
    return c;
  }

  function getDefaultPointAngle(points) {
    var minSkip = 1;
    var maxSkip = Math.ceil(points / 2) - 2;
    var skip = Math.floor((maxSkip + minSkip) / 2);
    return getPointAngle(points, skip);
  }

  // skip: number of adjacent points to skip when drawing a segment
  function getPointAngle(points, skip) {
    var unitAngle = 360 / points;
    var centerAngle = unitAngle * (skip + 1);
    return 180 - centerAngle;
  }

  // Returns a svg-symbol object
  function makeRingSymbol(d, opts) {
    var scale = +opts.scale || 1;
    var radii = parseRings(d.radii || '2').map(function(r) { return r * scale; });
    var solidCenter = utils.isOdd(radii.length);
    var color = getSymbolFillColor(d);
    var opacity = opts.opacity || undefined;
    var parts = [];
    if (solidCenter) {
      parts.push({
        type: 'circle',
        fill: color,
        opacity: opacity,
        r: radii.shift()
      });
    }
    for (var i=0; i<radii.length; i+= 2) {
      parts.push({
        type: 'circle',
        fill: 'none', // TODO remove default black fill so this is not needed
        stroke: color,
        opacity: opacity,
        'stroke-width':  roundToTenths(radii[i+1] - radii[i]),
        r: roundToTenths(radii[i+1] * 0.5 + radii[i] * 0.5)
      });
    }
    return {
      type: 'group',
      parts: parts
    };
  }

  // Returns GeoJSON MultiPolygon coords
  function getRingCoords(d) {
    var radii = parseRings(d.radii || '2');
    var coords = [];
    var solidCenter = utils.isOdd(radii.length);
    var ring, hole;
    for (var i=0; i<radii.length; i++) {
      ring = getPolygonCoords({
        type: 'circle',
        radius: radii[i]
      });
      if (!solidCenter || i > 0) {
        i++;
        hole = ring;
        ring = getPolygonCoords({
          type: 'circle',
          radius: radii[i]
        });
        ring.push(hole[0]);
      }
      coords.push(ring);
    }
    return coords;
  }

  function parseRings(arg) {
    var arr = Array.isArray(arg) ? arg : parseNumberList(arg);
    utils.genericSort(arr, true);
    return utils.uniq(arr);
  }

  // Returns an svg-symbol data object for one symbol
  function makePathSymbol(coords, properties, geojsonType) {
    var sym;
    if (geojsonType == 'MultiPolygon' || geojsonType == 'Polygon') {
      sym = {
        type: 'polygon',
        coordinates: geojsonType == 'Polygon' ? coords : flattenMultiPolygonCoords(coords)
      };
    } else if (geojsonType == 'LineString' || geojsonType == 'MultiLineString') {
      sym = {
        type: 'polyline',
        'stroke-width': properties['stroke-width'] || 2,
        coordinates: geojsonType == 'LineString' ? [coords] : coords
      };
    } else {
      error('Unsupported type:', geojsonType);
    }
    applySymbolStyles(sym, properties);
    roundCoordsForSVG(sym.coordinates);
    return sym;
  }

  // TODO: refactor to remove duplication in mapshaper-svg-style.js
  cmd.symbols = function(inputLyr, dataset, opts) {
    requireSinglePointLayer(inputLyr);
    var lyr = opts.no_replace ? copyLayer(inputLyr) : inputLyr;
    var shapeMode = !!opts.geographic;
    var metersPerPx;
    if (shapeMode) {
      requireProjectedDataset(dataset);
      metersPerPx = opts.pixel_scale || getMetersPerPixel(lyr);
    }
    var records = getLayerDataTable(lyr).getRecords();
    var getSymbolData = getSymbolDataAccessor(lyr, opts);
    var geometries = lyr.shapes.map(function(shp, i) {
      if (!shp) return null;
      var d = getSymbolData(i);
      var rec = records[i] || {};

      // non-polygon symbols
      if (!shapeMode && d.type == 'circle') {
        rec['svg-symbol'] = makeCircleSymbol(d, opts);
        return;
      }
      if (!shapeMode && d.type == 'ring') {
        rec['svg-symbol'] = makeRingSymbol(d, opts);
        return;
      }

      var geojsonType = 'Polygon';
      var coords;
      // these symbols get converted to polygon shapes
      if (d.type == 'arrow' && opts.arrow_style == 'stick') {
        coords = getStickArrowCoords(d);
        geojsonType = 'MultiLineString';
      } else if (d.type == 'arrow') {
        coords = getFilledArrowCoords(d);
      } else if (d.type == 'ring') {
        coords = getRingCoords(d);
        geojsonType = 'MultiPolygon';
      } else if (d.type == 'star') {
        coords = getStarCoords(d);
      } else {
        coords = getPolygonCoords(d);
      }
      if (!coords) return null;
      rotateCoords(coords, +d.rotation || 0);
      if (!shapeMode) {
        flipY(coords);
      }
      if (+opts.scale) {
        scaleAndShiftCoords(coords, +opts.scale, [0, 0]);
      }
      if (shapeMode) {
        scaleAndShiftCoords(coords, metersPerPx, shp[0]);
        if (d.fill) rec.fill = d.fill;
        if (d.stroke) rec.stroke = d.stroke;
        if (d.opacity) rec.opacity = d.opacity;
        return createGeometry(coords, geojsonType);
      } else {
        rec['svg-symbol'] = makePathSymbol(coords, d, geojsonType);
      }
    });

    var outputLyr, dataset2;
    if (shapeMode) {
      dataset2 = importGeometries(geometries, records);
      outputLyr = mergeOutputLayerIntoDataset(inputLyr, dataset, dataset2, opts);
      outputLyr.data = lyr.data;
    } else {
      outputLyr = lyr;
    }
    return [outputLyr];
  };

  function importGeometries(geometries, records) {
    var features = geometries.map(function(geom, i) {
      records[i];
      return {
        type: 'Feature',
        properties: records[i] || null,
        geometry: geom
      };
    });
    var geojson = {
      type: 'FeatureCollection',
      features: features
    };
    return importGeoJSON(geojson);
  }

  function createGeometry(coords, type) {
    return {
      type: type,
      coordinates: coords
    };
  }

  function getMetersPerPixel(lyr, dataset) {
    var bounds = getLayerBounds(lyr);
    // TODO: need a better way to handle a single point with no extent
    var extent = bounds.width() || bounds.height() || 1000;
    return extent / 800;
  }

  var Symbols = /*#__PURE__*/Object.freeze({
    __proto__: null
  });

  cmd.target = function(catalog, opts) {
    var type = (opts.type || '').toLowerCase().replace('linestring', 'polyline');
    var pattern = opts.target || '*';
    var targets = catalog.findCommandTargets(pattern, type);
    if (type && 'polygon,polyline,point'.split(',').indexOf(type) == -1) {
      stop("Invalid layer type:", opts.type);
    }
    if (targets.length === 0) {
      stop("No layers were matched (pattern: " + pattern + (type ? ' type: ' + type : '') + ")");
    }
    if (opts.name || opts.name === '') {
      // TODO: improve this
      targets[0].layers[0].name = opts.name;
    }
    if (opts.combine) {
      targets = combineTargets(targets, catalog);
    } else if (opts.isolate) {
      targets = isolateTargets(targets, catalog);
    }
    catalog.setDefaultTargets(targets);
  };

  function combineTargets(targets, catalog) {
    var datasets = [];
    var layers = [];
    targets.forEach(function(o) {
      datasets.push(o.dataset);
      catalog.removeDataset(o.dataset);
      layers = layers.concat(o.layers);
    });
    var combined = mergeDatasets(datasets);
    catalog.addDataset(combined);
    return [{
      dataset: combined,
      layers: layers
    }];
  }

  function isolateTargets(targets, catalog) {
    var datasets = [];
    targets.forEach(function(o) {
      datasets.push(o.dataset);
      o.layers.forEach(function(lyr) {
        catalog.removeLayer(lyr, o.dataset);

      });
    });
  }

  cmd.union = function(targetLayers, targetDataset, opts) {
    if (targetLayers.length < 2) {
      stop('Command requires at least two target layers');
    }
    targetLayers.forEach(requirePolygonLayer);

    // Need to add cuts before creating merged layer (arc ids may change)
    var nodes = addIntersectionCuts(targetDataset, opts);
    var allFields = [];
    var allShapes = [];
    var layerData = [];
    targetLayers.forEach(function(lyr, i) {
      var fields = lyr.data ? lyr.data.getFields() : [];
      if (opts.fields) {
        fields = opts.fields.indexOf('*') > 1 ? fields :
          fields.filter(function(name) {return opts.fields.indexOf(name) > -1;});
      }
      layerData.push({
        layer: lyr,
        fields: fields,
        records: lyr.data ? lyr.data.getRecords() : null,
        offset: allShapes.length,
        size: lyr.shapes.length
      });
      allFields = allFields.concat(fields);
      allShapes = allShapes.concat(lyr.shapes);
    });
    var unionFields = utils.uniqifyNames(allFields, function(name, n) {
      return name + '_' + n;
    });
    var mergedLyr = {
      geometry_type: 'polygon',
      shapes: allShapes
    };
    var mosaicIndex = new MosaicIndex(mergedLyr, nodes, {flat: false});
    var mosaicShapes = mosaicIndex.mosaic;
    var mosaicRecords = mosaicShapes.map(function(shp, i) {
      var mergedIds = mosaicIndex.getSourceIdsByTileId(i);
      var values = [];
      var lyrInfo, srcId, rec;
      for (var lyrId=0, n=layerData.length; lyrId < n; lyrId++) {
        lyrInfo = layerData[lyrId];
        srcId = unionFindOriginId(mergedIds, lyrInfo.offset, lyrInfo.size);
        rec = srcId == -1 || lyrInfo.records === null ? null : lyrInfo.records[srcId];
        unionAddDataValues(values, lyrInfo.fields, rec);
      }
      return unionMakeDataRecord(unionFields, values);
    });

    var unionLyr = {
      name: 'union',
      geometry_type: 'polygon',
      shapes: mosaicShapes,
      data: new DataTable(mosaicRecords)
    };
    return [unionLyr];
  };

  function unionFindOriginId(mergedIds, offset, length) {
    var mergedId;
    for (var i=0; i<mergedIds.length; i++) {
      mergedId = mergedIds[i];
      if (mergedId >= offset && mergedId < offset + length) {
        return mergedId - offset;
      }
    }
    return -1;
  }

  function unionAddDataValues(arr, fields, rec) {
    for (var i=0; i<fields.length; i++) {
      arr.push(rec ? rec[fields[i]] : null);
    }
  }

  function unionMakeDataRecord(fields, values) {
    var rec = {};
    for (var i=0; i<fields.length; i++) {
      rec[fields[i]] = values[i];
    }
    return rec;
  }

  cmd.uniq = function(lyr, arcs, opts) {
    var n = getFeatureCount(lyr),
        compiled = compileFeatureExpression(opts.expression, lyr, arcs),
        maxCount = opts.max_count || 1,
        counts = {},
        keepFlags = [],
        verbose = !!opts.verbose,
        invert = !!opts.invert,
        index = !!opts.index,
        records = lyr.data ? lyr.data.getRecords() : null,
        filter = function(d, i) {return keepFlags[i];};


    utils.repeat(n, function(i) {
      var val = compiled(i);
      var count = val in counts ? counts[val] + 1 : 1;
      var keep = count <= maxCount;
      var rec;
      if (index) {
        keep = true;
        rec = records && records[i];
        if (rec) rec.index = count;
      } else if (invert) {
        keep = !keep;
      }
      keepFlags[i] = keep;
      counts[val] = count;
      if (verbose && !keep) {
        message(utils.format('Removing feature %i key: [%s]', i, val));
      }
    });

    if (lyr.shapes) {
      lyr.shapes = lyr.shapes.filter(filter);
    }
    if (records) {
      lyr.data = new DataTable(records.filter(filter));
    }
    if (opts.verbose !== false) {
      message(utils.format('Retained %,d of %,d features', getFeatureCount(lyr), n));
    }
  };

  cmd.variableSimplify = function(layers, dataset, opts) {
    var lyr = layers[0];
    var arcs = dataset.arcs;
    var getShapeThreshold;
    var arcThresholds;
    if (layers.length != 1) {
      stop('Variable simplification requires a single target layer');
    }
    if (!layerHasPaths(lyr)) {
      stop('Target layer is missing path data');
    }

    opts = getStandardSimplifyOpts(dataset, opts);
    simplifyPaths(arcs, opts);

    if (opts.interval) {
      getShapeThreshold = getVariableIntervalFunction(opts.interval, lyr, dataset, opts);
    } else if (opts.percentage) {
      getShapeThreshold = getVariablePercentageFunction(opts.percentage, lyr, dataset);
    } else if (opts.resolution) {
      getShapeThreshold = getVariableResolutionFunction(opts.resolution, lyr, dataset, opts);
    } else {
      stop("Missing a simplification expression");
    }

    arcThresholds = calculateVariableThresholds(lyr, arcs, getShapeThreshold);
    applyArcThresholds(arcs, arcThresholds);
    arcs.setRetainedInterval(1e20); // set to a huge value
    finalizeSimplification(dataset, opts);
    arcs.flatten(); // bake in simplification (different from standard -simplify)
  };

  function getVariableIntervalFunction(exp, lyr, dataset, opts) {
    var compiled = compileFeatureExpression(exp, lyr, dataset.arcs);
    return function(shpId) {
      var val = compiled(shpId);
      return convertSimplifyInterval(val, dataset, opts);
    };
  }

  function getVariableResolutionFunction(exp, lyr, dataset, opts) {
    var compiled = compileSimplifyExpression(exp, lyr, dataset.arcs);
    return function(shpId) {
      var val = compiled(shpId);
      return convertSimplifyResolution(val, dataset.arcs, opts);
    };
  }

  function getVariablePercentageFunction(exp, lyr, dataset, opts) {
    var compiled = compileSimplifyExpression(exp, lyr, dataset.arcs);
    var pctToInterval = getThresholdFunction(dataset.arcs);
    return function(shpId) {
      var val = compiled(shpId);
      var pct = utils.parsePercent(val);
      return pctToInterval(pct);
    };
  }

  // TODO: memoize?
  function compileSimplifyExpression(exp, lyr, arcs) {
    return compileFeatureExpression(exp, lyr, arcs);
  }

  // Filter arcs based on an array of thresholds
  function applyArcThresholds(arcs, thresholds) {
    arcs.getVertexData().zz;
    arcs.forEach2(function(start, n, xx, yy, zz, arcId) {
      var arcZ = thresholds[arcId];
      var z;
      for (var i=1; i<n-1; i++) {
        z = zz[start + i];
        // if (z >= arcZ || arcZ === Infinity) { // Infinity test is a bug
        if (z >= arcZ) {
          // protect vertices with thresholds that are >= than the computed threshold
          // for this arc
          zz[start + i] = Infinity;
        }
      }
    });
  }

  function calculateVariableThresholds(lyr, arcs, getShapeThreshold) {
    var thresholds = new Float64Array(arcs.size()); // init to 0s
    var UNUSED = -1;
    var currThresh;
    utils.initializeArray(thresholds, UNUSED);
    lyr.shapes.forEach(function(shp, shpId) {
      currThresh = getShapeThreshold(shpId);
      forEachArcId(shp || [], procArc);
    });
    // set unset arcs to 0 so they are not simplified
    for (var i=0, n=thresholds.length; i<n; i++) {
      if (thresholds[i] == UNUSED) {
        thresholds[i] = 0;
      }
    }
    return thresholds;

    function procArc(arcId) {
      var i = arcId < 0 ? ~arcId : arcId;
      var savedThresh = thresholds[i];
      if (savedThresh > currThresh || savedThresh == UNUSED) {
        thresholds[i] = currThresh;
      }
    }
  }

  // Split the shapes in a layer according to a grid
  // Return array of layers. Use -o bbox-index option to create index
  //
  cmd.splitLayerOnGrid = function(lyr, arcs, opts) {
    var shapes = lyr.shapes,
        type = lyr.geometry_type,
        setId = !!opts.id_field, // assign id but, don't split to layers
        fieldName = opts.id_field || "__split__",
        classify = getShapeClassifier(getLayerBounds(lyr, arcs), opts.cols, opts.rows),
        properties;

    if (!type) {
      stop("Layer has no geometry");
    }

    if (!lyr.data) {
      lyr.data = new DataTable(shapes.length);
    }
    properties = lyr.data.getRecords();

    lyr.shapes.forEach(function(shp, i) {
      var bounds = type == 'point' ? getPointBounds$1([shp]) : arcs.getMultiShapeBounds(shp);
      var name = bounds.hasBounds() ? classify(bounds) : '';
      var rec = properties[i] = properties[i] || {};
      rec[fieldName] = name;
    });

    if (setId) return lyr; // don't split layer (instead assign cell ids)

    return cmd.splitLayer(lyr, fieldName).filter(function(lyr) {
      var name = lyr.data.getRecordAt(0)[fieldName];
      lyr.name = name;
      lyr.data.deleteField(fieldName);
      return !!name;
    });

    function getShapeClassifier(bounds, cols, rows) {
      var xmin = bounds.xmin,
          ymin = bounds.ymin,
          w = bounds.width(),
          h = bounds.height();

      if (rows > 0 === false || cols > 0 === false) {
        stop('Invalid grid parameters');
      }

      if (w > 0 === false || h > 0 === false) {
        cols = 1;
        rows = 1;
      }

      return function(bounds) {
        var c = Math.floor((bounds.centerX() - xmin) / w * cols),
            r = Math.floor((bounds.centerY() - ymin) / h * rows);
        c = utils.clamp(c, 0, cols-1) || 0;
        r = utils.clamp(r, 0, rows-1) || 0;
        return "r" + r + "c" + c;
      };
    }
  };

  // Recursively divide a layer into two layers until a (compiled) expression
  // no longer returns true. The original layer is split along the long side of
  // its bounding box, so that each split-off layer contains half of the original
  // shapes (+/- 1).
  //
  cmd.subdivideLayer = function(lyr, arcs, exp) {
    return subdivide(lyr, arcs, exp);
  };

  function subdivide(lyr, arcs, exp) {
    var divide = evalCalcExpression(lyr, arcs, exp),
        subdividedLayers = [],
        tmp, bounds, lyr1, lyr2, layerName;
    requireBooleanResult(divide, 'Expression must evaluate to true or false');
    if (divide) {
      bounds = getLayerBounds(lyr, arcs);
      tmp = divideLayer(lyr, arcs, bounds);
      lyr1 = tmp[0];
      if (lyr1.shapes.length > 1 && lyr1.shapes.length < lyr.shapes.length) {
        utils.merge(subdividedLayers, subdivide(lyr1, arcs, exp));
      } else {
        subdividedLayers.push(lyr1);
      }

      lyr2 = tmp[1];
      if (lyr2.shapes.length > 1 && lyr2.shapes.length < lyr.shapes.length) {
        utils.merge(subdividedLayers, subdivide(lyr2, arcs, exp));
      } else {
        subdividedLayers.push(lyr2);
      }
    } else {
      subdividedLayers.push(lyr);
    }
    layerName = getSplitNameFunction(lyr);
    subdividedLayers.forEach(function(lyr2, i) {
      lyr2.name = layerName(i);
      utils.defaults(lyr2, lyr);
    });
    return subdividedLayers;
  }

  // split one layer into two layers containing the same number of shapes (+-1),
  // either horizontally or vertically
  //
  function divideLayer(lyr, arcs, bounds) {
    var properties = lyr.data ? lyr.data.getRecords() : null,
        shapes = lyr.shapes,
        lyr1, lyr2;
    lyr1 = {
      geometry_type: lyr.geometry_type,
      shapes: [],
      data: properties ? [] : null
    };
    lyr2 = {
      geometry_type: lyr.geometry_type,
      shapes: [],
      data: properties ? [] : null
    };

    var useX = bounds && bounds.width() > bounds.height();
    // TODO: think about case where there are null shapes with NaN centers
    var centers = shapes.map(function(shp) {
      var bounds = arcs.getMultiShapeBounds(shp);
      return useX ? bounds.centerX() : bounds.centerY();
    });
    var ids = utils.range(centers.length);
    ids.sort(function(a, b) {
      return centers[a] - centers[b];
    });
    ids.forEach(function(shapeId, i) {
      var dest = i < shapes.length / 2 ? lyr1 : lyr2;
      dest.shapes.push(shapes[shapeId]);
      if (properties) {
        dest.data.push(properties[shapeId]);
      }
    });

    if (properties) {
      lyr1.data = new DataTable(lyr1.data);
      lyr2.data = new DataTable(lyr2.data);
    }
    return [lyr1, lyr2];
  }

  function commandAcceptsMultipleTargetDatasets(name) {
    return name == 'rotate' || name == 'info' || name == 'proj' ||
      name == 'require' || name == 'drop' || name == 'target' ||
      name == 'if' || name == 'elif' || name == 'else' || name == 'endif' ||
      name == 'run' || name == 'i' || name == 'snap' || name == 'frame' ||
      name == 'comment';
  }

  function commandAcceptsEmptyTarget(name) {
    return name == 'graticule' || name == 'i' || name == 'help' ||
      name == 'point-grid' || name == 'shape' || name == 'rectangle' || name == 'frame' ||
      name == 'require' || name == 'run' || name == 'define' ||
      name == 'include' || name == 'print' || name == 'comment' || name == 'if' || name == 'elif' ||
      name == 'else' || name == 'endif' || name == 'stop' || name == 'add-shape' ||
      name == 'scalebar';
  }

  async function runCommand(command, job) {
    var name = command.name,
        opts = command.options,
        source,
        outputDataset,
        outputLayers,
        outputFiles,
        targets,
        targetDataset,
        targetLayers,
        arcs;

    if (skipCommand(name, job)) {
      return done(null);
    }

    if (name == 'comment') {
      cmd.comment(opts);
      return done(null);
    }

    if (!job) job = new Job();
    job.startCommand(command);


    try { // catch errors from synchronous functions
      T$1.start();

      if (name == 'rename-layers') {
        // default target is all layers
        targets = job.catalog.findCommandTargets(opts.target || '*');
        targetLayers = targets.reduce(function(memo, obj) {
          return memo.concat(obj.layers);
        }, []);

      } else if (name == 'o') {
        // when combining GeoJSON layers, default is all layers
        // TODO: check that combine_layers is only used w/ GeoJSON output
        targets = job.catalog.findCommandTargets(opts.target || opts.combine_layers && '*');

      } else if (commandAcceptsMultipleTargetDatasets(name)) {
        targets = job.catalog.findCommandTargets(opts.target);

      } else {
        targets = job.catalog.findCommandTargets(opts.target);
        // special case to allow -merge-layers and -union to combine layers from multiple datasets
        // TODO: support multi-dataset targets for other commands
        if (targets.length > 1 && (name == 'merge-layers' || name == 'union')) {
          targets = mergeCommandTargets(targets, job.catalog);
        }

        if (targets.length == 1) {
          targetDataset = targets[0].dataset;
          arcs = targetDataset.arcs;
          targetLayers = targets[0].layers;
          // target= option sets default target
          job.catalog.setDefaultTarget(targetLayers, targetDataset);

        } else if (targets.length > 1) {
          stop("This command does not support targetting layers from different datasets");
        }
      }

      if (targets.length === 0) {
        if (opts.target) {
          stop(utils.format('Missing target: %s\nAvailable layers: %s',
              opts.target, getFormattedLayerList(job.catalog)));
        }
        if (!commandAcceptsEmptyTarget(name)) {
          stop("No data is available");
        }
      }

      if (opts.source) {
        source = findCommandSource(convertSourceName(opts.source, targets), job.catalog, opts);
      }

      // identify command target/input (for postprocessing)
      // TODO: support commands with multiple target datasets
      // target = name == 'i' ? null : targets[0];

      if (name == 'add-shape') {
        if (!targetDataset) {
          targetDataset = {info: {}, layers: []};
          targetLayers = targetDataset.layers;
          job.catalog.addDataset(targetDataset);
        }
        outputLayers = cmd.addShape(targetLayers, targetDataset, opts);
      } else if (name == 'affine') {
        cmd.affine(targetLayers, targetDataset, opts);

      } else if (name == 'alpha-shapes') {
        outputLayers = applyCommandToEachLayer(cmd.alphaShapes, targetLayers, targetDataset, opts);
        // outputLayers = null;

      } else if (name == 'buffer') {
         outputLayers = applyCommandToEachLayer(cmd.buffer, targetLayers, targetDataset, opts);
        // outputLayers = cmd.buffer(targetLayers, targetDataset, opts);

      } else if (name == 'data-fill') {
        applyCommandToEachLayer(cmd.dataFill, targetLayers, arcs, opts);

      } else if (name == 'cluster') {
        applyCommandToEachLayer(cmd.cluster, targetLayers, arcs, opts);

      } else if (name == 'calc') {
        outputDataset = cmd.calc(targetLayers, arcs, opts);

      } else if (name == 'check-geometry') {
        applyCommandToEachLayer(cmd.checkGeometry, targetLayers, targetDataset, opts);

      } else if (name == 'classify') {
        applyCommandToEachLayer(cmd.classify, targetLayers, targetDataset, opts);

      } else if (name == 'clean') {
        cmd.cleanLayers(targetLayers, targetDataset, opts);

      } else if (name == 'clip') {
        outputLayers = cmd.clipLayers(targetLayers, source, targetDataset, opts);

      } else if (name == 'colorizer') {
        outputLayers = cmd.colorizer(opts);

      // } else if (name == 'comment') {
      //   // no-op

      } else if (name == 'dashlines') {
        applyCommandToEachLayer(cmd.dashlines, targetLayers, targetDataset, opts);

      } else if (name == 'define') {
        cmd.define(job.catalog, opts);

      } else if (name == 'dissolve') {
        outputLayers = applyCommandToEachLayer(cmd.dissolve, targetLayers, arcs, opts);

      } else if (name == 'dissolve2') {
        outputLayers = cmd.dissolve2(targetLayers, targetDataset, opts);

      } else if (name == 'divide') {
        cmd.divide(targetLayers, targetDataset, source, opts);

      } else if (name == 'dots') {
        outputLayers = applyCommandToEachLayer(cmd.dots, targetLayers, arcs, opts);

      } else if (name == 'drop') {
        cmd.drop2(job.catalog, targets, opts);
        // cmd.drop(catalog, targetLayers, targetDataset, opts);

      } else if (name == 'each') {
        applyCommandToEachLayer(cmd.evaluateEachFeature, targetLayers, targetDataset, opts.expression, opts);

      } else if (name == 'erase') {
        outputLayers = cmd.eraseLayers(targetLayers, source, targetDataset, opts);

      } else if (name == 'explode') {
        outputLayers = applyCommandToEachLayer(cmd.explodeFeatures, targetLayers, arcs, opts);

      // -require now incorporates functionality of -external
      // } else if (name == 'external') {
      //   cmd.require(targets, opts);

      } else if (name == 'filter') {
        outputLayers = applyCommandToEachLayer(cmd.filterFeatures, targetLayers, arcs, opts);

      } else if (name == 'filter-fields') {
        applyCommandToEachLayer(cmd.filterFields, targetLayers, opts.fields, opts);

      } else if (name == 'filter-geom') {
        applyCommandToEachLayer(cmd.filterGeom, targetLayers, arcs, opts);

      } else if (name == 'filter-islands') {
        applyCommandToEachLayer(cmd.filterIslands, targetLayers, targetDataset, opts);

      } else if (name == 'filter-islands2') {
        applyCommandToEachLayer(cmd.filterIslands2, targetLayers, targetDataset, opts);

      } else if (name == 'filter-points') {
        applyCommandToEachLayer(cmd.filterPoints, targetLayers, targetDataset, opts);

      } else if (name == 'filter-slivers') {
        applyCommandToEachLayer(cmd.filterSlivers, targetLayers, targetDataset, opts);

      } else if (name == 'frame') {
        cmd.frame(job.catalog, targets, opts);

      } else if (name == 'fuzzy-join') {
        applyCommandToEachLayer(cmd.fuzzyJoin, targetLayers, arcs, source, opts);

      } else if (name == 'graticule') {
        job.catalog.addDataset(cmd.graticule(targetDataset, opts));

      } else if (name == 'grid') {
        outputDataset = cmd.polygonGrid(targetLayers, targetDataset, opts);

      } else if (name == 'grid2') {
        outputDataset = cmd.polygonGrid2(targetLayers, targetDataset, opts);

      } else if (name == 'help') {
        // placing help command here to handle errors from invalid command names
        cmd.printHelp(command.options);

      } else if (name == 'i') {
        if (opts.replace) job.catalog = new Catalog(); // is this what we want?
        targetDataset = await cmd.importFiles(job.catalog, command.options);
        if (targetDataset) {
          outputLayers = targetDataset.layers; // kludge to allow layer naming below
        }

      } else if (name == 'if' || name == 'elif') {
        // target = findSingleTargetLayer(opts.layer, targets[0], catalog);
        // cmd[name](target.layer, target.dataset, opts);
        cmd[name](job, opts);

      } else if (name == 'else' || name == 'endif') {
        cmd[name](job);

      } else if (name == 'ignore') {
        applyCommandToEachLayer(cmd.ignore, targetLayers, targetDataset, opts);

      } else if (name == 'include') {
        cmd.include(opts);

      } else if (name == 'info') {
        outputDataset = cmd.info(targets, opts);

      } else if (name == 'inlay') {
        outputLayers = cmd.inlay(targetLayers, source, targetDataset, opts);

      } else if (name == 'inspect') {
        applyCommandToEachLayer(cmd.inspect, targetLayers, arcs, opts);

      } else if (name == 'innerlines') {
        outputLayers = applyCommandToEachLayer(cmd.innerlines, targetLayers, arcs, opts);

      } else if (name == 'join') {
        applyCommandToEachLayer(cmd.join, targetLayers, targetDataset, source, opts);

      } else if (name == 'lines') {
        outputLayers = applyCommandToEachLayer(cmd.lines, targetLayers, targetDataset, opts);

      } else if (name == 'merge-layers') {
        // returned layers are modified input layers
        // (assumes that targetLayers are replaced by outputLayers below)
        outputLayers = cmd.mergeAndFlattenLayers(targetLayers, targetDataset, opts);
        // outputLayers = cmd.mergeLayers(targetLayers, opts);

      } else if (name == 'mosaic') {
        // opts.no_replace = true; // add mosaic as a new layer
        outputLayers = cmd.mosaic(targetLayers, targetDataset, opts);

      } else if (name == 'o') {
        // kludge
        outputFiles = await exportTargetLayers(job.catalog, targets, opts);
        if (opts.final) {
          // don't propagate data if output is final
          //// catalog = null;
          job.catalog = new Catalog();
        }
        await writeFiles(outputFiles, opts);

      } else if (name == 'point-grid') {
        outputLayers = [cmd.pointGrid(targetDataset, opts)];
        if (!targetDataset) {
          job.catalog.addDataset({layers: outputLayers});
        }

      } else if (name == 'point-to-grid') {
        outputLayers = cmd.pointToGrid(targetLayers, targetDataset, opts);

      } else if (name == 'points') {
        outputLayers = applyCommandToEachLayer(cmd.createPointLayer, targetLayers, targetDataset, opts);

      } else if (name == 'polygons') {
        outputLayers = cmd.polygons(targetLayers, targetDataset, opts);

      } else if (name == 'print') {
        cmd.print(command._.join(' '));

      } else if (name == 'proj') {
        await initProjLibrary(opts);
        job.resumeCommand();
        targets.forEach(function(targ) {
          cmd.proj(targ.dataset, job.catalog, opts);
        });

      } else if (name == 'rectangle') {
        if (source || opts.bbox || targets.length === 0) {
          job.catalog.addDataset(cmd.rectangle(source || targets?.[0], opts));
        } else {
          outputLayers = cmd.rectangle2(targets[0], opts);
        }

      } else if (name == 'rectangles') {
        outputLayers = applyCommandToEachLayer(cmd.rectangles, targetLayers, targetDataset, opts);

      } else if (name == 'rename-fields') {
        applyCommandToEachLayer(cmd.renameFields, targetLayers, opts.fields);

      } else if (name == 'rename-layers') {
        cmd.renameLayers(targetLayers, opts.names, job.catalog);

      } else if (name == 'require') {
        await cmd.require(opts);

      } else if (name == 'rotate') {
        targets.forEach(function(targ) {
          cmd.rotate(targ.dataset, opts);
        });

      } else if (name == 'run') {
        await cmd.run(job, targets, opts);

      } else if (name == 'scalebar') {
        cmd.scalebar(job.catalog, opts);

      } else if (name == 'shape') {
        job.catalog.addDataset(cmd.shape(targetDataset, opts));

      } else if (name == 'shapes') {
        outputLayers = applyCommandToEachLayer(cmd.shapes, targetLayers, targetDataset, opts);

      } else if (name == 'simplify') {
        if (opts.variable) {
          cmd.variableSimplify(targetLayers, targetDataset, opts);
        } else {
          cmd.simplify(targetDataset, opts);
        }

      } else if (name == 'slice') {
        outputLayers = cmd.sliceLayers(targetLayers, source, targetDataset, opts);

      } else if (name == 'snap') {
        // cmd.snap(targetDataset, opts);
        applyCommandToEachTarget(cmd.snap, targets, opts);

      } else if (name == 'sort') {
        applyCommandToEachLayer(cmd.sortFeatures, targetLayers, arcs, opts);

      } else if (name == 'split') {
        outputLayers = applyCommandToEachLayer(cmd.splitLayer, targetLayers, opts.expression, opts);

      } else if (name == 'stop') {
        cmd.stop(job);

      } else if (name == 'split-on-grid') {
        outputLayers = applyCommandToEachLayer(cmd.splitLayerOnGrid, targetLayers, arcs, opts);

      } else if (name == 'stitch') {
        cmd.stitch(targetDataset);

      } else if (name == 'style') {
        applyCommandToEachLayer(cmd.svgStyle, targetLayers, targetDataset, opts);

      } else if (name == 'symbols') {
        outputLayers = applyCommandToEachLayer(cmd.symbols, targetLayers, targetDataset, opts);

      } else if (name == 'subdivide') {
        outputLayers = applyCommandToEachLayer(cmd.subdivideLayer, targetLayers, arcs, opts.expression);

      } else if (name == 'target') {
        cmd.target(job.catalog, opts);

      } else if (name == 'union') {
        outputLayers = cmd.union(targetLayers, targetDataset, opts);

      } else if (name == 'uniq') {
        applyCommandToEachLayer(cmd.uniq, targetLayers, arcs, opts);

      } else {
        // throws error if command is not registered
        cmd.runExternalCommand(command, job.catalog);
      }

      // apply name parameter
      if (('name' in opts) && outputLayers) {
        // TODO: consider uniqifying multiple layers here
        outputLayers.forEach(function(lyr) {
          lyr.name = opts.name;
        });
      }

      if (outputDataset) {
        job.catalog.addDataset(outputDataset); // also sets default target
        outputLayers = outputDataset.layers;
        if (targetLayers && !opts.no_replace) {
          // remove target layers from target dataset
          targetLayers.forEach(function(lyr) {
            job.catalog.deleteLayer(lyr, targetDataset);
          });
        }
      } else if (outputLayers && targetDataset && outputLayers != targetDataset.layers) {
        // integrate output layers into the target dataset
        if (opts.no_replace) {
          // make sure commands do not return input layers with 'no_replace' option
          if (!outputLayersAreDifferent(outputLayers, targetLayers || [])) {
            error('Command returned invalid output');
          }

          targetDataset.layers = targetDataset.layers.concat(outputLayers);
        } else {
          // TODO: consider replacing old layers as they are generated, for gc
          replaceLayers(targetDataset, targetLayers, outputLayers);
          // some operations leave unreferenced arcs that should be cleaned up
          if ((name == 'clip' || name == 'erase' || name == 'rectangle' ||
              name == 'rectangles' || name == 'filter' && opts.cleanup) && !opts.no_cleanup) {
            dissolveArcs(targetDataset);
          }
        }

        if (opts.apart) {
          job.catalog.setDefaultTargets(splitApartLayers( targetDataset, outputLayers).map(function(dataset) {
            return {
              dataset: dataset,
              layers: dataset.layers.concat()
            };
          }));
        } else {
          // use command output as new default target
          job.catalog.setDefaultTarget(outputLayers, targetDataset);
        }
      }

      // delete arcs if no longer needed (e.g. after -points command)
      // (after output layers have been integrated)
      // TODO: be more selective (e.g. -i command doesn't need cleanup)
      //   or: detect if arcs have been changed
      if (targetDataset) {
        cleanupArcs(targetDataset);
      }

    } catch(e) {
      return done(e);
    }

    // non-erroring synchronous commands are done
    return done(null);

    function done(err) {
      job.endCommand();
      verbose('-', T$1.stop());
      if (err) throw err;
      return job;
    }
  }

  function outputLayersAreDifferent(output, input) {
    return !utils.some(input, function(lyr) {
      return output.indexOf(lyr) > -1;
    });
  }

  var version = "0.6.102";

  // Parse command line args into commands and run them
  // Function takes an optional Node-style callback. A Promise is returned if no callback is given.
  //   function(argv[, input], callback)
  //   function(argv[, input]) (returns Promise)
  // argv: String or array containing command line args.
  // input: (optional) Object containing file contents indexed by filename
  //
  function runCommands(argv) {
    var opts = importRunArgs.apply(null, arguments);
    _runCommands(argv, opts, function(err) {
      opts.callback(err);
    });
    if (opts.promise) return opts.promise;
  }

  // Similar to runCommands(), but returns output files to the callback or Promise
  //   instead of using file I/O.
  // Callback signature: function(<error>, <data>) -- data is an object
  //   containing output from any -o commands, indexed by filename.
  //
  function applyCommands(argv) {
    var opts = importRunArgs.apply(null, arguments);
    var callback = opts.callback;
    var outputArr = opts.output = []; // output gets added to this array
    _runCommands(argv, opts, function(err) {
      if (err) {
        return callback(err);
      }
      if (opts.legacy) return callback(null, toLegacyOutputFormat(outputArr));
      return callback(null, toOutputFormat(outputArr));
    });
    if (opts.promise) return opts.promise;
  }

  // Run commands with extra heap memory
  //   function(argv[, options], callback)
  //   function(argv[, options]) (returns Promise)
  // options: (optional) object with "xl" property, e.g. {xl: "16gb"}
  //
  function runCommandsXL(argv) {
    var opts = importRunArgs.apply(null, arguments);
    var mapshaperScript = require$1('path').join(__dirname, 'bin/mapshaper');
    var gb = parseFloat(opts.options.xl) || 8;
    var err;
    if (gb < 1 || gb > 64) {
      err = new Error('Unsupported heap size:' + gb + 'GB');
      printError(err);
      opts.callback(err);
      return opts.promise; // may be undefined
    }
    if (!loggingEnabled()) argv += ' -quiet'; // kludge to pass logging setting to subprocess
    var mb = Math.round(gb * 1000);
    var command = [process.execPath, '--max-old-space-size=' + mb, mapshaperScript, argv].join(' ');
    var child = require$1('child_process').exec(command, {}, function(err, stdout, stderr) {
      opts.callback(err);
    });
    child.stdout.pipe(process.stdout);
    child.stderr.pipe(process.stderr);
    if (opts.promise) return opts.promise;
  }

  // Parse the arguments from runCommands() or applyCommands()
  function importRunArgs(arg0, arg1, arg2) {
    var opts = {options: {}};
    if (utils.isFunction(arg1)) {
      opts.callback = arg1;
    } else if (utils.isFunction(arg2)) {
      opts.callback = arg2;
      // identify legacy input format (used by some tests)
      opts.legacy = arg1 && guessInputContentType(arg1) != null;
      opts.input = arg1;
    } else {
      // if no callback, create a promise and a callback for resolving the promise
      opts.promise = new Promise(function(resolve, reject) {
        opts.callback = function(err, data) {
          if (err) reject(err);
          else resolve(data);
        };
      });
    }
    if (!opts.legacy && utils.isObject(arg1)) {
      if (arg1.xl) {
        // options for runCommandsXL()
        opts.options = arg1;
      } else {
        // input data for runCommands() and applyCommands()
        opts.input = arg1;
      }
    }
    return opts;
  }

  // Return an object containing content of zero or more output files, indexed by filename.
  function toOutputFormat(arr) {
    return arr.reduce(function(memo, o) {
      memo[o.filename] = o.content;
      return memo;
    }, {});
  }

  // Unified function for processing calls to runCommands() and applyCommands()
  function _runCommands(argv, opts, callback) {
    var outputArr = opts.output || null,
        inputObj = opts.input,
        commands;
    try {
      commands = parseCommands(argv);

    } catch(e) {
      printError(e);
      return callback(e);
    }

    if (opts.legacy) {
      message("Warning: deprecated input format");
      commands = convertLegacyCommands(commands, inputObj);
      inputObj = null;
    }

    if (commands.length === 0) {
      return callback(new UserError("No commands to run"));
    }

    commands = runAndRemoveInfoCommands(commands);
    if (commands.length === 0) return done(null);

    // add options to -i -o -join -clip -erase etc. commands to bypass file i/o
    // TODO: find a less kludgy solution
    commands.forEach(function(cmd) {
      if (commandTakesFileInput(cmd.name) && inputObj) {
        cmd.options.input = inputObj;
      }
      if (outputArr && (cmd.name == 'o' || cmd.name == 'info' && cmd.options.save_to)) {
        cmd.options.output = outputArr;
      }
    });

    var lastCmd = commands[commands.length - 1];
    if (!runningInBrowser() && lastCmd.name == 'o') {
      // in CLI, set 'final' flag on final -o command, so the export function knows
      // that it can modify the output dataset in-place instead of making a copy.
      lastCmd.options.final = true;
    }

    var batches = divideImportCommand(commands);
    utils.reduceAsync(batches, null, nextGroup, done);

    function nextGroup(prevJob, commands, next) {
      runParsedCommands(commands, new Job(), function(err, job) {
        err = handleNonFatalError(err);
        next(err, job);
      });
    }

    function done(err, job) {
      if (job && inControlBlock(job)) {
        message('Warning: -if command is missing a matching -endif');
      }
      err = handleNonFatalError(err);
      if (err) printError(err);
      callback(err, job);
    }
  }


  function toLegacyOutputFormat(arr) {
    if (arr.length > 1) {
      // Return an array if multiple files are output
      return utils.pluck(arr, 'content');
    }
    if (arr.length == 1) {
      // Return content if a single file is output
      return arr[0].content;
    }
    return null;
  }

  function convertLegacyCommands(arr, inputObj) {
    var i = utils.find(arr, function(cmd) {return cmd.name == 'i';});
    var o = utils.find(arr, function(cmd) {return cmd.name == 'o';});
    if (!i) {
      i = {name: 'i', options: {}};
      arr.unshift(i);
    }
    i.options.files = ['__input__'];
    i.options.input = {__input__: inputObj};
    if (!o) {
      arr.push({name: 'o', options: {}});
    }
    return arr;
  }

  // TODO: rewrite tests and remove this function
  function testCommands(argv, done) {
    _runCommands(argv, {}, function(err, job) {
      var targets = job ? job.catalog.getDefaultTargets() : [];
      var output;
      if (!err && targets.length > 0) {
        // returns dataset for compatibility with some older tests
        output = targets[0].dataset;
      }
      done(err, output);
    });
  }


  // Execute a sequence of parsed commands
  // @commands Array of parsed commands
  // @job: Job object containing previously imported data
  // @done: function([error], [job])
  //
  function runParsedCommands(commands, job, done) {
    if (!job) job = new Job();
    commands = readAndRemoveSettings(job, commands);
    if (!runningInBrowser()) {
      printStartupMessages();
    }
    commands = runAndRemoveInfoCommands(commands);
    if (commands.length === 0) {
      return done(null);
    }
    // we're no longer using the same Job for all batches -- no reset needed
    // // resetting closes any unterminated -if blocks from a previous command sequence
    // resetControlFlow(job);
    utils.reduceAsync(commands, job, nextCommand, done);

    function nextCommand(job, cmd, next) {
      runCommand(cmd, job).then(function(result) {
        next(null, result);
      }).catch(function(e) {
        next(e);
      });
    }
  }

  function handleNonFatalError(err) {
    if (err && err.name == 'NonFatalError') {
      printError(err);
      return null;
    }
    return err;
  }

  // If an initial import command indicates that several input files should be
  //   processed separately, then duplicate the sequence of commands to run
  //   once for each input file
  // @commands Array of parsed commands
  // Returns: Array of one or more sequences of parsed commands
  //
  function divideImportCommand(commands) {
    var firstCmd = commands[0],
        opts = firstCmd.options;

    if (firstCmd.name != 'i' || opts.stdin || opts.merge_files ||
      opts.combine_files || !opts.files || opts.files.length < 2) {
      return [commands];
    }

    return opts.files.map(function(file) {
      var group = [{
        name: 'i',
        options: utils.defaults({
          files:[file],
          replace: true  // kludge to replace data catalog
        }, opts)
      }];
      group.push.apply(group, commands.slice(1));
      return group;
    });
  }


  function printStartupMessages() {
    // print heap memory message if running with a custom amount
    var rxp = /^--max-old-space-size=([0-9]+)$/;
    var arg = process.execArgv.find(function(s) {
      return rxp.test(s);
    });
    if (arg) {
      message('Allocating', rxp.exec(arg)[1] / 1000, 'GB of heap memory');
    }
  }

  // Some settings use command syntax and are parsed as commands.
  function readAndRemoveSettings(job, commands) {
    var settings = {VERBOSE: false, QUIET: false, DEBUG: false};
    var filtered = commands.filter(function(cmd) {
      if (cmd.name == 'verbose') {
        settings.VERBOSE = true;
      } else if (cmd.name == 'quiet') {
        settings.QUIET = true;
      } else if (cmd.name == 'debug') {
        settings.DEBUG = true;
      } else {
        return true;
      }
      return false;
    });
    job.initSettings(settings);
    return filtered;
  }

  // Run informational commands and remove them from the array of parsed commands
  function runAndRemoveInfoCommands(commands) {
    return commands.filter(function(cmd) {
      if (cmd.name == 'version') {
        print(version);
      } else if (cmd.name == 'encodings') {
        printEncodings();
      } else if (cmd.name == 'colors') {
        printColorSchemeNames();
      } else if (cmd.name == 'projections') {
        printProjections();
      } else {
        return true;
      }
      return false;
    });
  }

  var RunCommands = /*#__PURE__*/Object.freeze({
    __proto__: null,
    runCommands: runCommands,
    applyCommands: applyCommands,
    runCommandsXL: runCommandsXL,
    testCommands: testCommands,
    runParsedCommands: runParsedCommands,
    runAndRemoveInfoCommands: runAndRemoveInfoCommands
  });

  // Return an array containing points from a path iterator, clipped to a bounding box
  // Currently using this function for clipping styled polygons in the GUI to speed up layer rendering.
  // Artifacts along the edges make this unsuitable for clipping datasets
  // TODO: support clipping a single-part shape to multiple parts
  // TODO: prevent artifacts along edges
  function clipIterByBounds(iter, bounds) {
    var points = [];
    var bbox = getClippingBBox(bounds);
    var xy, xyp, first, isRing;
    while (iter.hasNext()) {
      xy = [iter.x, iter.y];
      addClippedPoint(points, xyp, xy, bbox);
      xyp = xy;
      if (!first) first = xy;
    }
    // detect closed rings
    isRing = pointsAreEqual(first, xy);
    if (isRing && points.length > 0 && !pointsAreEqual(points[0], points[points.length - 1])) {
      // some rings need to be closed
      points.push(points[0].concat());
    }
    if (isRing && points.length < 4 || points.length < 2) {
      // catch defective rings and polylines
      points = [];
    }
    return points;
  }

  function pointsAreEqual(a, b) {
    return a && b && a[0] === b[0] && a[1] === b[1];
  }

  //  2 3 4
  //  1 8 5
  //  0 7 6
  function getPointSector(x, y, bbox) {
    var bl = bbox[0];
    var tr = bbox[2];
    var i;
    if (x > tr[0]) {
      i = y > tr[1] && 4 || y >= bl[1] && 5 || 6; // right col
    } else if (x >= bl[0]) {
      i = y > tr[1] && 3 || y >= bl[1] && 8 || 7; // middle col
    } else {
      i = y > tr[1] && 2 || y >= bl[1] && 1 || 0; // left col
    }
    return i;
  }

  function isCornerSector(q) {
    return q == 0 || q == 2 || q == 4 || q == 6;
  }

  // Number of CCW turns to normalize
  function getSectorRotation(q) {
    return q > 1 && q < 8 ? Math.floor(q / 2) : 0;
  }

  // i: rotation number
  // b: bbox object
  function rotateClippingBox(i, bbox) {
    var a = bbox[0],
        b = bbox[1],
        c = bbox[2],
        d = bbox[3];
    if (i === 0) {
      bbox = [a, b, c, d];
    } else if (i == 1) {
      bbox = [b, c, d, a];
    } else if (i == 2) {
      bbox = [c, d, a, b];
    } else if (i == 3) {
      bbox = [d, a, b, c];
    } else error('Invalid rotation number');
    return bbox;
  }

  // Convert a Bounds object to an array of 4 points designed to be rotated
  function getClippingBBox(bounds) {
    return [[bounds.xmin, bounds.ymin],
            [bounds.xmin, bounds.ymax],
            [bounds.xmax, bounds.ymax],
            [bounds.xmax, bounds.ymin]];
  }

  // i: ccw turns (0-3)
  function rotateSector(i, q) {
    return q < 8 && q >= 0 ? (q + 8 - i * 2) % 8 : q;
  }

  function getCornerBySector(q, bbox) {
    if (isCornerSector(q)) {
      return bbox[q / 2].concat();
    }
    error('Invalid corner sector:', q);
  }

  function addCornerPoint(points, q, bbox) {
    points.push(getCornerBySector(q, bbox));
  }

  function addClippedPoint(points, p1, p2, bbox) {
    var q1 = p1 ? getPointSector(p1[0], p1[1], bbox) : -1;
    var q2 = getPointSector(p2[0], p2[1], bbox);
    var rot;
    // even polylines need to be connected along bbox edges to prevent artifact
    //   segments cutting through the bbox
    // TODO: convert disconnected parts to individual polylines or rings
    var closed = true;

    if (q1 == 8 && q2 == 8) {
      // segment is fully within box
      points.push(p2);

    } else if (q1 == q2) ; else if (q1 == -1) {
      // p2 is first point in the path
      if (q2 == 8) {
        points.push(p2);
      } else if (isCornerSector(q2)) {
        addCornerPoint(points, q2, bbox);
      }

    } else if (q1 == 8) {
      // segment leaves box
      addSegmentBoundsIntersection(points, p1, p2, bbox);
      if (isCornerSector(q2)) {
        addCornerPoint(points, q2, bbox);
      }

    } else if (q2 == 8) {
      // segment enters box
      addSegmentBoundsIntersection(points, p1, p2, bbox);
      points.push(p2);

    } else {
      // segment travels from one outer sector to another outer sector
      // normalise segment by rotating bbox so that p1 is
      // in the 0 or 1 sector relative to the bbox coordinates, if p1 is in an
      // outer segment
      rot = getSectorRotation(q1);
      bbox = rotateClippingBox(rot, bbox);
      q1 = rotateSector(rot, q1);
      q2 = rotateSector(rot, q2);
      if (q1 == 0) {
        // first point is in a corner sector
        if (q2 === 0 || q2 === 1 || q2 === 7) ; else if (q2 == 2 || q2 == 6) {
          // move to adjacent corner
          addCornerPoint(points, q2, bbox);

        } else if (q2 == 3) {
          // far left edge (intersection or left corner)
          if (!addSegmentBoundsIntersection(points, p1, p2, bbox) && closed) addCornerPoint(points, 2, bbox);

        } else if (q2 == 4) {
          // opposite corner
          if (!addSegmentBoundsIntersection(points, p1, p2, bbox)) {
            // determine if bbox is to the left or right of segment
            if (geom.orient2D(p1[0], p1[1], p2[0], p2[1], bbox[0][0], bbox[0][1]) > 1) {
              // bbox is on the left (seg -> nearest corner is CCW)
              addCornerPoint(points, 6, bbox);
            } else {
              // bbox is on the right
              addCornerPoint(points, 2, bbox);
            }
          }
          addCornerPoint(points, q2, bbox);

        } else if (q2 == 5) {
          // far right edge (intersection or right corner)
          if (!addSegmentBoundsIntersection(points, p1, p2, bbox) && closed) addCornerPoint(points, 6, bbox);
        }

      } else if (q1 == 1) {
        // first point is in a side sector
        if (q2 == 2 || q2 === 0) {
          // near left corner, near right corner
          addCornerPoint(points, q2, bbox);

        } else if (q2 == 3) {
          // to left side
          if (!addSegmentBoundsIntersection(points, p1, p2, bbox) && closed) addCornerPoint(points, 2, bbox);

        } else if (q2 == 4) {
          // to far left corner
          if (!addSegmentBoundsIntersection(points, p1, p2, bbox) && closed) addCornerPoint(points, 2, bbox);
          addCornerPoint(points, 4, bbox);

        } else if (q2 == 5) {
          // to opposite side
          addSegmentBoundsIntersection(points, p1, p2, bbox);

        } else if (q2 == 6) {
          // to far right corner
          if (!addSegmentBoundsIntersection(points, p1, p2, bbox) && closed) addCornerPoint(points, 0, bbox);
          addCornerPoint(points, 6, bbox);

        } else if (q2 == 7) {
          // to right side
          if (!addSegmentBoundsIntersection(points, p1, p2, bbox) && closed) addCornerPoint(points, 0, bbox);
        }

      } else {
        error("Sector error");
      }
    }
  }

  function addSegmentSegmentIntersection(points, a, b, c, d) {
    var p = geom.segmentIntersection(a[0], a[1], b[0], b[1], c[0], c[1],
          d[0], d[1]);
    if (p) points.push(p);
  }

  function addSegmentBoundsIntersection(points, a, b, bounds) {
    var hits = [];
    addSegmentSegmentIntersection(hits, a, b, bounds[0], bounds[1]); // first edge
    addSegmentSegmentIntersection(hits, a, b, bounds[0], bounds[3]); // last edge
    addSegmentSegmentIntersection(hits, a, b, bounds[1], bounds[2]);
    addSegmentSegmentIntersection(hits, a, b, bounds[2], bounds[3]);
    if (hits.length > 0 ) {
      points.push.apply(points, hits);
      return true;
    }
    return false;
  }

  // TODO: Need to rethink polygon repair: these function can cause problems
  // when part of a self-intersecting polygon is removed
  //
  function repairPolygonGeometry(layers, dataset, opts) {
    var nodes = addIntersectionCuts(dataset);
    layers.forEach(function(lyr) {
      repairSelfIntersections(lyr, nodes);
    });
    return layers;
  }

  // Remove any small shapes formed by twists in each ring
  // // OOPS, NO // Retain only the part with largest area
  // // this causes problems when a cut-off hole has a matching ring in another polygon
  // TODO: consider cases where cut-off parts should be retained
  //
  function repairSelfIntersections(lyr, nodes) {
    var splitter = getSelfIntersectionSplitter(nodes);

    lyr.shapes = lyr.shapes.map(function(shp, i) {
      return cleanPolygon(shp);
    });

    function cleanPolygon(shp) {
      var cleanedPolygon = [];
      forEachShapePart(shp, function(ids) {
        // TODO: consider returning null if path can't be split
        var splitIds = splitter(ids);
        if (splitIds.length === 0) {
          error("[cleanPolygon()] Defective path:", ids);
        } else if (splitIds.length == 1) {
          cleanedPolygon.push(splitIds[0]);
        } else {
          var shapeArea = geom.getPlanarPathArea(ids, nodes.arcs),
              sign = shapeArea > 0 ? 1 : -1,
              mainRing;

          splitIds.reduce(function(max, ringIds, i) {
            var pathArea = geom.getPlanarPathArea(ringIds, nodes.arcs) * sign;
            if (pathArea > max) {
              mainRing = ringIds;
              max = pathArea;
            }
            return max;
          }, 0);

          if (mainRing) {
            cleanedPolygon.push(mainRing);
          }
        }
      });
      return cleanedPolygon.length > 0 ? cleanedPolygon : null;
    }
  }

  var PolygonRepair = /*#__PURE__*/Object.freeze({
    __proto__: null,
    repairPolygonGeometry: repairPolygonGeometry,
    repairSelfIntersections: repairSelfIntersections
  });

  // Attach functions exported by modules to the "internal" object,
  // so they can be run by tests and by the GUI.
  // TODO: rewrite tests to import functions directly from modules,
  //       export only functions called by the GUI.
  var internal = {};

  internal.svg = Object.assign({}, SvgStringify, SvgPathUtils, GeojsonToSvg, SvgLabels, SvgSymbols);

  // Assign functions and objects exported from modules to the 'internal' namespace
  // to maintain compatibility with tests and to expose (some of) them to the GUI.

  Object.assign(internal, {
    Job,
    Dbf,
    DbfReader,
    DouglasPeucker,
    parseGeoJSON,
    geojson: GeoJSON,
    json: { parse: parseJSON },
    ShpType,
    topojson: TopoJSON,
    Visvalingam,
    ArcCollection,
    Bounds,
    clipIterByBounds,
    CommandParser,
    DataTable,
    editArcs,
    Heap,
    IdLookupIndex,
    NodeCollection,
    parseDMS,
    formatDMS,
    PathIndex,
    PolygonIndex,
    ShpReader,
    Transform
  });

  Object.assign(internal,
    AnchorPoints,
    ArcClassifier,
    ArcDissolve,
    ArcUtils,
    Bbox2Clipping,
    BinArray$1,
    BufferCommon,
    Calc,
    CalcUtils,
    Catalog$1,
    ClipErase,
    ClipPoints,
    Colorizer,
    CustomProjections,
    DataAggregation,
    DatasetUtils,
    DataUtils,
    DbfImport,
    DelimExport,
    DelimImport,
    DelimReader,
    EncodingDetection,
    Encodings,
    Explode,
    Export,
    Expressions,
    FeatureExpressions,
    FileExport,
    FileImport,
    FilenameUtils,
    FileReader$1,
    FileTypes,
    FilterGeom,
    Frame,
    FrameUtils,
    Furniture,
    Geodesic,
    GeojsonExport,
    GeojsonImport,
    Gzip,
    Import,
    Info,
    IntersectionCuts,
    Join,
    JoinCalc,
    JoinFilter,
    JoinTables,
    JsonImport,
    JsonTable,
    KeepShapes,
    LatLon,
    LayerUtils,
    Lines,
    Logging,
    Merging,
    MosaicIndex$1,
    OptionParsingUtils,
    OutputFormat,
    OverlayUtils,
    Pack, Unpack,
    ParseCommands,
    PathBuffer,
    PathEndpoints,
    PathExport,
    Pathfinder,
    PathfinderUtils,
    PathImport,
    PathRepair,
    PathUtils,
    // PixelTransform,
    PointPolygonJoin,
    Points,
    PointToGrid,
    PointUtils,
    PolygonDissolve,
    PolygonDissolve2,
    PolygonHoles,
    PolygonMosaic,
    PolygonNeighbors,
    PolygonRepair,
    PolygonTiler$1,
    PolylineClipping,
    PostSimplifyRepair,
    Proj,
    Projections,
    ProjectionParams,
    Rectangle,
    RectangleUtils,
    Rounding,
    RunCommands,
    Scalebar,
    SegmentGeom,
    SegmentIntersection,
    ShapeIter$1,
    ShapeUtils,
    ShpCommon,
    ShpExport,
    ShpImport,
    Simplify,
    SimplifyFast,
    SimplifyPct,
    Slivers,
    Snapping,
    SourceUtils,
    Split,
    Env,
    Stash,
    Stringify,
    Svg,
    SvgProperties,
    Symbols,
    TargetUtils,
    TopojsonExport,
    TopojsonImport,
    Topology,
    Units,
    SvgHatch,
    SvgEffect,
    VertexUtils,
    Zip
  );

  // the mapshaper public api only has 4 functions
  var api = {
    runCommands,
    applyCommands,
    runCommandsXL,
    enableLogging
  };

  // Add some namespaces, for easier testability and
  // to expose internal functions to the web UI
  Object.assign(api, {
    cli, cmd, geom, utils, internal,
  });

  // The entry point for the core mapshaper module

  if (typeof module === "object" && module.exports) {
    module.exports = api;
  } else if (typeof window === "object" && window) {
    window.mapshaper = api;
  }

})();
